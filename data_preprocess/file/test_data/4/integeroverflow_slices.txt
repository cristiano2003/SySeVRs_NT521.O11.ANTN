1 /home/speedy/test/source2slice/NVD/CVE-2015-0811_VULN_read_tag_lutType.c lut -> output_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , output_offset + i * entry_size ) ) 95
static struct lutType *read_tag_lutType(struct mem_source *src, struct tag_index index, uint32_t tag_id) 1
struct tag * tag = find_tag ( index , tag_id ) ; 3
uint32_t offset = tag -> offset ; 4
uint32_t type = read_u32 ( src , offset ) ; 5
uint16_t num_input_table_entries ; 6
uint16_t num_output_table_entries ; 7
uint8_t in_chan , grid_points , out_chan ; 8
uint32_t clut_offset , output_offset ; 9
uint32_t clut_size ; 10
size_t entry_size ; 11
struct lutType * lut ; 12
uint32_t i ; 13
if ( type == LUT8_TYPE )  17
num_input_table_entries = 256; 18
num_output_table_entries = 256; 19
entry_size = 1; 20
if ( type == LUT16_TYPE )  21
num_input_table_entries = read_u16 ( src , offset + 48 ); 22
num_output_table_entries = read_u16 ( src , offset + 50 ); 23
entry_size = 2; 24
in_chan = read_u8 ( src , offset + 8 ); 31
out_chan = read_u8 ( src , offset + 9 ); 32
grid_points = read_u8 ( src , offset + 10 ); 33
clut_size = pow ( grid_points , in_chan ); 35
if ( clut_size > MAX_CLUT_SIZE )  36
if ( in_chan != 3 || out_chan != 3 )  40
lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ); 44
if ( ! lut )  45
lut -> input_table = & lut -> table_data [ 0 ]; 50
lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ]; 51
lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ]; 52
lut -> num_input_table_entries = num_input_table_entries; 54
lut -> num_output_table_entries = num_output_table_entries; 55
lut -> num_input_channels = read_u8 ( src , offset + 8 ); 56
lut -> num_output_channels = read_u8 ( src , offset + 9 ); 57
lut -> num_clut_grid_points = read_u8 ( src , offset + 10 ); 58
lut -> e00 = read_s15Fixed16Number ( src , offset + 12 ); 59
lut -> e01 = read_s15Fixed16Number ( src , offset + 16 ); 60
lut -> e02 = read_s15Fixed16Number ( src , offset + 20 ); 61
lut -> e10 = read_s15Fixed16Number ( src , offset + 24 ); 62
lut -> e11 = read_s15Fixed16Number ( src , offset + 28 ); 63
lut -> e12 = read_s15Fixed16Number ( src , offset + 32 ); 64
lut -> e20 = read_s15Fixed16Number ( src , offset + 36 ); 65
lut -> e21 = read_s15Fixed16Number ( src , offset + 40 ); 66
lut -> e22 = read_s15Fixed16Number ( src , offset + 44 ); 67
for (i = 0; i < lut->num_input_table_entries * in_chan; i++) 69
if ( type == LUT8_TYPE )  70
lut -> input_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , offset + 52 + i * entry_size ) ); 73
clut_offset = offset + 52 + lut -> num_input_table_entries * in_chan * entry_size; 77
for (i = 0; i < clut_size * out_chan; i+=3) 78
if ( type == LUT8_TYPE )  79
lut -> clut_table [ i + 0 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 0 ) ); 84
lut -> clut_table [ i + 1 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 2 ) ); 85
lut -> clut_table [ i + 2 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 4 ) ); 86
output_offset = clut_offset + clut_size * out_chan * entry_size; 90
for (i = 0; i < lut->num_output_table_entries * out_chan; i++) 91
if ( type == LUT8_TYPE )  92
lut -> output_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , output_offset + i * entry_size ) ); 95
return lut ; 99
------------------------------
2 /home/speedy/test/source2slice/NVD/CVE-2015-0811_VULN_read_tag_lutType.c lut -> output_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , output_offset + i * entry_size ) ) 93
static struct lutType *read_tag_lutType(struct mem_source *src, struct tag_index index, uint32_t tag_id) 1
struct tag * tag = find_tag ( index , tag_id ) ; 3
uint32_t offset = tag -> offset ; 4
uint32_t type = read_u32 ( src , offset ) ; 5
uint16_t num_input_table_entries ; 6
uint16_t num_output_table_entries ; 7
uint8_t in_chan , grid_points , out_chan ; 8
uint32_t clut_offset , output_offset ; 9
uint32_t clut_size ; 10
size_t entry_size ; 11
struct lutType * lut ; 12
uint32_t i ; 13
if ( type == LUT8_TYPE )  17
num_input_table_entries = 256; 18
num_output_table_entries = 256; 19
entry_size = 1; 20
if ( type == LUT16_TYPE )  21
num_input_table_entries = read_u16 ( src , offset + 48 ); 22
num_output_table_entries = read_u16 ( src , offset + 50 ); 23
entry_size = 2; 24
in_chan = read_u8 ( src , offset + 8 ); 31
out_chan = read_u8 ( src , offset + 9 ); 32
grid_points = read_u8 ( src , offset + 10 ); 33
clut_size = pow ( grid_points , in_chan ); 35
if ( clut_size > MAX_CLUT_SIZE )  36
if ( in_chan != 3 || out_chan != 3 )  40
lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ); 44
if ( ! lut )  45
lut -> input_table = & lut -> table_data [ 0 ]; 50
lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ]; 51
lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ]; 52
lut -> num_input_table_entries = num_input_table_entries; 54
lut -> num_output_table_entries = num_output_table_entries; 55
lut -> num_input_channels = read_u8 ( src , offset + 8 ); 56
lut -> num_output_channels = read_u8 ( src , offset + 9 ); 57
lut -> num_clut_grid_points = read_u8 ( src , offset + 10 ); 58
lut -> e00 = read_s15Fixed16Number ( src , offset + 12 ); 59
lut -> e01 = read_s15Fixed16Number ( src , offset + 16 ); 60
lut -> e02 = read_s15Fixed16Number ( src , offset + 20 ); 61
lut -> e10 = read_s15Fixed16Number ( src , offset + 24 ); 62
lut -> e11 = read_s15Fixed16Number ( src , offset + 28 ); 63
lut -> e12 = read_s15Fixed16Number ( src , offset + 32 ); 64
lut -> e20 = read_s15Fixed16Number ( src , offset + 36 ); 65
lut -> e21 = read_s15Fixed16Number ( src , offset + 40 ); 66
lut -> e22 = read_s15Fixed16Number ( src , offset + 44 ); 67
for (i = 0; i < lut->num_input_table_entries * in_chan; i++) 69
if ( type == LUT8_TYPE )  70
lut -> input_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , offset + 52 + i * entry_size ) ); 73
clut_offset = offset + 52 + lut -> num_input_table_entries * in_chan * entry_size; 77
for (i = 0; i < clut_size * out_chan; i+=3) 78
if ( type == LUT8_TYPE )  79
lut -> clut_table [ i + 0 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 0 ) ); 84
lut -> clut_table [ i + 1 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 2 ) ); 85
lut -> clut_table [ i + 2 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 4 ) ); 86
output_offset = clut_offset + clut_size * out_chan * entry_size; 90
for (i = 0; i < lut->num_output_table_entries * out_chan; i++) 91
if ( type == LUT8_TYPE )  92
lut -> output_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , output_offset + i * entry_size ) ); 93
------------------------------
3 /home/speedy/test/source2slice/NVD/CVE-2015-0811_VULN_read_tag_lutType.c output_offset = clut_offset + clut_size * out_chan * entry_size 90
static struct lutType *read_tag_lutType(struct mem_source *src, struct tag_index index, uint32_t tag_id) 1
struct tag * tag = find_tag ( index , tag_id ) ; 3
uint32_t offset = tag -> offset ; 4
uint32_t type = read_u32 ( src , offset ) ; 5
uint16_t num_input_table_entries ; 6
uint16_t num_output_table_entries ; 7
uint8_t in_chan , grid_points , out_chan ; 8
uint32_t clut_offset , output_offset ; 9
uint32_t clut_size ; 10
size_t entry_size ; 11
struct lutType * lut ; 12
uint32_t i ; 13
if ( type == LUT8_TYPE )  17
num_input_table_entries = 256; 18
num_output_table_entries = 256; 19
entry_size = 1; 20
if ( type == LUT16_TYPE )  21
num_input_table_entries = read_u16 ( src , offset + 48 ); 22
num_output_table_entries = read_u16 ( src , offset + 50 ); 23
entry_size = 2; 24
in_chan = read_u8 ( src , offset + 8 ); 31
out_chan = read_u8 ( src , offset + 9 ); 32
grid_points = read_u8 ( src , offset + 10 ); 33
clut_size = pow ( grid_points , in_chan ); 35
if ( clut_size > MAX_CLUT_SIZE )  36
if ( in_chan != 3 || out_chan != 3 )  40
lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ); 44
if ( ! lut )  45
lut -> input_table = & lut -> table_data [ 0 ]; 50
lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ]; 51
lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ]; 52
lut -> num_input_table_entries = num_input_table_entries; 54
lut -> num_output_table_entries = num_output_table_entries; 55
lut -> num_input_channels = read_u8 ( src , offset + 8 ); 56
lut -> num_output_channels = read_u8 ( src , offset + 9 ); 57
lut -> num_clut_grid_points = read_u8 ( src , offset + 10 ); 58
lut -> e00 = read_s15Fixed16Number ( src , offset + 12 ); 59
lut -> e01 = read_s15Fixed16Number ( src , offset + 16 ); 60
lut -> e02 = read_s15Fixed16Number ( src , offset + 20 ); 61
lut -> e10 = read_s15Fixed16Number ( src , offset + 24 ); 62
lut -> e11 = read_s15Fixed16Number ( src , offset + 28 ); 63
lut -> e12 = read_s15Fixed16Number ( src , offset + 32 ); 64
lut -> e20 = read_s15Fixed16Number ( src , offset + 36 ); 65
lut -> e21 = read_s15Fixed16Number ( src , offset + 40 ); 66
lut -> e22 = read_s15Fixed16Number ( src , offset + 44 ); 67
for (i = 0; i < lut->num_input_table_entries * in_chan; i++) 69
if ( type == LUT8_TYPE )  70
lut -> input_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , offset + 52 + i * entry_size ) ); 73
clut_offset = offset + 52 + lut -> num_input_table_entries * in_chan * entry_size; 77
output_offset = clut_offset + clut_size * out_chan * entry_size; 90
lut -> output_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , output_offset + i * entry_size ) ); 93
lut -> output_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , output_offset + i * entry_size ) ); 95
return lut ; 99
------------------------------
4 /home/speedy/test/source2slice/NVD/CVE-2015-0811_VULN_read_tag_lutType.c lut -> clut_table [ i + 2 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 4 ) ) 86
static struct lutType *read_tag_lutType(struct mem_source *src, struct tag_index index, uint32_t tag_id) 1
struct tag * tag = find_tag ( index , tag_id ) ; 3
uint32_t offset = tag -> offset ; 4
uint32_t type = read_u32 ( src , offset ) ; 5
uint16_t num_input_table_entries ; 6
uint16_t num_output_table_entries ; 7
uint8_t in_chan , grid_points , out_chan ; 8
uint32_t clut_offset , output_offset ; 9
uint32_t clut_size ; 10
size_t entry_size ; 11
struct lutType * lut ; 12
uint32_t i ; 13
if ( type == LUT8_TYPE )  17
num_input_table_entries = 256; 18
num_output_table_entries = 256; 19
entry_size = 1; 20
if ( type == LUT16_TYPE )  21
num_input_table_entries = read_u16 ( src , offset + 48 ); 22
num_output_table_entries = read_u16 ( src , offset + 50 ); 23
entry_size = 2; 24
in_chan = read_u8 ( src , offset + 8 ); 31
out_chan = read_u8 ( src , offset + 9 ); 32
grid_points = read_u8 ( src , offset + 10 ); 33
clut_size = pow ( grid_points , in_chan ); 35
if ( clut_size > MAX_CLUT_SIZE )  36
if ( in_chan != 3 || out_chan != 3 )  40
lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ); 44
if ( ! lut )  45
lut -> input_table = & lut -> table_data [ 0 ]; 50
lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ]; 51
lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ]; 52
lut -> num_input_table_entries = num_input_table_entries; 54
lut -> num_output_table_entries = num_output_table_entries; 55
lut -> num_input_channels = read_u8 ( src , offset + 8 ); 56
lut -> num_output_channels = read_u8 ( src , offset + 9 ); 57
lut -> num_clut_grid_points = read_u8 ( src , offset + 10 ); 58
lut -> e00 = read_s15Fixed16Number ( src , offset + 12 ); 59
lut -> e01 = read_s15Fixed16Number ( src , offset + 16 ); 60
lut -> e02 = read_s15Fixed16Number ( src , offset + 20 ); 61
lut -> e10 = read_s15Fixed16Number ( src , offset + 24 ); 62
lut -> e11 = read_s15Fixed16Number ( src , offset + 28 ); 63
lut -> e12 = read_s15Fixed16Number ( src , offset + 32 ); 64
lut -> e20 = read_s15Fixed16Number ( src , offset + 36 ); 65
lut -> e21 = read_s15Fixed16Number ( src , offset + 40 ); 66
lut -> e22 = read_s15Fixed16Number ( src , offset + 44 ); 67
for (i = 0; i < lut->num_input_table_entries * in_chan; i++) 69
if ( type == LUT8_TYPE )  70
lut -> input_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , offset + 52 + i * entry_size ) ); 73
clut_offset = offset + 52 + lut -> num_input_table_entries * in_chan * entry_size; 77
for (i = 0; i < clut_size * out_chan; i+=3) 78
if ( type == LUT8_TYPE )  79
lut -> clut_table [ i + 0 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 0 ) ); 84
lut -> clut_table [ i + 1 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 2 ) ); 85
lut -> clut_table [ i + 2 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 4 ) ); 86
for (i = 0; i < lut->num_output_table_entries * out_chan; i++) 91
lut -> output_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , output_offset + i * entry_size ) ); 93
lut -> output_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , output_offset + i * entry_size ) ); 95
return lut ; 99
------------------------------
5 /home/speedy/test/source2slice/NVD/CVE-2015-0811_VULN_read_tag_lutType.c lut -> clut_table [ i + 1 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 2 ) ) 85
static struct lutType *read_tag_lutType(struct mem_source *src, struct tag_index index, uint32_t tag_id) 1
struct tag * tag = find_tag ( index , tag_id ) ; 3
uint32_t offset = tag -> offset ; 4
uint32_t type = read_u32 ( src , offset ) ; 5
uint16_t num_input_table_entries ; 6
uint16_t num_output_table_entries ; 7
uint8_t in_chan , grid_points , out_chan ; 8
uint32_t clut_offset , output_offset ; 9
uint32_t clut_size ; 10
size_t entry_size ; 11
struct lutType * lut ; 12
uint32_t i ; 13
if ( type == LUT8_TYPE )  17
num_input_table_entries = 256; 18
num_output_table_entries = 256; 19
entry_size = 1; 20
if ( type == LUT16_TYPE )  21
num_input_table_entries = read_u16 ( src , offset + 48 ); 22
num_output_table_entries = read_u16 ( src , offset + 50 ); 23
entry_size = 2; 24
in_chan = read_u8 ( src , offset + 8 ); 31
out_chan = read_u8 ( src , offset + 9 ); 32
grid_points = read_u8 ( src , offset + 10 ); 33
clut_size = pow ( grid_points , in_chan ); 35
if ( clut_size > MAX_CLUT_SIZE )  36
if ( in_chan != 3 || out_chan != 3 )  40
lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ); 44
if ( ! lut )  45
lut -> input_table = & lut -> table_data [ 0 ]; 50
lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ]; 51
lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ]; 52
lut -> num_input_table_entries = num_input_table_entries; 54
lut -> num_output_table_entries = num_output_table_entries; 55
lut -> num_input_channels = read_u8 ( src , offset + 8 ); 56
lut -> num_output_channels = read_u8 ( src , offset + 9 ); 57
lut -> num_clut_grid_points = read_u8 ( src , offset + 10 ); 58
lut -> e00 = read_s15Fixed16Number ( src , offset + 12 ); 59
lut -> e01 = read_s15Fixed16Number ( src , offset + 16 ); 60
lut -> e02 = read_s15Fixed16Number ( src , offset + 20 ); 61
lut -> e10 = read_s15Fixed16Number ( src , offset + 24 ); 62
lut -> e11 = read_s15Fixed16Number ( src , offset + 28 ); 63
lut -> e12 = read_s15Fixed16Number ( src , offset + 32 ); 64
lut -> e20 = read_s15Fixed16Number ( src , offset + 36 ); 65
lut -> e21 = read_s15Fixed16Number ( src , offset + 40 ); 66
lut -> e22 = read_s15Fixed16Number ( src , offset + 44 ); 67
for (i = 0; i < lut->num_input_table_entries * in_chan; i++) 69
if ( type == LUT8_TYPE )  70
lut -> input_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , offset + 52 + i * entry_size ) ); 73
clut_offset = offset + 52 + lut -> num_input_table_entries * in_chan * entry_size; 77
for (i = 0; i < clut_size * out_chan; i+=3) 78
if ( type == LUT8_TYPE )  79
lut -> clut_table [ i + 0 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 0 ) ); 84
lut -> clut_table [ i + 1 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 2 ) ); 85
lut -> clut_table [ i + 2 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 4 ) ); 86
for (i = 0; i < lut->num_output_table_entries * out_chan; i++) 91
lut -> output_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , output_offset + i * entry_size ) ); 93
lut -> output_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , output_offset + i * entry_size ) ); 95
return lut ; 99
------------------------------
6 /home/speedy/test/source2slice/NVD/CVE-2015-0811_VULN_read_tag_lutType.c lut -> clut_table [ i + 0 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 0 ) ) 84
static struct lutType *read_tag_lutType(struct mem_source *src, struct tag_index index, uint32_t tag_id) 1
struct tag * tag = find_tag ( index , tag_id ) ; 3
uint32_t offset = tag -> offset ; 4
uint32_t type = read_u32 ( src , offset ) ; 5
uint16_t num_input_table_entries ; 6
uint16_t num_output_table_entries ; 7
uint8_t in_chan , grid_points , out_chan ; 8
uint32_t clut_offset , output_offset ; 9
uint32_t clut_size ; 10
size_t entry_size ; 11
struct lutType * lut ; 12
uint32_t i ; 13
if ( type == LUT8_TYPE )  17
num_input_table_entries = 256; 18
num_output_table_entries = 256; 19
entry_size = 1; 20
if ( type == LUT16_TYPE )  21
num_input_table_entries = read_u16 ( src , offset + 48 ); 22
num_output_table_entries = read_u16 ( src , offset + 50 ); 23
entry_size = 2; 24
in_chan = read_u8 ( src , offset + 8 ); 31
out_chan = read_u8 ( src , offset + 9 ); 32
grid_points = read_u8 ( src , offset + 10 ); 33
clut_size = pow ( grid_points , in_chan ); 35
if ( clut_size > MAX_CLUT_SIZE )  36
if ( in_chan != 3 || out_chan != 3 )  40
lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ); 44
if ( ! lut )  45
lut -> input_table = & lut -> table_data [ 0 ]; 50
lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ]; 51
lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ]; 52
lut -> num_input_table_entries = num_input_table_entries; 54
lut -> num_output_table_entries = num_output_table_entries; 55
lut -> num_input_channels = read_u8 ( src , offset + 8 ); 56
lut -> num_output_channels = read_u8 ( src , offset + 9 ); 57
lut -> num_clut_grid_points = read_u8 ( src , offset + 10 ); 58
lut -> e00 = read_s15Fixed16Number ( src , offset + 12 ); 59
lut -> e01 = read_s15Fixed16Number ( src , offset + 16 ); 60
lut -> e02 = read_s15Fixed16Number ( src , offset + 20 ); 61
lut -> e10 = read_s15Fixed16Number ( src , offset + 24 ); 62
lut -> e11 = read_s15Fixed16Number ( src , offset + 28 ); 63
lut -> e12 = read_s15Fixed16Number ( src , offset + 32 ); 64
lut -> e20 = read_s15Fixed16Number ( src , offset + 36 ); 65
lut -> e21 = read_s15Fixed16Number ( src , offset + 40 ); 66
lut -> e22 = read_s15Fixed16Number ( src , offset + 44 ); 67
for (i = 0; i < lut->num_input_table_entries * in_chan; i++) 69
if ( type == LUT8_TYPE )  70
lut -> input_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , offset + 52 + i * entry_size ) ); 73
clut_offset = offset + 52 + lut -> num_input_table_entries * in_chan * entry_size; 77
for (i = 0; i < clut_size * out_chan; i+=3) 78
if ( type == LUT8_TYPE )  79
lut -> clut_table [ i + 0 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 0 ) ); 84
lut -> clut_table [ i + 1 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 2 ) ); 85
lut -> clut_table [ i + 2 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 4 ) ); 86
for (i = 0; i < lut->num_output_table_entries * out_chan; i++) 91
lut -> output_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , output_offset + i * entry_size ) ); 93
lut -> output_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , output_offset + i * entry_size ) ); 95
return lut ; 99
------------------------------
7 /home/speedy/test/source2slice/NVD/CVE-2015-0811_VULN_read_tag_lutType.c lut -> clut_table [ i + 2 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 2 ) ) 82
static struct lutType *read_tag_lutType(struct mem_source *src, struct tag_index index, uint32_t tag_id) 1
struct tag * tag = find_tag ( index , tag_id ) ; 3
uint32_t offset = tag -> offset ; 4
uint32_t type = read_u32 ( src , offset ) ; 5
uint16_t num_input_table_entries ; 6
uint16_t num_output_table_entries ; 7
uint8_t in_chan , grid_points , out_chan ; 8
uint32_t clut_offset , output_offset ; 9
uint32_t clut_size ; 10
size_t entry_size ; 11
struct lutType * lut ; 12
uint32_t i ; 13
if ( type == LUT8_TYPE )  17
num_input_table_entries = 256; 18
num_output_table_entries = 256; 19
entry_size = 1; 20
if ( type == LUT16_TYPE )  21
num_input_table_entries = read_u16 ( src , offset + 48 ); 22
num_output_table_entries = read_u16 ( src , offset + 50 ); 23
entry_size = 2; 24
in_chan = read_u8 ( src , offset + 8 ); 31
out_chan = read_u8 ( src , offset + 9 ); 32
grid_points = read_u8 ( src , offset + 10 ); 33
clut_size = pow ( grid_points , in_chan ); 35
if ( clut_size > MAX_CLUT_SIZE )  36
if ( in_chan != 3 || out_chan != 3 )  40
lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ); 44
if ( ! lut )  45
lut -> input_table = & lut -> table_data [ 0 ]; 50
lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ]; 51
lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ]; 52
lut -> num_input_table_entries = num_input_table_entries; 54
lut -> num_output_table_entries = num_output_table_entries; 55
lut -> num_input_channels = read_u8 ( src , offset + 8 ); 56
lut -> num_output_channels = read_u8 ( src , offset + 9 ); 57
lut -> num_clut_grid_points = read_u8 ( src , offset + 10 ); 58
lut -> e00 = read_s15Fixed16Number ( src , offset + 12 ); 59
lut -> e01 = read_s15Fixed16Number ( src , offset + 16 ); 60
lut -> e02 = read_s15Fixed16Number ( src , offset + 20 ); 61
lut -> e10 = read_s15Fixed16Number ( src , offset + 24 ); 62
lut -> e11 = read_s15Fixed16Number ( src , offset + 28 ); 63
lut -> e12 = read_s15Fixed16Number ( src , offset + 32 ); 64
lut -> e20 = read_s15Fixed16Number ( src , offset + 36 ); 65
lut -> e21 = read_s15Fixed16Number ( src , offset + 40 ); 66
lut -> e22 = read_s15Fixed16Number ( src , offset + 44 ); 67
for (i = 0; i < lut->num_input_table_entries * in_chan; i++) 69
if ( type == LUT8_TYPE )  70
lut -> input_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , offset + 52 + i * entry_size ) ); 73
clut_offset = offset + 52 + lut -> num_input_table_entries * in_chan * entry_size; 77
for (i = 0; i < clut_size * out_chan; i+=3) 78
if ( type == LUT8_TYPE )  79
lut -> clut_table [ i + 0 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 0 ) ); 80
lut -> clut_table [ i + 1 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 1 ) ); 81
lut -> clut_table [ i + 2 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 2 ) ); 82
------------------------------
8 /home/speedy/test/source2slice/NVD/CVE-2015-0811_VULN_read_tag_lutType.c lut -> clut_table [ i + 1 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 1 ) ) 81
static struct lutType *read_tag_lutType(struct mem_source *src, struct tag_index index, uint32_t tag_id) 1
struct tag * tag = find_tag ( index , tag_id ) ; 3
uint32_t offset = tag -> offset ; 4
uint32_t type = read_u32 ( src , offset ) ; 5
uint16_t num_input_table_entries ; 6
uint16_t num_output_table_entries ; 7
uint8_t in_chan , grid_points , out_chan ; 8
uint32_t clut_offset , output_offset ; 9
uint32_t clut_size ; 10
size_t entry_size ; 11
struct lutType * lut ; 12
uint32_t i ; 13
if ( type == LUT8_TYPE )  17
num_input_table_entries = 256; 18
num_output_table_entries = 256; 19
entry_size = 1; 20
if ( type == LUT16_TYPE )  21
num_input_table_entries = read_u16 ( src , offset + 48 ); 22
num_output_table_entries = read_u16 ( src , offset + 50 ); 23
entry_size = 2; 24
in_chan = read_u8 ( src , offset + 8 ); 31
out_chan = read_u8 ( src , offset + 9 ); 32
grid_points = read_u8 ( src , offset + 10 ); 33
clut_size = pow ( grid_points , in_chan ); 35
if ( clut_size > MAX_CLUT_SIZE )  36
if ( in_chan != 3 || out_chan != 3 )  40
lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ); 44
if ( ! lut )  45
lut -> input_table = & lut -> table_data [ 0 ]; 50
lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ]; 51
lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ]; 52
lut -> num_input_table_entries = num_input_table_entries; 54
lut -> num_output_table_entries = num_output_table_entries; 55
lut -> num_input_channels = read_u8 ( src , offset + 8 ); 56
lut -> num_output_channels = read_u8 ( src , offset + 9 ); 57
lut -> num_clut_grid_points = read_u8 ( src , offset + 10 ); 58
lut -> e00 = read_s15Fixed16Number ( src , offset + 12 ); 59
lut -> e01 = read_s15Fixed16Number ( src , offset + 16 ); 60
lut -> e02 = read_s15Fixed16Number ( src , offset + 20 ); 61
lut -> e10 = read_s15Fixed16Number ( src , offset + 24 ); 62
lut -> e11 = read_s15Fixed16Number ( src , offset + 28 ); 63
lut -> e12 = read_s15Fixed16Number ( src , offset + 32 ); 64
lut -> e20 = read_s15Fixed16Number ( src , offset + 36 ); 65
lut -> e21 = read_s15Fixed16Number ( src , offset + 40 ); 66
lut -> e22 = read_s15Fixed16Number ( src , offset + 44 ); 67
for (i = 0; i < lut->num_input_table_entries * in_chan; i++) 69
if ( type == LUT8_TYPE )  70
lut -> input_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , offset + 52 + i * entry_size ) ); 73
clut_offset = offset + 52 + lut -> num_input_table_entries * in_chan * entry_size; 77
for (i = 0; i < clut_size * out_chan; i+=3) 78
if ( type == LUT8_TYPE )  79
lut -> clut_table [ i + 0 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 0 ) ); 80
lut -> clut_table [ i + 1 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 1 ) ); 81
lut -> clut_table [ i + 2 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 2 ) ); 82
------------------------------
9 /home/speedy/test/source2slice/NVD/CVE-2015-0811_VULN_read_tag_lutType.c lut -> clut_table [ i + 0 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 0 ) ) 80
static struct lutType *read_tag_lutType(struct mem_source *src, struct tag_index index, uint32_t tag_id) 1
struct tag * tag = find_tag ( index , tag_id ) ; 3
uint32_t offset = tag -> offset ; 4
uint32_t type = read_u32 ( src , offset ) ; 5
uint16_t num_input_table_entries ; 6
uint16_t num_output_table_entries ; 7
uint8_t in_chan , grid_points , out_chan ; 8
uint32_t clut_offset , output_offset ; 9
uint32_t clut_size ; 10
size_t entry_size ; 11
struct lutType * lut ; 12
uint32_t i ; 13
if ( type == LUT8_TYPE )  17
num_input_table_entries = 256; 18
num_output_table_entries = 256; 19
entry_size = 1; 20
if ( type == LUT16_TYPE )  21
num_input_table_entries = read_u16 ( src , offset + 48 ); 22
num_output_table_entries = read_u16 ( src , offset + 50 ); 23
entry_size = 2; 24
in_chan = read_u8 ( src , offset + 8 ); 31
out_chan = read_u8 ( src , offset + 9 ); 32
grid_points = read_u8 ( src , offset + 10 ); 33
clut_size = pow ( grid_points , in_chan ); 35
if ( clut_size > MAX_CLUT_SIZE )  36
if ( in_chan != 3 || out_chan != 3 )  40
lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ); 44
if ( ! lut )  45
lut -> input_table = & lut -> table_data [ 0 ]; 50
lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ]; 51
lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ]; 52
lut -> num_input_table_entries = num_input_table_entries; 54
lut -> num_output_table_entries = num_output_table_entries; 55
lut -> num_input_channels = read_u8 ( src , offset + 8 ); 56
lut -> num_output_channels = read_u8 ( src , offset + 9 ); 57
lut -> num_clut_grid_points = read_u8 ( src , offset + 10 ); 58
lut -> e00 = read_s15Fixed16Number ( src , offset + 12 ); 59
lut -> e01 = read_s15Fixed16Number ( src , offset + 16 ); 60
lut -> e02 = read_s15Fixed16Number ( src , offset + 20 ); 61
lut -> e10 = read_s15Fixed16Number ( src , offset + 24 ); 62
lut -> e11 = read_s15Fixed16Number ( src , offset + 28 ); 63
lut -> e12 = read_s15Fixed16Number ( src , offset + 32 ); 64
lut -> e20 = read_s15Fixed16Number ( src , offset + 36 ); 65
lut -> e21 = read_s15Fixed16Number ( src , offset + 40 ); 66
lut -> e22 = read_s15Fixed16Number ( src , offset + 44 ); 67
for (i = 0; i < lut->num_input_table_entries * in_chan; i++) 69
if ( type == LUT8_TYPE )  70
lut -> input_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , offset + 52 + i * entry_size ) ); 73
clut_offset = offset + 52 + lut -> num_input_table_entries * in_chan * entry_size; 77
for (i = 0; i < clut_size * out_chan; i+=3) 78
if ( type == LUT8_TYPE )  79
lut -> clut_table [ i + 0 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 0 ) ); 80
lut -> clut_table [ i + 1 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 1 ) ); 81
lut -> clut_table [ i + 2 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 2 ) ); 82
------------------------------
10 /home/speedy/test/source2slice/NVD/CVE-2015-0811_VULN_read_tag_lutType.c clut_offset = offset + 52 + lut -> num_input_table_entries * in_chan * entry_size 77
static struct lutType *read_tag_lutType(struct mem_source *src, struct tag_index index, uint32_t tag_id) 1
struct tag * tag = find_tag ( index , tag_id ) ; 3
uint32_t offset = tag -> offset ; 4
uint32_t type = read_u32 ( src , offset ) ; 5
uint16_t num_input_table_entries ; 6
uint16_t num_output_table_entries ; 7
uint8_t in_chan , grid_points , out_chan ; 8
uint32_t clut_offset , output_offset ; 9
uint32_t clut_size ; 10
size_t entry_size ; 11
struct lutType * lut ; 12
uint32_t i ; 13
if ( type == LUT8_TYPE )  17
num_input_table_entries = 256; 18
num_output_table_entries = 256; 19
entry_size = 1; 20
if ( type == LUT16_TYPE )  21
num_input_table_entries = read_u16 ( src , offset + 48 ); 22
num_output_table_entries = read_u16 ( src , offset + 50 ); 23
entry_size = 2; 24
in_chan = read_u8 ( src , offset + 8 ); 31
out_chan = read_u8 ( src , offset + 9 ); 32
grid_points = read_u8 ( src , offset + 10 ); 33
clut_size = pow ( grid_points , in_chan ); 35
if ( clut_size > MAX_CLUT_SIZE )  36
if ( in_chan != 3 || out_chan != 3 )  40
lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ); 44
if ( ! lut )  45
lut -> input_table = & lut -> table_data [ 0 ]; 50
lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ]; 51
lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ]; 52
lut -> num_input_table_entries = num_input_table_entries; 54
lut -> num_output_table_entries = num_output_table_entries; 55
lut -> num_input_channels = read_u8 ( src , offset + 8 ); 56
lut -> num_output_channels = read_u8 ( src , offset + 9 ); 57
lut -> num_clut_grid_points = read_u8 ( src , offset + 10 ); 58
lut -> e00 = read_s15Fixed16Number ( src , offset + 12 ); 59
lut -> e01 = read_s15Fixed16Number ( src , offset + 16 ); 60
lut -> e02 = read_s15Fixed16Number ( src , offset + 20 ); 61
lut -> e10 = read_s15Fixed16Number ( src , offset + 24 ); 62
lut -> e11 = read_s15Fixed16Number ( src , offset + 28 ); 63
lut -> e12 = read_s15Fixed16Number ( src , offset + 32 ); 64
lut -> e20 = read_s15Fixed16Number ( src , offset + 36 ); 65
lut -> e21 = read_s15Fixed16Number ( src , offset + 40 ); 66
lut -> e22 = read_s15Fixed16Number ( src , offset + 44 ); 67
for (i = 0; i < lut->num_input_table_entries * in_chan; i++) 69
if ( type == LUT8_TYPE )  70
lut -> input_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , offset + 52 + i * entry_size ) ); 73
clut_offset = offset + 52 + lut -> num_input_table_entries * in_chan * entry_size; 77
lut -> clut_table [ i + 0 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 0 ) ); 80
lut -> clut_table [ i + 1 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 1 ) ); 81
lut -> clut_table [ i + 2 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 2 ) ); 82
lut -> clut_table [ i + 0 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 0 ) ); 84
lut -> clut_table [ i + 1 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 2 ) ); 85
lut -> clut_table [ i + 2 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 4 ) ); 86
output_offset = clut_offset + clut_size * out_chan * entry_size; 90
for (i = 0; i < lut->num_output_table_entries * out_chan; i++) 91
lut -> output_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , output_offset + i * entry_size ) ); 93
lut -> output_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , output_offset + i * entry_size ) ); 95
return lut ; 99
------------------------------
11 /home/speedy/test/source2slice/NVD/CVE-2015-0811_VULN_read_tag_lutType.c lut -> input_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , offset + 52 + i * entry_size ) ) 73
static struct lutType *read_tag_lutType(struct mem_source *src, struct tag_index index, uint32_t tag_id) 1
struct tag * tag = find_tag ( index , tag_id ) ; 3
uint32_t offset = tag -> offset ; 4
uint32_t type = read_u32 ( src , offset ) ; 5
uint16_t num_input_table_entries ; 6
uint16_t num_output_table_entries ; 7
uint8_t in_chan , grid_points , out_chan ; 8
uint32_t clut_size ; 10
size_t entry_size ; 11
struct lutType * lut ; 12
uint32_t i ; 13
if ( type == LUT8_TYPE )  17
num_input_table_entries = 256; 18
num_output_table_entries = 256; 19
entry_size = 1; 20
if ( type == LUT16_TYPE )  21
num_input_table_entries = read_u16 ( src , offset + 48 ); 22
num_output_table_entries = read_u16 ( src , offset + 50 ); 23
entry_size = 2; 24
in_chan = read_u8 ( src , offset + 8 ); 31
out_chan = read_u8 ( src , offset + 9 ); 32
grid_points = read_u8 ( src , offset + 10 ); 33
clut_size = pow ( grid_points , in_chan ); 35
if ( clut_size > MAX_CLUT_SIZE )  36
if ( in_chan != 3 || out_chan != 3 )  40
lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ); 44
if ( ! lut )  45
lut -> input_table = & lut -> table_data [ 0 ]; 50
lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ]; 51
lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ]; 52
lut -> num_input_table_entries = num_input_table_entries; 54
lut -> num_output_table_entries = num_output_table_entries; 55
lut -> num_input_channels = read_u8 ( src , offset + 8 ); 56
lut -> num_output_channels = read_u8 ( src , offset + 9 ); 57
lut -> num_clut_grid_points = read_u8 ( src , offset + 10 ); 58
lut -> e00 = read_s15Fixed16Number ( src , offset + 12 ); 59
lut -> e01 = read_s15Fixed16Number ( src , offset + 16 ); 60
lut -> e02 = read_s15Fixed16Number ( src , offset + 20 ); 61
lut -> e10 = read_s15Fixed16Number ( src , offset + 24 ); 62
lut -> e11 = read_s15Fixed16Number ( src , offset + 28 ); 63
lut -> e12 = read_s15Fixed16Number ( src , offset + 32 ); 64
lut -> e20 = read_s15Fixed16Number ( src , offset + 36 ); 65
lut -> e21 = read_s15Fixed16Number ( src , offset + 40 ); 66
lut -> e22 = read_s15Fixed16Number ( src , offset + 44 ); 67
for (i = 0; i < lut->num_input_table_entries * in_chan; i++) 69
if ( type == LUT8_TYPE )  70
lut -> input_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , offset + 52 + i * entry_size ) ); 73
clut_offset = offset + 52 + lut -> num_input_table_entries * in_chan * entry_size; 77
for (i = 0; i < clut_size * out_chan; i+=3) 78
lut -> clut_table [ i + 0 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 0 ) ); 80
lut -> clut_table [ i + 1 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 1 ) ); 81
lut -> clut_table [ i + 2 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 2 ) ); 82
lut -> clut_table [ i + 0 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 0 ) ); 84
lut -> clut_table [ i + 1 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 2 ) ); 85
lut -> clut_table [ i + 2 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 4 ) ); 86
output_offset = clut_offset + clut_size * out_chan * entry_size; 90
for (i = 0; i < lut->num_output_table_entries * out_chan; i++) 91
lut -> output_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , output_offset + i * entry_size ) ); 93
lut -> output_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , output_offset + i * entry_size ) ); 95
return lut ; 99
------------------------------
12 /home/speedy/test/source2slice/NVD/CVE-2015-0811_VULN_read_tag_lutType.c lut -> input_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , offset + 52 + i * entry_size ) ) 71
static struct lutType *read_tag_lutType(struct mem_source *src, struct tag_index index, uint32_t tag_id) 1
struct tag * tag = find_tag ( index , tag_id ) ; 3
uint32_t offset = tag -> offset ; 4
uint32_t type = read_u32 ( src , offset ) ; 5
uint16_t num_input_table_entries ; 6
uint16_t num_output_table_entries ; 7
uint8_t in_chan , grid_points , out_chan ; 8
uint32_t clut_size ; 10
size_t entry_size ; 11
struct lutType * lut ; 12
uint32_t i ; 13
if ( type == LUT8_TYPE )  17
num_input_table_entries = 256; 18
num_output_table_entries = 256; 19
entry_size = 1; 20
if ( type == LUT16_TYPE )  21
num_input_table_entries = read_u16 ( src , offset + 48 ); 22
num_output_table_entries = read_u16 ( src , offset + 50 ); 23
entry_size = 2; 24
in_chan = read_u8 ( src , offset + 8 ); 31
out_chan = read_u8 ( src , offset + 9 ); 32
grid_points = read_u8 ( src , offset + 10 ); 33
clut_size = pow ( grid_points , in_chan ); 35
if ( clut_size > MAX_CLUT_SIZE )  36
if ( in_chan != 3 || out_chan != 3 )  40
lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ); 44
if ( ! lut )  45
lut -> input_table = & lut -> table_data [ 0 ]; 50
lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ]; 51
lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ]; 52
lut -> num_input_table_entries = num_input_table_entries; 54
lut -> num_output_table_entries = num_output_table_entries; 55
lut -> num_input_channels = read_u8 ( src , offset + 8 ); 56
lut -> num_output_channels = read_u8 ( src , offset + 9 ); 57
lut -> num_clut_grid_points = read_u8 ( src , offset + 10 ); 58
lut -> e00 = read_s15Fixed16Number ( src , offset + 12 ); 59
lut -> e01 = read_s15Fixed16Number ( src , offset + 16 ); 60
lut -> e02 = read_s15Fixed16Number ( src , offset + 20 ); 61
lut -> e10 = read_s15Fixed16Number ( src , offset + 24 ); 62
lut -> e11 = read_s15Fixed16Number ( src , offset + 28 ); 63
lut -> e12 = read_s15Fixed16Number ( src , offset + 32 ); 64
lut -> e20 = read_s15Fixed16Number ( src , offset + 36 ); 65
lut -> e21 = read_s15Fixed16Number ( src , offset + 40 ); 66
lut -> e22 = read_s15Fixed16Number ( src , offset + 44 ); 67
for (i = 0; i < lut->num_input_table_entries * in_chan; i++) 69
if ( type == LUT8_TYPE )  70
lut -> input_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , offset + 52 + i * entry_size ) ); 71
------------------------------
13 /home/speedy/test/source2slice/NVD/CVE-2015-0811_VULN_read_tag_lutType.c lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ] 52
static struct lutType *read_tag_lutType(struct mem_source *src, struct tag_index index, uint32_t tag_id) 1
struct tag * tag = find_tag ( index , tag_id ) ; 3
uint32_t offset = tag -> offset ; 4
uint32_t type = read_u32 ( src , offset ) ; 5
uint16_t num_input_table_entries ; 6
uint16_t num_output_table_entries ; 7
uint8_t in_chan , grid_points , out_chan ; 8
uint32_t clut_size ; 10
struct lutType * lut ; 12
if ( type == LUT8_TYPE )  17
num_input_table_entries = 256; 18
num_output_table_entries = 256; 19
if ( type == LUT16_TYPE )  21
num_input_table_entries = read_u16 ( src , offset + 48 ); 22
num_output_table_entries = read_u16 ( src , offset + 50 ); 23
in_chan = read_u8 ( src , offset + 8 ); 31
out_chan = read_u8 ( src , offset + 9 ); 32
grid_points = read_u8 ( src , offset + 10 ); 33
clut_size = pow ( grid_points , in_chan ); 35
if ( clut_size > MAX_CLUT_SIZE )  36
if ( in_chan != 3 || out_chan != 3 )  40
lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ); 44
if ( ! lut )  45
lut -> input_table = & lut -> table_data [ 0 ]; 50
lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ]; 51
lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ]; 52
lut -> num_input_table_entries = num_input_table_entries; 54
lut -> num_output_table_entries = num_output_table_entries; 55
lut -> num_input_channels = read_u8 ( src , offset + 8 ); 56
lut -> num_output_channels = read_u8 ( src , offset + 9 ); 57
lut -> num_clut_grid_points = read_u8 ( src , offset + 10 ); 58
lut -> e00 = read_s15Fixed16Number ( src , offset + 12 ); 59
lut -> e01 = read_s15Fixed16Number ( src , offset + 16 ); 60
lut -> e02 = read_s15Fixed16Number ( src , offset + 20 ); 61
lut -> e10 = read_s15Fixed16Number ( src , offset + 24 ); 62
lut -> e11 = read_s15Fixed16Number ( src , offset + 28 ); 63
lut -> e12 = read_s15Fixed16Number ( src , offset + 32 ); 64
lut -> e20 = read_s15Fixed16Number ( src , offset + 36 ); 65
lut -> e21 = read_s15Fixed16Number ( src , offset + 40 ); 66
lut -> e22 = read_s15Fixed16Number ( src , offset + 44 ); 67
for (i = 0; i < lut->num_input_table_entries * in_chan; i++) 69
lut -> input_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , offset + 52 + i * entry_size ) ); 71
lut -> input_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , offset + 52 + i * entry_size ) ); 73
clut_offset = offset + 52 + lut -> num_input_table_entries * in_chan * entry_size; 77
for (i = 0; i < clut_size * out_chan; i+=3) 78
lut -> clut_table [ i + 0 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 0 ) ); 80
lut -> clut_table [ i + 1 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 1 ) ); 81
lut -> clut_table [ i + 2 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 2 ) ); 82
lut -> clut_table [ i + 0 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 0 ) ); 84
lut -> clut_table [ i + 1 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 2 ) ); 85
lut -> clut_table [ i + 2 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 4 ) ); 86
output_offset = clut_offset + clut_size * out_chan * entry_size; 90
for (i = 0; i < lut->num_output_table_entries * out_chan; i++) 91
lut -> output_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , output_offset + i * entry_size ) ); 93
lut -> output_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , output_offset + i * entry_size ) ); 95
return lut ; 99
------------------------------
14 /home/speedy/test/source2slice/NVD/CVE-2015-0811_VULN_read_tag_lutType.c lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ] 51
static struct lutType *read_tag_lutType(struct mem_source *src, struct tag_index index, uint32_t tag_id) 1
struct tag * tag = find_tag ( index , tag_id ) ; 3
uint32_t offset = tag -> offset ; 4
uint32_t type = read_u32 ( src , offset ) ; 5
uint16_t num_input_table_entries ; 6
uint16_t num_output_table_entries ; 7
uint8_t in_chan , grid_points , out_chan ; 8
uint32_t clut_size ; 10
struct lutType * lut ; 12
if ( type == LUT8_TYPE )  17
num_input_table_entries = 256; 18
num_output_table_entries = 256; 19
if ( type == LUT16_TYPE )  21
num_input_table_entries = read_u16 ( src , offset + 48 ); 22
num_output_table_entries = read_u16 ( src , offset + 50 ); 23
in_chan = read_u8 ( src , offset + 8 ); 31
out_chan = read_u8 ( src , offset + 9 ); 32
grid_points = read_u8 ( src , offset + 10 ); 33
clut_size = pow ( grid_points , in_chan ); 35
if ( clut_size > MAX_CLUT_SIZE )  36
if ( in_chan != 3 || out_chan != 3 )  40
lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ); 44
if ( ! lut )  45
lut -> input_table = & lut -> table_data [ 0 ]; 50
lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ]; 51
lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ]; 52
lut -> num_input_table_entries = num_input_table_entries; 54
lut -> num_output_table_entries = num_output_table_entries; 55
lut -> num_input_channels = read_u8 ( src , offset + 8 ); 56
lut -> num_output_channels = read_u8 ( src , offset + 9 ); 57
lut -> num_clut_grid_points = read_u8 ( src , offset + 10 ); 58
lut -> e00 = read_s15Fixed16Number ( src , offset + 12 ); 59
lut -> e01 = read_s15Fixed16Number ( src , offset + 16 ); 60
lut -> e02 = read_s15Fixed16Number ( src , offset + 20 ); 61
lut -> e10 = read_s15Fixed16Number ( src , offset + 24 ); 62
lut -> e11 = read_s15Fixed16Number ( src , offset + 28 ); 63
lut -> e12 = read_s15Fixed16Number ( src , offset + 32 ); 64
lut -> e20 = read_s15Fixed16Number ( src , offset + 36 ); 65
lut -> e21 = read_s15Fixed16Number ( src , offset + 40 ); 66
lut -> e22 = read_s15Fixed16Number ( src , offset + 44 ); 67
for (i = 0; i < lut->num_input_table_entries * in_chan; i++) 69
lut -> input_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , offset + 52 + i * entry_size ) ); 71
lut -> input_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , offset + 52 + i * entry_size ) ); 73
clut_offset = offset + 52 + lut -> num_input_table_entries * in_chan * entry_size; 77
for (i = 0; i < clut_size * out_chan; i+=3) 78
lut -> clut_table [ i + 0 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 0 ) ); 80
lut -> clut_table [ i + 1 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 1 ) ); 81
lut -> clut_table [ i + 2 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 2 ) ); 82
lut -> clut_table [ i + 0 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 0 ) ); 84
lut -> clut_table [ i + 1 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 2 ) ); 85
lut -> clut_table [ i + 2 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 4 ) ); 86
output_offset = clut_offset + clut_size * out_chan * entry_size; 90
for (i = 0; i < lut->num_output_table_entries * out_chan; i++) 91
lut -> output_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , output_offset + i * entry_size ) ); 93
lut -> output_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , output_offset + i * entry_size ) ); 95
return lut ; 99
------------------------------
15 /home/speedy/test/source2slice/NVD/CVE-2015-0811_VULN_read_tag_lutType.c lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ) 44
static struct lutType *read_tag_lutType(struct mem_source *src, struct tag_index index, uint32_t tag_id) 1
struct tag * tag = find_tag ( index , tag_id ) ; 3
uint32_t offset = tag -> offset ; 4
uint32_t type = read_u32 ( src , offset ) ; 5
uint16_t num_input_table_entries ; 6
uint16_t num_output_table_entries ; 7
uint8_t in_chan , grid_points , out_chan ; 8
uint32_t clut_size ; 10
struct lutType * lut ; 12
if ( type == LUT8_TYPE )  17
num_input_table_entries = 256; 18
num_output_table_entries = 256; 19
if ( type == LUT16_TYPE )  21
num_input_table_entries = read_u16 ( src , offset + 48 ); 22
num_output_table_entries = read_u16 ( src , offset + 50 ); 23
in_chan = read_u8 ( src , offset + 8 ); 31
out_chan = read_u8 ( src , offset + 9 ); 32
grid_points = read_u8 ( src , offset + 10 ); 33
clut_size = pow ( grid_points , in_chan ); 35
if ( clut_size > MAX_CLUT_SIZE )  36
if ( in_chan != 3 || out_chan != 3 )  40
lut = malloc ( sizeof ( struct lutType ) + ( num_input_table_entries * in_chan + clut_size * out_chan + num_output_table_entries * out_chan ) * sizeof ( float ) ); 44
if ( ! lut )  45
lut -> input_table = & lut -> table_data [ 0 ]; 50
lut -> clut_table = & lut -> table_data [ in_chan * num_input_table_entries ]; 51
lut -> output_table = & lut -> table_data [ in_chan * num_input_table_entries + clut_size * out_chan ]; 52
lut -> num_input_table_entries = num_input_table_entries; 54
lut -> num_output_table_entries = num_output_table_entries; 55
lut -> num_input_channels = read_u8 ( src , offset + 8 ); 56
lut -> num_output_channels = read_u8 ( src , offset + 9 ); 57
lut -> num_clut_grid_points = read_u8 ( src , offset + 10 ); 58
lut -> e00 = read_s15Fixed16Number ( src , offset + 12 ); 59
lut -> e01 = read_s15Fixed16Number ( src , offset + 16 ); 60
lut -> e02 = read_s15Fixed16Number ( src , offset + 20 ); 61
lut -> e10 = read_s15Fixed16Number ( src , offset + 24 ); 62
lut -> e11 = read_s15Fixed16Number ( src , offset + 28 ); 63
lut -> e12 = read_s15Fixed16Number ( src , offset + 32 ); 64
lut -> e20 = read_s15Fixed16Number ( src , offset + 36 ); 65
lut -> e21 = read_s15Fixed16Number ( src , offset + 40 ); 66
lut -> e22 = read_s15Fixed16Number ( src , offset + 44 ); 67
for (i = 0; i < lut->num_input_table_entries * in_chan; i++) 69
lut -> input_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , offset + 52 + i * entry_size ) ); 71
lut -> input_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , offset + 52 + i * entry_size ) ); 73
clut_offset = offset + 52 + lut -> num_input_table_entries * in_chan * entry_size; 77
for (i = 0; i < clut_size * out_chan; i+=3) 78
lut -> clut_table [ i + 0 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 0 ) ); 80
lut -> clut_table [ i + 1 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 1 ) ); 81
lut -> clut_table [ i + 2 ] = uInt8Number_to_float ( read_uInt8Number ( src , clut_offset + i * entry_size + 2 ) ); 82
lut -> clut_table [ i + 0 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 0 ) ); 84
lut -> clut_table [ i + 1 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 2 ) ); 85
lut -> clut_table [ i + 2 ] = uInt16Number_to_float ( read_uInt16Number ( src , clut_offset + i * entry_size + 4 ) ); 86
output_offset = clut_offset + clut_size * out_chan * entry_size; 90
for (i = 0; i < lut->num_output_table_entries * out_chan; i++) 91
lut -> output_table [ i ] = uInt8Number_to_float ( read_uInt8Number ( src , output_offset + i * entry_size ) ); 93
lut -> output_table [ i ] = uInt16Number_to_float ( read_uInt16Number ( src , output_offset + i * entry_size ) ); 95
return lut ; 99
------------------------------
16 /home/speedy/test/source2slice/NVD/CVE-2015-1872_VULN_ff_mjpeg_decode_sof.c s -> block_stride [ i ] = bw * s -> h_count [ i ] 371
int ff_mjpeg_decode_sof(MJpegDecodeContext *s) 1
int len , nb_components , i , width , height , bits , ret ; 3
unsigned pix_fmt_id ; 4
int h_count [ MAX_COMPONENTS ] ; 5
int v_count [ MAX_COMPONENTS ] ; 6
s -> cur_scan = 0; 8
s -> upscale_h = s -> upscale_v = 0; 9
s -> avctx -> bits_per_raw_sample = bits = get_bits ( & s -> gb , 8 ); 13
if ( bits > 16 || bits < 1 )  16
if ( s -> pegasus_rct )  21
bits = 9; 22
if ( bits == 9 && ! s -> pegasus_rct )  23
s -> rct = 1; 24
if ( s -> lossless && s -> avctx -> lowres )  26
height = get_bits ( & s -> gb , 16 ); 31
width = get_bits ( & s -> gb , 16 ); 32
if ( s -> interlaced && s -> width == width && s -> height == height + 1 )  38
height = s -> height; 39
if ( av_image_check_size ( width , height , 0 , s -> avctx ) )  42
nb_components = get_bits ( & s -> gb , 8 ); 45
if ( nb_components <= 0 || nb_components > MAX_COMPONENTS )  46
if ( s -> interlaced && ( s -> bottom_field == ! s -> interlace_polarity ) )  49
if ( nb_components != s -> nb_components )  50
if ( s -> ls && ! ( bits <= 8 || nb_components == 1 ) )  56
s -> nb_components = nb_components; 62
s -> h_max = 1; 63
s -> v_max = 1; 64
memset ( h_count , 0 , sizeof ( h_count ) ); 65
memset ( v_count , 0 , sizeof ( v_count ) ); 66
for (i = 0; i < nb_components; i++) 67
s -> component_id [ i ] = get_bits ( & s -> gb , 8 ) - 1; 69
h_count [ i ] = get_bits ( & s -> gb , 4 ); 70
v_count [ i ] = get_bits ( & s -> gb , 4 ); 71
if ( h_count [ i ] > s -> h_max )  73
s -> h_max = h_count [ i ]; 74
if ( v_count [ i ] > s -> v_max )  75
s -> v_max = v_count [ i ]; 76
s -> quant_index [ i ] = get_bits ( & s -> gb , 8 ); 77
if ( s -> quant_index [ i ] >= 4 )  78
if ( ! h_count [ i ] || ! v_count [ i ] )  82
if ( s -> ls && ( s -> h_max > 1 || s -> v_max > 1 ) )  94
if ( width != s -> width || height != s -> height || bits != s -> bits || memcmp ( s -> h_count , h_count , sizeof ( h_count ) ) || memcmp ( s -> v_count , v_count , sizeof ( v_count ) ) )  101
s -> width = width; 106
s -> height = height; 107
s -> bits = bits; 108
memcpy ( s -> h_count , h_count , sizeof ( h_count ) ); 109
memcpy ( s -> v_count , v_count , sizeof ( v_count ) ); 110
s -> interlaced = 0; 111
s -> got_picture = 0; 112
if ( s -> first_picture && s -> org_height != 0 && s -> height < ( ( s -> org_height * 3 ) / 4 ) )  115
s -> interlaced = 1; 118
s -> bottom_field = s -> interlace_polarity; 119
s -> picture_ptr -> interlaced_frame = 1; 120
s -> picture_ptr -> top_field_first = ! s -> interlace_polarity; 121
height *= 2; 122
ret = ff_set_dimensions ( s -> avctx , width , height ); 125
if ( ret < 0 )  126
s -> first_picture = 0; 129
if ( s -> got_picture && s -> interlaced && ( s -> bottom_field == ! s -> interlace_polarity ) )  132
if ( s -> progressive )  133
if ( s -> v_max == 1 && s -> h_max == 1 && s -> lossless == 1 && ( nb_components == 3 || nb_components == 4 ) )  138
s -> rgb = 1; 139
if ( ! s -> lossless )  140
s -> rgb = 0; 141
pix_fmt_id = ( ( unsigned ) s -> h_count [ 0 ] << 28 ) | ( s -> v_count [ 0 ] << 24 ) | ( s -> h_count [ 1 ] << 20 ) | ( s -> v_count [ 1 ] << 16 ) | ( s -> h_count [ 2 ] << 12 ) | ( s -> v_count [ 2 ] << 8 ) | ( s -> h_count [ 3 ] << 4 ) | s -> v_count [ 3 ]; 143
if ( ! ( pix_fmt_id & 0xD0D0D0D0 ) )  150
pix_fmt_id -= ( pix_fmt_id & 0xF0F0F0F0 ) >> 1; 151
if ( ! ( pix_fmt_id & 0x0D0D0D0D ) )  152
pix_fmt_id -= ( pix_fmt_id & 0x0F0F0F0F ) >> 1; 153
for (i = 0; i < 8; i++) 155
int j = 6 + ( i & 1 ) - ( i & 6 ) ; 156
int is = ( pix_fmt_id >> ( 4 * i ) ) & 0xF ; 157
int js = ( pix_fmt_id >> ( 4 * j ) ) & 0xF ; 158
if ( is == 1 && js != 2 && ( i < 2 || i > 5 ) )  160
js = ( pix_fmt_id >> ( 8 + 4 * ( i & 1 ) ) ) & 0xF; 161
if ( is == 1 && js != 2 && ( i < 2 || i > 5 ) )  162
js = ( pix_fmt_id >> ( 16 + 4 * ( i & 1 ) ) ) & 0xF; 163
if ( is == 1 && js == 2 )  165
if ( i & 1 )  166
s -> upscale_h |= 1 << ( j / 2 ); 166
s -> upscale_v |= 1 << ( j / 2 ); 167
switch ( pix_fmt_id )  171
if ( s -> rgb )  173
s -> avctx -> pix_fmt = s -> bits <= 9 ? AV_PIX_FMT_BGR24 : AV_PIX_FMT_BGR48; 174
if ( s -> component_id [ 0 ] == 'Q' && s -> component_id [ 1 ] == 'F' && s -> component_id [ 2 ] == 'A' )  176
s -> avctx -> pix_fmt = s -> bits <= 8 ? AV_PIX_FMT_GBRP : AV_PIX_FMT_GBRP16; 177
if ( s -> bits <= 8 )  179
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P; 179
s -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P16; 180
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 181
if ( s -> rgb )  187
s -> avctx -> pix_fmt = s -> bits <= 9 ? AV_PIX_FMT_ABGR : AV_PIX_FMT_RGBA64; 188
if ( s -> adobe_transform == 0 && s -> bits <= 8 )  190
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRAP; 191
s -> avctx -> pix_fmt = s -> bits <= 8 ? AV_PIX_FMT_YUVA444P : AV_PIX_FMT_YUVA444P16; 193
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 194
if ( s -> adobe_transform == 0 && s -> bits <= 8 )  201
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRAP; 202
s -> upscale_v |= 6; 203
s -> upscale_h |= 6; 204
if ( s -> adobe_transform == 2 && s -> bits <= 8 )  205
s -> avctx -> pix_fmt = AV_PIX_FMT_YUVA444P; 206
s -> upscale_v |= 6; 207
s -> upscale_h |= 6; 208
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 209
if ( s -> bits <= 8 )  211
s -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P; 211
s -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P16; 212
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 213
if ( s -> bits <= 8 )  221
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P; 221
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 224
if ( s -> bits <= 8 )  229
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P; 229
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 232
if ( s -> bits <= 8 )  243
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 244
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 246
if ( s -> component_id [ 0 ] == 'Q' && s -> component_id [ 1 ] == 'F' && s -> component_id [ 2 ] == 'A' )  253
if ( s -> bits <= 8 )  254
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRP; 254
s -> upscale_v |= 3; 257
if ( pix_fmt_id == 0x14111100 )  259
s -> upscale_v |= 6; 260
if ( s -> bits <= 8 )  261
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV440P : AV_PIX_FMT_YUVJ440P; 261
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 264
if ( s -> component_id [ 0 ] == 'Q' && s -> component_id [ 1 ] == 'F' && s -> component_id [ 2 ] == 'A' )  268
if ( s -> bits <= 8 )  269
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRP; 269
s -> upscale_h |= 3; 272
if ( s -> bits <= 8 )  274
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV422P : AV_PIX_FMT_YUVJ422P; 274
s -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P16; 275
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 276
if ( s -> bits <= 8 )  281
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV422P : AV_PIX_FMT_YUVJ422P; 281
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 284
if ( s -> bits <= 8 )  289
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV420P : AV_PIX_FMT_YUVJ420P; 289
s -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P16; 290
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 291
if ( pix_fmt_id == 0x42111100 )  292
if ( s -> bits > 8 )  293
s -> upscale_h = 6; 295
if ( pix_fmt_id == 0x24111100 )  296
if ( s -> bits > 8 )  297
s -> upscale_v = 6; 299
if ( s -> bits <= 8 )  303
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV411P : AV_PIX_FMT_YUVJ411P; 303
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 306
if ( ( s -> upscale_h || s -> upscale_v ) && s -> avctx -> lowres )  314
if ( s -> ls )  318
s -> upscale_h = s -> upscale_v = 0; 319
if ( s -> nb_components > 1 )  320
s -> avctx -> pix_fmt = AV_PIX_FMT_RGB24; 321
if ( s -> palette_index && s -> bits <= 8 )  322
s -> avctx -> pix_fmt = AV_PIX_FMT_PAL8; 323
if ( s -> bits <= 8 )  324
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 325
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 327
s -> pix_desc = av_pix_fmt_desc_get ( s -> avctx -> pix_fmt ); 330
if ( ! s -> pix_desc )  331
if ( ff_get_buffer ( s -> avctx , s -> picture_ptr , AV_GET_BUFFER_FLAG_REF ) < 0 )  337
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
s -> picture_ptr -> pict_type = AV_PICTURE_TYPE_I; 339
s -> picture_ptr -> key_frame = 1; 340
s -> got_picture = 1; 341
for (i = 0; i < 4; i++) 343
s -> linesize [ i ] = s -> picture_ptr -> linesize [ i ] << s -> interlaced; 344
if ( s -> rgb && ! s -> lossless && ! s -> ls )  354
if ( s -> progressive )  360
int bw = ( width + s -> h_max * 8 - 1 ) / ( s -> h_max * 8 ) ; 361
int bh = ( height + s -> v_max * 8 - 1 ) / ( s -> v_max * 8 ) ; 362
for (i = 0; i < s->nb_components; i++) 363
int size = bw * bh * s -> h_count [ i ] * s -> v_count [ i ] ; 364
s -> blocks [ i ] = av_mallocz_array ( size , sizeof ( * * s -> blocks ) ); 367
s -> last_nnz [ i ] = av_mallocz_array ( size , sizeof ( * * s -> last_nnz ) ); 368
if ( ! s -> blocks [ i ] || ! s -> last_nnz [ i ] )  369
s -> block_stride [ i ] = bw * s -> h_count [ i ]; 371
memset ( s -> coefs_finished , 0 , sizeof ( s -> coefs_finished ) ); 373
------------------------------
17 /home/speedy/test/source2slice/NVD/CVE-2015-4504_VULN_lut_inverse_interp16.c f = ( ( Value - b ) / a ) 92
uint16_fract_t lut_inverse_interp16(uint16_t Value, uint16_t LutTable[], int length) 1
int l = 1 ; 3
int r = 0x10000 ; 4
int x = 0 , res ; 5
int NumZeroes , NumPoles ; 6
int cell0 , cell1 ; 7
double val2 ; 8
double y0 , y1 , x0 , x1 ; 9
double a , b , f ; 10
NumZeroes = 0; 17
while ( LutTable [ NumZeroes ] == 0 && NumZeroes < length - 1 )  18
NumZeroes ++; 19
if ( NumZeroes == 0 && Value == 0 )  24
NumPoles = 0; 27
while ( LutTable [ length - 1 - NumPoles ] == 0xFFFF && NumPoles < length - 1 )  28
NumPoles ++; 29
if ( NumZeroes > 1 || NumPoles > 1 )  32
int a , b ; 34
if ( Value == 0 )  37
a = ( ( NumZeroes - 1 ) * 0xFFFF ) / ( length - 1 ); 42
b = ( ( length - 1 - NumPoles ) * 0xFFFF ) / ( length - 1 ); 43
l = a - 1; 45
r = b + 1; 46
while ( r > l )  52
x = ( l + r ) / 2; 54
res = ( int ) lut_interp_linear16 ( ( uint16_fract_t ) ( x - 1 ) , LutTable , length ); 56
if ( res == Value )  58
if ( res > Value )  65
r = x - 1; 65
l = x + 1; 66
val2 = ( length - 1 ) * ( ( double ) ( x - 1 ) / 65535.0 ); 74
cell0 = ( int ) floor ( val2 ); 76
cell1 = ( int ) ceil ( val2 ); 77
if ( cell0 == cell1 )  79
y0 = LutTable [ cell0 ]; 81
x0 = ( 65535.0 * cell0 ) / ( length - 1 ); 82
y1 = LutTable [ cell1 ]; 84
x1 = ( 65535.0 * cell1 ) / ( length - 1 ); 85
a = ( y1 - y0 ) / ( x1 - x0 ); 87
b = y0 - a * x0; 88
if ( fabs ( a ) < 0.01 )  90
f = ( ( Value - b ) / a ); 92
if ( f < 0.0 )  94
if ( f >= 65535.0 )  95
return ( uint16_fract_t ) floor ( f + 0.5 ) ; 97
------------------------------
18 /home/speedy/test/source2slice/NVD/CVE-2015-4504_VULN_lut_inverse_interp16.c b = y0 - a * x0 88
uint16_fract_t lut_inverse_interp16(uint16_t Value, uint16_t LutTable[], int length) 1
int l = 1 ; 3
int r = 0x10000 ; 4
int x = 0 , res ; 5
int NumZeroes , NumPoles ; 6
int cell0 , cell1 ; 7
double val2 ; 8
double y0 , y1 , x0 , x1 ; 9
double a , b , f ; 10
NumZeroes = 0; 17
while ( LutTable [ NumZeroes ] == 0 && NumZeroes < length - 1 )  18
NumZeroes ++; 19
if ( NumZeroes == 0 && Value == 0 )  24
NumPoles = 0; 27
while ( LutTable [ length - 1 - NumPoles ] == 0xFFFF && NumPoles < length - 1 )  28
NumPoles ++; 29
if ( NumZeroes > 1 || NumPoles > 1 )  32
int a , b ; 34
if ( Value == 0 )  37
a = ( ( NumZeroes - 1 ) * 0xFFFF ) / ( length - 1 ); 42
b = ( ( length - 1 - NumPoles ) * 0xFFFF ) / ( length - 1 ); 43
l = a - 1; 45
r = b + 1; 46
while ( r > l )  52
x = ( l + r ) / 2; 54
res = ( int ) lut_interp_linear16 ( ( uint16_fract_t ) ( x - 1 ) , LutTable , length ); 56
if ( res == Value )  58
if ( res > Value )  65
r = x - 1; 65
l = x + 1; 66
val2 = ( length - 1 ) * ( ( double ) ( x - 1 ) / 65535.0 ); 74
cell0 = ( int ) floor ( val2 ); 76
cell1 = ( int ) ceil ( val2 ); 77
if ( cell0 == cell1 )  79
y0 = LutTable [ cell0 ]; 81
x0 = ( 65535.0 * cell0 ) / ( length - 1 ); 82
y1 = LutTable [ cell1 ]; 84
x1 = ( 65535.0 * cell1 ) / ( length - 1 ); 85
a = ( y1 - y0 ) / ( x1 - x0 ); 87
b = y0 - a * x0; 88
f = ( ( Value - b ) / a ); 92
if ( f < 0.0 )  94
if ( f >= 65535.0 )  95
return ( uint16_fract_t ) floor ( f + 0.5 ) ; 97
------------------------------
19 /home/speedy/test/source2slice/NVD/CVE-2015-4504_VULN_lut_inverse_interp16.c a = ( y1 - y0 ) / ( x1 - x0 ) 87
uint16_fract_t lut_inverse_interp16(uint16_t Value, uint16_t LutTable[], int length) 1
int l = 1 ; 3
int r = 0x10000 ; 4
int x = 0 , res ; 5
int NumZeroes , NumPoles ; 6
int cell0 , cell1 ; 7
double val2 ; 8
double y0 , y1 , x0 , x1 ; 9
double a , b , f ; 10
NumZeroes = 0; 17
while ( LutTable [ NumZeroes ] == 0 && NumZeroes < length - 1 )  18
NumZeroes ++; 19
if ( NumZeroes == 0 && Value == 0 )  24
NumPoles = 0; 27
while ( LutTable [ length - 1 - NumPoles ] == 0xFFFF && NumPoles < length - 1 )  28
NumPoles ++; 29
if ( NumZeroes > 1 || NumPoles > 1 )  32
int a , b ; 34
if ( Value == 0 )  37
a = ( ( NumZeroes - 1 ) * 0xFFFF ) / ( length - 1 ); 42
b = ( ( length - 1 - NumPoles ) * 0xFFFF ) / ( length - 1 ); 43
l = a - 1; 45
r = b + 1; 46
while ( r > l )  52
x = ( l + r ) / 2; 54
res = ( int ) lut_interp_linear16 ( ( uint16_fract_t ) ( x - 1 ) , LutTable , length ); 56
if ( res == Value )  58
if ( res > Value )  65
r = x - 1; 65
l = x + 1; 66
val2 = ( length - 1 ) * ( ( double ) ( x - 1 ) / 65535.0 ); 74
cell0 = ( int ) floor ( val2 ); 76
cell1 = ( int ) ceil ( val2 ); 77
if ( cell0 == cell1 )  79
y0 = LutTable [ cell0 ]; 81
x0 = ( 65535.0 * cell0 ) / ( length - 1 ); 82
y1 = LutTable [ cell1 ]; 84
x1 = ( 65535.0 * cell1 ) / ( length - 1 ); 85
a = ( y1 - y0 ) / ( x1 - x0 ); 87
b = y0 - a * x0; 88
if ( fabs ( a ) < 0.01 )  90
f = ( ( Value - b ) / a ); 92
if ( f < 0.0 )  94
if ( f >= 65535.0 )  95
return ( uint16_fract_t ) floor ( f + 0.5 ) ; 97
------------------------------
20 /home/speedy/test/source2slice/NVD/CVE-2015-4504_VULN_lut_inverse_interp16.c x = ( l + r ) / 2 54
uint16_fract_t lut_inverse_interp16(uint16_t Value, uint16_t LutTable[], int length) 1
int l = 1 ; 3
int r = 0x10000 ; 4
int NumZeroes , NumPoles ; 6
double a , b , f ; 10
NumZeroes = 0; 17
while ( LutTable [ NumZeroes ] == 0 && NumZeroes < length - 1 )  18
NumZeroes ++; 19
if ( NumZeroes == 0 && Value == 0 )  24
NumPoles = 0; 27
while ( LutTable [ length - 1 - NumPoles ] == 0xFFFF && NumPoles < length - 1 )  28
NumPoles ++; 29
if ( NumZeroes > 1 || NumPoles > 1 )  32
int a , b ; 34
if ( Value == 0 )  37
a = ( ( NumZeroes - 1 ) * 0xFFFF ) / ( length - 1 ); 42
b = ( ( length - 1 - NumPoles ) * 0xFFFF ) / ( length - 1 ); 43
l = a - 1; 45
r = b + 1; 46
while ( r > l )  52
x = ( l + r ) / 2; 54
res = ( int ) lut_interp_linear16 ( ( uint16_fract_t ) ( x - 1 ) , LutTable , length ); 56
if ( res == Value )  58
return ( uint16_fract_t ) ( x - 1 ) ; 62
if ( res > Value )  65
r = x - 1; 65
l = x + 1; 66
val2 = ( length - 1 ) * ( ( double ) ( x - 1 ) / 65535.0 ); 74
cell0 = ( int ) floor ( val2 ); 76
cell1 = ( int ) ceil ( val2 ); 77
if ( cell0 == cell1 )  79
return ( uint16_fract_t ) x ; 79
y0 = LutTable [ cell0 ]; 81
x0 = ( 65535.0 * cell0 ) / ( length - 1 ); 82
y1 = LutTable [ cell1 ]; 84
x1 = ( 65535.0 * cell1 ) / ( length - 1 ); 85
a = ( y1 - y0 ) / ( x1 - x0 ); 87
b = y0 - a * x0; 88
if ( fabs ( a ) < 0.01 )  90
return ( uint16_fract_t ) x ; 90
f = ( ( Value - b ) / a ); 92
if ( f < 0.0 )  94
if ( f >= 65535.0 )  95
return ( uint16_fract_t ) floor ( f + 0.5 ) ; 97
------------------------------
21 /home/speedy/test/source2slice/NVD/CVE-2015-4511_VULN_ne_parse.c data_offset = ( int64_t * ) ( ctx -> ancestor -> data + element -> data_offset ) 37
ne_parse(nestegg * ctx, struct ebml_element_desc * top_level, int64_t max_offset) 1
int r ; 3
int64_t * data_offset ; 4
uint64_t id , size , peeked_id ; 5
struct ebml_element_desc * element ; 6
if ( ! ctx -> ancestor )  8
if ( max_offset > 0 && ne_io_tell ( ctx -> io ) >= max_offset )  12
r = ne_peek_element ( ctx , & id , & size ); 17
if ( r != 1 )  18
element = ne_find_element ( id , ctx -> ancestor -> node ); 22
if ( element )  23
if ( element -> flags & DESC_FLAG_SUSPEND )  24
r = ne_read_element ( ctx , & id , & size ); 31
if ( r != 1 )  32
if ( element -> flags & DESC_FLAG_OFFSET )  36
data_offset = ( int64_t * ) ( ctx -> ancestor -> data + element -> data_offset ); 37
* data_offset = ne_io_tell ( ctx -> io ); 38
if ( * data_offset < 0 )  39
if ( element -> type == TYPE_MASTER )  45
if ( element -> flags & DESC_FLAG_MULTI )  46
if ( ne_read_master ( ctx , element ) < 0 )  47
if ( ne_read_single_master ( ctx , element ) < 0 )  50
r = ne_read_simple ( ctx , element , size ); 55
if ( r < 0 )  56
if ( ne_is_ancestor_element ( id , ctx -> ancestor -> previous ) )  59
if ( top_level && ctx -> ancestor -> node == top_level )  61
r = ne_read_element ( ctx , & id , & size ); 68
if ( r != 1 )  69
r = ne_io_read_skip ( ctx -> io , size ); 74
if ( r != 1 )  75
------------------------------
22 /home/speedy/test/source2slice/NVD/CVE-2015-7199_VULN_AddWeightedPathSegs.c aResultSeg [ i ] = ( aSeg1 ? aCoeff1 * aSeg1 [ i ] : 0.0 ) + aCoeff2 * aSeg2 [ i ] 33
static inline void
AddWeightedPathSegs(double aCoeff1,
SVGPathDataAndInfo::const_iterator& aSeg1,
double aCoeff2,
SVGPathDataAndInfo::const_iterator& aSeg2,
SVGPathDataAndInfo::iterator& aResultSeg) 6
uint32_t segType = SVGPathSegUtils :: DecodeType ( aSeg2 [ 0 ] ) ; 11
aResultSeg [ 0 ] = aSeg2 [ 0 ]; 16
bool isArcType = SVGPathSegUtils :: IsArcType ( segType ) ; 18
if ( isArcType )  19
aResultSeg [ LARGE_ARC_FLAG_IDX ] = aSeg2 [ LARGE_ARC_FLAG_IDX ]; 23
aResultSeg [ SWEEP_FLAG_IDX ] = aSeg2 [ SWEEP_FLAG_IDX ]; 24
uint32_t numArgs = SVGPathSegUtils :: ArgCountForType ( segType ) ; 29
for (uint32_t i = 1; i < 1 + numArgs; ++i) 30
if ( ! ( isArcType && ( i == LARGE_ARC_FLAG_IDX || i == SWEEP_FLAG_IDX ) ) )  32
aResultSeg [ i ] = ( aSeg1 ? aCoeff1 * aSeg1 [ i ] : 0.0 ) + aCoeff2 * aSeg2 [ i ]; 33
aResultSeg += 1 + numArgs; 42
------------------------------
23 /home/speedy/test/source2slice/NVD/CVE-2015-8785_VULN_fuse_fill_write_pages.c bytes = min_t ( size_t , bytes , fc -> max_write - count ) 20
static ssize_t fuse_fill_write_pages(struct fuse_req *req,
struct address_space *mapping,
struct iov_iter *ii, loff_t pos) 3
struct fuse_conn * fc = get_fuse_conn ( mapping -> host ) ; 5
unsigned offset = pos & ( PAGE_CACHE_SIZE - 1 ) ; 6
size_t count = 0 ; 7
req -> in . argpages = 1; 10
req -> page_descs [ 0 ] . offset = offset; 11
size_t tmp ; 14
struct page * page ; 15
pgoff_t index = pos >> PAGE_CACHE_SHIFT ; 16
size_t bytes = min_t ( size_t , PAGE_CACHE_SIZE - offset , iov_iter_count ( ii ) ) ; 17
bytes = min_t ( size_t , bytes , fc -> max_write - count ); 20
if ( iov_iter_fault_in_readable ( ii , bytes ) )  24
page = grab_cache_page_write_begin ( mapping , index , 0 ); 28
if ( ! page )  29
flush_dcache_page ( page ); 33
tmp = iov_iter_copy_from_user_atomic ( page , ii , offset , bytes ); 35
flush_dcache_page ( page ); 36
if ( ! tmp )  38
unlock_page ( page ); 39
page_cache_release ( page ); 40
bytes = min ( bytes , iov_iter_single_seg_count ( ii ) ); 41
req -> pages [ req -> num_pages ] = page; 46
req -> page_descs [ req -> num_pages ] . length = tmp; 47
req -> num_pages ++; 48
iov_iter_advance ( ii , tmp ); 50
count += tmp; 51
pos += tmp; 52
offset += tmp; 53
if ( offset == PAGE_CACHE_SIZE )  54
offset = 0; 55
if ( ! fc -> big_writes )  57
while ( iov_iter_count ( ii ) && count < fc -> max_write && req -> num_pages < req -> max_pages && offset == 0 )  59
return count > 0 ? count : err ; 62
------------------------------
24 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c * dst = val << ( precision - cbps ) 164
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
const AVPixFmtDescriptor * pixdesc = av_pix_fmt_desc_get ( s -> avctx -> pix_fmt ) ; 4
int compno , reslevelno , bandno ; 5
int x , y ; 6
int planar = ! ! ( pixdesc -> flags & AV_PIX_FMT_FLAG_PLANAR ) ; 7
int pixelsize = planar ? 1 : pixdesc -> nb_components ; 8
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
int x , y ; 42
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
if ( s -> cdef [ 0 ] < 0 )  71
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
int precision = picture -> format == AV_PIX_FMT_XYZ12 || picture -> format == AV_PIX_FMT_RGB48 || picture -> format == AV_PIX_FMT_RGBA64 || picture -> format == AV_PIX_FMT_GRAY16 ? 16 : s -> precision ; 123
for (compno = 0; compno < s->ncomponents; compno++) 128
Jpeg2000Component * comp = tile -> comp + compno ; 129
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 130
int32_t * i_datap = comp -> i_data ; 132
uint16_t * linel ; 133
int cbps = s -> cbps [ compno ] ; 134
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 135
int plane = 0 ; 136
if ( planar )  138
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 139
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 141
linel = ( uint16_t * ) picture -> data [ plane ] + y * ( picture -> linesize [ plane ] >> 1 ); 142
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 143
uint16_t * dst ; 144
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 146
dst = linel + ( x * pixelsize + compno * ! planar ); 147
if ( codsty -> transform == FF_DWT97 )  148
for (; x < w; x ++) 159
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 160
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 162
* dst = val << ( precision - cbps ); 164
i_datap ++; 165
dst += pixelsize; 166
linel += picture -> linesize [ plane ] >> 1; 169
------------------------------
25 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c * dst = val << ( precision - cbps ) 154
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
const AVPixFmtDescriptor * pixdesc = av_pix_fmt_desc_get ( s -> avctx -> pix_fmt ) ; 4
int compno , reslevelno , bandno ; 5
int x , y ; 6
int planar = ! ! ( pixdesc -> flags & AV_PIX_FMT_FLAG_PLANAR ) ; 7
int pixelsize = planar ? 1 : pixdesc -> nb_components ; 8
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
int x , y ; 42
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
if ( s -> cdef [ 0 ] < 0 )  71
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
int precision = picture -> format == AV_PIX_FMT_XYZ12 || picture -> format == AV_PIX_FMT_RGB48 || picture -> format == AV_PIX_FMT_RGBA64 || picture -> format == AV_PIX_FMT_GRAY16 ? 16 : s -> precision ; 123
for (compno = 0; compno < s->ncomponents; compno++) 128
Jpeg2000Component * comp = tile -> comp + compno ; 129
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 130
float * datap = comp -> f_data ; 131
uint16_t * linel ; 133
int cbps = s -> cbps [ compno ] ; 134
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 135
int plane = 0 ; 136
if ( planar )  138
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 139
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 141
linel = ( uint16_t * ) picture -> data [ plane ] + y * ( picture -> linesize [ plane ] >> 1 ); 142
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 143
uint16_t * dst ; 144
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 146
dst = linel + ( x * pixelsize + compno * ! planar ); 147
if ( codsty -> transform == FF_DWT97 )  148
for (; x < w; x ++) 149
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 150
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 152
* dst = val << ( precision - cbps ); 154
datap ++; 155
dst += pixelsize; 156
linel += picture -> linesize [ plane ] >> 1; 169
------------------------------
26 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c dst = linel + ( x * pixelsize + compno * ! planar ) 147
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
const AVPixFmtDescriptor * pixdesc = av_pix_fmt_desc_get ( s -> avctx -> pix_fmt ) ; 4
int compno , reslevelno , bandno ; 5
int x , y ; 6
int planar = ! ! ( pixdesc -> flags & AV_PIX_FMT_FLAG_PLANAR ) ; 7
int pixelsize = planar ? 1 : pixdesc -> nb_components ; 8
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
int x , y ; 42
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
if ( s -> cdef [ 0 ] < 0 )  71
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 128
uint16_t * linel ; 133
int plane = 0 ; 136
if ( planar )  138
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 139
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 141
linel = ( uint16_t * ) picture -> data [ plane ] + y * ( picture -> linesize [ plane ] >> 1 ); 142
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 143
uint16_t * dst ; 144
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 146
dst = linel + ( x * pixelsize + compno * ! planar ); 147
* dst = val << ( precision - cbps ); 154
dst += pixelsize; 156
* dst = val << ( precision - cbps ); 164
dst += pixelsize; 166
linel += picture -> linesize [ plane ] >> 1; 169
------------------------------
27 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ] 146
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 5
int x , y ; 6
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
int x , y ; 42
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
if ( s -> cdef [ 0 ] < 0 )  71
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 128
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 141
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 143
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 146
dst = linel + ( x * pixelsize + compno * ! planar ); 147
for (; x < w; x ++) 149
* dst = val << ( precision - cbps ); 154
dst += pixelsize; 156
for (; x < w; x ++) 159
* dst = val << ( precision - cbps ); 164
dst += pixelsize; 166
------------------------------
28 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ] 141
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 5
int x , y ; 6
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
int x , y ; 42
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
if ( s -> cdef [ 0 ] < 0 )  71
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 128
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 141
linel = ( uint16_t * ) picture -> data [ plane ] + y * ( picture -> linesize [ plane ] >> 1 ); 142
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 143
dst = linel + ( x * pixelsize + compno * ! planar ); 147
* dst = val << ( precision - cbps ); 154
dst += pixelsize; 156
* dst = val << ( precision - cbps ); 164
dst += pixelsize; 166
linel += picture -> linesize [ plane ] >> 1; 169
------------------------------
29 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c dst = line + x * pixelsize + compno * ! planar 98
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
const AVPixFmtDescriptor * pixdesc = av_pix_fmt_desc_get ( s -> avctx -> pix_fmt ) ; 4
int compno , reslevelno , bandno ; 5
int x , y ; 6
int planar = ! ! ( pixdesc -> flags & AV_PIX_FMT_FLAG_PLANAR ) ; 7
int pixelsize = planar ? 1 : pixdesc -> nb_components ; 8
uint8_t * line ; 10
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
int x , y ; 42
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
y = cblk -> coord [ 1 ] [ 0 ] - band -> coord [ 1 ] [ 0 ]; 50
if ( s -> cdef [ 0 ] < 0 )  71
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 79
int plane = 0 ; 86
if ( planar )  88
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 89
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 92
line = picture -> data [ plane ] + y * picture -> linesize [ plane ]; 93
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 94
uint8_t * dst ; 95
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 97
dst = line + x * pixelsize + compno * ! planar; 98
* dst = val << ( 8 - cbps ); 105
dst += pixelsize; 107
* dst = val << ( 8 - cbps ); 114
dst += pixelsize; 116
line += picture -> linesize [ plane ]; 119
------------------------------
30 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ] 97
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 5
int x , y ; 6
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
int x , y ; 42
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
y = cblk -> coord [ 1 ] [ 0 ] - band -> coord [ 1 ] [ 0 ]; 50
if ( s -> cdef [ 0 ] < 0 )  71
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 79
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 92
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 94
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 97
dst = line + x * pixelsize + compno * ! planar; 98
for (; x < w; x ++) 101
* dst = val << ( 8 - cbps ); 105
dst += pixelsize; 107
for (; x < w; x ++) 110
* dst = val << ( 8 - cbps ); 114
dst += pixelsize; 116
------------------------------
31 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c line = picture -> data [ plane ] + y * picture -> linesize [ plane ] 93
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
const AVPixFmtDescriptor * pixdesc = av_pix_fmt_desc_get ( s -> avctx -> pix_fmt ) ; 4
int compno , reslevelno , bandno ; 5
int x , y ; 6
int planar = ! ! ( pixdesc -> flags & AV_PIX_FMT_FLAG_PLANAR ) ; 7
uint8_t * line ; 10
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
int x , y ; 42
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
y = cblk -> coord [ 1 ] [ 0 ] - band -> coord [ 1 ] [ 0 ]; 50
if ( s -> cdef [ 0 ] < 0 )  71
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 79
int plane = 0 ; 86
if ( planar )  88
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 89
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 92
line = picture -> data [ plane ] + y * picture -> linesize [ plane ]; 93
dst = line + x * pixelsize + compno * ! planar; 98
* dst = val << ( 8 - cbps ); 105
dst += pixelsize; 107
* dst = val << ( 8 - cbps ); 114
dst += pixelsize; 116
line += picture -> linesize [ plane ]; 119
------------------------------
32 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ] 92
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 5
int x , y ; 6
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
int x , y ; 42
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
if ( s -> cdef [ 0 ] < 0 )  71
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 79
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 92
line = picture -> data [ plane ] + y * picture -> linesize [ plane ]; 93
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 94
dst = line + x * pixelsize + compno * ! planar; 98
* dst = val << ( 8 - cbps ); 105
dst += pixelsize; 107
* dst = val << ( 8 - cbps ); 114
dst += pixelsize; 116
line += picture -> linesize [ plane ]; 119
------------------------------
33 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y 35
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 5
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
------------------------------
34 /home/speedy/test/source2slice/NVD/CVE-2016-2327_VULN_apng_encode_frame.c s -> bytestream = original_bytestream + best_bytestream_size 111
static int apng_encode_frame(AVCodecContext *avctx, const AVFrame *pict,
APNGFctlChunk *best_fctl_chunk, APNGFctlChunk *best_last_fctl_chunk) 2
PNGEncContext * s = avctx -> priv_data ; 4
int ret ; 5
AVFrame * diffFrame ; 7
uint8_t bpp = ( s -> bits_per_pixel + 7 ) >> 3 ; 8
uint8_t * original_bytestream , * original_bytestream_end ; 9
uint32_t best_sequence_number ; 11
uint8_t * best_bytestream ; 12
size_t best_bytestream_size = SIZE_MAX ; 13
APNGFctlChunk last_fctl_chunk = * best_last_fctl_chunk ; 14
APNGFctlChunk fctl_chunk = * best_fctl_chunk ; 15
if ( avctx -> frame_number == 0 )  17
diffFrame = av_frame_alloc ( ); 26
if ( ! diffFrame )  27
diffFrame -> format = pict -> format; 30
diffFrame -> width = pict -> width; 31
diffFrame -> height = pict -> height; 32
if ( ( ret = av_frame_get_buffer ( diffFrame , 32 ) ) < 0 )  33
original_bytestream = s -> bytestream; 36
original_bytestream_end = s -> bytestream_end; 37
temp_bytestream = av_malloc ( original_bytestream_end - original_bytestream ); 39
temp_bytestream_end = temp_bytestream + ( original_bytestream_end - original_bytestream ); 40
if ( ! temp_bytestream )  41
for (last_fctl_chunk.dispose_op = 0; last_fctl_chunk.dispose_op < 3; ++last_fctl_chunk.dispose_op) 46
for (fctl_chunk.blend_op = 0; fctl_chunk.blend_op < 2; ++fctl_chunk.blend_op) 51
uint32_t original_sequence_number = s -> sequence_number , sequence_number ; 55
uint8_t * bytestream_start = s -> bytestream ; 56
size_t bytestream_size ; 57
if ( last_fctl_chunk . dispose_op != APNG_DISPOSE_OP_PREVIOUS )  60
if ( ! s -> prev_frame )  71
memcpy ( diffFrame -> data [ 0 ] , s -> prev_frame -> data [ 0 ] , s -> prev_frame -> linesize [ 0 ] * s -> prev_frame -> height ); 74
if ( apng_do_inverse_blend ( diffFrame , pict , & fctl_chunk , bpp ) < 0 )  79
ret = encode_frame ( avctx , diffFrame ); 83
sequence_number = s -> sequence_number; 84
s -> sequence_number = original_sequence_number; 85
bytestream_size = s -> bytestream - bytestream_start; 86
s -> bytestream = bytestream_start; 87
if ( ret < 0 )  88
if ( bytestream_size < best_bytestream_size )  91
best_sequence_number = sequence_number; 95
best_bytestream = s -> bytestream; 96
best_bytestream_size = bytestream_size; 97
if ( best_bytestream == original_bytestream )  99
s -> bytestream = temp_bytestream; 100
s -> bytestream_end = temp_bytestream_end; 101
s -> bytestream = original_bytestream; 103
s -> bytestream_end = original_bytestream_end; 104
s -> sequence_number = best_sequence_number; 110
s -> bytestream = original_bytestream + best_bytestream_size; 111
s -> bytestream_end = original_bytestream_end; 112
------------------------------
35 /home/speedy/test/source2slice/NVD/CVE-2016-2327_VULN_apng_encode_frame.c bytestream_size = s -> bytestream - bytestream_start 86
static int apng_encode_frame(AVCodecContext *avctx, const AVFrame *pict,
APNGFctlChunk *best_fctl_chunk, APNGFctlChunk *best_last_fctl_chunk) 2
PNGEncContext * s = avctx -> priv_data ; 4
int ret ; 5
AVFrame * diffFrame ; 7
uint8_t bpp = ( s -> bits_per_pixel + 7 ) >> 3 ; 8
uint8_t * original_bytestream , * original_bytestream_end ; 9
uint8_t * best_bytestream ; 12
size_t best_bytestream_size = SIZE_MAX ; 13
APNGFctlChunk last_fctl_chunk = * best_last_fctl_chunk ; 14
APNGFctlChunk fctl_chunk = * best_fctl_chunk ; 15
if ( avctx -> frame_number == 0 )  17
diffFrame = av_frame_alloc ( ); 26
if ( ! diffFrame )  27
diffFrame -> format = pict -> format; 30
diffFrame -> width = pict -> width; 31
diffFrame -> height = pict -> height; 32
if ( ( ret = av_frame_get_buffer ( diffFrame , 32 ) ) < 0 )  33
original_bytestream = s -> bytestream; 36
original_bytestream_end = s -> bytestream_end; 37
temp_bytestream = av_malloc ( original_bytestream_end - original_bytestream ); 39
temp_bytestream_end = temp_bytestream + ( original_bytestream_end - original_bytestream ); 40
if ( ! temp_bytestream )  41
for (last_fctl_chunk.dispose_op = 0; last_fctl_chunk.dispose_op < 3; ++last_fctl_chunk.dispose_op) 46
for (fctl_chunk.blend_op = 0; fctl_chunk.blend_op < 2; ++fctl_chunk.blend_op) 51
uint32_t original_sequence_number = s -> sequence_number , sequence_number ; 55
uint8_t * bytestream_start = s -> bytestream ; 56
size_t bytestream_size ; 57
if ( last_fctl_chunk . dispose_op != APNG_DISPOSE_OP_PREVIOUS )  60
if ( ! s -> prev_frame )  71
memcpy ( diffFrame -> data [ 0 ] , s -> prev_frame -> data [ 0 ] , s -> prev_frame -> linesize [ 0 ] * s -> prev_frame -> height ); 74
if ( apng_do_inverse_blend ( diffFrame , pict , & fctl_chunk , bpp ) < 0 )  79
ret = encode_frame ( avctx , diffFrame ); 83
s -> sequence_number = original_sequence_number; 85
bytestream_size = s -> bytestream - bytestream_start; 86
s -> bytestream = bytestream_start; 87
if ( ret < 0 )  88
if ( bytestream_size < best_bytestream_size )  91
best_bytestream = s -> bytestream; 96
best_bytestream_size = bytestream_size; 97
if ( best_bytestream == original_bytestream )  99
s -> bytestream = temp_bytestream; 100
s -> bytestream_end = temp_bytestream_end; 101
s -> bytestream = original_bytestream; 103
s -> bytestream_end = original_bytestream_end; 104
s -> bytestream = original_bytestream + best_bytestream_size; 111
s -> bytestream_end = original_bytestream_end; 112
memcpy ( original_bytestream , best_bytestream , best_bytestream_size ); 114
------------------------------
36 /home/speedy/test/source2slice/NVD/CVE-2016-2327_VULN_apng_encode_frame.c temp_bytestream_end = temp_bytestream + ( original_bytestream_end - original_bytestream ) 40
static int apng_encode_frame(AVCodecContext *avctx, const AVFrame *pict,
APNGFctlChunk *best_fctl_chunk, APNGFctlChunk *best_last_fctl_chunk) 2
PNGEncContext * s = avctx -> priv_data ; 4
int ret ; 5
AVFrame * diffFrame ; 7
uint8_t * original_bytestream , * original_bytestream_end ; 9
if ( avctx -> frame_number == 0 )  17
diffFrame = av_frame_alloc ( ); 26
if ( ! diffFrame )  27
diffFrame -> format = pict -> format; 30
diffFrame -> width = pict -> width; 31
diffFrame -> height = pict -> height; 32
if ( ( ret = av_frame_get_buffer ( diffFrame , 32 ) ) < 0 )  33
original_bytestream = s -> bytestream; 36
original_bytestream_end = s -> bytestream_end; 37
temp_bytestream = av_malloc ( original_bytestream_end - original_bytestream ); 39
temp_bytestream_end = temp_bytestream + ( original_bytestream_end - original_bytestream ); 40
uint32_t original_sequence_number = s -> sequence_number , sequence_number ; 55
uint8_t * bytestream_start = s -> bytestream ; 56
memcpy ( diffFrame -> data [ 0 ] , s -> last_frame -> data [ 0 ] , s -> last_frame -> linesize [ 0 ] * s -> last_frame -> height ); 61
size_t row_start = s -> last_frame -> linesize [ 0 ] * y + bpp * last_fctl_chunk . x_offset ; 66
memset ( diffFrame -> data [ 0 ] + row_start , 0 , bpp * last_fctl_chunk . width ); 67
if ( ! s -> prev_frame )  71
memcpy ( diffFrame -> data [ 0 ] , s -> prev_frame -> data [ 0 ] , s -> prev_frame -> linesize [ 0 ] * s -> prev_frame -> height ); 74
if ( apng_do_inverse_blend ( diffFrame , pict , & fctl_chunk , bpp ) < 0 )  79
ret = encode_frame ( avctx , diffFrame ); 83
sequence_number = s -> sequence_number; 84
s -> sequence_number = original_sequence_number; 85
bytestream_size = s -> bytestream - bytestream_start; 86
s -> bytestream = bytestream_start; 87
if ( ret < 0 )  88
if ( bytestream_size < best_bytestream_size )  91
best_sequence_number = sequence_number; 95
best_bytestream = s -> bytestream; 96
best_bytestream_size = bytestream_size; 97
if ( best_bytestream == original_bytestream )  99
s -> bytestream_end = temp_bytestream_end; 101
s -> sequence_number = best_sequence_number; 110
s -> bytestream = original_bytestream + best_bytestream_size; 111
s -> bytestream_end = original_bytestream_end; 112
if ( best_bytestream != original_bytestream )  113
memcpy ( original_bytestream , best_bytestream , best_bytestream_size ); 114
av_frame_free ( & diffFrame ); 120
return ret ; 121
------------------------------
37 /home/speedy/test/source2slice/NVD/CVE-2016-2327_VULN_apng_encode_frame.c temp_bytestream = av_malloc ( original_bytestream_end - original_bytestream ) 39
static int apng_encode_frame(AVCodecContext *avctx, const AVFrame *pict,
APNGFctlChunk *best_fctl_chunk, APNGFctlChunk *best_last_fctl_chunk) 2
PNGEncContext * s = avctx -> priv_data ; 4
int ret ; 5
AVFrame * diffFrame ; 7
uint8_t * original_bytestream , * original_bytestream_end ; 9
if ( avctx -> frame_number == 0 )  17
diffFrame = av_frame_alloc ( ); 26
if ( ! diffFrame )  27
diffFrame -> format = pict -> format; 30
diffFrame -> width = pict -> width; 31
diffFrame -> height = pict -> height; 32
if ( ( ret = av_frame_get_buffer ( diffFrame , 32 ) ) < 0 )  33
original_bytestream = s -> bytestream; 36
original_bytestream_end = s -> bytestream_end; 37
temp_bytestream = av_malloc ( original_bytestream_end - original_bytestream ); 39
temp_bytestream_end = temp_bytestream + ( original_bytestream_end - original_bytestream ); 40
if ( ! temp_bytestream )  41
uint32_t original_sequence_number = s -> sequence_number , sequence_number ; 55
uint8_t * bytestream_start = s -> bytestream ; 56
memcpy ( diffFrame -> data [ 0 ] , s -> last_frame -> data [ 0 ] , s -> last_frame -> linesize [ 0 ] * s -> last_frame -> height ); 61
size_t row_start = s -> last_frame -> linesize [ 0 ] * y + bpp * last_fctl_chunk . x_offset ; 66
memset ( diffFrame -> data [ 0 ] + row_start , 0 , bpp * last_fctl_chunk . width ); 67
if ( ! s -> prev_frame )  71
memcpy ( diffFrame -> data [ 0 ] , s -> prev_frame -> data [ 0 ] , s -> prev_frame -> linesize [ 0 ] * s -> prev_frame -> height ); 74
if ( apng_do_inverse_blend ( diffFrame , pict , & fctl_chunk , bpp ) < 0 )  79
ret = encode_frame ( avctx , diffFrame ); 83
sequence_number = s -> sequence_number; 84
s -> sequence_number = original_sequence_number; 85
bytestream_size = s -> bytestream - bytestream_start; 86
s -> bytestream = bytestream_start; 87
if ( ret < 0 )  88
if ( bytestream_size < best_bytestream_size )  91
best_sequence_number = sequence_number; 95
best_bytestream = s -> bytestream; 96
best_bytestream_size = bytestream_size; 97
if ( best_bytestream == original_bytestream )  99
s -> bytestream = temp_bytestream; 100
s -> bytestream_end = temp_bytestream_end; 101
s -> sequence_number = best_sequence_number; 110
s -> bytestream = original_bytestream + best_bytestream_size; 111
s -> bytestream_end = original_bytestream_end; 112
if ( best_bytestream != original_bytestream )  113
memcpy ( original_bytestream , best_bytestream , best_bytestream_size ); 114
av_frame_free ( & diffFrame ); 120
return ret ; 121
------------------------------
38 /home/speedy/test/source2slice/NVD/CVE-2016-2330_VULN_gif_image_write_image.c ptr = buf + y_start * linesize + x_start 105
static int gif_image_write_image(AVCodecContext *avctx,
uint8_t **bytestream, uint8_t *end,
const uint32_t *palette,
const uint8_t *buf, const int linesize,
AVPacket *pkt) 5
GIFContext * s = avctx -> priv_data ; 7
int len = 0 , height = avctx -> height , width = avctx -> width , x , y ; 8
int x_start = 0 , y_start = 0 , trans = s -> transparent_index ; 9
int honor_transparency = ( s -> flags & GF_TRANSDIFF ) && s -> last_frame ; 10
const uint8_t * ptr ; 11
if ( ( s -> flags & GF_OFFSETTING ) && s -> last_frame && ! palette )  14
const uint8_t * ref = s -> last_frame -> data [ 0 ] ; 15
const int ref_linesize = s -> last_frame -> linesize [ 0 ] ; 16
int x_end = avctx -> width - 1 , y_end = avctx -> height - 1 ; 17
while ( y_start < y_end )  21
if ( memcmp ( ref + y_start * ref_linesize , buf + y_start * linesize , width ) )  22
y_start ++; 24
while ( y_end > y_start )  26
if ( memcmp ( ref + y_end * ref_linesize , buf + y_end * linesize , width ) )  27
y_end --; 29
height = y_end + 1 - y_start; 31
while ( x_start < x_end )  34
int same_column = 1 ; 35
for (y = y_start; y <= y_end; y++) 36
if ( ref [ y * ref_linesize + x_start ] != buf [ y * linesize + x_start ] )  37
same_column = 0; 38
if ( ! same_column )  42
x_start ++; 44
while ( x_end > x_start )  46
int same_column = 1 ; 47
for (y = y_start; y <= y_end; y++) 48
if ( ref [ y * ref_linesize + x_end ] != buf [ y * linesize + x_end ] )  49
same_column = 0; 50
if ( ! same_column )  54
x_end --; 56
width = x_end + 1 - x_start; 58
if ( honor_transparency && trans < 0 )  82
trans = pick_palette_entry ( buf + y_start * linesize + x_start , linesize , width , height ); 83
if ( trans < 0 )  85
uint8_t * pal_exdata = s -> pal_exdata ; 88
if ( ! pal_exdata )  89
pal_exdata = av_packet_new_side_data ( pkt , AV_PKT_DATA_PALETTE , AVPALETTE_SIZE ); 90
if ( ! pal_exdata )  91
ptr = buf + y_start * linesize + x_start; 105
memcpy ( s -> tmpl , ptr , width ); 111
if ( ref [ x ] == ptr [ x ] )  113
s -> tmpl [ x ] = trans; 114
len += ff_lzw_encode ( s -> lzw , s -> tmpl , width ); 115
ptr += linesize; 116
len += ff_lzw_encode ( s -> lzw , ptr , width ); 121
ptr += linesize; 122
len += ff_lzw_encode_flush ( s -> lzw , flush_put_bits ); 125
ptr = s -> buf; 127
while ( len > 0 )  128
int size = FFMIN ( 255 , len ) ; 129
bytestream_put_byte ( bytestream , size ); 130
if ( end - * bytestream < size )  131
bytestream_put_buffer ( bytestream , ptr , size ); 133
ptr += size; 134
len -= size; 135
------------------------------
39 /home/speedy/test/source2slice/NVD/CVE-2016-2330_VULN_gif_image_write_image.c trans = pick_palette_entry ( buf + y_start * linesize + x_start , linesize , width , height ) 83
static int gif_image_write_image(AVCodecContext *avctx,
uint8_t **bytestream, uint8_t *end,
const uint32_t *palette,
const uint8_t *buf, const int linesize,
AVPacket *pkt) 5
GIFContext * s = avctx -> priv_data ; 7
int len = 0 , height = avctx -> height , width = avctx -> width , x , y ; 8
int x_start = 0 , y_start = 0 , trans = s -> transparent_index ; 9
int honor_transparency = ( s -> flags & GF_TRANSDIFF ) && s -> last_frame ; 10
if ( ( s -> flags & GF_OFFSETTING ) && s -> last_frame && ! palette )  14
const uint8_t * ref = s -> last_frame -> data [ 0 ] ; 15
const int ref_linesize = s -> last_frame -> linesize [ 0 ] ; 16
int x_end = avctx -> width - 1 , y_end = avctx -> height - 1 ; 17
while ( y_start < y_end )  21
if ( memcmp ( ref + y_start * ref_linesize , buf + y_start * linesize , width ) )  22
y_start ++; 24
while ( y_end > y_start )  26
if ( memcmp ( ref + y_end * ref_linesize , buf + y_end * linesize , width ) )  27
y_end --; 29
height = y_end + 1 - y_start; 31
while ( x_start < x_end )  34
int same_column = 1 ; 35
for (y = y_start; y <= y_end; y++) 36
if ( ref [ y * ref_linesize + x_start ] != buf [ y * linesize + x_start ] )  37
same_column = 0; 38
if ( ! same_column )  42
x_start ++; 44
while ( x_end > x_start )  46
int same_column = 1 ; 47
for (y = y_start; y <= y_end; y++) 48
if ( ref [ y * ref_linesize + x_end ] != buf [ y * linesize + x_end ] )  49
same_column = 0; 50
if ( ! same_column )  54
x_end --; 56
width = x_end + 1 - x_start; 58
if ( honor_transparency && trans < 0 )  82
trans = pick_palette_entry ( buf + y_start * linesize + x_start , linesize , width , height ); 83
if ( trans < 0 )  85
pal_exdata [ trans * 4 + 3 * ! HAVE_BIGENDIAN ] = 0x00; 94
if ( trans < 0 )  97
if ( ref [ x ] == ptr [ x ] )  113
s -> tmpl [ x ] = trans; 114
len += ff_lzw_encode ( s -> lzw , s -> tmpl , width ); 115
len += ff_lzw_encode_flush ( s -> lzw , flush_put_bits ); 125
ptr = s -> buf; 127
while ( len > 0 )  128
int size = FFMIN ( 255 , len ) ; 129
bytestream_put_byte ( bytestream , size ); 130
if ( end - * bytestream < size )  131
bytestream_put_buffer ( bytestream , ptr , size ); 133
ptr += size; 134
len -= size; 135
------------------------------
40 /home/speedy/test/source2slice/NVD/CVE-2016-2522_VULN_dissect_ber_constrained_bitstring.c val = tvb_get_guint8 ( tvb , offset + nb -> bit / 8 ) 98
dissect_ber_constrained_bitstring(gboolean implicit_tag, asn1_ctx_t *actx, proto_tree *parent_tree, tvbuff_t *tvb, int offset, gint32 min_len, gint32 max_len, const asn_namedbit *named_bits, gint hf_id, gint ett_id, tvbuff_t **out_tvb) 1
gint8 ber_class ; 3
gboolean pc , ind ; 4
gint32 tag ; 5
guint32 len , byteno ; 6
guint8 pad = 0 , b0 , b1 , val , * bitstring ; 7
const asn_namedbit * nb ; 15
if ( ! implicit_tag )  17
offset = dissect_ber_identifier ( actx -> pinfo , parent_tree , tvb , offset , & ber_class , & pc , & tag ); 20
offset = dissect_ber_length ( actx -> pinfo , parent_tree , tvb , offset , & len , & ind ); 21
if ( ! implicit_tag && ( ber_class != BER_CLASS_APP ) )  32
if ( ( ber_class != BER_CLASS_UNI ) || ( tag != BER_UNI_TAG_BITSTRING ) )  33
pc = 0; 51
len = tvb_reported_length_remaining ( tvb , offset ); 52
if ( pc )  58
pad = tvb_get_guint8 ( tvb , offset ); 63
offset ++; 76
len --; 77
if ( named_bits )  90
nb = named_bits; 93
bitstring = ( guint8 * ) tvb_memdup ( wmem_packet_scope ( ) , tvb , offset , len ); 94
while ( nb -> p_id )  96
if ( ( len > 0 ) && ( pad < 8 * len ) && ( nb -> bit < ( 8 * len - pad ) ) )  97
val = tvb_get_guint8 ( tvb , offset + nb -> bit / 8 ); 98
bitstring [ ( nb -> bit / 8 ) ] &= ~ ( 0x80 >> ( nb -> bit % 8 ) ); 99
val &= 0x80 >> ( nb -> bit % 8 ); 100
if ( val )  110
nb ++; 123
------------------------------
41 /home/speedy/test/source2slice/NVD/CVE-2016-2522_VULN_dissect_ber_constrained_bitstring.c end_offset = offset + len 53
dissect_ber_constrained_bitstring(gboolean implicit_tag, asn1_ctx_t *actx, proto_tree *parent_tree, tvbuff_t *tvb, int offset, gint32 min_len, gint32 max_len, const asn_namedbit *named_bits, gint hf_id, gint ett_id, tvbuff_t **out_tvb) 1
guint32 len , byteno ; 6
int end_offset ; 8
if ( ! implicit_tag )  17
len = tvb_reported_length_remaining ( tvb , offset ); 52
end_offset = offset + len; 53
return end_offset ; 149
------------------------------
42 /home/speedy/test/source2slice/NVD/CVE-2016-2522_VULN_dissect_ber_constrained_bitstring.c end_offset = offset + len 22
dissect_ber_constrained_bitstring(gboolean implicit_tag, asn1_ctx_t *actx, proto_tree *parent_tree, tvbuff_t *tvb, int offset, gint32 min_len, gint32 max_len, const asn_namedbit *named_bits, gint hf_id, gint ett_id, tvbuff_t **out_tvb) 1
guint32 len , byteno ; 6
int end_offset ; 8
if ( ! implicit_tag )  17
offset = dissect_ber_identifier ( actx -> pinfo , parent_tree , tvb , offset , & ber_class , & pc , & tag ); 20
offset = dissect_ber_length ( actx -> pinfo , parent_tree , tvb , offset , & len , & ind ); 21
end_offset = offset + len; 22
return end_offset ; 47
return end_offset ; 149
------------------------------
43 /home/speedy/test/source2slice/NVD/CVE-2016-3062_VULN_mov_read_dref.c sc -> drefs = av_mallocz ( entries * sizeof ( * sc -> drefs ) ) 18
static int mov_read_dref(MOVContext *c, AVIOContext *pb, MOVAtom atom) 1
AVStream * st ; 3
MOVStreamContext * sc ; 4
int entries , i , j ; 5
if ( c -> fc -> nb_streams < 1 )  7
st = c -> fc -> streams [ c -> fc -> nb_streams - 1 ]; 9
sc = st -> priv_data; 10
entries = avio_rb32 ( pb ); 13
if ( entries >= UINT_MAX / sizeof ( * sc -> drefs ) )  14
sc -> drefs_count = 0; 17
sc -> drefs = av_mallocz ( entries * sizeof ( * sc -> drefs ) ); 18
if ( ! sc -> drefs )  19
sc -> drefs_count = entries; 21
for (i = 0; i < sc->drefs_count; i++) 23
MOVDref * dref = & sc -> drefs [ i ] ; 24
dref -> type = avio_rl32 ( pb ); 31
av_dlog ( c -> fc , "type %.4s size %d\n" , ( char * ) & dref -> type , size ); 33
if ( dref -> type == MKTAG ( 'a' , 'l' , 'i' , 's' ) && size > 150 )  35
avio_read ( pb , dref -> volume , 27 ); 44
dref -> volume [ volume_len ] = 0; 45
av_log ( c -> fc , AV_LOG_DEBUG , "volume %s, len %d\n" , dref -> volume , volume_len ); 46
avio_read ( pb , dref -> filename , 63 ); 52
dref -> filename [ len ] = 0; 53
av_log ( c -> fc , AV_LOG_DEBUG , "filename %s, len %d\n" , dref -> filename , len ); 54
dref -> nlvl_from = avio_rb16 ( pb ); 59
dref -> nlvl_to = avio_rb16 ( pb ); 60
av_log ( c -> fc , AV_LOG_DEBUG , "nlvl from %d, nlvl to %d\n" , dref -> nlvl_from , dref -> nlvl_to ); 61
av_free ( dref -> path ); 75
dref -> path = av_mallocz ( len + 1 ); 76
if ( ! dref -> path )  77
avio_read ( pb , dref -> path , len ); 79
if ( len > volume_len && ! strncmp ( dref -> path , dref -> volume , volume_len ) )  80
memmove ( dref -> path , dref -> path + volume_len , len ); 82
dref -> path [ len ] = 0; 83
for (j = 0; j < len; j++) 85
if ( dref -> path [ j ] == ':' )  86
dref -> path [ j ] = '/'; 87
av_log ( c -> fc , AV_LOG_DEBUG , "path %s\n" , dref -> path ); 88
av_free ( dref -> dir ); 90
dref -> dir = av_malloc ( len + 1 ); 91
if ( ! dref -> dir )  92
avio_read ( pb , dref -> dir , len ); 94
dref -> dir [ len ] = 0; 95
for (j = 0; j < len; j++) 96
if ( dref -> dir [ j ] == ':' )  97
dref -> dir [ j ] = '/'; 98
av_log ( c -> fc , AV_LOG_DEBUG , "dir %s\n" , dref -> dir ); 99
------------------------------
44 /home/speedy/test/source2slice/NVD/CVE-2016-4952_VULN_pvscsi_ring_init_data.c cmp_ring_size = ri -> cmpRingNumPages * PVSCSI_MAX_NUM_CMP_ENTRIES_PER_PAGE 9
pvscsi_ring_init_data(PVSCSIRingInfo *m, PVSCSICmdDescSetupRings *ri) 1
uint32_t req_ring_size , cmp_ring_size ; 5
cmp_ring_size = ri -> cmpRingNumPages * PVSCSI_MAX_NUM_CMP_ENTRIES_PER_PAGE; 9
rxr_len_log2 = pvscsi_log2 ( cmp_ring_size - 1 ); 11
m -> rxr_len_mask = MASK ( rxr_len_log2 ); 14
m -> consumed_ptr = 0; 16
m -> filled_cmp_ptr = 0; 17
m -> req_ring_pages_pa [ i ] = ri -> reqRingPPNs [ i ] << VMW_PAGE_SHIFT; 20
for (i = 0; i < ri->cmpRingNumPages; i++) 23
m -> cmp_ring_pages_pa [ i ] = ri -> cmpRingPPNs [ i ] << VMW_PAGE_SHIFT; 24
RS_SET_FIELD ( m , reqProdIdx , 0 ); 27
RS_SET_FIELD ( m , reqConsIdx , 0 ); 28
RS_SET_FIELD ( m , reqNumEntriesLog2 , txr_len_log2 ); 29
RS_SET_FIELD ( m , cmpProdIdx , 0 ); 31
RS_SET_FIELD ( m , cmpConsIdx , 0 ); 32
RS_SET_FIELD ( m , cmpNumEntriesLog2 , rxr_len_log2 ); 33
trace_pvscsi_ring_init_data ( txr_len_log2 , rxr_len_log2 ); 35
------------------------------
45 /home/speedy/test/source2slice/NVD/CVE-2016-4952_VULN_pvscsi_ring_init_data.c req_ring_size = ri -> reqRingNumPages * PVSCSI_MAX_NUM_REQ_ENTRIES_PER_PAGE 8
pvscsi_ring_init_data(PVSCSIRingInfo *m, PVSCSICmdDescSetupRings *ri) 1
uint32_t req_ring_size , cmp_ring_size ; 5
req_ring_size = ri -> reqRingNumPages * PVSCSI_MAX_NUM_REQ_ENTRIES_PER_PAGE; 8
txr_len_log2 = pvscsi_log2 ( req_ring_size - 1 ); 10
m -> txr_len_mask = MASK ( txr_len_log2 ); 13
m -> rxr_len_mask = MASK ( rxr_len_log2 ); 14
m -> consumed_ptr = 0; 16
m -> filled_cmp_ptr = 0; 17
m -> req_ring_pages_pa [ i ] = ri -> reqRingPPNs [ i ] << VMW_PAGE_SHIFT; 20
for (i = 0; i < ri->cmpRingNumPages; i++) 23
m -> cmp_ring_pages_pa [ i ] = ri -> cmpRingPPNs [ i ] << VMW_PAGE_SHIFT; 24
RS_SET_FIELD ( m , reqProdIdx , 0 ); 27
RS_SET_FIELD ( m , reqConsIdx , 0 ); 28
RS_SET_FIELD ( m , reqNumEntriesLog2 , txr_len_log2 ); 29
RS_SET_FIELD ( m , cmpProdIdx , 0 ); 31
RS_SET_FIELD ( m , cmpConsIdx , 0 ); 32
RS_SET_FIELD ( m , cmpNumEntriesLog2 , rxr_len_log2 ); 33
trace_pvscsi_ring_init_data ( txr_len_log2 , rxr_len_log2 ); 35
------------------------------
46 /home/speedy/test/source2slice/NVD/CVE-2016-5829_VULN_hiddev_ioctl_usage.c uref_multi -> values [ i ] = field -> value [ uref -> usage_index + i ] 95
static noinline int hiddev_ioctl_usage(struct hiddev *hiddev, unsigned int cmd, void __user *user_arg) 1
struct hid_device * hid = hiddev -> hid ; 3
struct hiddev_report_info rinfo ; 4
struct hiddev_usage_ref * uref ; 6
struct hid_report * report ; 7
struct hid_field * field ; 8
int i ; 9
uref_multi = kmalloc ( sizeof ( struct hiddev_usage_ref_multi ) , GFP_KERNEL ); 11
if ( ! uref_multi )  12
uref = & uref_multi -> uref; 14
if ( cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES )  15
if ( copy_from_user ( uref_multi , user_arg , sizeof ( * uref_multi ) ) )  16
if ( copy_from_user ( uref , user_arg , sizeof ( * uref ) ) )  20
switch ( cmd )  24
rinfo . report_type = uref -> report_type; 26
rinfo . report_id = uref -> report_id; 27
if ( ( report = hiddev_lookup_report ( hid , & rinfo ) ) == NULL )  28
if ( uref -> field_index >= report -> maxfield )  31
field = report -> field [ uref -> field_index ]; 34
if ( uref -> usage_index >= field -> maxusage )  35
uref -> usage_code = field -> usage [ uref -> usage_index ] . hid; 38
if ( cmd != HIDIOCGUSAGE && cmd != HIDIOCGUSAGES && uref -> report_type == HID_REPORT_TYPE_INPUT )  46
if ( uref -> report_id == HID_REPORT_ID_UNKNOWN )  51
field = hiddev_lookup_usage ( hid , uref ); 52
if ( field == NULL )  53
rinfo . report_type = uref -> report_type; 56
rinfo . report_id = uref -> report_id; 57
if ( ( report = hiddev_lookup_report ( hid , & rinfo ) ) == NULL )  58
if ( uref -> field_index >= report -> maxfield )  61
field = report -> field [ uref -> field_index ]; 64
if ( cmd == HIDIOCGCOLLECTIONINDEX )  66
if ( uref -> usage_index >= field -> maxusage )  67
if ( uref -> usage_index >= field -> report_count )  69
if ( ( cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES ) && ( uref_multi -> num_values > HID_MAX_MULTI_USAGES || uref -> usage_index + uref_multi -> num_values > field -> report_count ) )  72
switch ( cmd )  78
uref -> value = field -> value [ uref -> usage_index ]; 80
field -> value [ uref -> usage_index ] = uref -> value; 86
i = field -> usage [ uref -> usage_index ] . collection_index; 90
for (i = 0; i < uref_multi->num_values; i++) 94
uref_multi -> values [ i ] = field -> value [ uref -> usage_index + i ]; 95
if ( copy_to_user ( user_arg , uref_multi , sizeof ( * uref_multi ) ) )  97
for (i = 0; i < uref_multi->num_values; i++) 102
field -> value [ uref -> usage_index + i ] = uref_multi -> values [ i ]; 103
kfree ( uref_multi ); 109
kfree ( uref_multi ); 112
kfree ( uref_multi ); 115
------------------------------
47 /home/speedy/test/source2slice/NVD/CVE-2016-7042_VULN_proc_keys_show.c timo = key -> expiry - now . tv_sec 53
static int proc_keys_show(struct seq_file *m, void *v) 1
struct key * key = rb_entry ( _p , struct key , serial_node ) 4
struct timespec now ; 5
unsigned long timo ; 6
key_ref_t key_ref , skey_ref ; 7
int rc ; 9
struct keyring_search_context ctx =
. index_key . type = key -> type ,
. index_key . description = key -> description ,
. cred = current_cred ( ) ,
. match_data . cmp = lookup_user_key_possessed ,
. match_data . raw_data = key ,
. match_data . lookup_type = KEYRING_SEARCH_LOOKUP_DIRECT ,
. flags = KEYRING_SEARCH_NO_STATE_CHECK , 18
key_ref = make_key_ref ( key , 0 ); 21
if ( key -> perm & KEY_POS_VIEW )  26
skey_ref = search_my_process_keyrings ( & ctx ); 27
if ( ! IS_ERR ( skey_ref ) )  28
key_ref = make_key_ref ( key , 1 ); 30
rc = key_task_permission ( key_ref , ctx . cred , KEY_NEED_VIEW ); 39
if ( rc < 0 )  40
now = current_kernel_time ( ); 43
if ( key -> expiry == 0 )  48
if ( now . tv_sec >= key -> expiry )  50
timo = key -> expiry - now . tv_sec; 53
if ( timo < 60 )  55
sprintf ( xbuf , "%lus" , timo ); 56
if ( timo < 60 * 60 )  57
sprintf ( xbuf , "%lum" , timo / 60 ); 58
if ( timo < 60 * 60 * 24 )  59
sprintf ( xbuf , "%luh" , timo / ( 60 * 60 ) ); 60
if ( timo < 60 * 60 * 24 * 7 )  61
sprintf ( xbuf , "%lud" , timo / ( 60 * 60 * 24 ) ); 62
sprintf ( xbuf , "%luw" , timo / ( 60 * 60 * 24 * 7 ) ); 64
seq_printf ( m , "%08x %c%c%c%c%c%c%c %5d %4s %08x %5d %5d %-9.9s " , key -> serial , showflag ( key , 'I' , KEY_FLAG_INSTANTIATED ) , showflag ( key , 'R' , KEY_FLAG_REVOKED ) , showflag ( key , 'D' , KEY_FLAG_DEAD ) , showflag ( key , 'Q' , KEY_FLAG_IN_QUOTA ) , showflag ( key , 'U' , KEY_FLAG_USER_CONSTRUCT ) , showflag ( key , 'N' , KEY_FLAG_NEGATIVE ) , showflag ( key , 'i' , KEY_FLAG_INVALIDATED ) , atomic_read ( & key -> usage ) , xbuf , key -> perm , from_kuid_munged ( seq_user_ns ( m ) , key -> uid ) , from_kgid_munged ( seq_user_ns ( m ) , key -> gid ) , key -> type -> name ); 70
------------------------------
48 /home/speedy/test/source2slice/NVD/CVE-2016-7170_VULN_vmsvga_fifo_run.c args = x * y 121
static void vmsvga_fifo_run(struct vmsvga_state_s *s) 1
uint32_t cmd , colour ; 3
int args , len ; 4
int x , y , dx , dy , width , height ; 5
struct vmsvga_cursor_definition_s cursor ; 6
len = vmsvga_fifo_length ( s ); 9
static inline int vmsvga_fifo_length(struct vmsvga_state_s *s) 1
int num ; 3
if ( ! s -> config || ! s -> enable )  5
return 0 ; 6
num = CMD ( next_cmd ) - CMD ( stop ); 8
if ( num < 0 )  9
num += CMD ( max ) - CMD ( min ); 10
return num >> 2 ; 12
while ( len > 0 )  10
switch ( cmd = vmsvga_fifo_read ( s ) )  14
len -= 5; 17
if ( len < 0 )  18
len -= 6; 30
if ( len < 0 )  31
colour = vmsvga_fifo_read ( s ); 35
x = vmsvga_fifo_read ( s ); 36
y = vmsvga_fifo_read ( s ); 37
width = vmsvga_fifo_read ( s ); 38
height = vmsvga_fifo_read ( s ); 39
if ( vmsvga_fill_rect ( s , colour , x , y , width , height ) == 0 )  41
args = 0; 45
len -= 7; 49
if ( len < 0 )  50
x = vmsvga_fifo_read ( s ); 54
y = vmsvga_fifo_read ( s ); 55
dx = vmsvga_fifo_read ( s ); 56
dy = vmsvga_fifo_read ( s ); 57
width = vmsvga_fifo_read ( s ); 58
height = vmsvga_fifo_read ( s ); 59
if ( vmsvga_copy_rect ( s , x , y , dx , dy , width , height ) == 0 )  61
args = 0; 65
len -= 8; 69
if ( len < 0 )  70
cursor . id = vmsvga_fifo_read ( s ); 74
cursor . hot_x = vmsvga_fifo_read ( s ); 75
cursor . hot_y = vmsvga_fifo_read ( s ); 76
cursor . width = x = vmsvga_fifo_read ( s ); 77
cursor . height = y = vmsvga_fifo_read ( s ); 78
cursor . bpp = vmsvga_fifo_read ( s ); 80
args = SVGA_BITMAP_SIZE ( x , y ) + SVGA_PIXMAP_SIZE ( x , y , cursor . bpp ); 82
if ( SVGA_BITMAP_SIZE ( x , y ) > sizeof cursor . mask || SVGA_PIXMAP_SIZE ( x , y , cursor . bpp ) > sizeof cursor . image )  83
len -= args; 88
if ( len < 0 )  89
for (args = 0; args < SVGA_BITMAP_SIZE(x, y); args++) 93
cursor . mask [ args ] = vmsvga_fifo_read_raw ( s ); 94
for (args = 0; args < SVGA_PIXMAP_SIZE(x, y, cursor.bpp); args++) 96
cursor . image [ args ] = vmsvga_fifo_read_raw ( s ); 97
len -= 6; 112
if ( len < 0 )  113
x = vmsvga_fifo_read ( s ); 119
y = vmsvga_fifo_read ( s ); 120
args = x * y; 121
args = 6; 124
args = 7; 127
len -= 4; 130
if ( len < 0 )  131
args = 7 + ( vmsvga_fifo_read ( s ) >> 2 ); 136
args = 12; 139
args = 0; 154
len -= args; 156
if ( len < 0 )  157
while ( args -- )  160
------------------------------
49 /home/speedy/test/source2slice/NVD/CVE-2016-8658_VULN_brcmf_cfg80211_start_ap.c ssid_ie = brcmf_parse_tlvs ( ( u8 * ) & settings -> beacon . head [ ie_offset ] , settings -> beacon . head_len - ie_offset , WLAN_EID_SSID ) 40
brcmf_cfg80211_start_ap(struct wiphy *wiphy, struct net_device *ndev,
struct cfg80211_ap_settings *settings) 2
s32 ie_offset ; 4
const struct brcmf_tlv * ssid_ie ; 7
if ( settings -> ssid == NULL || settings -> ssid_len == 0 )  38
ie_offset = DOT11_MGMT_HDR_LEN + DOT11_BCN_PRB_FIXED_LEN; 39
ssid_ie = brcmf_parse_tlvs ( ( u8 * ) & settings -> beacon . head [ ie_offset ] , settings -> beacon . head_len - ie_offset , WLAN_EID_SSID ); 40
if ( ! ssid_ie )  44
memcpy ( ssid_le . SSID , ssid_ie -> data , ssid_ie -> len ); 47
ssid_le . SSID_len = cpu_to_le32 ( ssid_ie -> len ); 48
brcmf_dbg ( TRACE , "SSID is (%s) in Head\n" , ssid_le . SSID ); 49
------------------------------
50 /home/speedy/test/source2slice/NVD/CVE-2016-8658_VULN_brcmf_cfg80211_start_ap.c ie_offset = DOT11_MGMT_HDR_LEN + DOT11_BCN_PRB_FIXED_LEN 39
brcmf_cfg80211_start_ap(struct wiphy *wiphy, struct net_device *ndev,
struct cfg80211_ap_settings *settings) 2
s32 ie_offset ; 4
if ( settings -> ssid == NULL || settings -> ssid_len == 0 )  38
ie_offset = DOT11_MGMT_HDR_LEN + DOT11_BCN_PRB_FIXED_LEN; 39
ssid_ie = brcmf_parse_tlvs ( ( u8 * ) & settings -> beacon . head [ ie_offset ] , settings -> beacon . head_len - ie_offset , WLAN_EID_SSID ); 40
if ( ! ssid_ie )  44
memcpy ( ssid_le . SSID , ssid_ie -> data , ssid_ie -> len ); 47
ssid_le . SSID_len = cpu_to_le32 ( ssid_ie -> len ); 48
brcmf_dbg ( TRACE , "SSID is (%s) in Head\n" , ssid_le . SSID ); 49
------------------------------
51 /home/speedy/test/source2slice/NVD/CVE-2016-9685_VULN_xfs_attr_shortform_list.c sbsize = sf -> hdr . count * sizeof ( * sbuf ) 66
xfs_attr_shortform_list(xfs_attr_list_context_t *context) 1
attrlist_cursor_kern_t * cursor ; 3
xfs_attr_sf_sort_t * sbuf , * sbp ; 4
xfs_attr_shortform_t * sf ; 5
xfs_inode_t * dp ; 7
int sbsize , nsbuf , count , i ; 8
dp = context -> dp; 12
sf = ( xfs_attr_shortform_t * ) dp -> i_afp -> if_u1 . if_data; 15
if ( ! sf -> hdr . count )  17
cursor = context -> cursor; 19
if ( context -> bufsize == 0 || ( XFS_ISRESET_CURSOR ( cursor ) && ( dp -> i_afp -> if_bytes + sf -> hdr . count * 16 ) < context -> bufsize ) )  33
if ( context -> bufsize == 0 )  60
sbsize = sf -> hdr . count * sizeof ( * sbuf ); 66
sbp = sbuf = kmem_alloc ( sbsize , KM_SLEEP | KM_NOFS ); 67
kmem_free ( sbuf ); 81
sbp -> entno = i; 85
sbp -> hash = xfs_da_hashname ( sfe -> nameval , sfe -> namelen ); 86
sbp -> name = sfe -> nameval; 87
sbp -> namelen = sfe -> namelen; 88
sbp -> valuelen = sfe -> valuelen; 90
sbp -> flags = sfe -> flags; 91
sbp ++; 93
xfs_sort ( sbuf , nsbuf , sizeof ( * sbuf ) , xfs_attr_shortform_compare ); 100
for (sbp = sbuf, i = 0; i < nsbuf; i++, sbp++) 108
if ( sbp -> hash == cursor -> hashval )  109
if ( sbp -> hash > cursor -> hashval )  114
if ( i == nsbuf )  118
kmem_free ( sbuf ); 119
for ( ; i < nsbuf; i++, sbp++) 126
if ( cursor -> hashval != sbp -> hash )  127
cursor -> hashval = sbp -> hash; 128
cursor -> offset = 0; 129
error = context -> put_listent ( context , sbp -> flags , sbp -> name , sbp -> namelen , sbp -> valuelen , & sbp -> name [ sbp -> namelen ] ); 131
if ( error )  137
return error ; 138
cursor -> offset ++; 141
kmem_free ( sbuf ); 144
------------------------------
52 /home/speedy/test/source2slice/NVD/CVE-2016-9793_VULN_sock_setsockopt.c sk -> sk_lingertime = ( unsigned int ) ling . l_linger * HZ 149
int sock_setsockopt(struct socket *sock, int level, int optname,
char __user *optval, unsigned int optlen) 2
struct sock * sk = sock -> sk ; 4
int val ; 5
struct linger ling ; 7
if ( optname == SO_BINDTODEVICE )  14
if ( optlen < sizeof ( int ) )  17
if ( get_user ( val , ( int __user * ) optval ) )  20
switch ( optname )  27
if ( optlen < sizeof ( ling ) )  133
if ( copy_from_user ( & ling , optval , sizeof ( ling ) ) )  137
if ( ! ling . l_onoff )  141
if ( ( unsigned int ) ling . l_linger >= MAX_SCHEDULE_TIMEOUT / HZ )  145
sk -> sk_lingertime = ( unsigned int ) ling . l_linger * HZ; 149
sock_set_flag ( sk , SOCK_LINGER ); 150
------------------------------
53 /home/speedy/test/source2slice/NVD/CVE_2005_4886_PATCHED_selinux_parse_skb_ipv6.c offset = skb -> nh . raw - skb -> data 7
static int CVE_2005_4886_PATCHED_selinux_parse_skb_ipv6(struct sk_buff *skb, struct avc_audit_data *ad) 1
offset = skb -> nh . raw - skb -> data; 7
ip6 = skb_header_pointer ( skb , offset , sizeof ( _ipv6h ) , & _ipv6h ); 8
if ( ip6 == NULL )  9
ipv6_addr_copy ( & ad -> u . net . v6info . saddr , & ip6 -> saddr ); 12
ipv6_addr_copy ( & ad -> u . net . v6info . daddr , & ip6 -> daddr ); 13
nexthdr = ip6 -> nexthdr; 16
offset += sizeof ( _ipv6h ); 17
offset = ipv6_skip_exthdr ( skb , offset , & nexthdr ); 18
if ( offset < 0 )  19
switch ( nexthdr )  22
th = skb_header_pointer ( skb , offset , sizeof ( _tcph ) , & _tcph ); 26
if ( th == NULL )  27
ad -> u . net . sport = th -> source; 30
ad -> u . net . dport = th -> dest; 31
uh = skb_header_pointer ( skb , offset , sizeof ( _udph ) , & _udph ); 38
if ( uh == NULL )  39
ad -> u . net . sport = uh -> source; 42
ad -> u . net . dport = uh -> dest; 43
------------------------------
54 /home/speedy/test/source2slice/NVD/CVE_2005_4886_VULN_selinux_parse_skb_ipv6.c offset = ipv6_skip_exthdr ( skb , offset , & nexthdr , skb -> tail - skb -> head - offset ) 18
static int CVE_2005_4886_VULN_selinux_parse_skb_ipv6(struct sk_buff *skb, struct avc_audit_data *ad) 1
u8 nexthdr ; 3
struct ipv6hdr _ipv6h , * ip6 ; 5
offset = skb -> nh . raw - skb -> data; 7
ip6 = skb_header_pointer ( skb , offset , sizeof ( _ipv6h ) , & _ipv6h ); 8
if ( ip6 == NULL )  9
nexthdr = ip6 -> nexthdr; 16
offset += sizeof ( _ipv6h ); 17
offset = ipv6_skip_exthdr ( skb , offset , & nexthdr , skb -> tail - skb -> head - offset ); 18
if ( offset < 0 )  20
th = skb_header_pointer ( skb , offset , sizeof ( _tcph ) , & _tcph ); 27
if ( th == NULL )  28
ad -> u . net . sport = th -> source; 31
ad -> u . net . dport = th -> dest; 32
uh = skb_header_pointer ( skb , offset , sizeof ( _udph ) , & _udph ); 39
if ( uh == NULL )  40
ad -> u . net . sport = uh -> source; 43
ad -> u . net . dport = uh -> dest; 44
------------------------------
55 /home/speedy/test/source2slice/NVD/CVE_2005_4886_VULN_selinux_parse_skb_ipv6.c offset = skb -> nh . raw - skb -> data 7
static int CVE_2005_4886_VULN_selinux_parse_skb_ipv6(struct sk_buff *skb, struct avc_audit_data *ad) 1
offset = skb -> nh . raw - skb -> data; 7
ip6 = skb_header_pointer ( skb , offset , sizeof ( _ipv6h ) , & _ipv6h ); 8
if ( ip6 == NULL )  9
ipv6_addr_copy ( & ad -> u . net . v6info . saddr , & ip6 -> saddr ); 12
ipv6_addr_copy ( & ad -> u . net . v6info . daddr , & ip6 -> daddr ); 13
nexthdr = ip6 -> nexthdr; 16
offset += sizeof ( _ipv6h ); 17
offset = ipv6_skip_exthdr ( skb , offset , & nexthdr , skb -> tail - skb -> head - offset ); 18
if ( offset < 0 )  20
switch ( nexthdr )  23
th = skb_header_pointer ( skb , offset , sizeof ( _tcph ) , & _tcph ); 27
if ( th == NULL )  28
ad -> u . net . sport = th -> source; 31
ad -> u . net . dport = th -> dest; 32
uh = skb_header_pointer ( skb , offset , sizeof ( _udph ) , & _udph ); 39
if ( uh == NULL )  40
ad -> u . net . sport = uh -> source; 43
ad -> u . net . dport = uh -> dest; 44
------------------------------
56 /home/speedy/test/source2slice/NVD/CVE_2006_2778_PATCHED_nsCrypto__SignText.c rv = encoder -> Init ( charset . get ( ) , ( nsISaveAsCharset :: attr_EntityAfterCharsetConv + nsISaveAsCharset :: attr_FallbackDecimalNCR ) , 0 ) 284
NS_IMETHODIMP
CVE_2006_2778_PATCHED_nsCrypto::SignText(const nsAString& aStringToSign, const nsAString& aCaOption,
nsAString& aResult) 3
nsCOMPtr < nsIXPCNativeCallContext > ncc ; 11
if ( ! ncc )  17
PRUint32 argc ; 23
JSContext * cx ; 26
if ( ! cx )  28
if ( ! aCaOption . Equals ( NS_LITERAL_STRING ( "auto" ) ) && ! aCaOption . Equals ( NS_LITERAL_STRING ( "ask" ) ) )  34
nsCOMPtr < nsIInterfaceRequestor > uiContext = new PipUIContext 46
if ( ! uiContext )  47
PRBool bestOnly = PR_TRUE ; 53
PRBool validOnly = PR_TRUE ; 54
CERTCertList * certList = CERT_FindUserCertsByUsage ( CERT_GetDefaultCertDB ( ) , certUsageEmailSigner , bestOnly , validOnly , uiContext ) ; 55
PRUint32 numCAs = argc - 2 ; 59
if ( numCAs > 0 )  60
if ( ! caNames )  62
jsval * argv = nsnull ; 68
PRUint32 i ; 71
for (i = 2; i < argc; ++i) 72
JSString * caName = JS_ValueToString ( cx , argv [ i ] ) ; 73
if ( ! caName )  74
caNames [ i - 2 ] = JS_GetStringBytes ( caName ); 79
if ( certList && CERT_FilterCertListByCANames ( certList , numCAs , caNames , certUsageEmailSigner ) != SECSuccess )  82
if ( ! certList || CERT_LIST_EMPTY ( certList ) )  91
nsCOMPtr < nsIFormSigningDialog > fsd = do_CreateInstance ( NS_FORMSIGNINGDIALOG_CONTRACTID ) ; 97
if ( ! fsd )  99
nsCOMPtr < nsIProxyObjectManager > proxyman = do_GetService ( NS_XPCOMPROXY_CONTRACTID ) ; 105
if ( ! proxyman )  107
nsCOMPtr < nsIFormSigningDialog > proxied_fsd ; 113
nsresult rv = proxyman -> GetProxyForObject ( NS_UI_THREAD_EVENTQ , NS_GET_IID ( nsIFormSigningDialog ) , fsd , PROXY_SYNC , getter_AddRefs ( proxied_fsd ) ) ; 114
if ( NS_FAILED ( rv ) )  118
nsCOMPtr < nsIDocument > document ; 124
if ( ! document )  126
nsIURI * uri = document -> GetDocumentURI ( ) ; 133
if ( ! uri )  134
nsCString host ; 140
rv = uri -> GetHost ( host ); 141
if ( NS_FAILED ( rv ) )  142
CERTCertListNode * node ; 149
for (node = CERT_LIST_HEAD(certList); !CERT_LIST_END(node, certList);
node = CERT_LIST_NEXT(node)) 151
CERTCertNicknames * nicknames = CERT_NicknameStringsFromCertList ( certList , NICKNAME_EXPIRED_STRING , NICKNAME_NOT_YET_VALID_STRING ) ; 155
if ( ! nicknames )  158
if ( ! certNicknameList )  170
PRUnichar * * certDetailsList = certNicknameList . get ( ) + nicknames -> numnicknames ; 176
PRInt32 certsToUse ; 178
for (node = CERT_LIST_HEAD(certList), certsToUse = 0;
!CERT_LIST_END(node, certList) && certsToUse < nicknames->numnicknames;
node = CERT_LIST_NEXT(node)) 181
nsRefPtr < nsNSSCertificate > tempCert = new nsNSSCertificate ( node -> cert ) ; 182
if ( tempCert )  183
nsAutoString nickWithSerial , details ; 184
rv = tempCert -> FormatUIStrings ( NS_ConvertUTF8toUTF16 ( nicknames -> nicknames [ certsToUse ] ) , nickWithSerial , details ); 185
if ( NS_SUCCEEDED ( rv ) )  187
certNicknameList [ certsToUse ] = ToNewUnicode ( nickWithSerial ); 188
if ( certNicknameList [ certsToUse ] )  189
certDetailsList [ certsToUse ] = ToNewUnicode ( details ); 190
if ( ! certDetailsList [ certsToUse ] )  191
if ( certsToUse == 0 )  201
CERTCertificate * signingCert = nsnull ; 209
PRBool tryAgain , canceled ; 210
PRInt32 selectedIndex = - 1 ; 215
rv = proxied_fsd -> ConfirmSignText ( uiContext , utf16Host , aStringToSign ,
NS_CONST_CAST ( const PRUnichar * * , certNicknameList . get ( ) ) ,
NS_CONST_CAST ( const PRUnichar * * , certDetailsList ) ,
certsToUse , & selectedIndex , password ,
& canceled ) 220
if ( NS_FAILED ( rv ) || canceled )  221
PRInt32 j = 0 ; 225
for (node = CERT_LIST_HEAD(certList); !CERT_LIST_END(node, certList);
node = CERT_LIST_NEXT(node)) 227
if ( j == selectedIndex )  228
signingCert = CERT_DupCertificate ( node -> cert ); 229
if ( ! signingCert )  235
rv = NS_ERROR_FAILURE; 236
tryAgain =
PK11_CheckUserPassword ( signingCert -> slot ,
NS_CONST_CAST ( char * , pwUtf8 . get ( ) ) ) != SECSuccess 244
while ( tryAgain )  246
if ( NS_FAILED ( rv ) )  254
if ( canceled )  260
SECKEYPrivateKey * privKey = PK11_FindKeyByAnyCert ( signingCert , uiContext ) ; 266
if ( ! privKey )  267
nsCAutoString charset ( document -> GetDocumentCharacterSet ( ) ) ; 273
nsCOMPtr < nsISaveAsCharset > encoder = do_CreateInstance ( NS_SAVEASCHARSET_CONTRACTID ) ; 281
if ( encoder )  283
rv = encoder -> Init ( charset . get ( ) , ( nsISaveAsCharset :: attr_EntityAfterCharsetConv + nsISaveAsCharset :: attr_FallbackDecimalNCR ) , 0 ); 284
if ( encoder && NS_SUCCEEDED ( rv ) )  292
if ( NS_FAILED ( rv ) )  295
------------------------------
57 /home/speedy/test/source2slice/NVD/CVE_2006_2778_VULN_nsCrypto__SignText.c rv = encoder -> Init ( charset . get ( ) , ( nsISaveAsCharset :: attr_EntityAfterCharsetConv + nsISaveAsCharset :: attr_FallbackDecimalNCR ) , 0 ) 284
NS_IMETHODIMP
CVE_2006_2778_VULN_nsCrypto::SignText(const nsAString& aStringToSign, const nsAString& aCaOption,
nsAString& aResult) 3
nsCOMPtr < nsIXPCNativeCallContext > ncc ; 11
if ( ! ncc )  17
PRUint32 argc ; 23
JSContext * cx ; 26
if ( ! cx )  28
if ( ! aCaOption . Equals ( NS_LITERAL_STRING ( "auto" ) ) && ! aCaOption . Equals ( NS_LITERAL_STRING ( "ask" ) ) )  34
nsCOMPtr < nsIInterfaceRequestor > uiContext = new PipUIContext 46
if ( ! uiContext )  47
PRBool bestOnly = PR_TRUE ; 53
PRBool validOnly = PR_TRUE ; 54
CERTCertList * certList = CERT_FindUserCertsByUsage ( CERT_GetDefaultCertDB ( ) , certUsageEmailSigner , bestOnly , validOnly , uiContext ) ; 55
PRUint32 numCAs = argc - 2 ; 59
if ( numCAs > 0 )  60
if ( ! caNames )  62
jsval * argv = nsnull ; 68
PRUint32 i ; 71
for (i = 2; i < argc; ++i) 72
JSString * caName = JS_ValueToString ( cx , argv [ i ] ) ; 73
if ( ! caName )  74
caNames [ i ] = JS_GetStringBytes ( caName ); 79
if ( certList && CERT_FilterCertListByCANames ( certList , numCAs , caNames , certUsageEmailSigner ) != SECSuccess )  82
if ( ! certList || CERT_LIST_EMPTY ( certList ) )  91
nsCOMPtr < nsIFormSigningDialog > fsd = do_CreateInstance ( NS_FORMSIGNINGDIALOG_CONTRACTID ) ; 97
if ( ! fsd )  99
nsCOMPtr < nsIProxyObjectManager > proxyman = do_GetService ( NS_XPCOMPROXY_CONTRACTID ) ; 105
if ( ! proxyman )  107
nsCOMPtr < nsIFormSigningDialog > proxied_fsd ; 113
nsresult rv = proxyman -> GetProxyForObject ( NS_UI_THREAD_EVENTQ , NS_GET_IID ( nsIFormSigningDialog ) , fsd , PROXY_SYNC , getter_AddRefs ( proxied_fsd ) ) ; 114
if ( NS_FAILED ( rv ) )  118
nsCOMPtr < nsIDocument > document ; 124
if ( ! document )  126
nsIURI * uri = document -> GetDocumentURI ( ) ; 133
if ( ! uri )  134
nsCString host ; 140
rv = uri -> GetHost ( host ); 141
if ( NS_FAILED ( rv ) )  142
CERTCertListNode * node ; 149
for (node = CERT_LIST_HEAD(certList); !CERT_LIST_END(node, certList);
node = CERT_LIST_NEXT(node)) 151
CERTCertNicknames * nicknames = CERT_NicknameStringsFromCertList ( certList , NICKNAME_EXPIRED_STRING , NICKNAME_NOT_YET_VALID_STRING ) ; 155
if ( ! nicknames )  158
if ( ! certNicknameList )  170
PRUnichar * * certDetailsList = certNicknameList . get ( ) + nicknames -> numnicknames ; 176
PRInt32 certsToUse ; 178
for (node = CERT_LIST_HEAD(certList), certsToUse = 0;
!CERT_LIST_END(node, certList) && certsToUse < nicknames->numnicknames;
node = CERT_LIST_NEXT(node)) 181
nsRefPtr < nsNSSCertificate > tempCert = new nsNSSCertificate ( node -> cert ) ; 182
if ( tempCert )  183
nsAutoString nickWithSerial , details ; 184
rv = tempCert -> FormatUIStrings ( NS_ConvertUTF8toUTF16 ( nicknames -> nicknames [ certsToUse ] ) , nickWithSerial , details ); 185
if ( NS_SUCCEEDED ( rv ) )  187
certNicknameList [ certsToUse ] = ToNewUnicode ( nickWithSerial ); 188
if ( certNicknameList [ certsToUse ] )  189
certDetailsList [ certsToUse ] = ToNewUnicode ( details ); 190
if ( ! certDetailsList [ certsToUse ] )  191
if ( certsToUse == 0 )  201
CERTCertificate * signingCert = nsnull ; 209
PRBool tryAgain , canceled ; 210
PRInt32 selectedIndex = - 1 ; 215
rv = proxied_fsd -> ConfirmSignText ( uiContext , utf16Host , aStringToSign ,
NS_CONST_CAST ( const PRUnichar * * , certNicknameList . get ( ) ) ,
NS_CONST_CAST ( const PRUnichar * * , certDetailsList ) ,
certsToUse , & selectedIndex , password ,
& canceled ) 220
if ( NS_FAILED ( rv ) || canceled )  221
PRInt32 j = 0 ; 225
for (node = CERT_LIST_HEAD(certList); !CERT_LIST_END(node, certList);
node = CERT_LIST_NEXT(node)) 227
if ( j == selectedIndex )  228
signingCert = CERT_DupCertificate ( node -> cert ); 229
if ( ! signingCert )  235
rv = NS_ERROR_FAILURE; 236
tryAgain =
PK11_CheckUserPassword ( signingCert -> slot ,
NS_CONST_CAST ( char * , pwUtf8 . get ( ) ) ) != SECSuccess 244
while ( tryAgain )  246
if ( NS_FAILED ( rv ) )  254
if ( canceled )  260
SECKEYPrivateKey * privKey = PK11_FindKeyByAnyCert ( signingCert , uiContext ) ; 266
if ( ! privKey )  267
nsCAutoString charset ( document -> GetDocumentCharacterSet ( ) ) ; 273
nsCOMPtr < nsISaveAsCharset > encoder = do_CreateInstance ( NS_SAVEASCHARSET_CONTRACTID ) ; 281
if ( encoder )  283
rv = encoder -> Init ( charset . get ( ) , ( nsISaveAsCharset :: attr_EntityAfterCharsetConv + nsISaveAsCharset :: attr_FallbackDecimalNCR ) , 0 ); 284
if ( encoder && NS_SUCCEEDED ( rv ) )  292
if ( NS_FAILED ( rv ) )  295
------------------------------
58 /home/speedy/test/source2slice/NVD/CVE_2006_3741_PATCHED_sys_perfmonctl.c sz = xtra_sz + base_sz * count 50
asmlinkage long
CVE_2006_3741_PATCHED_sys_perfmonctl (int fd, int cmd, void __user *arg, int count) 2
void * args_k = NULL ; 7
long ret ; 8
size_t base_sz , sz , xtra_sz = 0 ; 9
int narg , completed_args = 0 , call_made = 0 , cmd_flags ; 10
if ( unlikely ( pmu_conf == NULL ) )  18
if ( unlikely ( cmd < 0 || cmd >= PFM_CMD_COUNT ) )  20
func = pfm_cmd_tab [ cmd ] . cmd_func; 25
narg = pfm_cmd_tab [ cmd ] . cmd_narg; 26
base_sz = pfm_cmd_tab [ cmd ] . cmd_argsize; 27
getsize = pfm_cmd_tab [ cmd ] . cmd_getsize; 28
if ( unlikely ( func == NULL ) )  31
if ( unlikely ( ( narg == PFM_CMD_ARG_MANY && count <= 0 ) || ( narg > 0 && narg != count ) ) )  46
sz = xtra_sz + base_sz * count; 50
if ( unlikely ( sz > PFM_MAX_ARGSIZE ) )  54
printk ( KERN_ERR "perfmon: [%d] argument too big %lu\n" , current -> pid , sz ) 55
if ( likely ( count && args_k == NULL ) )  62
args_k = kmalloc ( PFM_MAX_ARGSIZE , GFP_KERNEL ); 63
if ( args_k == NULL )  64
ret = - EFAULT; 67
if ( sz && copy_from_user ( args_k , arg , sz ) )  74
DPRINT ( ( "cannot copy_from_user %lu bytes @%p\n" , sz , arg ) ); 75
if ( completed_args == 0 && getsize )  82
ret = ( * getsize ) ( args_k , & xtra_sz ); 86
if ( ret )  87
completed_args = 1; 89
DPRINT ( ( "restart_args sz=%lu xtra_sz=%lu\n" , sz , xtra_sz ) ); 91
if ( likely ( xtra_sz ) )  94
------------------------------
59 /home/speedy/test/source2slice/NVD/CVE_2006_3741_VULN_sys_perfmonctl.c sz = xtra_sz + base_sz * count 50
asmlinkage long
CVE_2006_3741_VULN_sys_perfmonctl (int fd, int cmd, void __user *arg, int count) 2
void * args_k = NULL ; 7
long ret ; 8
size_t base_sz , sz , xtra_sz = 0 ; 9
int narg , completed_args = 0 , call_made = 0 , cmd_flags ; 10
if ( unlikely ( pmu_conf == NULL ) )  18
if ( unlikely ( cmd < 0 || cmd >= PFM_CMD_COUNT ) )  20
func = pfm_cmd_tab [ cmd ] . cmd_func; 25
narg = pfm_cmd_tab [ cmd ] . cmd_narg; 26
base_sz = pfm_cmd_tab [ cmd ] . cmd_argsize; 27
getsize = pfm_cmd_tab [ cmd ] . cmd_getsize; 28
if ( unlikely ( func == NULL ) )  31
if ( unlikely ( ( narg == PFM_CMD_ARG_MANY && count <= 0 ) || ( narg > 0 && narg != count ) ) )  46
sz = xtra_sz + base_sz * count; 50
if ( unlikely ( sz > PFM_MAX_ARGSIZE ) )  54
printk ( KERN_ERR "perfmon: [%d] argument too big %lu\n" , current -> pid , sz ) 55
if ( likely ( count && args_k == NULL ) )  62
args_k = kmalloc ( PFM_MAX_ARGSIZE , GFP_KERNEL ); 63
if ( args_k == NULL )  64
ret = - EFAULT; 67
if ( sz && copy_from_user ( args_k , arg , sz ) )  74
DPRINT ( ( "cannot copy_from_user %lu bytes @%p\n" , sz , arg ) ); 75
if ( completed_args == 0 && getsize )  82
ret = ( * getsize ) ( args_k , & xtra_sz ); 86
if ( ret )  87
completed_args = 1; 89
DPRINT ( ( "restart_args sz=%lu xtra_sz=%lu\n" , sz , xtra_sz ) ); 91
if ( likely ( xtra_sz ) )  94
------------------------------
60 /home/speedy/test/source2slice/NVD/CVE_2006_4813_PATCHED___block_prepare_write.c block_end = block_start + blocksize 98
static int CVE_2006_4813_PATCHED___block_prepare_write(struct inode *inode, struct page *page,
unsigned from, unsigned to, get_block_t *get_block) 2
unsigned block_start , block_end ; 4
sector_t block ; 5
int err = 0 ; 6
unsigned blocksize , bbits ; 7
struct buffer_head * bh , * head , * wait [ 2 ] , * * wait_bh = wait ; 8
blocksize = 1 << inode -> i_blkbits; 15
head = page_buffers ( page ); 18
bbits = inode -> i_blkbits; 20
block = ( sector_t ) page -> index << ( PAGE_CACHE_SHIFT - bbits ); 21
for(bh = head, block_start = 0; bh != head || !block_start;
block++, block_start=block_end, bh = bh->b_this_page) 24
block_end = block_start + blocksize; 25
if ( block_end <= from || block_start >= to )  26
if ( ! buffer_mapped ( bh ) )  35
err = get_block ( inode , block , bh , 1 ); 36
if ( err )  37
if ( buffer_new ( bh ) )  39
if ( PageUptodate ( page ) )  62
if ( ! buffer_uptodate ( bh ) && ! buffer_delay ( bh ) && ( block_start < from || block_end > to ) )  67
* wait_bh ++ = bh; 70
while ( wait_bh > wait )  76
if ( ! buffer_uptodate ( * wait_bh ) )  78
err = - EIO; 79
if ( ! err )  81
bh = head; 95
block_start = 0; 96
block_end = block_start + blocksize; 98
if ( block_end <= from )  99
if ( block_start >= to )  101
memset ( kaddr + block_start , 0 , bh -> b_size ); 108
kunmap_atomic ( kaddr , KM_USER0 ); 109
block_start = block_end; 114
bh = bh -> b_this_page; 115
while ( bh != head )  116
------------------------------
61 /home/speedy/test/source2slice/NVD/CVE_2006_4813_PATCHED___block_prepare_write.c block_end = block_start + blocksize 25
static int CVE_2006_4813_PATCHED___block_prepare_write(struct inode *inode, struct page *page,
unsigned from, unsigned to, get_block_t *get_block) 2
unsigned block_start , block_end ; 4
sector_t block ; 5
unsigned blocksize , bbits ; 7
blocksize = 1 << inode -> i_blkbits; 15
head = page_buffers ( page ); 18
bbits = inode -> i_blkbits; 20
block = ( sector_t ) page -> index << ( PAGE_CACHE_SHIFT - bbits ); 21
for(bh = head, block_start = 0; bh != head || !block_start;
block++, block_start=block_end, bh = bh->b_this_page) 24
block_end = block_start + blocksize; 25
if ( block_end <= from || block_start >= to )  26
if ( ! buffer_uptodate ( bh ) )  28
set_buffer_uptodate ( bh ); 29
if ( buffer_new ( bh ) )  33
clear_buffer_new ( bh ); 34
if ( ! buffer_mapped ( bh ) )  35
err = get_block ( inode , block , bh , 1 ); 36
if ( err )  37
if ( buffer_new ( bh ) )  39
unmap_underlying_metadata ( bh -> b_bdev , bh -> b_blocknr ); 40
set_buffer_uptodate ( bh ); 43
if ( block_end > to || block_start < from )  46
if ( block_end > to )  50
memset ( kaddr + to , 0 , block_end - to ); 51
if ( block_start < from )  53
memset ( kaddr + block_start , 0 , from - block_start ); 54
kunmap_atomic ( kaddr , KM_USER0 ); 57
if ( PageUptodate ( page ) )  62
if ( ! buffer_uptodate ( bh ) )  63
set_buffer_uptodate ( bh ); 64
if ( ! buffer_uptodate ( bh ) && ! buffer_delay ( bh ) && ( block_start < from || block_end > to ) )  67
ll_rw_block ( READ , 1 , & bh ); 69
* wait_bh ++ = bh; 70
while ( wait_bh > wait )  76
wait_on_buffer ( * -- wait_bh ); 77
if ( ! buffer_uptodate ( * wait_bh ) )  78
if ( ! err )  81
if ( buffer_new ( bh ) )  84
clear_buffer_new ( bh ); 85
while ( ( bh = bh -> b_this_page ) != head )  86
block_end = block_start + blocksize; 98
if ( block_end <= from )  99
if ( block_start >= to )  101
memset ( kaddr + block_start , 0 , bh -> b_size ); 108
kunmap_atomic ( kaddr , KM_USER0 ); 109
block_start = block_end; 114
return err ; 117
------------------------------
62 /home/speedy/test/source2slice/NVD/CVE_2006_4813_PATCHED___block_prepare_write.c block = ( sector_t ) page -> index << ( PAGE_CACHE_SHIFT - bbits ) 21
static int CVE_2006_4813_PATCHED___block_prepare_write(struct inode *inode, struct page *page,
unsigned from, unsigned to, get_block_t *get_block) 2
sector_t block ; 5
unsigned blocksize , bbits ; 7
bbits = inode -> i_blkbits; 20
block = ( sector_t ) page -> index << ( PAGE_CACHE_SHIFT - bbits ); 21
for(bh = head, block_start = 0; bh != head || !block_start;
block++, block_start=block_end, bh = bh->b_this_page) 24
block_end = block_start + blocksize; 25
if ( block_end <= from || block_start >= to )  26
if ( ! buffer_uptodate ( bh ) )  28
set_buffer_uptodate ( bh ); 29
if ( buffer_new ( bh ) )  33
clear_buffer_new ( bh ); 34
if ( ! buffer_mapped ( bh ) )  35
err = get_block ( inode , block , bh , 1 ); 36
if ( err )  37
if ( buffer_new ( bh ) )  39
unmap_underlying_metadata ( bh -> b_bdev , bh -> b_blocknr ); 40
set_buffer_uptodate ( bh ); 43
if ( block_end > to || block_start < from )  46
if ( block_end > to )  50
memset ( kaddr + to , 0 , block_end - to ); 51
if ( block_start < from )  53
memset ( kaddr + block_start , 0 , from - block_start ); 54
kunmap_atomic ( kaddr , KM_USER0 ); 57
if ( ! buffer_uptodate ( bh ) )  63
set_buffer_uptodate ( bh ); 64
if ( ! buffer_uptodate ( bh ) && ! buffer_delay ( bh ) && ( block_start < from || block_end > to ) )  67
ll_rw_block ( READ , 1 , & bh ); 69
* wait_bh ++ = bh; 70
while ( wait_bh > wait )  76
wait_on_buffer ( * -- wait_bh ); 77
if ( ! buffer_uptodate ( * wait_bh ) )  78
if ( ! err )  81
if ( buffer_new ( bh ) )  84
clear_buffer_new ( bh ); 85
while ( ( bh = bh -> b_this_page ) != head )  86
block_end = block_start + blocksize; 98
if ( block_end <= from )  99
if ( block_start >= to )  101
memset ( kaddr + block_start , 0 , bh -> b_size ); 108
kunmap_atomic ( kaddr , KM_USER0 ); 109
block_start = block_end; 114
return err ; 117
------------------------------
63 /home/speedy/test/source2slice/NVD/CVE_2006_4813_VULN___block_prepare_write.c block_end = block_start + blocksize 94
static int CVE_2006_4813_VULN___block_prepare_write(struct inode *inode, struct page *page,
unsigned from, unsigned to, get_block_t *get_block) 2
unsigned block_start , block_end ; 4
sector_t block ; 5
int err = 0 ; 6
unsigned blocksize , bbits ; 7
struct buffer_head * bh , * head , * wait [ 2 ] , * * wait_bh = wait ; 8
blocksize = 1 << inode -> i_blkbits; 15
head = page_buffers ( page ); 18
bbits = inode -> i_blkbits; 20
block = ( sector_t ) page -> index << ( PAGE_CACHE_SHIFT - bbits ); 21
for(bh = head, block_start = 0; bh != head || !block_start;
block++, block_start=block_end, bh = bh->b_this_page) 24
block_end = block_start + blocksize; 25
if ( block_end <= from || block_start >= to )  26
if ( ! buffer_mapped ( bh ) )  35
err = get_block ( inode , block , bh , 1 ); 36
if ( err )  37
if ( buffer_new ( bh ) )  39
if ( PageUptodate ( page ) )  63
if ( ! buffer_uptodate ( bh ) && ! buffer_delay ( bh ) && ( block_start < from || block_end > to ) )  68
* wait_bh ++ = bh; 71
while ( wait_bh > wait )  77
if ( ! buffer_uptodate ( * wait_bh ) )  79
err = - EIO; 80
if ( ! err )  82
bh = head; 91
block_start = 0; 92
block_end = block_start + blocksize; 94
if ( block_end <= from )  95
if ( block_start >= to )  97
memset ( kaddr + block_start , 0 , bh -> b_size ); 104
kunmap_atomic ( kaddr , KM_USER0 ); 105
block_start = block_end; 110
bh = bh -> b_this_page; 111
while ( bh != head )  112
------------------------------
64 /home/speedy/test/source2slice/NVD/CVE_2006_4813_VULN___block_prepare_write.c block_end = block_start + blocksize 25
static int CVE_2006_4813_VULN___block_prepare_write(struct inode *inode, struct page *page,
unsigned from, unsigned to, get_block_t *get_block) 2
unsigned block_start , block_end ; 4
sector_t block ; 5
unsigned blocksize , bbits ; 7
blocksize = 1 << inode -> i_blkbits; 15
head = page_buffers ( page ); 18
bbits = inode -> i_blkbits; 20
block = ( sector_t ) page -> index << ( PAGE_CACHE_SHIFT - bbits ); 21
for(bh = head, block_start = 0; bh != head || !block_start;
block++, block_start=block_end, bh = bh->b_this_page) 24
block_end = block_start + blocksize; 25
if ( block_end <= from || block_start >= to )  26
if ( ! buffer_uptodate ( bh ) )  28
set_buffer_uptodate ( bh ); 29
if ( buffer_new ( bh ) )  33
clear_buffer_new ( bh ); 34
if ( ! buffer_mapped ( bh ) )  35
err = get_block ( inode , block , bh , 1 ); 36
if ( err )  37
if ( buffer_new ( bh ) )  39
clear_buffer_new ( bh ); 40
unmap_underlying_metadata ( bh -> b_bdev , bh -> b_blocknr ); 41
set_buffer_uptodate ( bh ); 44
if ( block_end > to || block_start < from )  47
if ( block_end > to )  51
memset ( kaddr + to , 0 , block_end - to ); 52
if ( block_start < from )  54
memset ( kaddr + block_start , 0 , from - block_start ); 55
kunmap_atomic ( kaddr , KM_USER0 ); 58
if ( PageUptodate ( page ) )  63
if ( ! buffer_uptodate ( bh ) )  64
set_buffer_uptodate ( bh ); 65
if ( ! buffer_uptodate ( bh ) && ! buffer_delay ( bh ) && ( block_start < from || block_end > to ) )  68
ll_rw_block ( READ , 1 , & bh ); 70
* wait_bh ++ = bh; 71
while ( wait_bh > wait )  77
wait_on_buffer ( * -- wait_bh ); 78
if ( ! buffer_uptodate ( * wait_bh ) )  79
if ( ! err )  82
return err ; 83
block_end = block_start + blocksize; 94
if ( block_end <= from )  95
if ( block_start >= to )  97
if ( buffer_new ( bh ) )  99
clear_buffer_new ( bh ); 102
memset ( kaddr + block_start , 0 , bh -> b_size ); 104
kunmap_atomic ( kaddr , KM_USER0 ); 105
set_buffer_uptodate ( bh ); 106
mark_buffer_dirty ( bh ); 107
block_start = block_end; 110
bh = bh -> b_this_page; 111
while ( bh != head )  112
return err ; 113
------------------------------
65 /home/speedy/test/source2slice/NVD/CVE_2006_4813_VULN___block_prepare_write.c block = ( sector_t ) page -> index << ( PAGE_CACHE_SHIFT - bbits ) 21
static int CVE_2006_4813_VULN___block_prepare_write(struct inode *inode, struct page *page,
unsigned from, unsigned to, get_block_t *get_block) 2
sector_t block ; 5
unsigned blocksize , bbits ; 7
bbits = inode -> i_blkbits; 20
block = ( sector_t ) page -> index << ( PAGE_CACHE_SHIFT - bbits ); 21
for(bh = head, block_start = 0; bh != head || !block_start;
block++, block_start=block_end, bh = bh->b_this_page) 24
block_end = block_start + blocksize; 25
if ( block_end <= from || block_start >= to )  26
if ( ! buffer_uptodate ( bh ) )  28
set_buffer_uptodate ( bh ); 29
if ( buffer_new ( bh ) )  33
clear_buffer_new ( bh ); 34
if ( ! buffer_mapped ( bh ) )  35
err = get_block ( inode , block , bh , 1 ); 36
if ( err )  37
if ( buffer_new ( bh ) )  39
clear_buffer_new ( bh ); 40
unmap_underlying_metadata ( bh -> b_bdev , bh -> b_blocknr ); 41
set_buffer_uptodate ( bh ); 44
if ( block_end > to || block_start < from )  47
if ( block_end > to )  51
memset ( kaddr + to , 0 , block_end - to ); 52
if ( block_start < from )  54
memset ( kaddr + block_start , 0 , from - block_start ); 55
kunmap_atomic ( kaddr , KM_USER0 ); 58
if ( ! buffer_uptodate ( bh ) )  64
set_buffer_uptodate ( bh ); 65
if ( ! buffer_uptodate ( bh ) && ! buffer_delay ( bh ) && ( block_start < from || block_end > to ) )  68
ll_rw_block ( READ , 1 , & bh ); 70
* wait_bh ++ = bh; 71
while ( wait_bh > wait )  77
wait_on_buffer ( * -- wait_bh ); 78
if ( ! buffer_uptodate ( * wait_bh ) )  79
if ( ! err )  82
return err ; 83
block_end = block_start + blocksize; 94
if ( block_end <= from )  95
if ( block_start >= to )  97
if ( buffer_new ( bh ) )  99
clear_buffer_new ( bh ); 102
memset ( kaddr + block_start , 0 , bh -> b_size ); 104
kunmap_atomic ( kaddr , KM_USER0 ); 105
set_buffer_uptodate ( bh ); 106
mark_buffer_dirty ( bh ); 107
block_start = block_end; 110
bh = bh -> b_this_page; 111
while ( bh != head )  112
return err ; 113
------------------------------
66 /home/speedy/test/source2slice/NVD/CVE_2006_5751_PATCHED_get_fdb_entries.c size = maxnum * sizeof ( struct __fdb_entry ) 12
static int CVE_2006_5751_PATCHED_get_fdb_entries(struct net_bridge *br, void __user *userbuf,
unsigned long maxnum, unsigned long offset) 2
size_t size ; 6
if ( maxnum > PAGE_SIZE / sizeof ( struct __fdb_entry ) )  9
maxnum = PAGE_SIZE / sizeof ( struct __fdb_entry ); 10
size = maxnum * sizeof ( struct __fdb_entry ); 12
buf = kmalloc ( size , GFP_USER ); 14
if ( ! buf )  15
num = br_fdb_fillbuf ( br , buf , maxnum , offset ); 18
if ( num > 0 )  19
if ( copy_to_user ( userbuf , buf , num * sizeof ( struct __fdb_entry ) ) )  20
kfree ( buf ); 23
return num ; 25
------------------------------
67 /home/speedy/test/source2slice/NVD/CVE_2006_5751_PATCHED_get_fdb_entries.c maxnum = PAGE_SIZE / sizeof ( struct __fdb_entry ) 10
static int CVE_2006_5751_PATCHED_get_fdb_entries(struct net_bridge *br, void __user *userbuf,
unsigned long maxnum, unsigned long offset) 2
if ( maxnum > PAGE_SIZE / sizeof ( struct __fdb_entry ) )  9
maxnum = PAGE_SIZE / sizeof ( struct __fdb_entry ); 10
size = maxnum * sizeof ( struct __fdb_entry ); 12
buf = kmalloc ( size , GFP_USER ); 14
if ( ! buf )  15
num = br_fdb_fillbuf ( br , buf , maxnum , offset ); 18
if ( num > 0 )  19
if ( copy_to_user ( userbuf , buf , num * sizeof ( struct __fdb_entry ) ) )  20
kfree ( buf ); 23
return num ; 25
------------------------------
68 /home/speedy/test/source2slice/NVD/CVE_2006_5751_VULN_get_fdb_entries.c maxnum = PAGE_SIZE / sizeof ( struct __fdb_entry ) 10
static int CVE_2006_5751_VULN_get_fdb_entries(struct net_bridge *br, void __user *userbuf,
unsigned long maxnum, unsigned long offset) 2
size_t size = maxnum * sizeof ( struct __fdb_entry ) ; 6
if ( size > PAGE_SIZE )  8
maxnum = PAGE_SIZE / sizeof ( struct __fdb_entry ); 10
num = br_fdb_fillbuf ( br , buf , maxnum , offset ); 17
if ( num > 0 )  18
if ( copy_to_user ( userbuf , buf , num * sizeof ( struct __fdb_entry ) ) )  19
return num ; 24
------------------------------
69 /home/speedy/test/source2slice/NVD/CVE_2006_6333_PATCHED_tr_rx.c rbuffer_len = ntohs ( readw ( rbuf + BUFFER_LENGTH_OFST ) ) 139
static void CVE_2006_6333_PATCHED_tr_rx(struct net_device *dev) 1
struct tok_info * ti = ( struct tok_info * ) dev -> priv ; 3
__u32 rbuffer ; 4
void __iomem * rbuf , * rbufdata , * llc ; 5
unsigned int rbuffer_len , lan_hdr_len , hdr_len , ip_len , length ; 8
struct sk_buff * skb ; 10
struct arb_rec_req rarb ; 15
rbuffer = ntohs ( rarb . rec_buf_addr ); 19
rbuf = map_address ( ti , rbuffer , & rbuffer_page ); 20
lan_hdr_len = rarb . lan_hdr_len; 30
length = ntohs ( rarb . frame_len ); 60
skb_size = length - lan_hdr_len + sizeof ( struct trh_hdr ) + sizeof ( struct trllc ); 87
if ( ! ( skb = dev_alloc_skb ( skb_size ) ) )  89
if ( ibmtr_debug_trace & TRC_INITV && length < rbuffer_len )  123
DPRINTK ( "CURIOUS, length=%d < rbuffer_len=%d\n" , length , rbuffer_len ); 124
chksum = csum_partial_copy_nocheck ( ( void * ) rbufdata , data , length < rbuffer_len ? length : rbuffer_len , chksum ); 127
memcpy_fromio ( data , rbufdata , rbuffer_len ); 130
rbuffer = ntohs ( readw ( rbuf + BUFFER_POINTER_OFST ) ); 131
if ( ! rbuffer )  132
rbuffer -= 2; 134
length -= rbuffer_len; 135
data += rbuffer_len; 136
rbuf = map_address ( ti , rbuffer , & rbuffer_page ); 137
rbuffer_len = ntohs ( readw ( rbuf + BUFFER_LENGTH_OFST ) ); 139
rbufdata = rbuf + offsetof ( struct rec_buf , data ) 140
skb -> csum = chksum; 153
skb -> ip_summed = CHECKSUM_COMPLETE; 154
netif_rx ( skb ); 156
------------------------------
70 /home/speedy/test/source2slice/NVD/CVE_2006_6333_PATCHED_tr_rx.c rbuffer = ntohs ( readw ( rbuf + BUFFER_POINTER_OFST ) ) 131
static void CVE_2006_6333_PATCHED_tr_rx(struct net_device *dev) 1
struct tok_info * ti = ( struct tok_info * ) dev -> priv ; 3
__u32 rbuffer ; 4
void __iomem * rbuf , * rbufdata , * llc ; 5
unsigned int rbuffer_len , lan_hdr_len , hdr_len , ip_len , length ; 8
struct sk_buff * skb ; 10
struct arb_rec_req rarb ; 15
rbuffer = ntohs ( rarb . rec_buf_addr ); 19
rbuf = map_address ( ti , rbuffer , & rbuffer_page ); 20
lan_hdr_len = rarb . lan_hdr_len; 30
length = ntohs ( rarb . frame_len ); 60
skb_size = length - lan_hdr_len + sizeof ( struct trh_hdr ) + sizeof ( struct trllc ); 87
if ( ! ( skb = dev_alloc_skb ( skb_size ) ) )  89
if ( ibmtr_debug_trace & TRC_INITV && length < rbuffer_len )  123
DPRINTK ( "CURIOUS, length=%d < rbuffer_len=%d\n" , length , rbuffer_len ); 124
chksum = csum_partial_copy_nocheck ( ( void * ) rbufdata , data , length < rbuffer_len ? length : rbuffer_len , chksum ); 127
memcpy_fromio ( data , rbufdata , rbuffer_len ); 130
rbuffer = ntohs ( readw ( rbuf + BUFFER_POINTER_OFST ) ); 131
if ( ! rbuffer )  132
rbuffer -= 2; 134
length -= rbuffer_len; 135
data += rbuffer_len; 136
rbuf = map_address ( ti , rbuffer , & rbuffer_page ); 137
rbuffer_len = ntohs ( readw ( rbuf + BUFFER_LENGTH_OFST ) ); 139
rbufdata = rbuf + offsetof ( struct rec_buf , data ) 140
skb -> csum = chksum; 153
skb -> ip_summed = CHECKSUM_COMPLETE; 154
netif_rx ( skb ); 156
------------------------------
71 /home/speedy/test/source2slice/NVD/CVE_2006_6333_PATCHED_tr_rx.c iph = ( struct iphdr * ) ( data + lan_hdr_len + sizeof ( struct trllc ) ) 110
static void CVE_2006_6333_PATCHED_tr_rx(struct net_device *dev) 1
struct tok_info * ti = ( struct tok_info * ) dev -> priv ; 3
__u32 rbuffer ; 4
void __iomem * rbuf , * rbufdata , * llc ; 5
unsigned char * data ; 7
unsigned int rbuffer_len , lan_hdr_len , hdr_len , ip_len , length ; 8
struct sk_buff * skb ; 10
struct iphdr * iph ; 14
struct arb_rec_req rarb ; 15
rbuffer = ntohs ( rarb . rec_buf_addr ); 19
rbuf = map_address ( ti , rbuffer , & rbuffer_page ); 20
lan_hdr_len = rarb . lan_hdr_len; 30
if ( lan_hdr_len > sizeof ( struct trh_hdr ) )  31
hdr_len = lan_hdr_len + sizeof ( struct trllc ) + sizeof ( struct iphdr ); 36
llc = rbuf + offsetof ( struct rec_buf , data ) + lan_hdr_len 39
length = ntohs ( rarb . frame_len ); 60
if ( readb ( llc + DSAP_OFST ) == EXTENDED_SAP && readb ( llc + SSAP_OFST ) == EXTENDED_SAP && length >= hdr_len )  61
IPv4_p = 1; 63
skb_size = length - lan_hdr_len + sizeof ( struct trh_hdr ) + sizeof ( struct trllc ); 87
if ( ! ( skb = dev_alloc_skb ( skb_size ) ) )  89
skb -> dev = dev; 100
data = skb -> data; 101
if ( IPv4_p )  105
iph = ( struct iphdr * ) ( data + lan_hdr_len + sizeof ( struct trllc ) ); 110
ip_len = ntohs ( iph -> tot_len ) - sizeof ( struct iphdr ); 111
if ( ( ip_len <= length ) && ( ip_len > 7 ) )  113
length = ip_len; 114
if ( ibmtr_debug_trace & TRC_INITV && length < rbuffer_len )  123
DPRINTK ( "CURIOUS, length=%d < rbuffer_len=%d\n" , length , rbuffer_len ); 124
chksum = csum_partial_copy_nocheck ( ( void * ) rbufdata , data , length < rbuffer_len ? length : rbuffer_len , chksum ); 127
length -= rbuffer_len; 135
skb -> csum = chksum; 153
skb -> ip_summed = CHECKSUM_COMPLETE; 154
netif_rx ( skb ); 156
------------------------------
72 /home/speedy/test/source2slice/NVD/CVE_2006_6333_PATCHED_tr_rx.c skb_size = length - lan_hdr_len + sizeof ( struct trh_hdr ) + sizeof ( struct trllc ) 87
static void CVE_2006_6333_PATCHED_tr_rx(struct net_device *dev) 1
unsigned int rbuffer_len , lan_hdr_len , hdr_len , ip_len , length ; 8
struct arb_rec_req rarb ; 15
lan_hdr_len = rarb . lan_hdr_len; 30
length = ntohs ( rarb . frame_len ); 60
skb_size = length - lan_hdr_len + sizeof ( struct trh_hdr ) + sizeof ( struct trllc ); 87
if ( ! ( skb = dev_alloc_skb ( skb_size ) ) )  89
skb_reserve ( skb , sizeof ( struct trh_hdr ) - lan_hdr_len ); 98
skb_put ( skb , length ); 99
skb -> dev = dev; 100
data = skb -> data; 101
memcpy_fromio ( data , rbufdata , hdr_len ); 107
iph = ( struct iphdr * ) ( data + lan_hdr_len + sizeof ( struct trllc ) ); 110
ip_len = ntohs ( iph -> tot_len ) - sizeof ( struct iphdr ); 111
if ( ( ip_len <= length ) && ( ip_len > 7 ) )  113
length = ip_len; 114
data += hdr_len; 115
if ( ibmtr_debug_trace & TRC_INITV && length < rbuffer_len )  123
DPRINTK ( "CURIOUS, length=%d < rbuffer_len=%d\n" , length , rbuffer_len ); 124
chksum = csum_partial_copy_nocheck ( ( void * ) rbufdata , data , length < rbuffer_len ? length : rbuffer_len , chksum ); 127
memcpy_fromio ( data , rbufdata , rbuffer_len ); 130
length -= rbuffer_len; 135
data += rbuffer_len; 136
rbufdata = rbuf + offsetof ( struct rec_buf , data ) 140
ti -> tr_stats . rx_bytes += skb -> len; 148
ti -> tr_stats . rx_packets ++; 149
skb -> protocol = tr_type_trans ( skb , dev ); 151
skb -> csum = chksum; 153
skb -> ip_summed = CHECKSUM_COMPLETE; 154
netif_rx ( skb ); 156
------------------------------
73 /home/speedy/test/source2slice/NVD/CVE_2006_6333_PATCHED_tr_rx.c hdr_len = lan_hdr_len + sizeof ( struct trllc ) + sizeof ( struct iphdr ) 36
static void CVE_2006_6333_PATCHED_tr_rx(struct net_device *dev) 1
unsigned int rbuffer_len , lan_hdr_len , hdr_len , ip_len , length ; 8
struct arb_rec_req rarb ; 15
lan_hdr_len = rarb . lan_hdr_len; 30
if ( lan_hdr_len > sizeof ( struct trh_hdr ) )  31
hdr_len = lan_hdr_len + sizeof ( struct trllc ) + sizeof ( struct iphdr ); 36
if ( readb ( llc + DSAP_OFST ) == EXTENDED_SAP && readb ( llc + SSAP_OFST ) == EXTENDED_SAP && length >= hdr_len )  61
memcpy_fromio ( data , rbufdata , hdr_len ); 107
length -= hdr_len; 112
if ( ( ip_len <= length ) && ( ip_len > 7 ) )  113
data += hdr_len; 115
rbuffer_len -= hdr_len; 116
rbufdata += hdr_len; 117
if ( ibmtr_debug_trace & TRC_INITV && length < rbuffer_len )  123
DPRINTK ( "CURIOUS, length=%d < rbuffer_len=%d\n" , length , rbuffer_len ); 124
chksum = csum_partial_copy_nocheck ( ( void * ) rbufdata , data , length < rbuffer_len ? length : rbuffer_len , chksum ); 127
memcpy_fromio ( data , rbufdata , rbuffer_len ); 130
length -= rbuffer_len; 135
data += rbuffer_len; 136
rbufdata = rbuf + offsetof ( struct rec_buf , data ) 140
skb -> csum = chksum; 153
skb -> ip_summed = CHECKSUM_COMPLETE; 154
netif_rx ( skb ); 156
------------------------------
74 /home/speedy/test/source2slice/NVD/CVE_2006_6333_PATCHED_tr_rx.c dlc_hdr_len = readb ( ti -> arb + DLC_HDR_LENGTH_OFST ) 35
static void CVE_2006_6333_PATCHED_tr_rx(struct net_device *dev) 1
struct tok_info * ti = ( struct tok_info * ) dev -> priv ; 3
unsigned int rbuffer_len , lan_hdr_len , hdr_len , ip_len , length ; 8
unsigned char dlc_hdr_len ; 9
struct arb_rec_req rarb ; 15
lan_hdr_len = rarb . lan_hdr_len; 30
if ( lan_hdr_len > sizeof ( struct trh_hdr ) )  31
dlc_hdr_len = readb ( ti -> arb + DLC_HDR_LENGTH_OFST ); 35
------------------------------
75 /home/speedy/test/source2slice/NVD/CVE_2006_6333_VULN_tr_rx.c rbuffer_len = ntohs ( readw ( rbuf + BUFFER_LENGTH_OFST ) ) 139
static void CVE_2006_6333_VULN_tr_rx(struct net_device *dev) 1
struct tok_info * ti = ( struct tok_info * ) dev -> priv ; 3
__u32 rbuffer ; 4
void __iomem * rbuf , * rbufdata , * llc ; 5
unsigned int rbuffer_len , lan_hdr_len , hdr_len , ip_len , length ; 8
struct sk_buff * skb ; 10
struct arb_rec_req rarb ; 15
rbuffer = ntohs ( rarb . rec_buf_addr ); 19
rbuf = map_address ( ti , rbuffer , & rbuffer_page ); 20
lan_hdr_len = rarb . lan_hdr_len; 30
length = ntohs ( rarb . frame_len ); 60
skb_size = length - lan_hdr_len + sizeof ( struct trh_hdr ) + sizeof ( struct trllc ); 87
if ( ! ( skb = dev_alloc_skb ( skb_size ) ) )  89
if ( ibmtr_debug_trace & TRC_INITV && length < rbuffer_len )  123
DPRINTK ( "CURIOUS, length=%d < rbuffer_len=%d\n" , length , rbuffer_len ); 124
chksum = csum_partial_copy_nocheck ( ( void * ) rbufdata , data , length < rbuffer_len ? length : rbuffer_len , chksum ); 127
memcpy_fromio ( data , rbufdata , rbuffer_len ); 130
rbuffer = ntohs ( readw ( rbuf + BUFFER_POINTER_OFST ) ); 131
if ( ! rbuffer )  132
rbuffer -= 2; 134
length -= rbuffer_len; 135
data += rbuffer_len; 136
rbuf = map_address ( ti , rbuffer , & rbuffer_page ); 137
rbuffer_len = ntohs ( readw ( rbuf + BUFFER_LENGTH_OFST ) ); 139
rbufdata = rbuf + offsetof ( struct rec_buf , data ) 140
skb -> csum = chksum; 153
skb -> ip_summed = 1; 154
netif_rx ( skb ); 156
------------------------------
76 /home/speedy/test/source2slice/NVD/CVE_2006_6333_VULN_tr_rx.c rbuffer = ntohs ( readw ( rbuf + BUFFER_POINTER_OFST ) ) 131
static void CVE_2006_6333_VULN_tr_rx(struct net_device *dev) 1
struct tok_info * ti = ( struct tok_info * ) dev -> priv ; 3
__u32 rbuffer ; 4
void __iomem * rbuf , * rbufdata , * llc ; 5
unsigned int rbuffer_len , lan_hdr_len , hdr_len , ip_len , length ; 8
struct sk_buff * skb ; 10
struct arb_rec_req rarb ; 15
rbuffer = ntohs ( rarb . rec_buf_addr ); 19
rbuf = map_address ( ti , rbuffer , & rbuffer_page ); 20
lan_hdr_len = rarb . lan_hdr_len; 30
length = ntohs ( rarb . frame_len ); 60
skb_size = length - lan_hdr_len + sizeof ( struct trh_hdr ) + sizeof ( struct trllc ); 87
if ( ! ( skb = dev_alloc_skb ( skb_size ) ) )  89
if ( ibmtr_debug_trace & TRC_INITV && length < rbuffer_len )  123
DPRINTK ( "CURIOUS, length=%d < rbuffer_len=%d\n" , length , rbuffer_len ); 124
chksum = csum_partial_copy_nocheck ( ( void * ) rbufdata , data , length < rbuffer_len ? length : rbuffer_len , chksum ); 127
memcpy_fromio ( data , rbufdata , rbuffer_len ); 130
rbuffer = ntohs ( readw ( rbuf + BUFFER_POINTER_OFST ) ); 131
if ( ! rbuffer )  132
rbuffer -= 2; 134
length -= rbuffer_len; 135
data += rbuffer_len; 136
rbuf = map_address ( ti , rbuffer , & rbuffer_page ); 137
rbuffer_len = ntohs ( readw ( rbuf + BUFFER_LENGTH_OFST ) ); 139
rbufdata = rbuf + offsetof ( struct rec_buf , data ) 140
skb -> csum = chksum; 153
skb -> ip_summed = 1; 154
netif_rx ( skb ); 156
------------------------------
77 /home/speedy/test/source2slice/NVD/CVE_2006_6333_VULN_tr_rx.c iph = ( struct iphdr * ) ( data + lan_hdr_len + sizeof ( struct trllc ) ) 110
static void CVE_2006_6333_VULN_tr_rx(struct net_device *dev) 1
struct tok_info * ti = ( struct tok_info * ) dev -> priv ; 3
__u32 rbuffer ; 4
void __iomem * rbuf , * rbufdata , * llc ; 5
unsigned char * data ; 7
unsigned int rbuffer_len , lan_hdr_len , hdr_len , ip_len , length ; 8
struct sk_buff * skb ; 10
struct iphdr * iph ; 14
struct arb_rec_req rarb ; 15
rbuffer = ntohs ( rarb . rec_buf_addr ); 19
rbuf = map_address ( ti , rbuffer , & rbuffer_page ); 20
lan_hdr_len = rarb . lan_hdr_len; 30
if ( lan_hdr_len > sizeof ( struct trh_hdr ) )  31
hdr_len = lan_hdr_len + sizeof ( struct trllc ) + sizeof ( struct iphdr ); 36
llc = rbuf + offsetof ( struct rec_buf , data ) + lan_hdr_len 39
length = ntohs ( rarb . frame_len ); 60
if ( readb ( llc + DSAP_OFST ) == EXTENDED_SAP && readb ( llc + SSAP_OFST ) == EXTENDED_SAP && length >= hdr_len )  61
IPv4_p = 1; 63
skb_size = length - lan_hdr_len + sizeof ( struct trh_hdr ) + sizeof ( struct trllc ); 87
if ( ! ( skb = dev_alloc_skb ( skb_size ) ) )  89
skb -> dev = dev; 100
data = skb -> data; 101
if ( IPv4_p )  105
iph = ( struct iphdr * ) ( data + lan_hdr_len + sizeof ( struct trllc ) ); 110
ip_len = ntohs ( iph -> tot_len ) - sizeof ( struct iphdr ); 111
if ( ( ip_len <= length ) && ( ip_len > 7 ) )  113
length = ip_len; 114
if ( ibmtr_debug_trace & TRC_INITV && length < rbuffer_len )  123
DPRINTK ( "CURIOUS, length=%d < rbuffer_len=%d\n" , length , rbuffer_len ); 124
chksum = csum_partial_copy_nocheck ( ( void * ) rbufdata , data , length < rbuffer_len ? length : rbuffer_len , chksum ); 127
length -= rbuffer_len; 135
skb -> csum = chksum; 153
skb -> ip_summed = 1; 154
netif_rx ( skb ); 156
------------------------------
78 /home/speedy/test/source2slice/NVD/CVE_2006_6333_VULN_tr_rx.c skb_size = length - lan_hdr_len + sizeof ( struct trh_hdr ) + sizeof ( struct trllc ) 87
static void CVE_2006_6333_VULN_tr_rx(struct net_device *dev) 1
unsigned int rbuffer_len , lan_hdr_len , hdr_len , ip_len , length ; 8
struct arb_rec_req rarb ; 15
lan_hdr_len = rarb . lan_hdr_len; 30
length = ntohs ( rarb . frame_len ); 60
skb_size = length - lan_hdr_len + sizeof ( struct trh_hdr ) + sizeof ( struct trllc ); 87
if ( ! ( skb = dev_alloc_skb ( skb_size ) ) )  89
skb_reserve ( skb , sizeof ( struct trh_hdr ) - lan_hdr_len ); 98
skb_put ( skb , length ); 99
skb -> dev = dev; 100
data = skb -> data; 101
memcpy_fromio ( data , rbufdata , hdr_len ); 107
iph = ( struct iphdr * ) ( data + lan_hdr_len + sizeof ( struct trllc ) ); 110
ip_len = ntohs ( iph -> tot_len ) - sizeof ( struct iphdr ); 111
if ( ( ip_len <= length ) && ( ip_len > 7 ) )  113
length = ip_len; 114
data += hdr_len; 115
if ( ibmtr_debug_trace & TRC_INITV && length < rbuffer_len )  123
DPRINTK ( "CURIOUS, length=%d < rbuffer_len=%d\n" , length , rbuffer_len ); 124
chksum = csum_partial_copy_nocheck ( ( void * ) rbufdata , data , length < rbuffer_len ? length : rbuffer_len , chksum ); 127
memcpy_fromio ( data , rbufdata , rbuffer_len ); 130
length -= rbuffer_len; 135
data += rbuffer_len; 136
rbufdata = rbuf + offsetof ( struct rec_buf , data ) 140
ti -> tr_stats . rx_bytes += skb -> len; 148
ti -> tr_stats . rx_packets ++; 149
skb -> protocol = tr_type_trans ( skb , dev ); 151
skb -> csum = chksum; 153
skb -> ip_summed = 1; 154
netif_rx ( skb ); 156
------------------------------
79 /home/speedy/test/source2slice/NVD/CVE_2006_6333_VULN_tr_rx.c hdr_len = lan_hdr_len + sizeof ( struct trllc ) + sizeof ( struct iphdr ) 36
static void CVE_2006_6333_VULN_tr_rx(struct net_device *dev) 1
unsigned int rbuffer_len , lan_hdr_len , hdr_len , ip_len , length ; 8
struct arb_rec_req rarb ; 15
lan_hdr_len = rarb . lan_hdr_len; 30
if ( lan_hdr_len > sizeof ( struct trh_hdr ) )  31
hdr_len = lan_hdr_len + sizeof ( struct trllc ) + sizeof ( struct iphdr ); 36
if ( readb ( llc + DSAP_OFST ) == EXTENDED_SAP && readb ( llc + SSAP_OFST ) == EXTENDED_SAP && length >= hdr_len )  61
memcpy_fromio ( data , rbufdata , hdr_len ); 107
length -= hdr_len; 112
if ( ( ip_len <= length ) && ( ip_len > 7 ) )  113
data += hdr_len; 115
rbuffer_len -= hdr_len; 116
rbufdata += hdr_len; 117
if ( ibmtr_debug_trace & TRC_INITV && length < rbuffer_len )  123
DPRINTK ( "CURIOUS, length=%d < rbuffer_len=%d\n" , length , rbuffer_len ); 124
chksum = csum_partial_copy_nocheck ( ( void * ) rbufdata , data , length < rbuffer_len ? length : rbuffer_len , chksum ); 127
memcpy_fromio ( data , rbufdata , rbuffer_len ); 130
length -= rbuffer_len; 135
data += rbuffer_len; 136
rbufdata = rbuf + offsetof ( struct rec_buf , data ) 140
skb -> csum = chksum; 153
skb -> ip_summed = 1; 154
netif_rx ( skb ); 156
------------------------------
80 /home/speedy/test/source2slice/NVD/CVE_2006_6333_VULN_tr_rx.c dlc_hdr_len = readb ( ti -> arb + DLC_HDR_LENGTH_OFST ) 35
static void CVE_2006_6333_VULN_tr_rx(struct net_device *dev) 1
struct tok_info * ti = ( struct tok_info * ) dev -> priv ; 3
unsigned int rbuffer_len , lan_hdr_len , hdr_len , ip_len , length ; 8
unsigned char dlc_hdr_len ; 9
struct arb_rec_req rarb ; 15
lan_hdr_len = rarb . lan_hdr_len; 30
if ( lan_hdr_len > sizeof ( struct trh_hdr ) )  31
dlc_hdr_len = readb ( ti -> arb + DLC_HDR_LENGTH_OFST ); 35
------------------------------
81 /home/speedy/test/source2slice/NVD/CVE_2007_1217_PATCHED_bufprint.c r = cdb -> size - cdb -> pos 31
static _cdebbuf *CVE_2007_1217_PATCHED_bufprint(_cdebbuf *cdb, char *fmt,...) 1
va_list f ; 3
size_t n , r ; 4
if ( ! cdb )  6
r = cdb -> size - cdb -> pos; 9
n = vsnprintf ( cdb -> p , r , fmt , f ); 10
if ( n >= r )  12
size_t ns = 2 * cdb -> size ; 14
u_char * nb ; 15
while ( ( ns - cdb -> pos ) <= n )  17
ns *= 2; 18
nb = kmalloc ( ns , GFP_ATOMIC ); 19
if ( ! nb )  20
memcpy ( nb , cdb -> buf , cdb -> pos ); 24
nb [ cdb -> pos ] = 0; 26
cdb -> buf = nb; 27
cdb -> p = cdb -> buf + cdb -> pos; 28
cdb -> size = ns; 29
r = cdb -> size - cdb -> pos; 31
n = vsnprintf ( cdb -> p , r , fmt , f ); 32
cdb -> p += n; 35
cdb -> pos += n; 36
return cdb ; 37
------------------------------
82 /home/speedy/test/source2slice/NVD/CVE_2007_1217_PATCHED_bufprint.c cdb -> p = cdb -> buf + cdb -> pos 28
static _cdebbuf *CVE_2007_1217_PATCHED_bufprint(_cdebbuf *cdb, char *fmt,...) 1
va_list f ; 3
size_t n , r ; 4
if ( ! cdb )  6
r = cdb -> size - cdb -> pos; 9
n = vsnprintf ( cdb -> p , r , fmt , f ); 10
if ( n >= r )  12
size_t ns = 2 * cdb -> size ; 14
u_char * nb ; 15
while ( ( ns - cdb -> pos ) <= n )  17
ns *= 2; 18
nb = kmalloc ( ns , GFP_ATOMIC ); 19
if ( ! nb )  20
memcpy ( nb , cdb -> buf , cdb -> pos ); 24
nb [ cdb -> pos ] = 0; 26
cdb -> buf = nb; 27
cdb -> p = cdb -> buf + cdb -> pos; 28
cdb -> size = ns; 29
r = cdb -> size - cdb -> pos; 31
n = vsnprintf ( cdb -> p , r , fmt , f ); 32
cdb -> p += n; 35
cdb -> pos += n; 36
return cdb ; 37
------------------------------
83 /home/speedy/test/source2slice/NVD/CVE_2007_1217_PATCHED_bufprint.c r = cdb -> size - cdb -> pos 9
static _cdebbuf *CVE_2007_1217_PATCHED_bufprint(_cdebbuf *cdb, char *fmt,...) 1
size_t n , r ; 4
if ( ! cdb )  6
r = cdb -> size - cdb -> pos; 9
n = vsnprintf ( cdb -> p , r , fmt , f ); 10
if ( n >= r )  12
while ( ( ns - cdb -> pos ) <= n )  17
n = vsnprintf ( cdb -> p , r , fmt , f ); 32
cdb -> p += n; 35
cdb -> pos += n; 36
return cdb ; 37
------------------------------
84 /home/speedy/test/source2slice/NVD/CVE_2007_3642_PATCHED_decode_choice.c bs -> cur = beg + len 60
int CVE_2007_3642_PATCHED_decode_choice(bitstr_t * bs, field_t * f, char *base, int level) 1
int err ; 4
field_t * son ; 5
base = ( base && ( f -> attr & DECODE ) ) ? base + f -> offset : NULL; 11
if ( ( f -> attr & EXT ) && get_bit ( bs ) )  14
ext = 1; 15
type = get_bits ( bs , 7 ) + f -> lb; 16
ext = 0; 18
type = get_bits ( bs , f -> sz ); 19
if ( type >= f -> lb )  20
if ( base )  25
* ( unsigned * ) base = type; 26
if ( type >= f -> ub )  29
son = & f -> fields [ type ]; 38
if ( son -> attr & STOP )  39
if ( ext || ( son -> attr & OPEN ) )  44
len = get_len ( bs ); 46
if ( ! base || ! ( son -> attr & DECODE ) )  48
beg = bs -> cur; 54
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  56
bs -> cur = beg + len; 60
bs -> bit = 0; 61
------------------------------
85 /home/speedy/test/source2slice/NVD/CVE_2007_3642_PATCHED_decode_choice.c base = ( base && ( f -> attr & DECODE ) ) ? base + f -> offset : NULL 11
int CVE_2007_3642_PATCHED_decode_choice(bitstr_t * bs, field_t * f, char *base, int level) 1
base = ( base && ( f -> attr & DECODE ) ) ? base + f -> offset : NULL; 11
if ( base )  25
* ( unsigned * ) base = type; 26
if ( ! base || ! ( son -> attr & DECODE ) )  48
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  56
return err ; 58
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  62
return err ; 64
------------------------------
86 /home/speedy/test/source2slice/NVD/CVE_2007_3642_PATCHED_decode_seq.c bs -> cur = beg + len 110
int CVE_2007_3642_PATCHED_decode_seq(bitstr_t * bs, field_t * f, char *base, int level) 1
int err ; 4
field_t * son ; 5
base = ( base && ( f -> attr & DECODE ) ) ? base + f -> offset : NULL; 11
ext = ( f -> attr & EXT ) ? get_bit ( bs ) : 0; 14
bmp = get_bitmap ( bs , f -> sz ); 17
if ( base )  18
* ( unsigned * ) base = bmp; 19
for (i = opt = 0, son = f->fields; i < f->lb; i++, son++) 22
if ( son -> attr & STOP )  23
if ( son -> attr & OPT )  29
if ( ! ( ( 0x80000000U >> ( opt ++ ) ) & bmp ) )  30
if ( son -> attr & OPEN )  35
len = get_len ( bs ); 37
if ( ! base || ! ( son -> attr & DECODE ) )  39
bs -> cur += len; 42
beg = bs -> cur; 45
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  48
bs -> cur = beg + len; 53
bs -> bit = 0; 54
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  55
if ( ! ext )  62
bmp2_len = get_bits ( bs , 7 ) + 1; 66
bmp2 = get_bitmap ( bs , bmp2_len ); 68
bmp |= bmp2 >> f -> sz; 69
if ( base )  70
* ( unsigned * ) base = bmp; 71
for (opt = 0; opt < bmp2_len; opt++, i++, son++) 75
if ( i < f -> ub && son -> attr & STOP )  76
if ( ! ( ( 0x80000000 >> opt ) & bmp2 ) )  82
if ( i >= f -> ub )  86
len = get_len ( bs ); 88
bs -> cur += len; 90
len = get_len ( bs ); 95
if ( ! base || ! ( son -> attr & DECODE ) )  97
bs -> cur += len; 100
beg = bs -> cur; 103
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  105
bs -> cur = beg + len; 110
bs -> bit = 0; 111
------------------------------
87 /home/speedy/test/source2slice/NVD/CVE_2007_3642_PATCHED_decode_seq.c bs -> cur = beg + len 53
int CVE_2007_3642_PATCHED_decode_seq(bitstr_t * bs, field_t * f, char *base, int level) 1
int err ; 4
field_t * son ; 5
base = ( base && ( f -> attr & DECODE ) ) ? base + f -> offset : NULL; 11
bmp = get_bitmap ( bs , f -> sz ); 17
if ( base )  18
* ( unsigned * ) base = bmp; 19
for (i = opt = 0, son = f->fields; i < f->lb; i++, son++) 22
if ( son -> attr & STOP )  23
if ( son -> attr & OPT )  29
if ( ! ( ( 0x80000000U >> ( opt ++ ) ) & bmp ) )  30
if ( son -> attr & OPEN )  35
len = get_len ( bs ); 37
if ( ! base || ! ( son -> attr & DECODE ) )  39
bs -> cur += len; 42
beg = bs -> cur; 45
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  48
bs -> cur = beg + len; 53
bs -> bit = 0; 54
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  55
bmp2_len = get_bits ( bs , 7 ) + 1; 66
CHECK_BOUND ( bs , ( bmp2_len + 7 ) >> 3 ); 67
bmp2 = get_bitmap ( bs , bmp2_len ); 68
bmp |= bmp2 >> f -> sz; 69
* ( unsigned * ) base = bmp; 71
BYTE_ALIGN ( bs ); 72
for (opt = 0; opt < bmp2_len; opt++, i++, son++) 75
if ( ! ( ( 0x80000000 >> opt ) & bmp2 ) )  82
CHECK_BOUND ( bs , 2 ); 87
len = get_len ( bs ); 88
CHECK_BOUND ( bs , len ); 89
bs -> cur += len; 90
if ( ! base || ! ( son -> attr & DECODE ) )  97
bs -> cur += len; 100
beg = bs -> cur; 103
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  105
return err ; 108
bs -> cur = beg + len; 110
bs -> bit = 0; 111
------------------------------
88 /home/speedy/test/source2slice/NVD/CVE_2007_3642_PATCHED_decode_seq.c base = ( base && ( f -> attr & DECODE ) ) ? base + f -> offset : NULL 11
int CVE_2007_3642_PATCHED_decode_seq(bitstr_t * bs, field_t * f, char *base, int level) 1
base = ( base && ( f -> attr & DECODE ) ) ? base + f -> offset : NULL; 11
if ( base )  18
* ( unsigned * ) base = bmp; 19
if ( ! base || ! ( son -> attr & DECODE ) )  39
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  48
return err ; 51
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  55
return err ; 58
if ( base )  70
* ( unsigned * ) base = bmp; 71
if ( ! base || ! ( son -> attr & DECODE ) )  97
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  105
return err ; 108
------------------------------
89 /home/speedy/test/source2slice/NVD/CVE_2007_3642_VULN_decode_choice.c bs -> cur = beg + len 58
int CVE_2007_3642_VULN_decode_choice(bitstr_t * bs, field_t * f, char *base, int level) 1
int err ; 4
field_t * son ; 5
base = ( base && ( f -> attr & DECODE ) ) ? base + f -> offset : NULL; 11
if ( ( f -> attr & EXT ) && get_bit ( bs ) )  14
ext = 1; 15
type = get_bits ( bs , 7 ) + f -> lb; 16
ext = 0; 18
type = get_bits ( bs , f -> sz ); 19
if ( base )  23
* ( unsigned * ) base = type; 24
if ( type >= f -> ub )  27
son = & f -> fields [ type ]; 36
if ( son -> attr & STOP )  37
if ( ext || ( son -> attr & OPEN ) )  42
len = get_len ( bs ); 44
if ( ! base || ! ( son -> attr & DECODE ) )  46
beg = bs -> cur; 52
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  54
bs -> cur = beg + len; 58
bs -> bit = 0; 59
------------------------------
90 /home/speedy/test/source2slice/NVD/CVE_2007_3642_VULN_decode_choice.c base = ( base && ( f -> attr & DECODE ) ) ? base + f -> offset : NULL 11
int CVE_2007_3642_VULN_decode_choice(bitstr_t * bs, field_t * f, char *base, int level) 1
base = ( base && ( f -> attr & DECODE ) ) ? base + f -> offset : NULL; 11
if ( base )  23
* ( unsigned * ) base = type; 24
if ( ! base || ! ( son -> attr & DECODE ) )  46
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  54
return err ; 56
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  60
return err ; 62
------------------------------
91 /home/speedy/test/source2slice/NVD/CVE_2007_3642_VULN_decode_seq.c bs -> cur = beg + len 110
int CVE_2007_3642_VULN_decode_seq(bitstr_t * bs, field_t * f, char *base, int level) 1
int err ; 4
field_t * son ; 5
base = ( base && ( f -> attr & DECODE ) ) ? base + f -> offset : NULL; 11
ext = ( f -> attr & EXT ) ? get_bit ( bs ) : 0; 14
bmp = get_bitmap ( bs , f -> sz ); 17
if ( base )  18
* ( unsigned * ) base = bmp; 19
for (i = opt = 0, son = f->fields; i < f->lb; i++, son++) 22
if ( son -> attr & STOP )  23
if ( son -> attr & OPT )  29
if ( ! ( ( 0x80000000U >> ( opt ++ ) ) & bmp ) )  30
if ( son -> attr & OPEN )  35
len = get_len ( bs ); 37
if ( ! base )  39
bs -> cur += len; 42
beg = bs -> cur; 45
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  48
bs -> cur = beg + len; 53
bs -> bit = 0; 54
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  55
if ( ! ext )  62
bmp2_len = get_bits ( bs , 7 ) + 1; 66
bmp2 = get_bitmap ( bs , bmp2_len ); 68
bmp |= bmp2 >> f -> sz; 69
if ( base )  70
* ( unsigned * ) base = bmp; 71
for (opt = 0; opt < bmp2_len; opt++, i++, son++) 75
if ( i < f -> ub && son -> attr & STOP )  76
if ( ! ( ( 0x80000000 >> opt ) & bmp2 ) )  82
if ( i >= f -> ub )  86
len = get_len ( bs ); 88
bs -> cur += len; 90
len = get_len ( bs ); 95
if ( ! base || ! ( son -> attr & DECODE ) )  97
bs -> cur += len; 100
beg = bs -> cur; 103
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  105
bs -> cur = beg + len; 110
bs -> bit = 0; 111
------------------------------
92 /home/speedy/test/source2slice/NVD/CVE_2007_3642_VULN_decode_seq.c bs -> cur = beg + len 53
int CVE_2007_3642_VULN_decode_seq(bitstr_t * bs, field_t * f, char *base, int level) 1
int err ; 4
field_t * son ; 5
base = ( base && ( f -> attr & DECODE ) ) ? base + f -> offset : NULL; 11
bmp = get_bitmap ( bs , f -> sz ); 17
if ( base )  18
* ( unsigned * ) base = bmp; 19
for (i = opt = 0, son = f->fields; i < f->lb; i++, son++) 22
if ( son -> attr & STOP )  23
if ( son -> attr & OPT )  29
if ( ! ( ( 0x80000000U >> ( opt ++ ) ) & bmp ) )  30
if ( son -> attr & OPEN )  35
len = get_len ( bs ); 37
if ( ! base )  39
bs -> cur += len; 42
beg = bs -> cur; 45
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  48
bs -> cur = beg + len; 53
bs -> bit = 0; 54
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  55
bmp2_len = get_bits ( bs , 7 ) + 1; 66
CHECK_BOUND ( bs , ( bmp2_len + 7 ) >> 3 ); 67
bmp2 = get_bitmap ( bs , bmp2_len ); 68
bmp |= bmp2 >> f -> sz; 69
* ( unsigned * ) base = bmp; 71
BYTE_ALIGN ( bs ); 72
for (opt = 0; opt < bmp2_len; opt++, i++, son++) 75
if ( ! ( ( 0x80000000 >> opt ) & bmp2 ) )  82
CHECK_BOUND ( bs , 2 ); 87
len = get_len ( bs ); 88
CHECK_BOUND ( bs , len ); 89
bs -> cur += len; 90
if ( ! base || ! ( son -> attr & DECODE ) )  97
bs -> cur += len; 100
beg = bs -> cur; 103
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  105
return err ; 108
bs -> cur = beg + len; 110
bs -> bit = 0; 111
------------------------------
93 /home/speedy/test/source2slice/NVD/CVE_2007_3642_VULN_decode_seq.c base = ( base && ( f -> attr & DECODE ) ) ? base + f -> offset : NULL 11
int CVE_2007_3642_VULN_decode_seq(bitstr_t * bs, field_t * f, char *base, int level) 1
base = ( base && ( f -> attr & DECODE ) ) ? base + f -> offset : NULL; 11
if ( base )  18
* ( unsigned * ) base = bmp; 19
if ( ! base )  39
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  48
return err ; 51
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  55
return err ; 58
if ( base )  70
* ( unsigned * ) base = bmp; 71
if ( ! base || ! ( son -> attr & DECODE ) )  97
if ( ( err = ( Decoders [ son -> type ] ) ( bs , son , base , level + 1 ) ) < H323_ERROR_NONE )  105
return err ; 108
------------------------------
94 /home/speedy/test/source2slice/NVD/CVE_2008_0420_PATCHED_nsBMPDecoder__ProcessData.c mAlphaPtr = mAlpha + mBIH . width 355
NS_METHOD CVE_2008_0420_PATCHED_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
aBuffer += toCopy; 15
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
aCount -= toCopy; 32
aBuffer += toCopy; 33
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mNumColors = 1 << mBIH . bpp; 45
if ( mBIH . colors && mBIH . colors < mNumColors )  46
mNumColors = mBIH . colors; 47
mColors = new colorTable [ 256 ]; 51
if ( ! mColors )  52
memset ( mColors , 0 , 256 * sizeof ( colorTable ) ); 55
if ( mBIH . width < 0 )  65
PRUint32 real_height = ( mBIH . height > 0 ) ? mBIH . height : - mBIH . height ; 68
mCurLine = real_height; 73
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 75
if ( ! mRow )  79
PRUint8 bpc ; 95
bpc = ( mBFH . bihsize == OS2_BIH_LENGTH ) ? 3 : 4; 96
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  97
while ( aCount && ( mPos < ( mLOH + mNumColors * bpc ) ) )  102
mPos ++; 118
aBuffer ++; 118
aCount --; 118
if ( aCount && mBIH . compression == BI_BITFIELDS && mPos < ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) )  122
PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 125
if ( toCopy > aCount )  126
toCopy = aCount; 127
mPos += toCopy; 129
aBuffer += toCopy; 130
aCount -= toCopy; 131
while ( aCount && ( mPos < mBFH . dataoffset ) )  139
mPos ++; 140
aBuffer ++; 140
aCount --; 140
if ( aCount && ++ mPos >= mBFH . dataoffset )  142
if ( ! mBIH . compression || mBIH . compression == BI_BITFIELDS )  145
if ( ( mBIH . compression == BI_RLE8 ) || ( mBIH . compression == BI_RLE4 ) )  233
if ( ( ( mBIH . compression == BI_RLE8 ) && ( mBIH . bpp != 8 ) ) || ( ( mBIH . compression == BI_RLE4 ) && ( mBIH . bpp != 4 ) && ( mBIH . bpp != 1 ) ) )  234
if ( ! mAlpha )  240
PRUint32 alpha ; 241
mAlpha = ( PRUint8 * ) calloc ( alpha , 8 ); 245
if ( ! mAlpha )  246
mAlphaPtr = mAlpha; 248
if ( ! mDecoded )  251
mDecoded = ( PRUint8 * ) calloc ( mBpr , 1 ); 252
if ( ! mDecoded )  253
while ( aCount > 0 )  258
PRUint8 byte ; 259
switch ( mState )  261
mStateData = ( PRUint8 ) * aBuffer ++; 263
aCount --; 264
mState = eRLEStateNeedSecondEscapeByte; 266
byte = * aBuffer ++; 270
aCount --; 271
if ( mStateData != RLE_ESCAPE )  272
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  279
mStateData = ( PRUint32 ) ( mAlpha + mBIH . width - mAlphaPtr ); 280
memset ( mAlphaPtr , 0xFF , mStateData ); 281
mAlphaPtr += mStateData; 282
if ( mBIH . compression == BI_RLE8 )  283
while ( mStateData > 0 )  284
mStateData --; 286
while ( mStateData > 0 )  289
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 290
mState = eRLEStateInitial; 294
switch ( byte )  298
mAlphaPtr = mAlpha; 304
mState = eRLEStateInitial; 307
mState = eRLEStateNeedXDelta; 316
mStateData = byte; 321
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  322
mStateData -= mBIH . width & 1; 325
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  326
memset ( mAlphaPtr , 0xFF , mStateData ); 329
mAlphaPtr += mStateData; 330
if ( ( ( mStateData - 1 ) & mBIH . compression ) != 0 )  341
mState = eRLEStateAbsoluteMode; 342
mState = eRLEStateAbsoluteModePadded; 344
byte = * aBuffer ++; 351
aCount --; 352
mAlphaPtr += byte; 353
if ( mAlphaPtr > mAlpha + mBIH . width )  354
mAlphaPtr = mAlpha + mBIH . width; 355
mState = eRLEStateNeedYDelta; 358
byte = * aBuffer ++; 363
aCount --; 364
mState = eRLEStateInitial; 365
if ( byte == 0 )  366
if ( mBIH . compression == BI_RLE8 )  379
while ( aCount > 0 && mStateData > 0 )  380
byte = * aBuffer ++; 381
aCount --; 382
mStateData --; 384
while ( aCount > 0 && mStateData > 0 )  387
byte = * aBuffer ++; 388
aCount --; 389
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 390
if ( mStateData == 0 )  394
if ( mState == eRLEStateAbsoluteMode )  398
mState = eRLEStateInitial; 399
if ( aCount > 0 )  400
aBuffer ++; 403
aCount --; 404
mState = eRLEStateInitial; 405
if ( mCurLine == 0 )  417
------------------------------
95 /home/speedy/test/source2slice/NVD/CVE_2008_0420_PATCHED_nsBMPDecoder__ProcessData.c mStateData = ( PRUint32 ) ( mAlpha + mBIH . width - mAlphaPtr ) 280
NS_METHOD CVE_2008_0420_PATCHED_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
aBuffer += toCopy; 15
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
aCount -= toCopy; 32
aBuffer += toCopy; 33
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mNumColors = 1 << mBIH . bpp; 45
if ( mBIH . colors && mBIH . colors < mNumColors )  46
mNumColors = mBIH . colors; 47
mColors = new colorTable [ 256 ]; 51
if ( ! mColors )  52
memset ( mColors , 0 , 256 * sizeof ( colorTable ) ); 55
if ( mBIH . width < 0 )  65
PRUint32 real_height = ( mBIH . height > 0 ) ? mBIH . height : - mBIH . height ; 68
mCurLine = real_height; 73
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 75
if ( ! mRow )  79
PRUint8 bpc ; 95
bpc = ( mBFH . bihsize == OS2_BIH_LENGTH ) ? 3 : 4; 96
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  97
while ( aCount && ( mPos < ( mLOH + mNumColors * bpc ) ) )  102
mPos ++; 118
aBuffer ++; 118
aCount --; 118
if ( aCount && mBIH . compression == BI_BITFIELDS && mPos < ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) )  122
PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 125
if ( toCopy > aCount )  126
toCopy = aCount; 127
mPos += toCopy; 129
aBuffer += toCopy; 130
aCount -= toCopy; 131
while ( aCount && ( mPos < mBFH . dataoffset ) )  139
mPos ++; 140
aBuffer ++; 140
aCount --; 140
if ( aCount && ++ mPos >= mBFH . dataoffset )  142
if ( ! mBIH . compression || mBIH . compression == BI_BITFIELDS )  145
if ( ( mBIH . compression == BI_RLE8 ) || ( mBIH . compression == BI_RLE4 ) )  233
if ( ( ( mBIH . compression == BI_RLE8 ) && ( mBIH . bpp != 8 ) ) || ( ( mBIH . compression == BI_RLE4 ) && ( mBIH . bpp != 4 ) && ( mBIH . bpp != 1 ) ) )  234
if ( ! mAlpha )  240
PRUint32 alpha ; 241
mAlpha = ( PRUint8 * ) calloc ( alpha , 8 ); 245
if ( ! mAlpha )  246
mAlphaPtr = mAlpha; 248
if ( ! mDecoded )  251
mDecoded = ( PRUint8 * ) calloc ( mBpr , 1 ); 252
if ( ! mDecoded )  253
while ( aCount > 0 )  258
PRUint8 byte ; 259
switch ( mState )  261
mStateData = ( PRUint8 ) * aBuffer ++; 263
aCount --; 264
mState = eRLEStateNeedSecondEscapeByte; 266
byte = * aBuffer ++; 270
aCount --; 271
if ( mStateData != RLE_ESCAPE )  272
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  279
mStateData = ( PRUint32 ) ( mAlpha + mBIH . width - mAlphaPtr ); 280
memset ( mAlphaPtr , 0xFF , mStateData ); 281
mAlphaPtr += mStateData; 282
if ( mBIH . compression == BI_RLE8 )  283
while ( mStateData > 0 )  284
mStateData --; 286
while ( mStateData > 0 )  289
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 290
mState = eRLEStateInitial; 294
switch ( byte )  298
mAlphaPtr = mAlpha; 304
mState = eRLEStateInitial; 307
mState = eRLEStateNeedXDelta; 316
mStateData = byte; 321
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  322
mStateData -= mBIH . width & 1; 325
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  326
memset ( mAlphaPtr , 0xFF , mStateData ); 329
mAlphaPtr += mStateData; 330
if ( ( ( mStateData - 1 ) & mBIH . compression ) != 0 )  341
mState = eRLEStateAbsoluteMode; 342
mState = eRLEStateAbsoluteModePadded; 344
byte = * aBuffer ++; 351
aCount --; 352
mAlphaPtr += byte; 353
if ( mAlphaPtr > mAlpha + mBIH . width )  354
mAlphaPtr = mAlpha + mBIH . width; 355
mState = eRLEStateNeedYDelta; 358
byte = * aBuffer ++; 363
aCount --; 364
mState = eRLEStateInitial; 365
if ( byte == 0 )  366
if ( mBIH . compression == BI_RLE8 )  379
while ( aCount > 0 && mStateData > 0 )  380
byte = * aBuffer ++; 381
aCount --; 382
mStateData --; 384
while ( aCount > 0 && mStateData > 0 )  387
byte = * aBuffer ++; 388
aCount --; 389
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 390
if ( mStateData == 0 )  394
if ( mState == eRLEStateAbsoluteMode )  398
mState = eRLEStateInitial; 399
if ( aCount > 0 )  400
aBuffer ++; 403
aCount --; 404
mState = eRLEStateInitial; 405
if ( mCurLine == 0 )  417
------------------------------
96 /home/speedy/test/source2slice/NVD/CVE_2008_0420_PATCHED_nsBMPDecoder__ProcessData.c toCopy = rowSize - mRowBytes 151
NS_METHOD CVE_2008_0420_PATCHED_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
aCount -= toCopy; 32
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mNumColors = 1 << mBIH . bpp; 45
if ( mBIH . colors && mBIH . colors < mNumColors )  46
mNumColors = mBIH . colors; 47
mColors = new colorTable [ 256 ]; 51
if ( ! mColors )  52
memset ( mColors , 0 , 256 * sizeof ( colorTable ) ); 55
if ( mBIH . width < 0 )  65
PRUint32 real_height = ( mBIH . height > 0 ) ? mBIH . height : - mBIH . height ; 68
mCurLine = real_height; 73
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 75
if ( ! mRow )  79
PRUint8 bpc ; 95
bpc = ( mBFH . bihsize == OS2_BIH_LENGTH ) ? 3 : 4; 96
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  97
while ( aCount && ( mPos < ( mLOH + mNumColors * bpc ) ) )  102
mPos ++; 118
aCount --; 118
if ( aCount && mBIH . compression == BI_BITFIELDS && mPos < ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) )  122
PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 125
if ( toCopy > aCount )  126
toCopy = aCount; 127
mPos += toCopy; 129
aCount -= toCopy; 131
while ( aCount && ( mPos < mBFH . dataoffset ) )  139
mPos ++; 140
aCount --; 140
if ( aCount && ++ mPos >= mBFH . dataoffset )  142
if ( ! mBIH . compression || mBIH . compression == BI_BITFIELDS )  145
PRUint32 rowSize = ( mBIH . bpp * mBIH . width + 7 ) / 8 ; 146
if ( rowSize % 4 )  147
rowSize += ( 4 - ( rowSize % 4 ) ); 148
PRUint32 toCopy ; 149
toCopy = rowSize - mRowBytes; 151
if ( toCopy )  152
if ( toCopy > aCount )  153
toCopy = aCount; 154
memcpy ( mRow + mRowBytes , aBuffer , toCopy ); 155
aCount -= toCopy; 156
aBuffer += toCopy; 157
mRowBytes += toCopy; 158
if ( ( rowSize - mRowBytes ) == 0 )  160
if ( ! mDecoded )  161
mDecoded = ( PRUint8 * ) malloc ( mBpr ); 162
if ( ! mDecoded )  163
PRUint8 * p = mRow ; 167
idx = ( * p >> bit ) & 1; 176
SetPixel ( d , idx , mColors ); 177
Set4BitPixel ( d , * p , lpos , mColors ); 185
SetPixel ( d , * p , mColors ); 191
PRUint16 val = LITTLE_TO_NATIVE16 ( * ( PRUint16 * ) p ) ; 198
SetPixel ( d , ( val & mBitFields . red ) >> mBitFields . redRightShift << mBitFields . redLeftShift , ( val & mBitFields . green ) >> mBitFields . greenRightShift << mBitFields . greenLeftShift , ( val & mBitFields . blue ) >> mBitFields . blueRightShift << mBitFields . blueLeftShift ); 199
p += 2; 204
SetPixel ( d , p [ 2 ] , p [ 1 ] , p [ 0 ] ); 210
p += 2; 211
p ++; 214
if ( mCurLine == 0 )  225
mRowBytes = 0; 228
while ( aCount > 0 )  231
------------------------------
97 /home/speedy/test/source2slice/NVD/CVE_2008_0420_PATCHED_nsBMPDecoder__ProcessData.c mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ] 75
NS_METHOD CVE_2008_0420_PATCHED_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mColors = new colorTable [ 256 ]; 51
if ( ! mColors )  52
if ( mBIH . width < 0 )  65
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 75
if ( ! mRow )  79
memcpy ( mRow + mRowBytes , aBuffer , toCopy ); 155
PRUint8 * p = mRow ; 167
idx = ( * p >> bit ) & 1; 176
SetPixel ( d , idx , mColors ); 177
Set4BitPixel ( d , * p , lpos , mColors ); 185
SetPixel ( d , * p , mColors ); 191
PRUint16 val = LITTLE_TO_NATIVE16 ( * ( PRUint16 * ) p ) ; 198
SetPixel ( d , ( val & mBitFields . red ) >> mBitFields . redRightShift << mBitFields . redLeftShift , ( val & mBitFields . green ) >> mBitFields . greenRightShift << mBitFields . greenLeftShift , ( val & mBitFields . blue ) >> mBitFields . blueRightShift << mBitFields . blueLeftShift ); 199
p += 2; 204
SetPixel ( d , p [ 2 ] , p [ 1 ] , p [ 0 ] ); 210
p += 2; 211
p ++; 214
------------------------------
98 /home/speedy/test/source2slice/NVD/CVE_2008_0420_VULN_nsBMPDecoder__ProcessData.c mAlphaPtr = mAlpha + mBIH . width 351
NS_METHOD CVE_2008_0420_VULN_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
aBuffer += toCopy; 15
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
aCount -= toCopy; 32
aBuffer += toCopy; 33
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mNumColors = 1 << mBIH . bpp; 45
if ( mBIH . colors && mBIH . colors < mNumColors )  46
mNumColors = mBIH . colors; 47
mColors = new colorTable [ mNumColors ]; 49
if ( ! mColors )  50
if ( mBIH . width < 0 )  61
PRUint32 real_height = ( mBIH . height > 0 ) ? mBIH . height : - mBIH . height ; 64
mCurLine = real_height; 69
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 71
if ( ! mRow )  75
PRUint8 bpc ; 91
bpc = ( mBFH . bihsize == OS2_BIH_LENGTH ) ? 3 : 4; 92
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  93
while ( aCount && ( mPos < ( mLOH + mNumColors * bpc ) ) )  98
mPos ++; 114
aBuffer ++; 114
aCount --; 114
if ( aCount && mBIH . compression == BI_BITFIELDS && mPos < ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) )  118
PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 121
if ( toCopy > aCount )  122
toCopy = aCount; 123
mPos += toCopy; 125
aBuffer += toCopy; 126
aCount -= toCopy; 127
while ( aCount && ( mPos < mBFH . dataoffset ) )  135
mPos ++; 136
aBuffer ++; 136
aCount --; 136
if ( aCount && ++ mPos >= mBFH . dataoffset )  138
if ( ! mBIH . compression || mBIH . compression == BI_BITFIELDS )  141
if ( ( mBIH . compression == BI_RLE8 ) || ( mBIH . compression == BI_RLE4 ) )  229
if ( ( ( mBIH . compression == BI_RLE8 ) && ( mBIH . bpp != 8 ) ) || ( ( mBIH . compression == BI_RLE4 ) && ( mBIH . bpp != 4 ) && ( mBIH . bpp != 1 ) ) )  230
if ( ! mAlpha )  236
PRUint32 alpha ; 237
mAlpha = ( PRUint8 * ) calloc ( alpha , 8 ); 241
if ( ! mAlpha )  242
mAlphaPtr = mAlpha; 244
if ( ! mDecoded )  247
mDecoded = ( PRUint8 * ) calloc ( mBpr , 1 ); 248
if ( ! mDecoded )  249
while ( aCount > 0 )  254
PRUint8 byte ; 255
switch ( mState )  257
mStateData = ( PRUint8 ) * aBuffer ++; 259
aCount --; 260
mState = eRLEStateNeedSecondEscapeByte; 262
byte = * aBuffer ++; 266
aCount --; 267
if ( mStateData != RLE_ESCAPE )  268
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  275
mStateData = ( PRUint32 ) ( mAlpha + mBIH . width - mAlphaPtr ); 276
memset ( mAlphaPtr , 0xFF , mStateData ); 277
mAlphaPtr += mStateData; 278
if ( mBIH . compression == BI_RLE8 )  279
while ( mStateData > 0 )  280
mStateData --; 282
while ( mStateData > 0 )  285
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 286
mState = eRLEStateInitial; 290
switch ( byte )  294
mAlphaPtr = mAlpha; 300
mState = eRLEStateInitial; 303
mState = eRLEStateNeedXDelta; 312
mStateData = byte; 317
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  318
mStateData -= mBIH . width & 1; 321
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  322
memset ( mAlphaPtr , 0xFF , mStateData ); 325
mAlphaPtr += mStateData; 326
if ( ( ( mStateData - 1 ) & mBIH . compression ) != 0 )  337
mState = eRLEStateAbsoluteMode; 338
mState = eRLEStateAbsoluteModePadded; 340
byte = * aBuffer ++; 347
aCount --; 348
mAlphaPtr += byte; 349
if ( mAlphaPtr > mAlpha + mBIH . width )  350
mAlphaPtr = mAlpha + mBIH . width; 351
mState = eRLEStateNeedYDelta; 354
byte = * aBuffer ++; 359
aCount --; 360
mState = eRLEStateInitial; 361
if ( byte == 0 )  362
if ( mBIH . compression == BI_RLE8 )  375
while ( aCount > 0 && mStateData > 0 )  376
byte = * aBuffer ++; 377
aCount --; 378
mStateData --; 380
while ( aCount > 0 && mStateData > 0 )  383
byte = * aBuffer ++; 384
aCount --; 385
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 386
if ( mStateData == 0 )  390
if ( mState == eRLEStateAbsoluteMode )  394
mState = eRLEStateInitial; 395
if ( aCount > 0 )  396
aBuffer ++; 399
aCount --; 400
mState = eRLEStateInitial; 401
if ( mCurLine == 0 )  413
------------------------------
99 /home/speedy/test/source2slice/NVD/CVE_2008_0420_VULN_nsBMPDecoder__ProcessData.c mStateData = ( PRUint32 ) ( mAlpha + mBIH . width - mAlphaPtr ) 276
NS_METHOD CVE_2008_0420_VULN_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
aBuffer += toCopy; 15
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
aCount -= toCopy; 32
aBuffer += toCopy; 33
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mNumColors = 1 << mBIH . bpp; 45
if ( mBIH . colors && mBIH . colors < mNumColors )  46
mNumColors = mBIH . colors; 47
mColors = new colorTable [ mNumColors ]; 49
if ( ! mColors )  50
if ( mBIH . width < 0 )  61
PRUint32 real_height = ( mBIH . height > 0 ) ? mBIH . height : - mBIH . height ; 64
mCurLine = real_height; 69
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 71
if ( ! mRow )  75
PRUint8 bpc ; 91
bpc = ( mBFH . bihsize == OS2_BIH_LENGTH ) ? 3 : 4; 92
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  93
while ( aCount && ( mPos < ( mLOH + mNumColors * bpc ) ) )  98
mPos ++; 114
aBuffer ++; 114
aCount --; 114
if ( aCount && mBIH . compression == BI_BITFIELDS && mPos < ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) )  118
PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 121
if ( toCopy > aCount )  122
toCopy = aCount; 123
mPos += toCopy; 125
aBuffer += toCopy; 126
aCount -= toCopy; 127
while ( aCount && ( mPos < mBFH . dataoffset ) )  135
mPos ++; 136
aBuffer ++; 136
aCount --; 136
if ( aCount && ++ mPos >= mBFH . dataoffset )  138
if ( ! mBIH . compression || mBIH . compression == BI_BITFIELDS )  141
if ( ( mBIH . compression == BI_RLE8 ) || ( mBIH . compression == BI_RLE4 ) )  229
if ( ( ( mBIH . compression == BI_RLE8 ) && ( mBIH . bpp != 8 ) ) || ( ( mBIH . compression == BI_RLE4 ) && ( mBIH . bpp != 4 ) && ( mBIH . bpp != 1 ) ) )  230
if ( ! mAlpha )  236
PRUint32 alpha ; 237
mAlpha = ( PRUint8 * ) calloc ( alpha , 8 ); 241
if ( ! mAlpha )  242
mAlphaPtr = mAlpha; 244
if ( ! mDecoded )  247
mDecoded = ( PRUint8 * ) calloc ( mBpr , 1 ); 248
if ( ! mDecoded )  249
while ( aCount > 0 )  254
PRUint8 byte ; 255
switch ( mState )  257
mStateData = ( PRUint8 ) * aBuffer ++; 259
aCount --; 260
mState = eRLEStateNeedSecondEscapeByte; 262
byte = * aBuffer ++; 266
aCount --; 267
if ( mStateData != RLE_ESCAPE )  268
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  275
mStateData = ( PRUint32 ) ( mAlpha + mBIH . width - mAlphaPtr ); 276
memset ( mAlphaPtr , 0xFF , mStateData ); 277
mAlphaPtr += mStateData; 278
if ( mBIH . compression == BI_RLE8 )  279
while ( mStateData > 0 )  280
mStateData --; 282
while ( mStateData > 0 )  285
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 286
mState = eRLEStateInitial; 290
switch ( byte )  294
mAlphaPtr = mAlpha; 300
mState = eRLEStateInitial; 303
mState = eRLEStateNeedXDelta; 312
mStateData = byte; 317
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  318
mStateData -= mBIH . width & 1; 321
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  322
memset ( mAlphaPtr , 0xFF , mStateData ); 325
mAlphaPtr += mStateData; 326
if ( ( ( mStateData - 1 ) & mBIH . compression ) != 0 )  337
mState = eRLEStateAbsoluteMode; 338
mState = eRLEStateAbsoluteModePadded; 340
byte = * aBuffer ++; 347
aCount --; 348
mAlphaPtr += byte; 349
if ( mAlphaPtr > mAlpha + mBIH . width )  350
mAlphaPtr = mAlpha + mBIH . width; 351
mState = eRLEStateNeedYDelta; 354
byte = * aBuffer ++; 359
aCount --; 360
mState = eRLEStateInitial; 361
if ( byte == 0 )  362
if ( mBIH . compression == BI_RLE8 )  375
while ( aCount > 0 && mStateData > 0 )  376
byte = * aBuffer ++; 377
aCount --; 378
mStateData --; 380
while ( aCount > 0 && mStateData > 0 )  383
byte = * aBuffer ++; 384
aCount --; 385
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 386
if ( mStateData == 0 )  390
if ( mState == eRLEStateAbsoluteMode )  394
mState = eRLEStateInitial; 395
if ( aCount > 0 )  396
aBuffer ++; 399
aCount --; 400
mState = eRLEStateInitial; 401
if ( mCurLine == 0 )  413
------------------------------
100 /home/speedy/test/source2slice/NVD/CVE_2008_0420_VULN_nsBMPDecoder__ProcessData.c toCopy = rowSize - mRowBytes 147
NS_METHOD CVE_2008_0420_VULN_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
aCount -= toCopy; 32
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mNumColors = 1 << mBIH . bpp; 45
if ( mBIH . colors && mBIH . colors < mNumColors )  46
mNumColors = mBIH . colors; 47
mColors = new colorTable [ mNumColors ]; 49
if ( ! mColors )  50
if ( mBIH . width < 0 )  61
PRUint32 real_height = ( mBIH . height > 0 ) ? mBIH . height : - mBIH . height ; 64
mCurLine = real_height; 69
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 71
if ( ! mRow )  75
PRUint8 bpc ; 91
bpc = ( mBFH . bihsize == OS2_BIH_LENGTH ) ? 3 : 4; 92
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  93
while ( aCount && ( mPos < ( mLOH + mNumColors * bpc ) ) )  98
mPos ++; 114
aCount --; 114
if ( aCount && mBIH . compression == BI_BITFIELDS && mPos < ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) )  118
PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 121
if ( toCopy > aCount )  122
toCopy = aCount; 123
mPos += toCopy; 125
aCount -= toCopy; 127
while ( aCount && ( mPos < mBFH . dataoffset ) )  135
mPos ++; 136
aCount --; 136
if ( aCount && ++ mPos >= mBFH . dataoffset )  138
if ( ! mBIH . compression || mBIH . compression == BI_BITFIELDS )  141
PRUint32 rowSize = ( mBIH . bpp * mBIH . width + 7 ) / 8 ; 142
if ( rowSize % 4 )  143
rowSize += ( 4 - ( rowSize % 4 ) ); 144
PRUint32 toCopy ; 145
toCopy = rowSize - mRowBytes; 147
if ( toCopy )  148
if ( toCopy > aCount )  149
toCopy = aCount; 150
memcpy ( mRow + mRowBytes , aBuffer , toCopy ); 151
aCount -= toCopy; 152
aBuffer += toCopy; 153
mRowBytes += toCopy; 154
if ( ( rowSize - mRowBytes ) == 0 )  156
if ( ! mDecoded )  157
mDecoded = ( PRUint8 * ) malloc ( mBpr ); 158
if ( ! mDecoded )  159
PRUint8 * p = mRow ; 163
idx = ( * p >> bit ) & 1; 172
SetPixel ( d , idx , mColors ); 173
Set4BitPixel ( d , * p , lpos , mColors ); 181
SetPixel ( d , * p , mColors ); 187
PRUint16 val = LITTLE_TO_NATIVE16 ( * ( PRUint16 * ) p ) ; 194
SetPixel ( d , ( val & mBitFields . red ) >> mBitFields . redRightShift << mBitFields . redLeftShift , ( val & mBitFields . green ) >> mBitFields . greenRightShift << mBitFields . greenLeftShift , ( val & mBitFields . blue ) >> mBitFields . blueRightShift << mBitFields . blueLeftShift ); 195
p += 2; 200
SetPixel ( d , p [ 2 ] , p [ 1 ] , p [ 0 ] ); 206
p += 2; 207
p ++; 210
if ( mCurLine == 0 )  221
mRowBytes = 0; 224
while ( aCount > 0 )  227
------------------------------
101 /home/speedy/test/source2slice/NVD/CVE_2008_0420_VULN_nsBMPDecoder__ProcessData.c mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ] 71
NS_METHOD CVE_2008_0420_VULN_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mNumColors = 1 << mBIH . bpp; 45
if ( mBIH . colors && mBIH . colors < mNumColors )  46
mNumColors = mBIH . colors; 47
mColors = new colorTable [ mNumColors ]; 49
if ( ! mColors )  50
if ( mBIH . width < 0 )  61
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 71
if ( ! mRow )  75
memcpy ( mRow + mRowBytes , aBuffer , toCopy ); 151
PRUint8 * p = mRow ; 163
idx = ( * p >> bit ) & 1; 172
SetPixel ( d , idx , mColors ); 173
Set4BitPixel ( d , * p , lpos , mColors ); 181
SetPixel ( d , * p , mColors ); 187
PRUint16 val = LITTLE_TO_NATIVE16 ( * ( PRUint16 * ) p ) ; 194
SetPixel ( d , ( val & mBitFields . red ) >> mBitFields . redRightShift << mBitFields . redLeftShift , ( val & mBitFields . green ) >> mBitFields . greenRightShift << mBitFields . greenLeftShift , ( val & mBitFields . blue ) >> mBitFields . blueRightShift << mBitFields . blueLeftShift ); 195
p += 2; 200
SetPixel ( d , p [ 2 ] , p [ 1 ] , p [ 0 ] ); 206
p += 2; 207
p ++; 210
------------------------------
102 /home/speedy/test/source2slice/NVD/CVE_2008_1294_PATCHED_sys_setrlimit.c old_rlim = current -> signal -> rlim + resource 13
asmlinkage long CVE_2008_1294_PATCHED_sys_setrlimit(unsigned int resource, struct rlimit __user *rlim) 1
struct rlimit new_rlim , * old_rlim ; 3
if ( resource >= RLIM_NLIMITS )  7
if ( copy_from_user ( & new_rlim , rlim , sizeof ( * rlim ) ) )  9
if ( new_rlim . rlim_cur > new_rlim . rlim_max )  11
old_rlim = current -> signal -> rlim + resource; 13
if ( ( new_rlim . rlim_max > old_rlim -> rlim_max ) && ! capable ( CAP_SYS_RESOURCE ) )  14
* old_rlim = new_rlim; 35
------------------------------
103 /home/speedy/test/source2slice/NVD/CVE_2008_1294_VULN_sys_setrlimit.c old_rlim = current -> signal -> rlim + resource 13
asmlinkage long CVE_2008_1294_VULN_sys_setrlimit(unsigned int resource, struct rlimit __user *rlim) 1
struct rlimit new_rlim , * old_rlim ; 3
if ( resource >= RLIM_NLIMITS )  7
if ( copy_from_user ( & new_rlim , rlim , sizeof ( * rlim ) ) )  9
if ( new_rlim . rlim_cur > new_rlim . rlim_max )  11
old_rlim = current -> signal -> rlim + resource; 13
if ( ( new_rlim . rlim_max > old_rlim -> rlim_max ) && ! capable ( CAP_SYS_RESOURCE ) )  14
* old_rlim = new_rlim; 25
------------------------------
104 /home/speedy/test/source2slice/NVD/CVE_2008_1390_PATCHED_generic_http_callback.c c = retval + strlen ( retval ) 112
static char *CVE_2008_1390_PATCHED_generic_http_callback(int format, struct sockaddr_in *requestor, const char *uri, struct ast_variable *params, int *status, char **title, int *contentlength) 1
unsigned long ident = 0 ; 4
char workspace [ 512 ] ; 5
struct ast_variable * v ; 11
for (v = params; v; v = v->next) 13
if ( ! strcasecmp ( v -> name , "mansession_id" ) )  14
if ( ! ( s = find_session ( ident ) ) )  20
if ( ! ( s = ast_calloc ( 1 , sizeof ( * s ) ) ) )  22
memcpy ( & s -> sin , requestor , sizeof ( s -> sin ) ); 26
s -> fd = - 1; 27
s -> waiting_thread = AST_PTHREADT_NULL; 28
s -> send_events = 0; 29
s -> inuse = 1; 32
while ( ( s -> managerid = rand ( ) ^ ( unsigned long ) s ) == 0 )  38
s -> eventq = master_eventq; 42
while ( s -> eventq -> next )  43
s -> eventq = s -> eventq -> next; 44
if ( ! s -> authenticated && ( httptimeout > 5 ) )  52
s -> sessiontimeout += 5; 53
s -> sessiontimeout += httptimeout; 55
if ( s )  58
struct message m = { 0 } ; 59
char tmp [ 80 ] ; 60
unsigned int x ; 61
size_t hdrlen ; 62
for (x = 0, v = params; v && (x < AST_MAX_MANHEADERS); x++, v = v->next) 64
hdrlen = strlen ( v -> name ) + strlen ( v -> value ) + 3; 65
m . headers [ m . hdrcount ] = alloca ( hdrlen ); 66
snprintf ( ( char * ) m . headers [ m . hdrcount ] , hdrlen , "%s: %s" , v -> name , v -> value ); 67
m . hdrcount = x + 1; 68
if ( process_message ( s , & m ) )  71
s -> needdestroy = 1; 85
sprintf ( tmp , "%08lx" , s -> managerid ); 88
if ( s -> outputstr )  99
char * tmp ; 100
if ( format == FORMAT_XML )  101
tmp = xml_translate ( s -> outputstr -> str , params ); 102
if ( format == FORMAT_HTML )  103
tmp = html_translate ( s -> outputstr -> str ); 104
tmp = s -> outputstr -> str; 106
if ( tmp )  107
retval = malloc ( strlen ( workspace ) + strlen ( tmp ) + 128 ); 108
if ( retval )  109
strcpy ( retval , workspace ); 110
strcpy ( retval + strlen ( retval ) , tmp ); 111
c = retval + strlen ( retval ); 112
ast_build_string ( & c , & len , "</ajax-response>\n" ); 125
ast_build_string ( & c , & len , "</table></body>\r\n" ); 127
------------------------------
105 /home/speedy/test/source2slice/NVD/CVE_2008_1390_VULN_generic_http_callback.c c = retval + strlen ( retval ) 107
static char *CVE_2008_1390_VULN_generic_http_callback(int format, struct sockaddr_in *requestor, const char *uri, struct ast_variable *params, int *status, char **title, int *contentlength) 1
unsigned long ident = 0 ; 4
char workspace [ 512 ] ; 5
struct ast_variable * v ; 11
for (v = params; v; v = v->next) 13
if ( ! strcasecmp ( v -> name , "mansession_id" ) )  14
if ( ! ( s = find_session ( ident ) ) )  20
if ( ! ( s = ast_calloc ( 1 , sizeof ( * s ) ) ) )  22
memcpy ( & s -> sin , requestor , sizeof ( s -> sin ) ); 26
s -> fd = - 1; 27
s -> waiting_thread = AST_PTHREADT_NULL; 28
s -> send_events = 0; 29
s -> inuse = 1; 32
s -> managerid = rand ( ) | ( unsigned long ) s; 33
s -> eventq = master_eventq; 37
while ( s -> eventq -> next )  38
s -> eventq = s -> eventq -> next; 39
if ( ! s -> authenticated && ( httptimeout > 5 ) )  47
s -> sessiontimeout += 5; 48
s -> sessiontimeout += httptimeout; 50
if ( s )  53
struct message m = { 0 } ; 54
char tmp [ 80 ] ; 55
unsigned int x ; 56
size_t hdrlen ; 57
for (x = 0, v = params; v && (x < AST_MAX_MANHEADERS); x++, v = v->next) 59
hdrlen = strlen ( v -> name ) + strlen ( v -> value ) + 3; 60
m . headers [ m . hdrcount ] = alloca ( hdrlen ); 61
snprintf ( ( char * ) m . headers [ m . hdrcount ] , hdrlen , "%s: %s" , v -> name , v -> value ); 62
m . hdrcount = x + 1; 63
if ( process_message ( s , & m ) )  66
s -> needdestroy = 1; 80
sprintf ( tmp , "%08lx" , s -> managerid ); 83
if ( s -> outputstr )  94
char * tmp ; 95
if ( format == FORMAT_XML )  96
tmp = xml_translate ( s -> outputstr -> str , params ); 97
if ( format == FORMAT_HTML )  98
tmp = html_translate ( s -> outputstr -> str ); 99
tmp = s -> outputstr -> str; 101
if ( tmp )  102
retval = malloc ( strlen ( workspace ) + strlen ( tmp ) + 128 ); 103
if ( retval )  104
strcpy ( retval , workspace ); 105
strcpy ( retval + strlen ( retval ) , tmp ); 106
c = retval + strlen ( retval ); 107
ast_build_string ( & c , & len , "</ajax-response>\n" ); 120
ast_build_string ( & c , & len , "</table></body>\r\n" ); 122
------------------------------
106 /home/speedy/test/source2slice/NVD/CVE_2008_3527_VULN_arch_setup_additional_pages.c vma -> vm_end = addr + PAGE_SIZE 22
int CVE_2008_3527_VULN_arch_setup_additional_pages(struct linux_binprm *bprm, int exstack) 1
struct vm_area_struct * vma ; 3
unsigned long addr ; 5
addr = get_unmapped_area ( NULL , 0 , PAGE_SIZE , 0 , 0 ); 9
if ( IS_ERR_VALUE ( addr ) )  10
vma = kmem_cache_zalloc ( vm_area_cachep , GFP_KERNEL ); 15
if ( ! vma )  16
vma -> vm_start = addr; 21
vma -> vm_end = addr + PAGE_SIZE; 22
vma -> vm_flags = VM_READ | VM_EXEC | VM_MAYREAD | VM_MAYEXEC | VM_MAYWRITE; 24
vma -> vm_flags |= VM_ALWAYSDUMP; 31
vma -> vm_flags |= mm -> def_flags; 32
vma -> vm_page_prot = protection_map [ vma -> vm_flags & 7 ]; 33
vma -> vm_ops = & syscall_vm_ops; 34
vma -> vm_mm = mm; 35
ret = insert_vm_struct ( mm , vma ); 37
if ( unlikely ( ret ) )  38
kmem_cache_free ( vm_area_cachep , vma ); 39
return ret ; 49
------------------------------
107 /home/speedy/test/source2slice/NVD/CVE_2008_3686_PATCHED_rt6_fill_node.c expires = rt -> rt6i_expires - jiffies 103
static int CVE_2008_3686_PATCHED_rt6_fill_node(struct sk_buff *skb, struct rt6_info *rt,
struct in6_addr *dst, struct in6_addr *src,
int iif, int type, u32 pid, u32 seq,
int prefix, int nowait, unsigned int flags) 4
struct rtmsg * rtm ; 6
struct nlmsghdr * nlh ; 7
long expires ; 8
if ( prefix )  11
if ( ! ( rt -> rt6i_flags & RTF_PREFIX_RT ) )  12
nlh = nlmsg_put ( skb , pid , seq , type , sizeof ( * rtm ) , flags ); 18
if ( nlh == NULL )  19
rtm = nlmsg_data ( nlh ); 22
if ( rt -> rt6i_flags & RTF_REJECT )  33
if ( rt -> rt6i_dev && ( rt -> rt6i_dev -> flags & IFF_LOOPBACK ) )  35
rtm -> rtm_type = RTN_UNICAST; 38
rtm -> rtm_flags = 0; 39
rtm -> rtm_scope = RT_SCOPE_UNIVERSE; 40
rtm -> rtm_protocol = rt -> rt6i_protocol; 41
if ( rt -> rt6i_flags & RTF_DYNAMIC )  42
rtm -> rtm_protocol = RTPROT_REDIRECT; 43
if ( rt -> rt6i_flags & RTF_ADDRCONF )  44
rtm -> rtm_protocol = RTPROT_KERNEL; 45
if ( rt -> rt6i_flags & RTF_DEFAULT )  46
rtm -> rtm_protocol = RTPROT_RA; 47
if ( rt -> rt6i_flags & RTF_CACHE )  49
rtm -> rtm_flags |= RTM_F_CLONED; 50
if ( dst )  52
rtm -> rtm_dst_len = 128; 54
if ( src )  58
rtm -> rtm_src_len = 128; 60
if ( iif )  64
if ( ipv6_addr_is_multicast ( & rt -> rt6i_dst . addr ) )  66
int err = ip6mr_get_route ( skb , rtm , nowait ) ; 67
if ( err <= 0 )  68
if ( ! nowait )  69
if ( err == - EMSGSIZE )  74
if ( rtnetlink_put_metrics ( skb , rt -> u . dst . metrics ) < 0 )  89
if ( ! ( rt -> rt6i_flags & RTF_EXPIRES ) )  100
if ( rt -> rt6i_expires - jiffies < INT_MAX )  102
expires = rt -> rt6i_expires - jiffies; 103
if ( rtnl_put_cacheinfo ( skb , & rt -> u . dst , 0 , 0 , 0 , expires , rt -> u . dst . error ) < 0 )  107
------------------------------
108 /home/speedy/test/source2slice/NVD/CVE_2008_3686_VULN_rt6_fill_node.c expires = rt -> rt6i_expires - jiffies 102
static int CVE_2008_3686_VULN_rt6_fill_node(struct sk_buff *skb, struct rt6_info *rt,
struct in6_addr *dst, struct in6_addr *src,
int iif, int type, u32 pid, u32 seq,
int prefix, int nowait, unsigned int flags) 4
struct rtmsg * rtm ; 6
struct nlmsghdr * nlh ; 7
long expires ; 8
if ( prefix )  11
if ( ! ( rt -> rt6i_flags & RTF_PREFIX_RT ) )  12
nlh = nlmsg_put ( skb , pid , seq , type , sizeof ( * rtm ) , flags ); 18
if ( nlh == NULL )  19
rtm = nlmsg_data ( nlh ); 22
if ( rt -> rt6i_flags & RTF_REJECT )  33
if ( rt -> rt6i_dev && ( rt -> rt6i_dev -> flags & IFF_LOOPBACK ) )  35
rtm -> rtm_type = RTN_UNICAST; 38
rtm -> rtm_flags = 0; 39
rtm -> rtm_scope = RT_SCOPE_UNIVERSE; 40
rtm -> rtm_protocol = rt -> rt6i_protocol; 41
if ( rt -> rt6i_flags & RTF_DYNAMIC )  42
rtm -> rtm_protocol = RTPROT_REDIRECT; 43
if ( rt -> rt6i_flags & RTF_ADDRCONF )  44
rtm -> rtm_protocol = RTPROT_KERNEL; 45
if ( rt -> rt6i_flags & RTF_DEFAULT )  46
rtm -> rtm_protocol = RTPROT_RA; 47
if ( rt -> rt6i_flags & RTF_CACHE )  49
rtm -> rtm_flags |= RTM_F_CLONED; 50
if ( dst )  52
rtm -> rtm_dst_len = 128; 54
if ( src )  58
rtm -> rtm_src_len = 128; 60
if ( iif )  64
if ( ipv6_addr_is_multicast ( & rt -> rt6i_dst . addr ) )  66
int err = ip6mr_get_route ( skb , rtm , nowait ) ; 67
if ( err <= 0 )  68
if ( ! nowait )  69
if ( err == - EMSGSIZE )  74
if ( rtnetlink_put_metrics ( skb , rt -> u . dst . metrics ) < 0 )  88
if ( ! ( rt -> rt6i_flags & RTF_EXPIRES ) )  99
if ( rt -> rt6i_expires - jiffies < INT_MAX )  101
expires = rt -> rt6i_expires - jiffies; 102
if ( rtnl_put_cacheinfo ( skb , & rt -> u . dst , 0 , 0 , 0 , expires , rt -> u . dst . error ) < 0 )  106
------------------------------
109 /home/speedy/test/source2slice/NVD/CVE_2008_3792_PATCHED_sctp_getsockopt_hmac_ident.c num_idents = data_len / sizeof ( u16 ) 19
static int CVE_2008_3792_PATCHED_sctp_getsockopt_hmac_ident(struct sock *sk, int len,
char __user *optval, int __user *optlen) 2
struct sctp_hmac_algo_param * hmacs ; 5
u32 num_idents ; 7
if ( ! sctp_auth_enable )  9
hmacs = sctp_sk ( sk ) -> ep -> auth_hmacs_list; 12
data_len = ntohs ( hmacs -> param_hdr . length ) - sizeof ( sctp_paramhdr_t ); 13
if ( len < sizeof ( struct sctp_hmacalgo ) + data_len )  15
num_idents = data_len / sizeof ( u16 ); 19
if ( put_user ( num_idents , & p -> shmac_num_idents ) )  23
------------------------------
110 /home/speedy/test/source2slice/NVD/CVE_2008_3915_PATCHED_init_state.c alloc = sizeof ( struct posix_ace_state_array ) + cnt * sizeof ( struct posix_user_ace_state ) 13
static int
CVE_2008_3915_PATCHED_init_state(struct posix_acl_state *state, int cnt) 2
int alloc ; 4
alloc = sizeof ( struct posix_ace_state_array ) + cnt * sizeof ( struct posix_user_ace_state ); 13
state -> users = kzalloc ( alloc , GFP_KERNEL ); 15
if ( ! state -> users )  16
state -> groups = kzalloc ( alloc , GFP_KERNEL ); 18
if ( ! state -> groups )  19
kfree ( state -> users ); 20
------------------------------
111 /home/speedy/test/source2slice/NVD/CVE_2008_3915_VULN_init_state.c alloc = sizeof ( struct posix_ace_state_array ) + cnt * sizeof ( struct posix_ace_state ) 13
static int
CVE_2008_3915_VULN_init_state(struct posix_acl_state *state, int cnt) 2
int alloc ; 4
alloc = sizeof ( struct posix_ace_state_array ) + cnt * sizeof ( struct posix_ace_state ); 13
state -> users = kzalloc ( alloc , GFP_KERNEL ); 15
if ( ! state -> users )  16
state -> groups = kzalloc ( alloc , GFP_KERNEL ); 18
if ( ! state -> groups )  19
kfree ( state -> users ); 20
------------------------------
112 /home/speedy/test/source2slice/NVD/CVE_2008_4302_PATCHED_pipe_to_file.c ret = mapping -> a_ops -> commit_write ( file , page , offset , offset + this_len ) 75
static int CVE_2008_4302_PATCHED_pipe_to_file(struct pipe_inode_info *pipe, struct pipe_buffer *buf,
struct splice_desc *sd) 2
struct file * file = sd -> file ; 4
struct address_space * mapping = file -> f_mapping ; 5
unsigned int offset , this_len ; 6
struct page * page ; 7
pgoff_t index ; 8
int ret ; 9
ret = buf -> ops -> pin ( pipe , buf ); 14
if ( unlikely ( ret ) )  15
index = sd -> pos >> PAGE_CACHE_SHIFT; 18
offset = sd -> pos & ~PAGE_CACHE_MASK; 19
this_len = sd -> len; 21
if ( this_len + offset > PAGE_CACHE_SIZE )  22
this_len = PAGE_CACHE_SIZE - offset; 23
page = find_lock_page ( mapping , index ); 26
if ( ! page )  27
ret = - ENOMEM; 28
page = page_cache_alloc_cold ( mapping ); 29
if ( unlikely ( ! page ) )  30
ret = add_to_page_cache_lru ( page , mapping , index , GFP_KERNEL ); 36
if ( unlikely ( ret ) )  38
ret = mapping -> a_ops -> prepare_write ( file , page , offset , offset + this_len ); 42
if ( unlikely ( ret ) )  43
if ( ret == AOP_TRUNCATED_PAGE )  49
ret = mapping -> a_ops -> commit_write ( file , page , offset , offset + this_len ); 75
if ( ret )  76
if ( ret == AOP_TRUNCATED_PAGE )  77
if ( ret < 0 )  81
return ret ; 99
------------------------------
113 /home/speedy/test/source2slice/NVD/CVE_2008_4302_PATCHED_pipe_to_file.c ret = mapping -> a_ops -> prepare_write ( file , page , offset , offset + this_len ) 42
static int CVE_2008_4302_PATCHED_pipe_to_file(struct pipe_inode_info *pipe, struct pipe_buffer *buf,
struct splice_desc *sd) 2
struct file * file = sd -> file ; 4
struct address_space * mapping = file -> f_mapping ; 5
unsigned int offset , this_len ; 6
struct page * page ; 7
pgoff_t index ; 8
int ret ; 9
ret = buf -> ops -> pin ( pipe , buf ); 14
if ( unlikely ( ret ) )  15
index = sd -> pos >> PAGE_CACHE_SHIFT; 18
offset = sd -> pos & ~PAGE_CACHE_MASK; 19
this_len = sd -> len; 21
if ( this_len + offset > PAGE_CACHE_SIZE )  22
this_len = PAGE_CACHE_SIZE - offset; 23
page = find_lock_page ( mapping , index ); 26
if ( ! page )  27
ret = - ENOMEM; 28
page = page_cache_alloc_cold ( mapping ); 29
if ( unlikely ( ! page ) )  30
ret = add_to_page_cache_lru ( page , mapping , index , GFP_KERNEL ); 36
if ( unlikely ( ret ) )  38
ret = mapping -> a_ops -> prepare_write ( file , page , offset , offset + this_len ); 42
if ( unlikely ( ret ) )  43
if ( ret != AOP_TRUNCATED_PAGE )  46
if ( ret == AOP_TRUNCATED_PAGE )  49
ret = mapping -> a_ops -> commit_write ( file , page , offset , offset + this_len ); 75
if ( ret )  76
if ( ret == AOP_TRUNCATED_PAGE )  77
return ret ; 99
------------------------------
114 /home/speedy/test/source2slice/NVD/CVE_2008_4302_PATCHED_pipe_to_file.c this_len = PAGE_CACHE_SIZE - offset 23
static int CVE_2008_4302_PATCHED_pipe_to_file(struct pipe_inode_info *pipe, struct pipe_buffer *buf,
struct splice_desc *sd) 2
unsigned int offset , this_len ; 6
int ret ; 9
ret = buf -> ops -> pin ( pipe , buf ); 14
if ( unlikely ( ret ) )  15
offset = sd -> pos & ~PAGE_CACHE_MASK; 19
this_len = sd -> len; 21
if ( this_len + offset > PAGE_CACHE_SIZE )  22
this_len = PAGE_CACHE_SIZE - offset; 23
ret = mapping -> a_ops -> prepare_write ( file , page , offset , offset + this_len ); 42
if ( unlikely ( ret ) )  43
if ( ret != AOP_TRUNCATED_PAGE )  46
if ( ret == AOP_TRUNCATED_PAGE )  49
if ( sd -> pos + this_len > isize )  56
memcpy ( dst + offset , src + buf -> offset , this_len ); 69
kunmap_atomic ( dst , KM_USER1 ); 71
ret = mapping -> a_ops -> commit_write ( file , page , offset , offset + this_len ); 75
if ( ret )  76
if ( ret == AOP_TRUNCATED_PAGE )  77
if ( ret < 0 )  81
ret = this_len; 88
return ret ; 99
------------------------------
115 /home/speedy/test/source2slice/NVD/CVE_2008_4302_VULN_pipe_to_file.c ret = mapping -> a_ops -> commit_write ( file , page , offset , offset + this_len ) 75
static int CVE_2008_4302_VULN_pipe_to_file(struct pipe_inode_info *pipe, struct pipe_buffer *buf,
struct splice_desc *sd) 2
struct file * file = sd -> file ; 4
struct address_space * mapping = file -> f_mapping ; 5
unsigned int offset , this_len ; 6
struct page * page ; 7
pgoff_t index ; 8
int ret ; 9
ret = buf -> ops -> pin ( pipe , buf ); 14
if ( unlikely ( ret ) )  15
index = sd -> pos >> PAGE_CACHE_SHIFT; 18
offset = sd -> pos & ~PAGE_CACHE_MASK; 19
this_len = sd -> len; 21
if ( this_len + offset > PAGE_CACHE_SIZE )  22
this_len = PAGE_CACHE_SIZE - offset; 23
page = find_lock_page ( mapping , index ); 26
if ( ! page )  27
ret = - ENOMEM; 28
page = page_cache_alloc_cold ( mapping ); 29
if ( unlikely ( ! page ) )  30
ret = add_to_page_cache_lru ( page , mapping , index , GFP_KERNEL ); 36
if ( unlikely ( ret ) )  38
ret = mapping -> a_ops -> prepare_write ( file , page , offset , offset + this_len ); 42
if ( unlikely ( ret ) )  43
if ( ret == AOP_TRUNCATED_PAGE )  49
ret = mapping -> a_ops -> commit_write ( file , page , offset , offset + this_len ); 75
if ( ret )  76
if ( ret == AOP_TRUNCATED_PAGE )  77
if ( ret < 0 )  81
return ret ; 98
------------------------------
116 /home/speedy/test/source2slice/NVD/CVE_2008_4302_VULN_pipe_to_file.c ret = mapping -> a_ops -> prepare_write ( file , page , offset , offset + this_len ) 42
static int CVE_2008_4302_VULN_pipe_to_file(struct pipe_inode_info *pipe, struct pipe_buffer *buf,
struct splice_desc *sd) 2
struct file * file = sd -> file ; 4
struct address_space * mapping = file -> f_mapping ; 5
unsigned int offset , this_len ; 6
struct page * page ; 7
pgoff_t index ; 8
int ret ; 9
ret = buf -> ops -> pin ( pipe , buf ); 14
if ( unlikely ( ret ) )  15
index = sd -> pos >> PAGE_CACHE_SHIFT; 18
offset = sd -> pos & ~PAGE_CACHE_MASK; 19
this_len = sd -> len; 21
if ( this_len + offset > PAGE_CACHE_SIZE )  22
this_len = PAGE_CACHE_SIZE - offset; 23
page = find_lock_page ( mapping , index ); 26
if ( ! page )  27
ret = - ENOMEM; 28
page = page_cache_alloc_cold ( mapping ); 29
if ( unlikely ( ! page ) )  30
ret = add_to_page_cache_lru ( page , mapping , index , GFP_KERNEL ); 36
if ( unlikely ( ret ) )  38
ret = mapping -> a_ops -> prepare_write ( file , page , offset , offset + this_len ); 42
if ( unlikely ( ret ) )  43
if ( ret != AOP_TRUNCATED_PAGE )  46
if ( ret == AOP_TRUNCATED_PAGE )  49
ret = mapping -> a_ops -> commit_write ( file , page , offset , offset + this_len ); 75
if ( ret )  76
if ( ret == AOP_TRUNCATED_PAGE )  77
return ret ; 98
------------------------------
117 /home/speedy/test/source2slice/NVD/CVE_2008_4302_VULN_pipe_to_file.c this_len = PAGE_CACHE_SIZE - offset 23
static int CVE_2008_4302_VULN_pipe_to_file(struct pipe_inode_info *pipe, struct pipe_buffer *buf,
struct splice_desc *sd) 2
unsigned int offset , this_len ; 6
int ret ; 9
ret = buf -> ops -> pin ( pipe , buf ); 14
if ( unlikely ( ret ) )  15
offset = sd -> pos & ~PAGE_CACHE_MASK; 19
this_len = sd -> len; 21
if ( this_len + offset > PAGE_CACHE_SIZE )  22
this_len = PAGE_CACHE_SIZE - offset; 23
ret = mapping -> a_ops -> prepare_write ( file , page , offset , offset + this_len ); 42
if ( unlikely ( ret ) )  43
if ( ret != AOP_TRUNCATED_PAGE )  46
if ( ret == AOP_TRUNCATED_PAGE )  49
if ( sd -> pos + this_len > isize )  56
memcpy ( dst + offset , src + buf -> offset , this_len ); 69
kunmap_atomic ( dst , KM_USER1 ); 71
ret = mapping -> a_ops -> commit_write ( file , page , offset , offset + this_len ); 75
if ( ret )  76
if ( ret == AOP_TRUNCATED_PAGE )  77
if ( ret < 0 )  81
ret = this_len; 88
return ret ; 98
------------------------------
118 /home/speedy/test/source2slice/NVD/CVE_2008_5134_PATCHED_lbs_process_bss.c p = bss -> rates + n_basic_rates 170
static int CVE_2008_5134_PATCHED_lbs_process_bss(struct bss_descriptor *bss,
uint8_t **pbeaconinfo, int *bytesleft) 2
struct ieeetypes_dsparamset * pDS ; 5
struct ieeetypes_ibssparamset * pibss ; 7
struct ieeetypes_countryinfoset * pcountryinfo ; 9
uint8_t * pos , * end , * p ; 10
uint8_t n_ex_rates = 0 , got_basic_rates = 0 , n_basic_rates = 0 ; 11
uint16_t beaconsize = 0 ; 12
if ( * bytesleft >= sizeof ( beaconsize ) )  17
beaconsize = get_unaligned_le16 ( * pbeaconinfo ); 19
* bytesleft -= sizeof ( beaconsize ); 20
* pbeaconinfo += sizeof ( beaconsize ); 21
if ( beaconsize == 0 || beaconsize > * bytesleft )  24
pos = * pbeaconinfo; 32
end = pos + beaconsize; 33
memcpy ( bss -> bssid , pos , ETH_ALEN ); 39
pos += ETH_ALEN; 41
if ( ( end - pos ) < 12 )  43
bss -> rssi = * pos; 55
pos ++; 57
pos += 8; 60
bss -> beaconperiod = get_unaligned_le16 ( pos ); 63
pos += 2; 64
bss -> capability = get_unaligned_le16 ( pos ); 67
pos += 2; 69
if ( bss -> capability & WLAN_CAPABILITY_IBSS )  73
bss -> mode = IW_MODE_ADHOC; 74
bss -> mode = IW_MODE_INFRA; 76
while ( pos <= end - 2 )  83
struct ieee80211_info_element * elem = ( void * ) pos ; 84
if ( pos + elem -> len > end )  86
switch ( elem -> id )  92
bss -> ssid_len = min_t ( int , 32 , elem -> len ); 94
memcpy ( bss -> ssid , elem -> data , bss -> ssid_len ); 95
n_basic_rates = min_t ( uint8_t , MAX_RATES , elem -> len ); 102
memcpy ( bss -> rates , elem -> data , n_basic_rates ); 103
got_basic_rates = 1; 104
pDS = ( struct ieeetypes_dsparamset * ) pos; 116
bss -> channel = pDS -> currentchan; 117
pibss = ( struct ieeetypes_ibssparamset * ) pos; 131
bss -> atimwindow = le16_to_cpu ( pibss -> atimwindow ); 132
pcountryinfo = ( struct ieeetypes_countryinfoset * ) pos; 139
if ( pcountryinfo -> len < sizeof ( pcountryinfo -> countrycode ) || pcountryinfo -> len > 254 )  141
memcpy ( & bss -> countryinfo , pcountryinfo , pcountryinfo -> len + 2 ); 149
if ( ! got_basic_rates )  161
p = bss -> rates + n_basic_rates; 170
memcpy ( p , elem -> data , n_ex_rates ); 171
if ( elem -> len >= 4 && elem -> data [ 0 ] == 0x00 && elem -> data [ 1 ] == 0x50 && elem -> data [ 2 ] == 0xf2 && elem -> data [ 3 ] == 0x01 )  175
bss -> wpa_ie_len = min ( elem -> len + 2 , MAX_WPA_IE_LEN ); 178
if ( elem -> len >= MARVELL_MESH_IE_LENGTH && elem -> data [ 0 ] == 0x00 && elem -> data [ 1 ] == 0x50 && elem -> data [ 2 ] == 0x43 && elem -> data [ 3 ] == 0x04 )  182
bss -> mesh = 1; 186
bss -> rsn_ie_len = min ( elem -> len + 2 , MAX_WPA_IE_LEN ); 197
pos += elem -> len + 2; 209
------------------------------
119 /home/speedy/test/source2slice/NVD/CVE_2008_5134_PATCHED_lbs_process_bss.c n_ex_rates = MAX_RATES - n_basic_rates 168
static int CVE_2008_5134_PATCHED_lbs_process_bss(struct bss_descriptor *bss,
uint8_t **pbeaconinfo, int *bytesleft) 2
struct ieeetypes_countryinfoset * pcountryinfo ; 9
uint8_t * pos , * end , * p ; 10
uint8_t n_ex_rates = 0 , got_basic_rates = 0 , n_basic_rates = 0 ; 11
uint16_t beaconsize = 0 ; 12
if ( * bytesleft >= sizeof ( beaconsize ) )  17
beaconsize = get_unaligned_le16 ( * pbeaconinfo ); 19
* bytesleft -= sizeof ( beaconsize ); 20
* pbeaconinfo += sizeof ( beaconsize ); 21
if ( beaconsize == 0 || beaconsize > * bytesleft )  24
pos = * pbeaconinfo; 32
end = pos + beaconsize; 33
pos += ETH_ALEN; 41
if ( ( end - pos ) < 12 )  43
pos ++; 57
pos += 8; 60
pos += 2; 64
pos += 2; 69
while ( pos <= end - 2 )  83
struct ieee80211_info_element * elem = ( void * ) pos ; 84
if ( pos + elem -> len > end )  86
switch ( elem -> id )  92
n_basic_rates = min_t ( uint8_t , MAX_RATES , elem -> len ); 102
got_basic_rates = 1; 104
pcountryinfo = ( struct ieeetypes_countryinfoset * ) pos; 139
if ( pcountryinfo -> len < sizeof ( pcountryinfo -> countrycode ) || pcountryinfo -> len > 254 )  141
if ( ! got_basic_rates )  161
n_ex_rates = elem -> len; 166
if ( n_basic_rates + n_ex_rates > MAX_RATES )  167
n_ex_rates = MAX_RATES - n_basic_rates; 168
memcpy ( p , elem -> data , n_ex_rates ); 171
pos += elem -> len + 2; 209
------------------------------
120 /home/speedy/test/source2slice/NVD/CVE_2008_5134_PATCHED_lbs_process_bss.c end = pos + beaconsize 33
static int CVE_2008_5134_PATCHED_lbs_process_bss(struct bss_descriptor *bss,
uint8_t **pbeaconinfo, int *bytesleft) 2
uint8_t * pos , * end , * p ; 10
uint16_t beaconsize = 0 ; 12
if ( * bytesleft >= sizeof ( beaconsize ) )  17
beaconsize = get_unaligned_le16 ( * pbeaconinfo ); 19
* bytesleft -= sizeof ( beaconsize ); 20
* pbeaconinfo += sizeof ( beaconsize ); 21
if ( beaconsize == 0 || beaconsize > * bytesleft )  24
pos = * pbeaconinfo; 32
end = pos + beaconsize; 33
if ( ( end - pos ) < 12 )  43
lbs_deb_scan ( "process_bss: IE len %zd\n" , end - pos ); 79
lbs_deb_hex ( LBS_DEB_SCAN , "process_bss: IE info" , pos , end - pos ); 80
while ( pos <= end - 2 )  83
if ( pos + elem -> len > end )  86
------------------------------
121 /home/speedy/test/source2slice/NVD/CVE_2008_5134_VULN_lbs_process_bss.c p = bss -> rates + n_basic_rates 170
static int CVE_2008_5134_VULN_lbs_process_bss(struct bss_descriptor *bss,
uint8_t **pbeaconinfo, int *bytesleft) 2
struct ieeetypes_dsparamset * pDS ; 5
struct ieeetypes_ibssparamset * pibss ; 7
struct ieeetypes_countryinfoset * pcountryinfo ; 9
uint8_t * pos , * end , * p ; 10
uint8_t n_ex_rates = 0 , got_basic_rates = 0 , n_basic_rates = 0 ; 11
uint16_t beaconsize = 0 ; 12
if ( * bytesleft >= sizeof ( beaconsize ) )  17
beaconsize = get_unaligned_le16 ( * pbeaconinfo ); 19
* bytesleft -= sizeof ( beaconsize ); 20
* pbeaconinfo += sizeof ( beaconsize ); 21
if ( beaconsize == 0 || beaconsize > * bytesleft )  24
pos = * pbeaconinfo; 32
end = pos + beaconsize; 33
memcpy ( bss -> bssid , pos , ETH_ALEN ); 39
pos += ETH_ALEN; 41
if ( ( end - pos ) < 12 )  43
bss -> rssi = * pos; 55
pos ++; 57
pos += 8; 60
bss -> beaconperiod = get_unaligned_le16 ( pos ); 63
pos += 2; 64
bss -> capability = get_unaligned_le16 ( pos ); 67
pos += 2; 69
if ( bss -> capability & WLAN_CAPABILITY_IBSS )  73
bss -> mode = IW_MODE_ADHOC; 74
bss -> mode = IW_MODE_INFRA; 76
while ( pos <= end - 2 )  83
struct ieee80211_info_element * elem = ( void * ) pos ; 84
if ( pos + elem -> len > end )  86
switch ( elem -> id )  92
bss -> ssid_len = elem -> len; 94
n_basic_rates = min_t ( uint8_t , MAX_RATES , elem -> len ); 102
memcpy ( bss -> rates , elem -> data , n_basic_rates ); 103
got_basic_rates = 1; 104
pDS = ( struct ieeetypes_dsparamset * ) pos; 116
bss -> channel = pDS -> currentchan; 117
pibss = ( struct ieeetypes_ibssparamset * ) pos; 131
bss -> atimwindow = le16_to_cpu ( pibss -> atimwindow ); 132
pcountryinfo = ( struct ieeetypes_countryinfoset * ) pos; 139
if ( pcountryinfo -> len < sizeof ( pcountryinfo -> countrycode ) || pcountryinfo -> len > 254 )  141
memcpy ( & bss -> countryinfo , pcountryinfo , pcountryinfo -> len + 2 ); 149
if ( ! got_basic_rates )  161
p = bss -> rates + n_basic_rates; 170
memcpy ( p , elem -> data , n_ex_rates ); 171
if ( elem -> len >= 4 && elem -> data [ 0 ] == 0x00 && elem -> data [ 1 ] == 0x50 && elem -> data [ 2 ] == 0xf2 && elem -> data [ 3 ] == 0x01 )  175
bss -> wpa_ie_len = min ( elem -> len + 2 , MAX_WPA_IE_LEN ); 178
if ( elem -> len >= MARVELL_MESH_IE_LENGTH && elem -> data [ 0 ] == 0x00 && elem -> data [ 1 ] == 0x50 && elem -> data [ 2 ] == 0x43 && elem -> data [ 3 ] == 0x04 )  182
bss -> mesh = 1; 186
bss -> rsn_ie_len = min ( elem -> len + 2 , MAX_WPA_IE_LEN ); 197
pos += elem -> len + 2; 209
------------------------------
122 /home/speedy/test/source2slice/NVD/CVE_2008_5134_VULN_lbs_process_bss.c n_ex_rates = MAX_RATES - n_basic_rates 168
static int CVE_2008_5134_VULN_lbs_process_bss(struct bss_descriptor *bss,
uint8_t **pbeaconinfo, int *bytesleft) 2
struct ieeetypes_countryinfoset * pcountryinfo ; 9
uint8_t * pos , * end , * p ; 10
uint8_t n_ex_rates = 0 , got_basic_rates = 0 , n_basic_rates = 0 ; 11
uint16_t beaconsize = 0 ; 12
if ( * bytesleft >= sizeof ( beaconsize ) )  17
beaconsize = get_unaligned_le16 ( * pbeaconinfo ); 19
* bytesleft -= sizeof ( beaconsize ); 20
* pbeaconinfo += sizeof ( beaconsize ); 21
if ( beaconsize == 0 || beaconsize > * bytesleft )  24
pos = * pbeaconinfo; 32
end = pos + beaconsize; 33
pos += ETH_ALEN; 41
if ( ( end - pos ) < 12 )  43
pos ++; 57
pos += 8; 60
pos += 2; 64
pos += 2; 69
while ( pos <= end - 2 )  83
struct ieee80211_info_element * elem = ( void * ) pos ; 84
if ( pos + elem -> len > end )  86
switch ( elem -> id )  92
n_basic_rates = min_t ( uint8_t , MAX_RATES , elem -> len ); 102
got_basic_rates = 1; 104
pcountryinfo = ( struct ieeetypes_countryinfoset * ) pos; 139
if ( pcountryinfo -> len < sizeof ( pcountryinfo -> countrycode ) || pcountryinfo -> len > 254 )  141
if ( ! got_basic_rates )  161
n_ex_rates = elem -> len; 166
if ( n_basic_rates + n_ex_rates > MAX_RATES )  167
n_ex_rates = MAX_RATES - n_basic_rates; 168
memcpy ( p , elem -> data , n_ex_rates ); 171
pos += elem -> len + 2; 209
------------------------------
123 /home/speedy/test/source2slice/NVD/CVE_2008_5134_VULN_lbs_process_bss.c end = pos + beaconsize 33
static int CVE_2008_5134_VULN_lbs_process_bss(struct bss_descriptor *bss,
uint8_t **pbeaconinfo, int *bytesleft) 2
uint8_t * pos , * end , * p ; 10
uint16_t beaconsize = 0 ; 12
if ( * bytesleft >= sizeof ( beaconsize ) )  17
beaconsize = get_unaligned_le16 ( * pbeaconinfo ); 19
* bytesleft -= sizeof ( beaconsize ); 20
* pbeaconinfo += sizeof ( beaconsize ); 21
if ( beaconsize == 0 || beaconsize > * bytesleft )  24
pos = * pbeaconinfo; 32
end = pos + beaconsize; 33
if ( ( end - pos ) < 12 )  43
lbs_deb_scan ( "process_bss: IE len %zd\n" , end - pos ); 79
lbs_deb_hex ( LBS_DEB_SCAN , "process_bss: IE info" , pos , end - pos ); 80
while ( pos <= end - 2 )  83
if ( pos + elem -> len > end )  86
------------------------------
124 /home/speedy/test/source2slice/NVD/CVE_2009_0746_PATCHED_make_indexed_dir.c de -> rec_len = ext4_rec_len_to_disk ( blocksize - EXT4_DIR_REC_LEN ( 2 ) ) 60
static int CVE_2009_0746_PATCHED_make_indexed_dir(handle_t *handle, struct dentry *dentry,
struct inode *inode, struct buffer_head *bh) 2
struct inode * dir = dentry -> d_parent -> d_inode ; 4
struct buffer_head * bh2 ; 7
struct dx_root * root ; 8
struct ext4_dir_entry_2 * de , * de2 ; 11
char * data1 , * top ; 12
unsigned len ; 13
int retval ; 14
unsigned blocksize ; 15
struct fake_dirent * fde ; 18
blocksize = dir -> i_sb -> s_blocksize; 20
retval = ext4_journal_get_write_access ( handle , bh ); 22
if ( retval )  23
root = ( struct dx_root * ) bh -> b_data; 28
fde = & root -> dotdot; 31
de = ( struct ext4_dir_entry_2 * ) ( ( char * ) fde + ext4_rec_len_from_disk ( fde -> rec_len ) ); 32
if ( ( char * ) de >= ( ( ( char * ) root ) + blocksize ) )  34
len = ( ( char * ) root ) + blocksize - ( char * ) de; 41
bh2 = ext4_append ( handle , dir , & block , & retval ); 44
if ( ! ( bh2 ) )  45
data1 = bh2 -> b_data; 50
memcpy ( data1 , de , len ); 52
de = ( struct ext4_dir_entry_2 * ) data1; 53
top = data1 + len; 54
while ( ( char * ) ( de2 = ext4_next_entry ( de ) ) < top )  55
de = de2; 56
de -> rec_len = ext4_rec_len_to_disk ( data1 + blocksize - ( char * ) de ); 57
de = ( struct ext4_dir_entry_2 * ) ( & root -> dotdot ); 59
de -> rec_len = ext4_rec_len_to_disk ( blocksize - EXT4_DIR_REC_LEN ( 2 ) ); 60
if ( ! ( de ) )  80
return add_dirent_to_buf ( handle , dentry , inode , de , bh ) ; 83
------------------------------
125 /home/speedy/test/source2slice/NVD/CVE_2009_0746_PATCHED_make_indexed_dir.c de -> rec_len = ext4_rec_len_to_disk ( data1 + blocksize - ( char * ) de ) 57
static int CVE_2009_0746_PATCHED_make_indexed_dir(handle_t *handle, struct dentry *dentry,
struct inode *inode, struct buffer_head *bh) 2
struct inode * dir = dentry -> d_parent -> d_inode ; 4
struct buffer_head * bh2 ; 7
struct dx_root * root ; 8
struct ext4_dir_entry_2 * de , * de2 ; 11
char * data1 , * top ; 12
unsigned len ; 13
int retval ; 14
unsigned blocksize ; 15
struct fake_dirent * fde ; 18
blocksize = dir -> i_sb -> s_blocksize; 20
retval = ext4_journal_get_write_access ( handle , bh ); 22
if ( retval )  23
root = ( struct dx_root * ) bh -> b_data; 28
fde = & root -> dotdot; 31
de = ( struct ext4_dir_entry_2 * ) ( ( char * ) fde + ext4_rec_len_from_disk ( fde -> rec_len ) ); 32
if ( ( char * ) de >= ( ( ( char * ) root ) + blocksize ) )  34
len = ( ( char * ) root ) + blocksize - ( char * ) de; 41
bh2 = ext4_append ( handle , dir , & block , & retval ); 44
if ( ! ( bh2 ) )  45
data1 = bh2 -> b_data; 50
memcpy ( data1 , de , len ); 52
de = ( struct ext4_dir_entry_2 * ) data1; 53
top = data1 + len; 54
while ( ( char * ) ( de2 = ext4_next_entry ( de ) ) < top )  55
de = de2; 56
de -> rec_len = ext4_rec_len_to_disk ( data1 + blocksize - ( char * ) de ); 57
de -> rec_len = ext4_rec_len_to_disk ( blocksize - EXT4_DIR_REC_LEN ( 2 ) ); 60
if ( ! ( de ) )  80
return add_dirent_to_buf ( handle , dentry , inode , de , bh ) ; 83
------------------------------
126 /home/speedy/test/source2slice/NVD/CVE_2009_0746_PATCHED_make_indexed_dir.c top = data1 + len 54
static int CVE_2009_0746_PATCHED_make_indexed_dir(handle_t *handle, struct dentry *dentry,
struct inode *inode, struct buffer_head *bh) 2
struct inode * dir = dentry -> d_parent -> d_inode ; 4
struct buffer_head * bh2 ; 7
struct dx_root * root ; 8
struct ext4_dir_entry_2 * de , * de2 ; 11
char * data1 , * top ; 12
unsigned len ; 13
int retval ; 14
unsigned blocksize ; 15
struct fake_dirent * fde ; 18
blocksize = dir -> i_sb -> s_blocksize; 20
retval = ext4_journal_get_write_access ( handle , bh ); 22
if ( retval )  23
root = ( struct dx_root * ) bh -> b_data; 28
fde = & root -> dotdot; 31
de = ( struct ext4_dir_entry_2 * ) ( ( char * ) fde + ext4_rec_len_from_disk ( fde -> rec_len ) ); 32
if ( ( char * ) de >= ( ( ( char * ) root ) + blocksize ) )  34
len = ( ( char * ) root ) + blocksize - ( char * ) de; 41
bh2 = ext4_append ( handle , dir , & block , & retval ); 44
if ( ! ( bh2 ) )  45
data1 = bh2 -> b_data; 50
memcpy ( data1 , de , len ); 52
top = data1 + len; 54
while ( ( char * ) ( de2 = ext4_next_entry ( de ) ) < top )  55
de = de2; 56
de -> rec_len = ext4_rec_len_to_disk ( data1 + blocksize - ( char * ) de ); 57
de -> rec_len = ext4_rec_len_to_disk ( blocksize - EXT4_DIR_REC_LEN ( 2 ) ); 60
if ( ! ( de ) )  80
return add_dirent_to_buf ( handle , dentry , inode , de , bh ) ; 83
------------------------------
127 /home/speedy/test/source2slice/NVD/CVE_2009_0746_PATCHED_make_indexed_dir.c de = ( struct ext4_dir_entry_2 * ) ( ( char * ) fde + ext4_rec_len_from_disk ( fde -> rec_len ) ) 32
static int CVE_2009_0746_PATCHED_make_indexed_dir(handle_t *handle, struct dentry *dentry,
struct inode *inode, struct buffer_head *bh) 2
struct dx_root * root ; 8
struct ext4_dir_entry_2 * de , * de2 ; 11
int retval ; 14
struct fake_dirent * fde ; 18
retval = ext4_journal_get_write_access ( handle , bh ); 22
if ( retval )  23
root = ( struct dx_root * ) bh -> b_data; 28
fde = & root -> dotdot; 31
de = ( struct ext4_dir_entry_2 * ) ( ( char * ) fde + ext4_rec_len_from_disk ( fde -> rec_len ) ); 32
if ( ( char * ) de >= ( ( ( char * ) root ) + blocksize ) )  34
len = ( ( char * ) root ) + blocksize - ( char * ) de; 41
memcpy ( data1 , de , len ); 52
de = ( struct ext4_dir_entry_2 * ) data1; 53
top = data1 + len; 54
while ( ( char * ) ( de2 = ext4_next_entry ( de ) ) < top )  55
de = de2; 56
de -> rec_len = ext4_rec_len_to_disk ( data1 + blocksize - ( char * ) de ); 57
de -> rec_len = ext4_rec_len_to_disk ( blocksize - EXT4_DIR_REC_LEN ( 2 ) ); 60
if ( ! ( de ) )  80
return add_dirent_to_buf ( handle , dentry , inode , de , bh ) ; 83
------------------------------
128 /home/speedy/test/source2slice/NVD/CVE_2009_0746_VULN_make_indexed_dir.c de -> rec_len = ext4_rec_len_to_disk ( blocksize - EXT4_DIR_REC_LEN ( 2 ) ) 51
static int CVE_2009_0746_VULN_make_indexed_dir(handle_t *handle, struct dentry *dentry,
struct inode *inode, struct buffer_head *bh) 2
struct inode * dir = dentry -> d_parent -> d_inode ; 4
struct buffer_head * bh2 ; 7
struct dx_root * root ; 8
struct ext4_dir_entry_2 * de , * de2 ; 11
char * data1 , * top ; 12
unsigned len ; 13
int retval ; 14
unsigned blocksize ; 15
struct fake_dirent * fde ; 18
blocksize = dir -> i_sb -> s_blocksize; 20
retval = ext4_journal_get_write_access ( handle , bh ); 22
if ( retval )  23
root = ( struct dx_root * ) bh -> b_data; 28
bh2 = ext4_append ( handle , dir , & block , & retval ); 30
if ( ! ( bh2 ) )  31
data1 = bh2 -> b_data; 36
fde = & root -> dotdot; 39
de = ( struct ext4_dir_entry_2 * ) ( ( char * ) fde + ext4_rec_len_from_disk ( fde -> rec_len ) ); 40
len = ( ( char * ) root ) + blocksize - ( char * ) de; 42
memcpy ( data1 , de , len ); 43
de = ( struct ext4_dir_entry_2 * ) data1; 44
top = data1 + len; 45
while ( ( char * ) ( de2 = ext4_next_entry ( de ) ) < top )  46
de = de2; 47
de -> rec_len = ext4_rec_len_to_disk ( data1 + blocksize - ( char * ) de ); 48
de = ( struct ext4_dir_entry_2 * ) ( & root -> dotdot ); 50
de -> rec_len = ext4_rec_len_to_disk ( blocksize - EXT4_DIR_REC_LEN ( 2 ) ); 51
if ( ! ( de ) )  71
return add_dirent_to_buf ( handle , dentry , inode , de , bh ) ; 74
------------------------------
129 /home/speedy/test/source2slice/NVD/CVE_2009_0746_VULN_make_indexed_dir.c de -> rec_len = ext4_rec_len_to_disk ( data1 + blocksize - ( char * ) de ) 48
static int CVE_2009_0746_VULN_make_indexed_dir(handle_t *handle, struct dentry *dentry,
struct inode *inode, struct buffer_head *bh) 2
struct inode * dir = dentry -> d_parent -> d_inode ; 4
struct buffer_head * bh2 ; 7
struct dx_root * root ; 8
struct ext4_dir_entry_2 * de , * de2 ; 11
char * data1 , * top ; 12
unsigned len ; 13
int retval ; 14
unsigned blocksize ; 15
struct fake_dirent * fde ; 18
blocksize = dir -> i_sb -> s_blocksize; 20
retval = ext4_journal_get_write_access ( handle , bh ); 22
if ( retval )  23
root = ( struct dx_root * ) bh -> b_data; 28
bh2 = ext4_append ( handle , dir , & block , & retval ); 30
if ( ! ( bh2 ) )  31
data1 = bh2 -> b_data; 36
fde = & root -> dotdot; 39
de = ( struct ext4_dir_entry_2 * ) ( ( char * ) fde + ext4_rec_len_from_disk ( fde -> rec_len ) ); 40
len = ( ( char * ) root ) + blocksize - ( char * ) de; 42
memcpy ( data1 , de , len ); 43
de = ( struct ext4_dir_entry_2 * ) data1; 44
top = data1 + len; 45
while ( ( char * ) ( de2 = ext4_next_entry ( de ) ) < top )  46
de = de2; 47
de -> rec_len = ext4_rec_len_to_disk ( data1 + blocksize - ( char * ) de ); 48
de -> rec_len = ext4_rec_len_to_disk ( blocksize - EXT4_DIR_REC_LEN ( 2 ) ); 51
if ( ! ( de ) )  71
return add_dirent_to_buf ( handle , dentry , inode , de , bh ) ; 74
------------------------------
130 /home/speedy/test/source2slice/NVD/CVE_2009_0746_VULN_make_indexed_dir.c top = data1 + len 45
static int CVE_2009_0746_VULN_make_indexed_dir(handle_t *handle, struct dentry *dentry,
struct inode *inode, struct buffer_head *bh) 2
struct inode * dir = dentry -> d_parent -> d_inode ; 4
struct buffer_head * bh2 ; 7
struct dx_root * root ; 8
struct ext4_dir_entry_2 * de , * de2 ; 11
char * data1 , * top ; 12
unsigned len ; 13
int retval ; 14
unsigned blocksize ; 15
struct fake_dirent * fde ; 18
blocksize = dir -> i_sb -> s_blocksize; 20
retval = ext4_journal_get_write_access ( handle , bh ); 22
if ( retval )  23
root = ( struct dx_root * ) bh -> b_data; 28
bh2 = ext4_append ( handle , dir , & block , & retval ); 30
if ( ! ( bh2 ) )  31
data1 = bh2 -> b_data; 36
fde = & root -> dotdot; 39
de = ( struct ext4_dir_entry_2 * ) ( ( char * ) fde + ext4_rec_len_from_disk ( fde -> rec_len ) ); 40
len = ( ( char * ) root ) + blocksize - ( char * ) de; 42
memcpy ( data1 , de , len ); 43
top = data1 + len; 45
while ( ( char * ) ( de2 = ext4_next_entry ( de ) ) < top )  46
de = de2; 47
de -> rec_len = ext4_rec_len_to_disk ( data1 + blocksize - ( char * ) de ); 48
de -> rec_len = ext4_rec_len_to_disk ( blocksize - EXT4_DIR_REC_LEN ( 2 ) ); 51
if ( ! ( de ) )  71
return add_dirent_to_buf ( handle , dentry , inode , de , bh ) ; 74
------------------------------
131 /home/speedy/test/source2slice/NVD/CVE_2009_0746_VULN_make_indexed_dir.c de = ( struct ext4_dir_entry_2 * ) ( ( char * ) fde + ext4_rec_len_from_disk ( fde -> rec_len ) ) 40
static int CVE_2009_0746_VULN_make_indexed_dir(handle_t *handle, struct dentry *dentry,
struct inode *inode, struct buffer_head *bh) 2
struct inode * dir = dentry -> d_parent -> d_inode ; 4
struct buffer_head * bh2 ; 7
struct dx_root * root ; 8
struct ext4_dir_entry_2 * de , * de2 ; 11
int retval ; 14
struct fake_dirent * fde ; 18
retval = ext4_journal_get_write_access ( handle , bh ); 22
if ( retval )  23
root = ( struct dx_root * ) bh -> b_data; 28
bh2 = ext4_append ( handle , dir , & block , & retval ); 30
if ( ! ( bh2 ) )  31
fde = & root -> dotdot; 39
de = ( struct ext4_dir_entry_2 * ) ( ( char * ) fde + ext4_rec_len_from_disk ( fde -> rec_len ) ); 40
len = ( ( char * ) root ) + blocksize - ( char * ) de; 42
memcpy ( data1 , de , len ); 43
de = ( struct ext4_dir_entry_2 * ) data1; 44
top = data1 + len; 45
while ( ( char * ) ( de2 = ext4_next_entry ( de ) ) < top )  46
de = de2; 47
de -> rec_len = ext4_rec_len_to_disk ( data1 + blocksize - ( char * ) de ); 48
de -> rec_len = ext4_rec_len_to_disk ( blocksize - EXT4_DIR_REC_LEN ( 2 ) ); 51
if ( ! ( de ) )  71
return add_dirent_to_buf ( handle , dentry , inode , de , bh ) ; 74
------------------------------
132 /home/speedy/test/source2slice/NVD/CVE_2009_0935_PATCHED_inotify_read.c ret = buf - start 49
static ssize_t CVE_2009_0935_PATCHED_inotify_read(struct file *file, char __user *buf,
size_t count, loff_t *pos) 2
struct inotify_device * dev ; 4
char __user * start ; 5
int ret ; 6
start = buf; 9
dev = file -> private_data; 10
while ( 1 )  12
struct inotify_kernel_event * kevent ; 13
kevent = get_one_event ( dev , count ); 18
if ( kevent )  21
ret = PTR_ERR ( kevent ); 22
if ( IS_ERR ( kevent ) )  23
ret = copy_event_to_user ( kevent , buf ); 25
if ( ret < 0 )  27
buf += ret; 29
count -= ret; 30
ret = - EAGAIN; 34
if ( file -> f_flags & O_NONBLOCK )  35
ret = - EINTR; 37
if ( signal_pending ( current ) )  38
if ( start != buf )  41
if ( start != buf && ret != - EFAULT )  48
ret = buf - start; 49
return ret ; 50
------------------------------
133 /home/speedy/test/source2slice/NVD/CVE_2009_0935_VULN_inotify_read.c ret = buf - start 44
static ssize_t CVE_2009_0935_VULN_inotify_read(struct file *file, char __user *buf,
size_t count, loff_t *pos) 2
size_t event_size = sizeof ( struct inotify_event ) ; 4
struct inotify_device * dev ; 5
char __user * start ; 6
int ret ; 7
start = buf; 10
dev = file -> private_data; 11
while ( 1 )  13
if ( ! list_empty ( & dev -> events ) )  18
ret = 0; 19
if ( file -> f_flags & O_NONBLOCK )  24
ret = - EAGAIN; 25
if ( signal_pending ( current ) )  29
ret = - EINTR; 30
if ( ret )  38
while ( 1 )  41
struct inotify_kernel_event * kevent ; 42
ret = buf - start; 44
if ( list_empty ( & dev -> events ) )  45
kevent = inotify_dev_get_event ( dev ); 48
if ( event_size + kevent -> event . len > count )  49
if ( ret == 0 && count > 0 )  50
if ( copy_to_user ( buf , & kevent -> event , event_size ) )  67
buf += event_size; 71
count -= event_size; 72
if ( kevent -> name )  74
if ( copy_to_user ( buf , kevent -> name , kevent -> event . len ) )  75
buf += kevent -> event . len; 79
count -= kevent -> event . len; 80
return ret ; 89
------------------------------
134 /home/speedy/test/source2slice/NVD/CVE_2009_0946_PATCHED_cff_charset_load.c charset -> offset = base_offset + offset 21
static FT_Error
CVE_2009_0946_PATCHED_cff_charset_load( CFF_Charset  charset,
FT_UInt      num_glyphs,
FT_Stream    stream,
FT_ULong     base_offset,
FT_ULong     offset,
FT_Bool      invert ) 7
if ( offset > 2 )  16
charset -> offset = base_offset + offset; 21
if ( FT_STREAM_SEEK ( charset -> offset ) || FT_READ_BYTE ( charset -> format ) )  24
if ( FT_NEW_ARRAY ( charset -> sids , num_glyphs ) )  29
charset -> sids [ 0 ] = 0; 33
switch ( charset -> format )  35
charset -> sids [ j ] = sid; 50
charset -> sids [ j ] = 0; 55
while ( j < num_glyphs )  72
if ( charset -> format == 2 )  79
charset -> sids [ j ] = glyph_sid; 106
FT_FREE ( charset -> sids ); 199
FT_FREE ( charset -> cids ); 200
------------------------------
135 /home/speedy/test/source2slice/NVD/CVE_2009_0946_PATCHED_ft_smooth_render_generic.c height = ( FT_UInt ) ( ( cbox . yMax - cbox . yMin ) >> 6 ) 47
static FT_Error
CVE_2009_0946_PATCHED_ft_smooth_render_generic( FT_Renderer       render,
FT_GlyphSlot      slot,
FT_Render_Mode    mode,
const FT_Vector*  origin,
FT_Render_Mode    required_mode ) 6
FT_BBox cbox ; 10
FT_UInt width , height , height_org , width_org , pitch ; 11
if ( slot -> format != render -> glyph_format )  22
if ( mode != required_mode )  29
cbox . xMin = FT_PIX_FLOOR ( cbox . xMin ); 41
cbox . yMin = FT_PIX_FLOOR ( cbox . yMin ); 42
cbox . xMax = FT_PIX_CEIL ( cbox . xMax ); 43
cbox . yMax = FT_PIX_CEIL ( cbox . yMax ); 44
height = ( FT_UInt ) ( ( cbox . yMax - cbox . yMin ) >> 6 ); 47
height_org = height; 52
height *= 3; 70
height += 3 * extra; 95
if ( pitch > 0xFFFF || height > 0xFFFF )  102
FT_ERROR ( ( "CVE_2009_0946_PATCHED_ft_smooth_render_generic: glyph too large: %d x %d\n" , width , height ) ); 104
bitmap -> rows = height; 112
bitmap -> pitch = pitch; 113
if ( FT_ALLOC ( bitmap -> buffer , ( FT_ULong ) pitch * height ) )  118
params . target = bitmap; 124
params . source = outline; 125
params . flags = FT_RASTER_FLAG_AA; 126
error = render -> raster_render ( render -> raster , & params ); 147
slot -> library -> lcd_filter_func ( bitmap , mode , slot -> library ); 166
if ( error )  225
return error ; 236
------------------------------
136 /home/speedy/test/source2slice/NVD/CVE_2009_0946_PATCHED_ft_smooth_render_generic.c width = ( FT_UInt ) ( ( cbox . xMax - cbox . xMin ) >> 6 ) 46
static FT_Error
CVE_2009_0946_PATCHED_ft_smooth_render_generic( FT_Renderer       render,
FT_GlyphSlot      slot,
FT_Render_Mode    mode,
const FT_Vector*  origin,
FT_Render_Mode    required_mode ) 6
FT_BBox cbox ; 10
FT_UInt width , height , height_org , width_org , pitch ; 11
if ( slot -> format != render -> glyph_format )  22
if ( mode != required_mode )  29
cbox . xMin = FT_PIX_FLOOR ( cbox . xMin ); 41
cbox . yMin = FT_PIX_FLOOR ( cbox . yMin ); 42
cbox . xMax = FT_PIX_CEIL ( cbox . xMax ); 43
cbox . yMax = FT_PIX_CEIL ( cbox . yMax ); 44
width = ( FT_UInt ) ( ( cbox . xMax - cbox . xMin ) >> 6 ); 46
width_org = width; 51
pitch = width; 62
width = width * 3; 65
pitch = FT_PAD_CEIL ( width , 4 ); 66
width += 3 * extra; 87
pitch = FT_PAD_CEIL ( width , 4 ); 88
if ( pitch > 0xFFFF || height > 0xFFFF )  102
FT_ERROR ( ( "CVE_2009_0946_PATCHED_ft_smooth_render_generic: glyph too large: %d x %d\n" , width , height ) ); 104
bitmap -> width = width; 111
bitmap -> rows = height; 112
bitmap -> pitch = pitch; 113
if ( FT_ALLOC ( bitmap -> buffer , ( FT_ULong ) pitch * height ) )  118
params . target = bitmap; 124
params . source = outline; 125
params . flags = FT_RASTER_FLAG_AA; 126
error = render -> raster_render ( render -> raster , & params ); 147
slot -> library -> lcd_filter_func ( bitmap , mode , slot -> library ); 166
if ( error )  225
return error ; 236
------------------------------
137 /home/speedy/test/source2slice/NVD/CVE_2009_0946_PATCHED_tt_cmap8_validate.c count = ( FT_UInt32 ) ( end - start + 1 ) 49
CVE_2009_0946_PATCHED_tt_cmap8_validate( FT_Byte*      table,
FT_Validator  valid ) 2
FT_Byte * is32 ; 5
FT_UInt32 num_groups ; 7
is32 = table + 12; 17
p = is32 + 8192; 18
num_groups = TT_NEXT_ULONG ( p ); 19
for ( n = 0; n < num_groups; n++ ) 29
start = TT_NEXT_ULONG ( p ); 34
end = TT_NEXT_ULONG ( p ); 35
if ( valid -> level >= FT_VALIDATE_TIGHT )  44
count = ( FT_UInt32 ) ( end - start + 1 ); 49
for ( ; count > 0; count--, start++ ) 55
hi = ( FT_UInt ) ( start >> 16 ); 57
lo = ( FT_UInt ) ( start & 0xFFFFU ); 58
if ( ( is32 [ hi >> 3 ] & ( 0x80 >> ( hi & 7 ) ) ) == 0 )  60
if ( ( is32 [ lo >> 3 ] & ( 0x80 >> ( lo & 7 ) ) ) == 0 )  63
for ( ; count > 0; count--, start++ ) 76
lo = ( FT_UInt ) ( start & 0xFFFFU ); 78
if ( ( is32 [ lo >> 3 ] & ( 0x80 >> ( lo & 7 ) ) ) != 0 )  80
------------------------------
138 /home/speedy/test/source2slice/NVD/CVE_2009_0946_VULN_cff_charset_load.c charset -> offset = base_offset + offset 21
static FT_Error
CVE_2009_0946_VULN_cff_charset_load( CFF_Charset  charset,
FT_UInt      num_glyphs,
FT_Stream    stream,
FT_ULong     base_offset,
FT_ULong     offset,
FT_Bool      invert ) 7
if ( offset > 2 )  16
charset -> offset = base_offset + offset; 21
if ( FT_STREAM_SEEK ( charset -> offset ) || FT_READ_BYTE ( charset -> format ) )  24
if ( FT_NEW_ARRAY ( charset -> sids , num_glyphs ) )  29
charset -> sids [ 0 ] = 0; 33
switch ( charset -> format )  35
charset -> sids [ j ] = FT_GET_USHORT ( ); 44
while ( j < num_glyphs )  59
if ( FT_READ_USHORT ( glyph_sid ) )  62
if ( charset -> format == 2 )  66
for ( i = 0; j < num_glyphs && i <= nleft; i++, j++, glyph_sid++ ) 78
charset -> sids [ j ] = glyph_sid; 79
FT_FREE ( charset -> sids ); 172
FT_FREE ( charset -> cids ); 173
------------------------------
139 /home/speedy/test/source2slice/NVD/CVE_2009_0946_VULN_ft_smooth_render_generic.c height = ( FT_UInt ) ( ( cbox . yMax - cbox . yMin ) >> 6 ) 47
static FT_Error
CVE_2009_0946_VULN_ft_smooth_render_generic( FT_Renderer       render,
FT_GlyphSlot      slot,
FT_Render_Mode    mode,
const FT_Vector*  origin,
FT_Render_Mode    required_mode ) 6
FT_BBox cbox ; 10
FT_UInt width , height , height_org , width_org , pitch ; 11
if ( slot -> format != render -> glyph_format )  22
if ( mode != required_mode )  29
cbox . xMin = FT_PIX_FLOOR ( cbox . xMin ); 41
cbox . yMin = FT_PIX_FLOOR ( cbox . yMin ); 42
cbox . xMax = FT_PIX_CEIL ( cbox . xMax ); 43
cbox . yMax = FT_PIX_CEIL ( cbox . yMax ); 44
height = ( FT_UInt ) ( ( cbox . yMax - cbox . yMin ) >> 6 ); 47
height_org = height; 52
height *= 3; 70
height += 3 * extra; 95
bitmap -> rows = height; 105
bitmap -> pitch = pitch; 106
if ( FT_ALLOC ( bitmap -> buffer , ( FT_ULong ) pitch * height ) )  111
params . target = bitmap; 117
params . source = outline; 118
params . flags = FT_RASTER_FLAG_AA; 119
error = render -> raster_render ( render -> raster , & params ); 140
slot -> library -> lcd_filter_func ( bitmap , mode , slot -> library ); 159
if ( error )  218
return error ; 229
------------------------------
140 /home/speedy/test/source2slice/NVD/CVE_2009_0946_VULN_ft_smooth_render_generic.c width = ( FT_UInt ) ( ( cbox . xMax - cbox . xMin ) >> 6 ) 46
static FT_Error
CVE_2009_0946_VULN_ft_smooth_render_generic( FT_Renderer       render,
FT_GlyphSlot      slot,
FT_Render_Mode    mode,
const FT_Vector*  origin,
FT_Render_Mode    required_mode ) 6
FT_BBox cbox ; 10
FT_UInt width , height , height_org , width_org , pitch ; 11
if ( slot -> format != render -> glyph_format )  22
if ( mode != required_mode )  29
cbox . xMin = FT_PIX_FLOOR ( cbox . xMin ); 41
cbox . yMin = FT_PIX_FLOOR ( cbox . yMin ); 42
cbox . xMax = FT_PIX_CEIL ( cbox . xMax ); 43
cbox . yMax = FT_PIX_CEIL ( cbox . yMax ); 44
width = ( FT_UInt ) ( ( cbox . xMax - cbox . xMin ) >> 6 ); 46
width_org = width; 51
pitch = width; 62
width = width * 3; 65
pitch = FT_PAD_CEIL ( width , 4 ); 66
width += 3 * extra; 87
pitch = FT_PAD_CEIL ( width , 4 ); 88
bitmap -> width = width; 104
bitmap -> rows = height; 105
bitmap -> pitch = pitch; 106
if ( FT_ALLOC ( bitmap -> buffer , ( FT_ULong ) pitch * height ) )  111
params . target = bitmap; 117
params . source = outline; 118
params . flags = FT_RASTER_FLAG_AA; 119
error = render -> raster_render ( render -> raster , & params ); 140
slot -> library -> lcd_filter_func ( bitmap , mode , slot -> library ); 159
if ( error )  218
return error ; 229
------------------------------
141 /home/speedy/test/source2slice/NVD/CVE_2009_0946_VULN_tt_cmap8_validate.c count = ( FT_UInt32 ) ( end - start + 1 ) 49
CVE_2009_0946_VULN_tt_cmap8_validate( FT_Byte*      table,
FT_Validator  valid ) 2
FT_Byte * is32 ; 5
FT_UInt32 num_groups ; 7
is32 = table + 12; 17
p = is32 + 8192; 18
num_groups = TT_NEXT_ULONG ( p ); 19
for ( n = 0; n < num_groups; n++ ) 29
start = TT_NEXT_ULONG ( p ); 34
end = TT_NEXT_ULONG ( p ); 35
if ( valid -> level >= FT_VALIDATE_TIGHT )  44
count = ( FT_UInt32 ) ( end - start + 1 ); 49
for ( ; count > 0; count--, start++ ) 55
hi = ( FT_UInt ) ( start >> 16 ); 57
lo = ( FT_UInt ) ( start & 0xFFFFU ); 58
if ( ( is32 [ hi >> 3 ] & ( 0x80 >> ( hi & 7 ) ) ) == 0 )  60
if ( ( is32 [ lo >> 3 ] & ( 0x80 >> ( lo & 7 ) ) ) == 0 )  63
for ( ; count > 0; count--, start++ ) 76
lo = ( FT_UInt ) ( start & 0xFFFFU ); 78
if ( ( is32 [ lo >> 3 ] & ( 0x80 >> ( lo & 7 ) ) ) != 0 )  80
------------------------------
142 /home/speedy/test/source2slice/NVD/CVE_2009_1046_PATCHED_set_selection.c sel_buffer_lth = bp - sel_buffer 164
int CVE_2009_1046_PATCHED_set_selection(const struct tiocl_selection __user *sel, struct tty_struct *tty) 1
struct vc_data * vc = vc_cons [ fg_console ] . d ; 3
int sel_mode , new_sel_start , new_sel_end , spc ; 4
char * bp , * obp ; 5
int i , ps , pe , multiplier ; 6
u16 c ; 7
struct kbd_struct * kbd = kbd_table + fg_console ; 8
unsigned short xs , ys , xe , ye ; 12
if ( ! access_ok ( VERIFY_READ , sel , sizeof ( * sel ) ) )  14
xs --; 21
ys --; 21
xe --; 21
ye --; 21
xs = limit ( xs , vc -> vc_cols - 1 ); 22
ys = limit ( ys , vc -> vc_rows - 1 ); 23
xe = limit ( xe , vc -> vc_cols - 1 ); 24
ye = limit ( ye , vc -> vc_rows - 1 ); 25
ps = ys * vc -> vc_size_row + ( xs << 1 ); 26
pe = ye * vc -> vc_size_row + ( xe << 1 ); 27
if ( sel_mode == TIOCL_SELCLEAR )  29
if ( mouse_reporting ( ) && ( sel_mode & TIOCL_SELMOUSEREPORT ) )  35
if ( ps > pe )  41
int tmp = ps ; 43
ps = pe; 44
pe = tmp; 45
use_unicode = kbd && kbd -> kbdmode == VC_UNICODE; 52
switch ( sel_mode )  54
new_sel_start = ps; 57
new_sel_end = pe; 58
spc = isspace ( sel_pos ( ps ) ); 61
ps -= 2 62
if ( ( spc && ! isspace ( sel_pos ( ps ) ) ) || ( ! spc && ! inword ( sel_pos ( ps ) ) ) )  64
new_sel_start = ps; 67
if ( ! ( ps % vc -> vc_size_row ) )  68
spc = isspace ( sel_pos ( pe ) ); 71
pe += 2 72
if ( ( spc && ! isspace ( sel_pos ( pe ) ) ) || ( ! spc && ! inword ( sel_pos ( pe ) ) ) )  74
new_sel_end = pe; 77
if ( ! ( ( pe + 2 ) % vc -> vc_size_row ) )  78
new_sel_start = ps - ps % vc -> vc_size_row; 83
new_sel_end = pe + vc -> vc_size_row - pe % vc -> vc_size_row - 2; 84
if ( new_sel_end > new_sel_start && ! atedge ( new_sel_end , vc -> vc_size_row ) && isspace ( sel_pos ( new_sel_end ) ) )  98
pe += 2 101
if ( ! isspace ( sel_pos ( pe ) ) || atedge ( pe , vc -> vc_size_row ) )  102
if ( isspace ( sel_pos ( pe ) ) )  105
new_sel_end = pe; 106
if ( sel_start == - 1 )  108
if ( new_sel_start == sel_start )  110
if ( new_sel_end == sel_end )  112
sel_start = new_sel_start; 131
sel_end = new_sel_end; 132
multiplier = use_unicode ? 3 : 1; 135
bp = kmalloc ( ( ( sel_end - sel_start ) / 2 + 1 ) * multiplier , GFP_KERNEL ); 136
if ( ! bp )  137
sel_buffer = bp; 143
obp = bp; 145
for (i = sel_start; i <= sel_end; i += 2) 146
c = sel_pos ( i ); 147
if ( use_unicode )  148
bp += store_utf8 ( c , bp ); 149
* bp ++ = c; 151
if ( ! isspace ( c ) )  152
obp = bp; 153
if ( ! ( ( i + 2 ) % vc -> vc_size_row ) )  154
if ( obp != bp )  157
bp = obp; 158
* bp ++ = '\r'; 159
obp = bp; 161
sel_buffer_lth = bp - sel_buffer; 164
------------------------------
143 /home/speedy/test/source2slice/NVD/CVE_2009_1046_PATCHED_set_selection.c bp = kmalloc ( ( ( sel_end - sel_start ) / 2 + 1 ) * multiplier , GFP_KERNEL ) 136
int CVE_2009_1046_PATCHED_set_selection(const struct tiocl_selection __user *sel, struct tty_struct *tty) 1
struct vc_data * vc = vc_cons [ fg_console ] . d ; 3
int sel_mode , new_sel_start , new_sel_end , spc ; 4
char * bp , * obp ; 5
int i , ps , pe , multiplier ; 6
struct kbd_struct * kbd = kbd_table + fg_console ; 8
unsigned short xs , ys , xe , ye ; 12
if ( ! access_ok ( VERIFY_READ , sel , sizeof ( * sel ) ) )  14
xs --; 21
ys --; 21
xe --; 21
ye --; 21
xs = limit ( xs , vc -> vc_cols - 1 ); 22
ys = limit ( ys , vc -> vc_rows - 1 ); 23
xe = limit ( xe , vc -> vc_cols - 1 ); 24
ye = limit ( ye , vc -> vc_rows - 1 ); 25
ps = ys * vc -> vc_size_row + ( xs << 1 ); 26
pe = ye * vc -> vc_size_row + ( xe << 1 ); 27
if ( sel_mode == TIOCL_SELCLEAR )  29
if ( mouse_reporting ( ) && ( sel_mode & TIOCL_SELMOUSEREPORT ) )  35
if ( ps > pe )  41
int tmp = ps ; 43
ps = pe; 44
pe = tmp; 45
use_unicode = kbd && kbd -> kbdmode == VC_UNICODE; 52
switch ( sel_mode )  54
new_sel_start = ps; 57
new_sel_end = pe; 58
spc = isspace ( sel_pos ( ps ) ); 61
ps -= 2 62
if ( ( spc && ! isspace ( sel_pos ( ps ) ) ) || ( ! spc && ! inword ( sel_pos ( ps ) ) ) )  64
new_sel_start = ps; 67
if ( ! ( ps % vc -> vc_size_row ) )  68
spc = isspace ( sel_pos ( pe ) ); 71
pe += 2 72
if ( ( spc && ! isspace ( sel_pos ( pe ) ) ) || ( ! spc && ! inword ( sel_pos ( pe ) ) ) )  74
new_sel_end = pe; 77
if ( ! ( ( pe + 2 ) % vc -> vc_size_row ) )  78
new_sel_start = ps - ps % vc -> vc_size_row; 83
new_sel_end = pe + vc -> vc_size_row - pe % vc -> vc_size_row - 2; 84
if ( new_sel_end > new_sel_start && ! atedge ( new_sel_end , vc -> vc_size_row ) && isspace ( sel_pos ( new_sel_end ) ) )  98
pe += 2 101
if ( ! isspace ( sel_pos ( pe ) ) || atedge ( pe , vc -> vc_size_row ) )  102
if ( isspace ( sel_pos ( pe ) ) )  105
new_sel_end = pe; 106
if ( sel_start == - 1 )  108
if ( new_sel_start == sel_start )  110
if ( new_sel_end == sel_end )  112
sel_start = new_sel_start; 131
sel_end = new_sel_end; 132
multiplier = use_unicode ? 3 : 1; 135
bp = kmalloc ( ( ( sel_end - sel_start ) / 2 + 1 ) * multiplier , GFP_KERNEL ); 136
if ( ! bp )  137
sel_buffer = bp; 143
obp = bp; 145
bp += store_utf8 ( c , bp ); 149
* bp ++ = c; 151
obp = bp; 153
if ( obp != bp )  157
bp = obp; 158
* bp ++ = '\r'; 159
obp = bp; 161
sel_buffer_lth = bp - sel_buffer; 164
------------------------------
144 /home/speedy/test/source2slice/NVD/CVE_2009_1046_PATCHED_set_selection.c new_sel_end = pe + vc -> vc_size_row - pe % vc -> vc_size_row - 2 84
int CVE_2009_1046_PATCHED_set_selection(const struct tiocl_selection __user *sel, struct tty_struct *tty) 1
struct vc_data * vc = vc_cons [ fg_console ] . d ; 3
int sel_mode , new_sel_start , new_sel_end , spc ; 4
int i , ps , pe , multiplier ; 6
unsigned short xs , ys , xe , ye ; 12
if ( ! access_ok ( VERIFY_READ , sel , sizeof ( * sel ) ) )  14
xs --; 21
ys --; 21
xe --; 21
ye --; 21
xs = limit ( xs , vc -> vc_cols - 1 ); 22
ys = limit ( ys , vc -> vc_rows - 1 ); 23
xe = limit ( xe , vc -> vc_cols - 1 ); 24
ye = limit ( ye , vc -> vc_rows - 1 ); 25
ps = ys * vc -> vc_size_row + ( xs << 1 ); 26
pe = ye * vc -> vc_size_row + ( xe << 1 ); 27
if ( sel_mode == TIOCL_SELCLEAR )  29
if ( mouse_reporting ( ) && ( sel_mode & TIOCL_SELMOUSEREPORT ) )  35
if ( ps > pe )  41
int tmp = ps ; 43
pe = tmp; 45
switch ( sel_mode )  54
new_sel_end = pe + vc -> vc_size_row - pe % vc -> vc_size_row - 2; 84
if ( new_sel_end > new_sel_start && ! atedge ( new_sel_end , vc -> vc_size_row ) && isspace ( sel_pos ( new_sel_end ) ) )  98
pe += 2 101
if ( ! isspace ( sel_pos ( pe ) ) || atedge ( pe , vc -> vc_size_row ) )  102
if ( isspace ( sel_pos ( pe ) ) )  105
new_sel_end = pe; 106
highlight ( new_sel_start , new_sel_end ); 109
if ( new_sel_end == sel_end )  112
if ( new_sel_end > sel_end )  114
highlight ( sel_end + 2 , new_sel_end ); 115
highlight ( new_sel_end + 2 , sel_end ); 117
if ( new_sel_end == sel_end )  119
highlight ( new_sel_start , new_sel_end ); 129
sel_end = new_sel_end; 132
bp = kmalloc ( ( ( sel_end - sel_start ) / 2 + 1 ) * multiplier , GFP_KERNEL ); 136
if ( ! bp )  137
sel_buffer = bp; 143
obp = bp; 145
for (i = sel_start; i <= sel_end; i += 2) 146
bp += store_utf8 ( c , bp ); 149
* bp ++ = c; 151
obp = bp; 153
if ( obp != bp )  157
bp = obp; 158
* bp ++ = '\r'; 159
obp = bp; 161
sel_buffer_lth = bp - sel_buffer; 164
------------------------------
145 /home/speedy/test/source2slice/NVD/CVE_2009_1046_PATCHED_set_selection.c new_sel_start = ps - ps % vc -> vc_size_row 83
int CVE_2009_1046_PATCHED_set_selection(const struct tiocl_selection __user *sel, struct tty_struct *tty) 1
struct vc_data * vc = vc_cons [ fg_console ] . d ; 3
int sel_mode , new_sel_start , new_sel_end , spc ; 4
int i , ps , pe , multiplier ; 6
unsigned short xs , ys , xe , ye ; 12
if ( ! access_ok ( VERIFY_READ , sel , sizeof ( * sel ) ) )  14
xs --; 21
ys --; 21
xe --; 21
ye --; 21
xs = limit ( xs , vc -> vc_cols - 1 ); 22
ys = limit ( ys , vc -> vc_rows - 1 ); 23
xe = limit ( xe , vc -> vc_cols - 1 ); 24
ye = limit ( ye , vc -> vc_rows - 1 ); 25
ps = ys * vc -> vc_size_row + ( xs << 1 ); 26
pe = ye * vc -> vc_size_row + ( xe << 1 ); 27
if ( sel_mode == TIOCL_SELCLEAR )  29
if ( mouse_reporting ( ) && ( sel_mode & TIOCL_SELMOUSEREPORT ) )  35
if ( ps > pe )  41
ps = pe; 44
switch ( sel_mode )  54
new_sel_start = ps - ps % vc -> vc_size_row; 83
if ( new_sel_end > new_sel_start && ! atedge ( new_sel_end , vc -> vc_size_row ) && isspace ( sel_pos ( new_sel_end ) ) )  98
highlight ( new_sel_start , new_sel_end ); 109
if ( new_sel_start == sel_start )  110
if ( new_sel_start < sel_start )  121
highlight ( new_sel_start , sel_start - 2 ); 122
highlight ( sel_start , new_sel_start - 2 ); 124
highlight ( new_sel_start , new_sel_end ); 129
sel_start = new_sel_start; 131
bp = kmalloc ( ( ( sel_end - sel_start ) / 2 + 1 ) * multiplier , GFP_KERNEL ); 136
if ( ! bp )  137
sel_buffer = bp; 143
obp = bp; 145
for (i = sel_start; i <= sel_end; i += 2) 146
c = sel_pos ( i ); 147
bp += store_utf8 ( c , bp ); 149
* bp ++ = c; 151
if ( ! isspace ( c ) )  152
obp = bp; 153
if ( ! ( ( i + 2 ) % vc -> vc_size_row ) )  154
if ( obp != bp )  157
bp = obp; 158
* bp ++ = '\r'; 159
obp = bp; 161
sel_buffer_lth = bp - sel_buffer; 164
------------------------------
146 /home/speedy/test/source2slice/NVD/CVE_2009_1046_PATCHED_set_selection.c pe = ye * vc -> vc_size_row + ( xe << 1 ) 27
int CVE_2009_1046_PATCHED_set_selection(const struct tiocl_selection __user *sel, struct tty_struct *tty) 1
struct vc_data * vc = vc_cons [ fg_console ] . d ; 3
int i , ps , pe , multiplier ; 6
unsigned short xs , ys , xe , ye ; 12
if ( ! access_ok ( VERIFY_READ , sel , sizeof ( * sel ) ) )  14
xe --; 21
ye --; 21
xe = limit ( xe , vc -> vc_cols - 1 ); 24
ye = limit ( ye , vc -> vc_rows - 1 ); 25
pe = ye * vc -> vc_size_row + ( xe << 1 ); 27
if ( ps > pe )  41
ps = pe; 44
new_sel_start = ps; 57
new_sel_end = pe; 58
spc = isspace ( sel_pos ( ps ) ); 61
ps -= 2 62
if ( ( spc && ! isspace ( sel_pos ( ps ) ) ) || ( ! spc && ! inword ( sel_pos ( ps ) ) ) )  64
new_sel_start = ps; 67
if ( ! ( ps % vc -> vc_size_row ) )  68
spc = isspace ( sel_pos ( pe ) ); 71
pe += 2 72
if ( ( spc && ! isspace ( sel_pos ( pe ) ) ) || ( ! spc && ! inword ( sel_pos ( pe ) ) ) )  74
new_sel_end = pe; 77
if ( ! ( ( pe + 2 ) % vc -> vc_size_row ) )  78
new_sel_start = ps - ps % vc -> vc_size_row; 83
new_sel_end = pe + vc -> vc_size_row - pe % vc -> vc_size_row - 2; 84
highlight_pointer ( pe ); 88
if ( new_sel_end > new_sel_start && ! atedge ( new_sel_end , vc -> vc_size_row ) && isspace ( sel_pos ( new_sel_end ) ) )  98
pe += 2 101
if ( ! isspace ( sel_pos ( pe ) ) || atedge ( pe , vc -> vc_size_row ) )  102
if ( isspace ( sel_pos ( pe ) ) )  105
new_sel_end = pe; 106
highlight ( new_sel_start , new_sel_end ); 109
if ( new_sel_start == sel_start )  110
if ( new_sel_end == sel_end )  112
if ( new_sel_end > sel_end )  114
highlight ( sel_end + 2 , new_sel_end ); 115
highlight ( new_sel_end + 2 , sel_end ); 117
if ( new_sel_end == sel_end )  119
if ( new_sel_start < sel_start )  121
highlight ( new_sel_start , sel_start - 2 ); 122
highlight ( sel_start , new_sel_start - 2 ); 124
highlight ( new_sel_start , new_sel_end ); 129
sel_start = new_sel_start; 131
sel_end = new_sel_end; 132
bp = kmalloc ( ( ( sel_end - sel_start ) / 2 + 1 ) * multiplier , GFP_KERNEL ); 136
if ( ! bp )  137
sel_buffer = bp; 143
obp = bp; 145
for (i = sel_start; i <= sel_end; i += 2) 146
c = sel_pos ( i ); 147
bp += store_utf8 ( c , bp ); 149
* bp ++ = c; 151
if ( ! isspace ( c ) )  152
obp = bp; 153
if ( ! ( ( i + 2 ) % vc -> vc_size_row ) )  154
if ( obp != bp )  157
bp = obp; 158
* bp ++ = '\r'; 159
obp = bp; 161
sel_buffer_lth = bp - sel_buffer; 164
------------------------------
147 /home/speedy/test/source2slice/NVD/CVE_2009_1046_PATCHED_set_selection.c ps = ys * vc -> vc_size_row + ( xs << 1 ) 26
int CVE_2009_1046_PATCHED_set_selection(const struct tiocl_selection __user *sel, struct tty_struct *tty) 1
struct vc_data * vc = vc_cons [ fg_console ] . d ; 3
int i , ps , pe , multiplier ; 6
unsigned short xs , ys , xe , ye ; 12
if ( ! access_ok ( VERIFY_READ , sel , sizeof ( * sel ) ) )  14
xs --; 21
ys --; 21
xs = limit ( xs , vc -> vc_cols - 1 ); 22
ys = limit ( ys , vc -> vc_rows - 1 ); 23
ps = ys * vc -> vc_size_row + ( xs << 1 ); 26
if ( ps > pe )  41
int tmp = ps ; 43
pe = tmp; 45
new_sel_start = ps; 57
new_sel_end = pe; 58
spc = isspace ( sel_pos ( ps ) ); 61
ps -= 2 62
if ( ( spc && ! isspace ( sel_pos ( ps ) ) ) || ( ! spc && ! inword ( sel_pos ( ps ) ) ) )  64
new_sel_start = ps; 67
if ( ! ( ps % vc -> vc_size_row ) )  68
spc = isspace ( sel_pos ( pe ) ); 71
pe += 2 72
if ( ( spc && ! isspace ( sel_pos ( pe ) ) ) || ( ! spc && ! inword ( sel_pos ( pe ) ) ) )  74
new_sel_end = pe; 77
if ( ! ( ( pe + 2 ) % vc -> vc_size_row ) )  78
new_sel_start = ps - ps % vc -> vc_size_row; 83
new_sel_end = pe + vc -> vc_size_row - pe % vc -> vc_size_row - 2; 84
highlight_pointer ( pe ); 88
if ( new_sel_end > new_sel_start && ! atedge ( new_sel_end , vc -> vc_size_row ) && isspace ( sel_pos ( new_sel_end ) ) )  98
pe += 2 101
if ( ! isspace ( sel_pos ( pe ) ) || atedge ( pe , vc -> vc_size_row ) )  102
if ( isspace ( sel_pos ( pe ) ) )  105
new_sel_end = pe; 106
highlight ( new_sel_start , new_sel_end ); 109
if ( new_sel_start == sel_start )  110
if ( new_sel_end == sel_end )  112
if ( new_sel_end > sel_end )  114
highlight ( sel_end + 2 , new_sel_end ); 115
highlight ( new_sel_end + 2 , sel_end ); 117
if ( new_sel_end == sel_end )  119
if ( new_sel_start < sel_start )  121
highlight ( new_sel_start , sel_start - 2 ); 122
highlight ( sel_start , new_sel_start - 2 ); 124
highlight ( new_sel_start , new_sel_end ); 129
sel_start = new_sel_start; 131
sel_end = new_sel_end; 132
bp = kmalloc ( ( ( sel_end - sel_start ) / 2 + 1 ) * multiplier , GFP_KERNEL ); 136
if ( ! bp )  137
sel_buffer = bp; 143
obp = bp; 145
for (i = sel_start; i <= sel_end; i += 2) 146
c = sel_pos ( i ); 147
bp += store_utf8 ( c , bp ); 149
* bp ++ = c; 151
if ( ! isspace ( c ) )  152
obp = bp; 153
if ( ! ( ( i + 2 ) % vc -> vc_size_row ) )  154
if ( obp != bp )  157
bp = obp; 158
* bp ++ = '\r'; 159
obp = bp; 161
sel_buffer_lth = bp - sel_buffer; 164
------------------------------
148 /home/speedy/test/source2slice/NVD/CVE_2009_1046_VULN_set_selection.c sel_buffer_lth = bp - sel_buffer 164
int CVE_2009_1046_VULN_set_selection(const struct tiocl_selection __user *sel, struct tty_struct *tty) 1
struct vc_data * vc = vc_cons [ fg_console ] . d ; 3
int sel_mode , new_sel_start , new_sel_end , spc ; 4
char * bp , * obp ; 5
int i , ps , pe , multiplier ; 6
u16 c ; 7
struct kbd_struct * kbd = kbd_table + fg_console ; 8
unsigned short xs , ys , xe , ye ; 12
if ( ! access_ok ( VERIFY_READ , sel , sizeof ( * sel ) ) )  14
xs --; 21
ys --; 21
xe --; 21
ye --; 21
xs = limit ( xs , vc -> vc_cols - 1 ); 22
ys = limit ( ys , vc -> vc_rows - 1 ); 23
xe = limit ( xe , vc -> vc_cols - 1 ); 24
ye = limit ( ye , vc -> vc_rows - 1 ); 25
ps = ys * vc -> vc_size_row + ( xs << 1 ); 26
pe = ye * vc -> vc_size_row + ( xe << 1 ); 27
if ( sel_mode == TIOCL_SELCLEAR )  29
if ( mouse_reporting ( ) && ( sel_mode & TIOCL_SELMOUSEREPORT ) )  35
if ( ps > pe )  41
int tmp = ps ; 43
ps = pe; 44
pe = tmp; 45
use_unicode = kbd && kbd -> kbdmode == VC_UNICODE; 52
switch ( sel_mode )  54
new_sel_start = ps; 57
new_sel_end = pe; 58
spc = isspace ( sel_pos ( ps ) ); 61
ps -= 2 62
if ( ( spc && ! isspace ( sel_pos ( ps ) ) ) || ( ! spc && ! inword ( sel_pos ( ps ) ) ) )  64
new_sel_start = ps; 67
if ( ! ( ps % vc -> vc_size_row ) )  68
spc = isspace ( sel_pos ( pe ) ); 71
pe += 2 72
if ( ( spc && ! isspace ( sel_pos ( pe ) ) ) || ( ! spc && ! inword ( sel_pos ( pe ) ) ) )  74
new_sel_end = pe; 77
if ( ! ( ( pe + 2 ) % vc -> vc_size_row ) )  78
new_sel_start = ps - ps % vc -> vc_size_row; 83
new_sel_end = pe + vc -> vc_size_row - pe % vc -> vc_size_row - 2; 84
if ( new_sel_end > new_sel_start && ! atedge ( new_sel_end , vc -> vc_size_row ) && isspace ( sel_pos ( new_sel_end ) ) )  98
pe += 2 101
if ( ! isspace ( sel_pos ( pe ) ) || atedge ( pe , vc -> vc_size_row ) )  102
if ( isspace ( sel_pos ( pe ) ) )  105
new_sel_end = pe; 106
if ( sel_start == - 1 )  108
if ( new_sel_start == sel_start )  110
if ( new_sel_end == sel_end )  112
sel_start = new_sel_start; 131
sel_end = new_sel_end; 132
multiplier = use_unicode ? 3 : 1; 135
bp = kmalloc ( ( sel_end - sel_start ) / 2 * multiplier + 1 , GFP_KERNEL ); 136
if ( ! bp )  137
sel_buffer = bp; 143
obp = bp; 145
for (i = sel_start; i <= sel_end; i += 2) 146
c = sel_pos ( i ); 147
if ( use_unicode )  148
bp += store_utf8 ( c , bp ); 149
* bp ++ = c; 151
if ( ! isspace ( c ) )  152
obp = bp; 153
if ( ! ( ( i + 2 ) % vc -> vc_size_row ) )  154
if ( obp != bp )  157
bp = obp; 158
* bp ++ = '\r'; 159
obp = bp; 161
sel_buffer_lth = bp - sel_buffer; 164
------------------------------
149 /home/speedy/test/source2slice/NVD/CVE_2009_1046_VULN_set_selection.c bp = kmalloc ( ( sel_end - sel_start ) / 2 * multiplier + 1 , GFP_KERNEL ) 136
int CVE_2009_1046_VULN_set_selection(const struct tiocl_selection __user *sel, struct tty_struct *tty) 1
struct vc_data * vc = vc_cons [ fg_console ] . d ; 3
int sel_mode , new_sel_start , new_sel_end , spc ; 4
char * bp , * obp ; 5
int i , ps , pe , multiplier ; 6
struct kbd_struct * kbd = kbd_table + fg_console ; 8
unsigned short xs , ys , xe , ye ; 12
if ( ! access_ok ( VERIFY_READ , sel , sizeof ( * sel ) ) )  14
xs --; 21
ys --; 21
xe --; 21
ye --; 21
xs = limit ( xs , vc -> vc_cols - 1 ); 22
ys = limit ( ys , vc -> vc_rows - 1 ); 23
xe = limit ( xe , vc -> vc_cols - 1 ); 24
ye = limit ( ye , vc -> vc_rows - 1 ); 25
ps = ys * vc -> vc_size_row + ( xs << 1 ); 26
pe = ye * vc -> vc_size_row + ( xe << 1 ); 27
if ( sel_mode == TIOCL_SELCLEAR )  29
if ( mouse_reporting ( ) && ( sel_mode & TIOCL_SELMOUSEREPORT ) )  35
if ( ps > pe )  41
int tmp = ps ; 43
ps = pe; 44
pe = tmp; 45
use_unicode = kbd && kbd -> kbdmode == VC_UNICODE; 52
switch ( sel_mode )  54
new_sel_start = ps; 57
new_sel_end = pe; 58
spc = isspace ( sel_pos ( ps ) ); 61
ps -= 2 62
if ( ( spc && ! isspace ( sel_pos ( ps ) ) ) || ( ! spc && ! inword ( sel_pos ( ps ) ) ) )  64
new_sel_start = ps; 67
if ( ! ( ps % vc -> vc_size_row ) )  68
spc = isspace ( sel_pos ( pe ) ); 71
pe += 2 72
if ( ( spc && ! isspace ( sel_pos ( pe ) ) ) || ( ! spc && ! inword ( sel_pos ( pe ) ) ) )  74
new_sel_end = pe; 77
if ( ! ( ( pe + 2 ) % vc -> vc_size_row ) )  78
new_sel_start = ps - ps % vc -> vc_size_row; 83
new_sel_end = pe + vc -> vc_size_row - pe % vc -> vc_size_row - 2; 84
if ( new_sel_end > new_sel_start && ! atedge ( new_sel_end , vc -> vc_size_row ) && isspace ( sel_pos ( new_sel_end ) ) )  98
pe += 2 101
if ( ! isspace ( sel_pos ( pe ) ) || atedge ( pe , vc -> vc_size_row ) )  102
if ( isspace ( sel_pos ( pe ) ) )  105
new_sel_end = pe; 106
if ( sel_start == - 1 )  108
if ( new_sel_start == sel_start )  110
if ( new_sel_end == sel_end )  112
sel_start = new_sel_start; 131
sel_end = new_sel_end; 132
multiplier = use_unicode ? 3 : 1; 135
bp = kmalloc ( ( sel_end - sel_start ) / 2 * multiplier + 1 , GFP_KERNEL ); 136
if ( ! bp )  137
sel_buffer = bp; 143
obp = bp; 145
bp += store_utf8 ( c , bp ); 149
* bp ++ = c; 151
obp = bp; 153
if ( obp != bp )  157
bp = obp; 158
* bp ++ = '\r'; 159
obp = bp; 161
sel_buffer_lth = bp - sel_buffer; 164
------------------------------
150 /home/speedy/test/source2slice/NVD/CVE_2009_1046_VULN_set_selection.c new_sel_end = pe + vc -> vc_size_row - pe % vc -> vc_size_row - 2 84
int CVE_2009_1046_VULN_set_selection(const struct tiocl_selection __user *sel, struct tty_struct *tty) 1
struct vc_data * vc = vc_cons [ fg_console ] . d ; 3
int sel_mode , new_sel_start , new_sel_end , spc ; 4
int i , ps , pe , multiplier ; 6
unsigned short xs , ys , xe , ye ; 12
if ( ! access_ok ( VERIFY_READ , sel , sizeof ( * sel ) ) )  14
xs --; 21
ys --; 21
xe --; 21
ye --; 21
xs = limit ( xs , vc -> vc_cols - 1 ); 22
ys = limit ( ys , vc -> vc_rows - 1 ); 23
xe = limit ( xe , vc -> vc_cols - 1 ); 24
ye = limit ( ye , vc -> vc_rows - 1 ); 25
ps = ys * vc -> vc_size_row + ( xs << 1 ); 26
pe = ye * vc -> vc_size_row + ( xe << 1 ); 27
if ( sel_mode == TIOCL_SELCLEAR )  29
if ( mouse_reporting ( ) && ( sel_mode & TIOCL_SELMOUSEREPORT ) )  35
if ( ps > pe )  41
int tmp = ps ; 43
pe = tmp; 45
switch ( sel_mode )  54
new_sel_end = pe + vc -> vc_size_row - pe % vc -> vc_size_row - 2; 84
if ( new_sel_end > new_sel_start && ! atedge ( new_sel_end , vc -> vc_size_row ) && isspace ( sel_pos ( new_sel_end ) ) )  98
pe += 2 101
if ( ! isspace ( sel_pos ( pe ) ) || atedge ( pe , vc -> vc_size_row ) )  102
if ( isspace ( sel_pos ( pe ) ) )  105
new_sel_end = pe; 106
highlight ( new_sel_start , new_sel_end ); 109
if ( new_sel_end == sel_end )  112
if ( new_sel_end > sel_end )  114
highlight ( sel_end + 2 , new_sel_end ); 115
highlight ( new_sel_end + 2 , sel_end ); 117
if ( new_sel_end == sel_end )  119
highlight ( new_sel_start , new_sel_end ); 129
sel_end = new_sel_end; 132
bp = kmalloc ( ( sel_end - sel_start ) / 2 * multiplier + 1 , GFP_KERNEL ); 136
if ( ! bp )  137
sel_buffer = bp; 143
obp = bp; 145
for (i = sel_start; i <= sel_end; i += 2) 146
bp += store_utf8 ( c , bp ); 149
* bp ++ = c; 151
obp = bp; 153
if ( obp != bp )  157
bp = obp; 158
* bp ++ = '\r'; 159
obp = bp; 161
sel_buffer_lth = bp - sel_buffer; 164
------------------------------
151 /home/speedy/test/source2slice/NVD/CVE_2009_1046_VULN_set_selection.c new_sel_start = ps - ps % vc -> vc_size_row 83
int CVE_2009_1046_VULN_set_selection(const struct tiocl_selection __user *sel, struct tty_struct *tty) 1
struct vc_data * vc = vc_cons [ fg_console ] . d ; 3
int sel_mode , new_sel_start , new_sel_end , spc ; 4
int i , ps , pe , multiplier ; 6
unsigned short xs , ys , xe , ye ; 12
if ( ! access_ok ( VERIFY_READ , sel , sizeof ( * sel ) ) )  14
xs --; 21
ys --; 21
xe --; 21
ye --; 21
xs = limit ( xs , vc -> vc_cols - 1 ); 22
ys = limit ( ys , vc -> vc_rows - 1 ); 23
xe = limit ( xe , vc -> vc_cols - 1 ); 24
ye = limit ( ye , vc -> vc_rows - 1 ); 25
ps = ys * vc -> vc_size_row + ( xs << 1 ); 26
pe = ye * vc -> vc_size_row + ( xe << 1 ); 27
if ( sel_mode == TIOCL_SELCLEAR )  29
if ( mouse_reporting ( ) && ( sel_mode & TIOCL_SELMOUSEREPORT ) )  35
if ( ps > pe )  41
ps = pe; 44
switch ( sel_mode )  54
new_sel_start = ps - ps % vc -> vc_size_row; 83
if ( new_sel_end > new_sel_start && ! atedge ( new_sel_end , vc -> vc_size_row ) && isspace ( sel_pos ( new_sel_end ) ) )  98
highlight ( new_sel_start , new_sel_end ); 109
if ( new_sel_start == sel_start )  110
if ( new_sel_start < sel_start )  121
highlight ( new_sel_start , sel_start - 2 ); 122
highlight ( sel_start , new_sel_start - 2 ); 124
highlight ( new_sel_start , new_sel_end ); 129
sel_start = new_sel_start; 131
bp = kmalloc ( ( sel_end - sel_start ) / 2 * multiplier + 1 , GFP_KERNEL ); 136
if ( ! bp )  137
sel_buffer = bp; 143
obp = bp; 145
for (i = sel_start; i <= sel_end; i += 2) 146
c = sel_pos ( i ); 147
bp += store_utf8 ( c , bp ); 149
* bp ++ = c; 151
if ( ! isspace ( c ) )  152
obp = bp; 153
if ( ! ( ( i + 2 ) % vc -> vc_size_row ) )  154
if ( obp != bp )  157
bp = obp; 158
* bp ++ = '\r'; 159
obp = bp; 161
sel_buffer_lth = bp - sel_buffer; 164
------------------------------
152 /home/speedy/test/source2slice/NVD/CVE_2009_1046_VULN_set_selection.c pe = ye * vc -> vc_size_row + ( xe << 1 ) 27
int CVE_2009_1046_VULN_set_selection(const struct tiocl_selection __user *sel, struct tty_struct *tty) 1
struct vc_data * vc = vc_cons [ fg_console ] . d ; 3
int i , ps , pe , multiplier ; 6
unsigned short xs , ys , xe , ye ; 12
if ( ! access_ok ( VERIFY_READ , sel , sizeof ( * sel ) ) )  14
xe --; 21
ye --; 21
xe = limit ( xe , vc -> vc_cols - 1 ); 24
ye = limit ( ye , vc -> vc_rows - 1 ); 25
pe = ye * vc -> vc_size_row + ( xe << 1 ); 27
if ( ps > pe )  41
ps = pe; 44
new_sel_start = ps; 57
new_sel_end = pe; 58
spc = isspace ( sel_pos ( ps ) ); 61
ps -= 2 62
if ( ( spc && ! isspace ( sel_pos ( ps ) ) ) || ( ! spc && ! inword ( sel_pos ( ps ) ) ) )  64
new_sel_start = ps; 67
if ( ! ( ps % vc -> vc_size_row ) )  68
spc = isspace ( sel_pos ( pe ) ); 71
pe += 2 72
if ( ( spc && ! isspace ( sel_pos ( pe ) ) ) || ( ! spc && ! inword ( sel_pos ( pe ) ) ) )  74
new_sel_end = pe; 77
if ( ! ( ( pe + 2 ) % vc -> vc_size_row ) )  78
new_sel_start = ps - ps % vc -> vc_size_row; 83
new_sel_end = pe + vc -> vc_size_row - pe % vc -> vc_size_row - 2; 84
highlight_pointer ( pe ); 88
if ( new_sel_end > new_sel_start && ! atedge ( new_sel_end , vc -> vc_size_row ) && isspace ( sel_pos ( new_sel_end ) ) )  98
pe += 2 101
if ( ! isspace ( sel_pos ( pe ) ) || atedge ( pe , vc -> vc_size_row ) )  102
if ( isspace ( sel_pos ( pe ) ) )  105
new_sel_end = pe; 106
highlight ( new_sel_start , new_sel_end ); 109
if ( new_sel_start == sel_start )  110
if ( new_sel_end == sel_end )  112
if ( new_sel_end > sel_end )  114
highlight ( sel_end + 2 , new_sel_end ); 115
highlight ( new_sel_end + 2 , sel_end ); 117
if ( new_sel_end == sel_end )  119
if ( new_sel_start < sel_start )  121
highlight ( new_sel_start , sel_start - 2 ); 122
highlight ( sel_start , new_sel_start - 2 ); 124
highlight ( new_sel_start , new_sel_end ); 129
sel_start = new_sel_start; 131
sel_end = new_sel_end; 132
bp = kmalloc ( ( sel_end - sel_start ) / 2 * multiplier + 1 , GFP_KERNEL ); 136
if ( ! bp )  137
sel_buffer = bp; 143
obp = bp; 145
for (i = sel_start; i <= sel_end; i += 2) 146
c = sel_pos ( i ); 147
bp += store_utf8 ( c , bp ); 149
* bp ++ = c; 151
if ( ! isspace ( c ) )  152
obp = bp; 153
if ( ! ( ( i + 2 ) % vc -> vc_size_row ) )  154
if ( obp != bp )  157
bp = obp; 158
* bp ++ = '\r'; 159
obp = bp; 161
sel_buffer_lth = bp - sel_buffer; 164
------------------------------
153 /home/speedy/test/source2slice/NVD/CVE_2009_1046_VULN_set_selection.c ps = ys * vc -> vc_size_row + ( xs << 1 ) 26
int CVE_2009_1046_VULN_set_selection(const struct tiocl_selection __user *sel, struct tty_struct *tty) 1
struct vc_data * vc = vc_cons [ fg_console ] . d ; 3
int i , ps , pe , multiplier ; 6
unsigned short xs , ys , xe , ye ; 12
if ( ! access_ok ( VERIFY_READ , sel , sizeof ( * sel ) ) )  14
xs --; 21
ys --; 21
xs = limit ( xs , vc -> vc_cols - 1 ); 22
ys = limit ( ys , vc -> vc_rows - 1 ); 23
ps = ys * vc -> vc_size_row + ( xs << 1 ); 26
if ( ps > pe )  41
int tmp = ps ; 43
pe = tmp; 45
new_sel_start = ps; 57
new_sel_end = pe; 58
spc = isspace ( sel_pos ( ps ) ); 61
ps -= 2 62
if ( ( spc && ! isspace ( sel_pos ( ps ) ) ) || ( ! spc && ! inword ( sel_pos ( ps ) ) ) )  64
new_sel_start = ps; 67
if ( ! ( ps % vc -> vc_size_row ) )  68
spc = isspace ( sel_pos ( pe ) ); 71
pe += 2 72
if ( ( spc && ! isspace ( sel_pos ( pe ) ) ) || ( ! spc && ! inword ( sel_pos ( pe ) ) ) )  74
new_sel_end = pe; 77
if ( ! ( ( pe + 2 ) % vc -> vc_size_row ) )  78
new_sel_start = ps - ps % vc -> vc_size_row; 83
new_sel_end = pe + vc -> vc_size_row - pe % vc -> vc_size_row - 2; 84
highlight_pointer ( pe ); 88
if ( new_sel_end > new_sel_start && ! atedge ( new_sel_end , vc -> vc_size_row ) && isspace ( sel_pos ( new_sel_end ) ) )  98
pe += 2 101
if ( ! isspace ( sel_pos ( pe ) ) || atedge ( pe , vc -> vc_size_row ) )  102
if ( isspace ( sel_pos ( pe ) ) )  105
new_sel_end = pe; 106
highlight ( new_sel_start , new_sel_end ); 109
if ( new_sel_start == sel_start )  110
if ( new_sel_end == sel_end )  112
if ( new_sel_end > sel_end )  114
highlight ( sel_end + 2 , new_sel_end ); 115
highlight ( new_sel_end + 2 , sel_end ); 117
if ( new_sel_end == sel_end )  119
if ( new_sel_start < sel_start )  121
highlight ( new_sel_start , sel_start - 2 ); 122
highlight ( sel_start , new_sel_start - 2 ); 124
highlight ( new_sel_start , new_sel_end ); 129
sel_start = new_sel_start; 131
sel_end = new_sel_end; 132
bp = kmalloc ( ( sel_end - sel_start ) / 2 * multiplier + 1 , GFP_KERNEL ); 136
if ( ! bp )  137
sel_buffer = bp; 143
obp = bp; 145
for (i = sel_start; i <= sel_end; i += 2) 146
c = sel_pos ( i ); 147
bp += store_utf8 ( c , bp ); 149
* bp ++ = c; 151
if ( ! isspace ( c ) )  152
obp = bp; 153
if ( ! ( ( i + 2 ) % vc -> vc_size_row ) )  154
if ( obp != bp )  157
bp = obp; 158
* bp ++ = '\r'; 159
obp = bp; 161
sel_buffer_lth = bp - sel_buffer; 164
------------------------------
154 /home/speedy/test/source2slice/NVD/CVE_2009_1298_PATCHED_ip_frag_reasm.c clone -> len = clone -> data_len = head -> data_len - plen 60
static int CVE_2009_1298_PATCHED_ip_frag_reasm(struct ipq *qp, struct sk_buff *prev,
struct net_device *dev) 2
struct sk_buff * fp , * head = qp -> q . fragments ; 6
int len ; 7
int ihlen ; 8
if ( prev )  14
head = prev -> next; 15
fp = skb_clone ( head , GFP_ATOMIC ); 16
if ( ! fp )  17
head -> next = qp -> q . fragments -> next; 24
qp -> q . fragments = head; 27
ihlen = ip_hdrlen ( head ); 34
len = ihlen + qp -> q . len; 35
if ( len > 65535 )  38
if ( skb_cloned ( head ) && pskb_expand_head ( head , 0 , 0 , GFP_ATOMIC ) )  42
if ( skb_shinfo ( head ) -> frag_list )  48
struct sk_buff * clone ; 49
int i , plen = 0 ; 50
if ( ( clone = alloc_skb ( 0 , GFP_ATOMIC ) ) == NULL )  52
clone -> next = head -> next; 54
head -> next = clone; 55
skb_shinfo ( clone ) -> frag_list = skb_shinfo ( head ) -> frag_list; 56
skb_shinfo ( head ) -> frag_list = NULL; 57
for (i=0; i<skb_shinfo(head)->nr_frags; i++) 58
plen += skb_shinfo ( head ) -> frags [ i ] . size; 59
clone -> len = clone -> data_len = head -> data_len - plen; 60
head -> data_len -= clone -> len; 61
head -> len -= clone -> len; 62
clone -> csum = 0; 63
clone -> ip_summed = head -> ip_summed; 64
atomic_add ( clone -> truesize , & qp -> q . net -> mem ); 65
skb_shinfo ( head ) -> frag_list = head -> next; 68
skb_push ( head , head -> data - skb_network_header ( head ) ); 69
atomic_sub ( head -> truesize , & qp -> q . net -> mem ); 70
for (fp=head->next; fp; fp = fp->next) 72
head -> data_len += fp -> len; 73
head -> len += fp -> len; 74
if ( head -> ip_summed != fp -> ip_summed )  75
head -> ip_summed = CHECKSUM_NONE; 76
if ( head -> ip_summed == CHECKSUM_COMPLETE )  77
head -> csum = csum_add ( head -> csum , fp -> csum ); 78
head -> truesize += fp -> truesize; 79
atomic_sub ( fp -> truesize , & qp -> q . net -> mem ); 80
head -> next = NULL; 83
head -> dev = dev; 84
head -> tstamp = qp -> q . stamp; 85
iph = ip_hdr ( head ); 87
iph -> frag_off = 0; 88
iph -> tot_len = htons ( len ); 89
------------------------------
155 /home/speedy/test/source2slice/NVD/CVE_2009_1298_PATCHED_ip_frag_reasm.c len = ihlen + qp -> q . len 35
static int CVE_2009_1298_PATCHED_ip_frag_reasm(struct ipq *qp, struct sk_buff *prev,
struct net_device *dev) 2
struct sk_buff * fp , * head = qp -> q . fragments ; 6
int len ; 7
int ihlen ; 8
if ( prev )  14
head = prev -> next; 15
fp = skb_clone ( head , GFP_ATOMIC ); 16
if ( ! fp )  17
head -> next = qp -> q . fragments -> next; 24
qp -> q . fragments = head; 27
ihlen = ip_hdrlen ( head ); 34
len = ihlen + qp -> q . len; 35
if ( len > 65535 )  38
iph -> tot_len = htons ( len ); 89
------------------------------
156 /home/speedy/test/source2slice/NVD/CVE_2009_1298_VULN_ip_frag_reasm.c clone -> len = clone -> data_len = head -> data_len - plen 60
static int CVE_2009_1298_VULN_ip_frag_reasm(struct ipq *qp, struct sk_buff *prev,
struct net_device *dev) 2
struct sk_buff * fp , * head = qp -> q . fragments ; 6
int len ; 7
int ihlen ; 8
if ( prev )  14
head = prev -> next; 15
fp = skb_clone ( head , GFP_ATOMIC ); 16
if ( ! fp )  17
head -> next = qp -> q . fragments -> next; 24
qp -> q . fragments = head; 27
ihlen = ip_hdrlen ( head ); 34
len = ihlen + qp -> q . len; 35
if ( len > 65535 )  38
if ( skb_cloned ( head ) && pskb_expand_head ( head , 0 , 0 , GFP_ATOMIC ) )  42
if ( skb_shinfo ( head ) -> frag_list )  48
struct sk_buff * clone ; 49
int i , plen = 0 ; 50
if ( ( clone = alloc_skb ( 0 , GFP_ATOMIC ) ) == NULL )  52
clone -> next = head -> next; 54
head -> next = clone; 55
skb_shinfo ( clone ) -> frag_list = skb_shinfo ( head ) -> frag_list; 56
skb_shinfo ( head ) -> frag_list = NULL; 57
for (i=0; i<skb_shinfo(head)->nr_frags; i++) 58
plen += skb_shinfo ( head ) -> frags [ i ] . size; 59
clone -> len = clone -> data_len = head -> data_len - plen; 60
head -> data_len -= clone -> len; 61
head -> len -= clone -> len; 62
clone -> csum = 0; 63
clone -> ip_summed = head -> ip_summed; 64
atomic_add ( clone -> truesize , & qp -> q . net -> mem ); 65
skb_shinfo ( head ) -> frag_list = head -> next; 68
skb_push ( head , head -> data - skb_network_header ( head ) ); 69
atomic_sub ( head -> truesize , & qp -> q . net -> mem ); 70
for (fp=head->next; fp; fp = fp->next) 72
head -> data_len += fp -> len; 73
head -> len += fp -> len; 74
if ( head -> ip_summed != fp -> ip_summed )  75
head -> ip_summed = CHECKSUM_NONE; 76
if ( head -> ip_summed == CHECKSUM_COMPLETE )  77
head -> csum = csum_add ( head -> csum , fp -> csum ); 78
head -> truesize += fp -> truesize; 79
atomic_sub ( fp -> truesize , & qp -> q . net -> mem ); 80
head -> next = NULL; 83
head -> dev = dev; 84
head -> tstamp = qp -> q . stamp; 85
iph = ip_hdr ( head ); 87
iph -> frag_off = 0; 88
iph -> tot_len = htons ( len ); 89
------------------------------
157 /home/speedy/test/source2slice/NVD/CVE_2009_1298_VULN_ip_frag_reasm.c len = ihlen + qp -> q . len 35
static int CVE_2009_1298_VULN_ip_frag_reasm(struct ipq *qp, struct sk_buff *prev,
struct net_device *dev) 2
struct sk_buff * fp , * head = qp -> q . fragments ; 6
int len ; 7
int ihlen ; 8
if ( prev )  14
head = prev -> next; 15
fp = skb_clone ( head , GFP_ATOMIC ); 16
if ( ! fp )  17
head -> next = qp -> q . fragments -> next; 24
qp -> q . fragments = head; 27
ihlen = ip_hdrlen ( head ); 34
len = ihlen + qp -> q . len; 35
if ( len > 65535 )  38
iph -> tot_len = htons ( len ); 89
------------------------------
158 /home/speedy/test/source2slice/NVD/CVE_2009_1336_PATCHED_nfs_init_server.c server -> acdirmax = data -> acdirmax * HZ 37
static int CVE_2009_1336_PATCHED_nfs_init_server(struct nfs_server *server, const struct nfs_mount_data *data) 1
struct nfs_client * clp ; 3
int error , nfsvers = 2 ; 4
if ( data -> flags & NFS_MOUNT_VER3 )  9
nfsvers = 3; 10
clp = nfs_get_client ( data -> hostname , & data -> addr , nfsvers ); 14
if ( IS_ERR ( clp ) )  15
error = nfs_init_client ( clp , data ); 20
if ( error < 0 )  21
server -> nfs_client = clp; 24
server -> flags = data -> flags & NFS_MOUNT_FLAGMASK; 27
if ( data -> rsize )  29
server -> rsize = nfs_block_size ( data -> rsize , NULL ); 30
if ( data -> wsize )  31
server -> wsize = nfs_block_size ( data -> wsize , NULL ); 32
server -> acregmin = data -> acregmin * HZ; 34
server -> acregmax = data -> acregmax * HZ; 35
server -> acdirmin = data -> acdirmin * HZ; 36
server -> acdirmax = data -> acdirmax * HZ; 37
error = nfs_start_lockd ( server ); 40
if ( error < 0 )  41
error = nfs_init_server_rpcclient ( server , data -> pseudoflavor ); 44
if ( error < 0 )  45
server -> namelen = data -> namlen; 48
nfs_init_server_aclclient ( server ); 50
dprintk ( "<-- CVE_2009_1336_PATCHED_nfs_init_server() = xerror %d\n" , error ); 57
return error ; 58
------------------------------
159 /home/speedy/test/source2slice/NVD/CVE_2009_1336_PATCHED_nfs_init_server.c server -> acdirmin = data -> acdirmin * HZ 36
static int CVE_2009_1336_PATCHED_nfs_init_server(struct nfs_server *server, const struct nfs_mount_data *data) 1
struct nfs_client * clp ; 3
int error , nfsvers = 2 ; 4
if ( data -> flags & NFS_MOUNT_VER3 )  9
nfsvers = 3; 10
clp = nfs_get_client ( data -> hostname , & data -> addr , nfsvers ); 14
if ( IS_ERR ( clp ) )  15
error = nfs_init_client ( clp , data ); 20
if ( error < 0 )  21
server -> nfs_client = clp; 24
server -> flags = data -> flags & NFS_MOUNT_FLAGMASK; 27
if ( data -> rsize )  29
server -> rsize = nfs_block_size ( data -> rsize , NULL ); 30
if ( data -> wsize )  31
server -> wsize = nfs_block_size ( data -> wsize , NULL ); 32
server -> acregmin = data -> acregmin * HZ; 34
server -> acregmax = data -> acregmax * HZ; 35
server -> acdirmin = data -> acdirmin * HZ; 36
server -> acdirmax = data -> acdirmax * HZ; 37
error = nfs_start_lockd ( server ); 40
if ( error < 0 )  41
error = nfs_init_server_rpcclient ( server , data -> pseudoflavor ); 44
if ( error < 0 )  45
server -> namelen = data -> namlen; 48
nfs_init_server_aclclient ( server ); 50
dprintk ( "<-- CVE_2009_1336_PATCHED_nfs_init_server() = xerror %d\n" , error ); 57
return error ; 58
------------------------------
160 /home/speedy/test/source2slice/NVD/CVE_2009_1336_PATCHED_nfs_init_server.c server -> acregmax = data -> acregmax * HZ 35
static int CVE_2009_1336_PATCHED_nfs_init_server(struct nfs_server *server, const struct nfs_mount_data *data) 1
struct nfs_client * clp ; 3
int error , nfsvers = 2 ; 4
if ( data -> flags & NFS_MOUNT_VER3 )  9
nfsvers = 3; 10
clp = nfs_get_client ( data -> hostname , & data -> addr , nfsvers ); 14
if ( IS_ERR ( clp ) )  15
error = nfs_init_client ( clp , data ); 20
if ( error < 0 )  21
server -> nfs_client = clp; 24
server -> flags = data -> flags & NFS_MOUNT_FLAGMASK; 27
if ( data -> rsize )  29
server -> rsize = nfs_block_size ( data -> rsize , NULL ); 30
if ( data -> wsize )  31
server -> wsize = nfs_block_size ( data -> wsize , NULL ); 32
server -> acregmin = data -> acregmin * HZ; 34
server -> acregmax = data -> acregmax * HZ; 35
server -> acdirmin = data -> acdirmin * HZ; 36
server -> acdirmax = data -> acdirmax * HZ; 37
error = nfs_start_lockd ( server ); 40
if ( error < 0 )  41
error = nfs_init_server_rpcclient ( server , data -> pseudoflavor ); 44
if ( error < 0 )  45
server -> namelen = data -> namlen; 48
nfs_init_server_aclclient ( server ); 50
dprintk ( "<-- CVE_2009_1336_PATCHED_nfs_init_server() = xerror %d\n" , error ); 57
return error ; 58
------------------------------
161 /home/speedy/test/source2slice/NVD/CVE_2009_1336_PATCHED_nfs_init_server.c server -> acregmin = data -> acregmin * HZ 34
static int CVE_2009_1336_PATCHED_nfs_init_server(struct nfs_server *server, const struct nfs_mount_data *data) 1
struct nfs_client * clp ; 3
int error , nfsvers = 2 ; 4
if ( data -> flags & NFS_MOUNT_VER3 )  9
nfsvers = 3; 10
clp = nfs_get_client ( data -> hostname , & data -> addr , nfsvers ); 14
if ( IS_ERR ( clp ) )  15
error = nfs_init_client ( clp , data ); 20
if ( error < 0 )  21
server -> nfs_client = clp; 24
server -> flags = data -> flags & NFS_MOUNT_FLAGMASK; 27
if ( data -> rsize )  29
server -> rsize = nfs_block_size ( data -> rsize , NULL ); 30
if ( data -> wsize )  31
server -> wsize = nfs_block_size ( data -> wsize , NULL ); 32
server -> acregmin = data -> acregmin * HZ; 34
server -> acregmax = data -> acregmax * HZ; 35
server -> acdirmin = data -> acdirmin * HZ; 36
server -> acdirmax = data -> acdirmax * HZ; 37
error = nfs_start_lockd ( server ); 40
if ( error < 0 )  41
error = nfs_init_server_rpcclient ( server , data -> pseudoflavor ); 44
if ( error < 0 )  45
server -> namelen = data -> namlen; 48
nfs_init_server_aclclient ( server ); 50
dprintk ( "<-- CVE_2009_1336_PATCHED_nfs_init_server() = xerror %d\n" , error ); 57
return error ; 58
------------------------------
162 /home/speedy/test/source2slice/NVD/CVE_2009_1336_VULN_nfs_init_server.c server -> acdirmax = data -> acdirmax * HZ 37
static int CVE_2009_1336_VULN_nfs_init_server(struct nfs_server *server, const struct nfs_mount_data *data) 1
struct nfs_client * clp ; 3
int error , nfsvers = 2 ; 4
if ( data -> flags & NFS_MOUNT_VER3 )  9
nfsvers = 3; 10
clp = nfs_get_client ( data -> hostname , & data -> addr , nfsvers ); 14
if ( IS_ERR ( clp ) )  15
error = nfs_init_client ( clp , data ); 20
if ( error < 0 )  21
server -> nfs_client = clp; 24
server -> flags = data -> flags & NFS_MOUNT_FLAGMASK; 27
if ( data -> rsize )  29
server -> rsize = nfs_block_size ( data -> rsize , NULL ); 30
if ( data -> wsize )  31
server -> wsize = nfs_block_size ( data -> wsize , NULL ); 32
server -> acregmin = data -> acregmin * HZ; 34
server -> acregmax = data -> acregmax * HZ; 35
server -> acdirmin = data -> acdirmin * HZ; 36
server -> acdirmax = data -> acdirmax * HZ; 37
error = nfs_start_lockd ( server ); 40
if ( error < 0 )  41
error = nfs_init_server_rpcclient ( server , data -> pseudoflavor ); 44
if ( error < 0 )  45
server -> namelen = data -> namlen; 48
nfs_init_server_aclclient ( server ); 50
if ( server -> namelen == 0 || server -> namelen > NFS3_MAXNAMLEN )  52
server -> namelen = NFS3_MAXNAMLEN; 53
server -> caps |= NFS_CAP_READDIRPLUS; 55
if ( server -> namelen == 0 || server -> namelen > NFS2_MAXNAMLEN )  57
dprintk ( "<-- CVE_2009_1336_VULN_nfs_init_server() = xerror %d\n" , error ); 67
return error ; 68
------------------------------
163 /home/speedy/test/source2slice/NVD/CVE_2009_1336_VULN_nfs_init_server.c server -> acdirmin = data -> acdirmin * HZ 36
static int CVE_2009_1336_VULN_nfs_init_server(struct nfs_server *server, const struct nfs_mount_data *data) 1
struct nfs_client * clp ; 3
int error , nfsvers = 2 ; 4
if ( data -> flags & NFS_MOUNT_VER3 )  9
nfsvers = 3; 10
clp = nfs_get_client ( data -> hostname , & data -> addr , nfsvers ); 14
if ( IS_ERR ( clp ) )  15
error = nfs_init_client ( clp , data ); 20
if ( error < 0 )  21
server -> nfs_client = clp; 24
server -> flags = data -> flags & NFS_MOUNT_FLAGMASK; 27
if ( data -> rsize )  29
server -> rsize = nfs_block_size ( data -> rsize , NULL ); 30
if ( data -> wsize )  31
server -> wsize = nfs_block_size ( data -> wsize , NULL ); 32
server -> acregmin = data -> acregmin * HZ; 34
server -> acregmax = data -> acregmax * HZ; 35
server -> acdirmin = data -> acdirmin * HZ; 36
server -> acdirmax = data -> acdirmax * HZ; 37
error = nfs_start_lockd ( server ); 40
if ( error < 0 )  41
error = nfs_init_server_rpcclient ( server , data -> pseudoflavor ); 44
if ( error < 0 )  45
server -> namelen = data -> namlen; 48
nfs_init_server_aclclient ( server ); 50
if ( server -> namelen == 0 || server -> namelen > NFS3_MAXNAMLEN )  52
server -> namelen = NFS3_MAXNAMLEN; 53
server -> caps |= NFS_CAP_READDIRPLUS; 55
if ( server -> namelen == 0 || server -> namelen > NFS2_MAXNAMLEN )  57
dprintk ( "<-- CVE_2009_1336_VULN_nfs_init_server() = xerror %d\n" , error ); 67
return error ; 68
------------------------------
164 /home/speedy/test/source2slice/NVD/CVE_2009_1336_VULN_nfs_init_server.c server -> acregmax = data -> acregmax * HZ 35
static int CVE_2009_1336_VULN_nfs_init_server(struct nfs_server *server, const struct nfs_mount_data *data) 1
struct nfs_client * clp ; 3
int error , nfsvers = 2 ; 4
if ( data -> flags & NFS_MOUNT_VER3 )  9
nfsvers = 3; 10
clp = nfs_get_client ( data -> hostname , & data -> addr , nfsvers ); 14
if ( IS_ERR ( clp ) )  15
error = nfs_init_client ( clp , data ); 20
if ( error < 0 )  21
server -> nfs_client = clp; 24
server -> flags = data -> flags & NFS_MOUNT_FLAGMASK; 27
if ( data -> rsize )  29
server -> rsize = nfs_block_size ( data -> rsize , NULL ); 30
if ( data -> wsize )  31
server -> wsize = nfs_block_size ( data -> wsize , NULL ); 32
server -> acregmin = data -> acregmin * HZ; 34
server -> acregmax = data -> acregmax * HZ; 35
server -> acdirmin = data -> acdirmin * HZ; 36
server -> acdirmax = data -> acdirmax * HZ; 37
error = nfs_start_lockd ( server ); 40
if ( error < 0 )  41
error = nfs_init_server_rpcclient ( server , data -> pseudoflavor ); 44
if ( error < 0 )  45
server -> namelen = data -> namlen; 48
nfs_init_server_aclclient ( server ); 50
if ( server -> namelen == 0 || server -> namelen > NFS3_MAXNAMLEN )  52
server -> namelen = NFS3_MAXNAMLEN; 53
server -> caps |= NFS_CAP_READDIRPLUS; 55
if ( server -> namelen == 0 || server -> namelen > NFS2_MAXNAMLEN )  57
dprintk ( "<-- CVE_2009_1336_VULN_nfs_init_server() = xerror %d\n" , error ); 67
return error ; 68
------------------------------
165 /home/speedy/test/source2slice/NVD/CVE_2009_1336_VULN_nfs_init_server.c server -> acregmin = data -> acregmin * HZ 34
static int CVE_2009_1336_VULN_nfs_init_server(struct nfs_server *server, const struct nfs_mount_data *data) 1
struct nfs_client * clp ; 3
int error , nfsvers = 2 ; 4
if ( data -> flags & NFS_MOUNT_VER3 )  9
nfsvers = 3; 10
clp = nfs_get_client ( data -> hostname , & data -> addr , nfsvers ); 14
if ( IS_ERR ( clp ) )  15
error = nfs_init_client ( clp , data ); 20
if ( error < 0 )  21
server -> nfs_client = clp; 24
server -> flags = data -> flags & NFS_MOUNT_FLAGMASK; 27
if ( data -> rsize )  29
server -> rsize = nfs_block_size ( data -> rsize , NULL ); 30
if ( data -> wsize )  31
server -> wsize = nfs_block_size ( data -> wsize , NULL ); 32
server -> acregmin = data -> acregmin * HZ; 34
server -> acregmax = data -> acregmax * HZ; 35
server -> acdirmin = data -> acdirmin * HZ; 36
server -> acdirmax = data -> acdirmax * HZ; 37
error = nfs_start_lockd ( server ); 40
if ( error < 0 )  41
error = nfs_init_server_rpcclient ( server , data -> pseudoflavor ); 44
if ( error < 0 )  45
server -> namelen = data -> namlen; 48
nfs_init_server_aclclient ( server ); 50
if ( server -> namelen == 0 || server -> namelen > NFS3_MAXNAMLEN )  52
server -> namelen = NFS3_MAXNAMLEN; 53
server -> caps |= NFS_CAP_READDIRPLUS; 55
if ( server -> namelen == 0 || server -> namelen > NFS2_MAXNAMLEN )  57
dprintk ( "<-- CVE_2009_1336_VULN_nfs_init_server() = xerror %d\n" , error ); 67
return error ; 68
------------------------------
166 /home/speedy/test/source2slice/NVD/CVE_2009_1385_PATCHED_e1000_clean_rx_irq.c last_byte = * ( skb -> data + length - 1 ) 62
static bool CVE_2009_1385_PATCHED_e1000_clean_rx_irq(struct e1000_adapter *adapter,
struct e1000_rx_ring *rx_ring,
int *work_done, int work_to_do) 3
struct e1000_hw * hw = & adapter -> hw ; 5
struct net_device * netdev = adapter -> netdev ; 6
struct e1000_rx_desc * rx_desc , * next_rxd ; 8
struct e1000_buffer * buffer_info , * next_buffer ; 9
u32 length ; 11
u8 last_byte ; 12
unsigned int i ; 13
i = rx_ring -> next_to_clean; 18
rx_desc = E1000_RX_DESC ( * rx_ring , i ); 19
buffer_info = & rx_ring -> buffer_info [ i ]; 20
while ( rx_desc -> status & E1000_RXD_STAT_DD )  22
struct sk_buff * skb ; 23
u8 status ; 24
if ( * work_done >= work_to_do )  26
( * work_done ) ++; 28
status = rx_desc -> status; 30
skb = buffer_info -> skb; 31
buffer_info -> skb = NULL; 32
if ( ++ i == rx_ring -> count )  36
i = 0; 36
next_rxd = E1000_RX_DESC ( * rx_ring , i ); 37
next_buffer = & rx_ring -> buffer_info [ i ]; 40
length = le16_to_cpu ( rx_desc -> length ); 49
if ( unlikely ( ! ( status & E1000_RXD_STAT_EOP ) || ( length <= 4 ) ) )  52
buffer_info -> skb = skb; 57
if ( unlikely ( rx_desc -> errors & E1000_RXD_ERR_FRAME_ERR_MASK ) )  61
last_byte = * ( skb -> data + length - 1 ); 62
if ( TBI_ACCEPT ( hw , status , rx_desc -> errors , length , last_byte ) )  63
length --; 70
buffer_info -> skb = skb; 73
length -= 4; 80
if ( length < copybreak )  89
struct sk_buff * new_skb = netdev_alloc_skb ( netdev , length + NET_IP_ALIGN ) ; 90
if ( new_skb )  92
buffer_info -> skb = skb; 101
skb = new_skb; 102
skb -> protocol = eth_type_trans ( skb , netdev ); 115
rx_desc -> status = 0; 126
rx_desc = next_rxd; 135
buffer_info = next_buffer; 136
------------------------------
167 /home/speedy/test/source2slice/NVD/CVE_2009_1385_VULN_e1000_clean_rx_irq.c last_byte = * ( skb -> data + length - 1 ) 61
static bool CVE_2009_1385_VULN_e1000_clean_rx_irq(struct e1000_adapter *adapter,
struct e1000_rx_ring *rx_ring,
int *work_done, int work_to_do) 3
struct e1000_hw * hw = & adapter -> hw ; 5
struct net_device * netdev = adapter -> netdev ; 6
struct e1000_rx_desc * rx_desc , * next_rxd ; 8
struct e1000_buffer * buffer_info , * next_buffer ; 9
u32 length ; 11
u8 last_byte ; 12
unsigned int i ; 13
i = rx_ring -> next_to_clean; 18
rx_desc = E1000_RX_DESC ( * rx_ring , i ); 19
buffer_info = & rx_ring -> buffer_info [ i ]; 20
while ( rx_desc -> status & E1000_RXD_STAT_DD )  22
struct sk_buff * skb ; 23
u8 status ; 24
if ( * work_done >= work_to_do )  26
( * work_done ) ++; 28
status = rx_desc -> status; 30
skb = buffer_info -> skb; 31
buffer_info -> skb = NULL; 32
if ( ++ i == rx_ring -> count )  36
i = 0; 36
next_rxd = E1000_RX_DESC ( * rx_ring , i ); 37
next_buffer = & rx_ring -> buffer_info [ i ]; 40
length = le16_to_cpu ( rx_desc -> length ); 49
if ( unlikely ( ! ( status & E1000_RXD_STAT_EOP ) ) )  51
buffer_info -> skb = skb; 56
if ( unlikely ( rx_desc -> errors & E1000_RXD_ERR_FRAME_ERR_MASK ) )  60
last_byte = * ( skb -> data + length - 1 ); 61
if ( TBI_ACCEPT ( hw , status , rx_desc -> errors , length , last_byte ) )  62
length --; 69
buffer_info -> skb = skb; 72
length -= 4; 79
if ( length < copybreak )  88
struct sk_buff * new_skb = netdev_alloc_skb ( netdev , length + NET_IP_ALIGN ) ; 89
if ( new_skb )  91
buffer_info -> skb = skb; 100
skb = new_skb; 101
skb -> protocol = eth_type_trans ( skb , netdev ); 114
rx_desc -> status = 0; 125
rx_desc = next_rxd; 134
buffer_info = next_buffer; 135
------------------------------
168 /home/speedy/test/source2slice/NVD/CVE_2009_1961_PATCHED_generic_file_splice_write.c nr_pages = ( ret + PAGE_CACHE_SIZE - 1 ) >> PAGE_CACHE_SHIFT 30
ssize_t
CVE_2009_1961_PATCHED_generic_file_splice_write(struct pipe_inode_info *pipe, struct file *out,
loff_t *ppos, size_t len, unsigned int flags) 3
struct splice_desc sd =
. total_len = len ,
. flags = flags ,
. pos = * ppos ,
. u . file = out , 11
ssize_t ret ; 13
ret = file_remove_suid ( out ); 17
if ( likely ( ! ret ) )  18
ret = __splice_from_pipe ( pipe , & sd , pipe_to_file ); 21
if ( ret > 0 )  26
unsigned long nr_pages ; 27
nr_pages = ( ret + PAGE_CACHE_SIZE - 1 ) >> PAGE_CACHE_SHIFT; 30
balance_dirty_pages_ratelimited_nr ( mapping , nr_pages ); 47
------------------------------
169 /home/speedy/test/source2slice/NVD/CVE_2009_1961_VULN_generic_file_splice_write.c nr_pages = ( ret + PAGE_CACHE_SIZE - 1 ) >> PAGE_CACHE_SHIFT 24
ssize_t
CVE_2009_1961_VULN_generic_file_splice_write(struct pipe_inode_info *pipe, struct file *out,
loff_t *ppos, size_t len, unsigned int flags) 3
struct splice_desc sd =
. total_len = len ,
. flags = flags ,
. pos = * ppos ,
. u . file = out , 11
ssize_t ret ; 13
ret = file_remove_suid ( out ); 16
if ( likely ( ! ret ) )  17
ret = __splice_from_pipe ( pipe , & sd , pipe_to_file ); 18
if ( ret > 0 )  20
unsigned long nr_pages ; 21
nr_pages = ( ret + PAGE_CACHE_SIZE - 1 ) >> PAGE_CACHE_SHIFT; 24
balance_dirty_pages_ratelimited_nr ( mapping , nr_pages ); 41
------------------------------
170 /home/speedy/test/source2slice/NVD/CVE_2009_2846_PATCHED_eisa_eeprom_read.c count = * ppos + count < HPEE_MAX_LENGTH ? count : HPEE_MAX_LENGTH - * ppos 11
static ssize_t CVE_2009_2846_PATCHED_eisa_eeprom_read(struct file * file,
char __user *buf, size_t count, loff_t *ppos ) 2
if ( * ppos < 0 || * ppos >= HPEE_MAX_LENGTH )  8
count = * ppos + count < HPEE_MAX_LENGTH ? count : HPEE_MAX_LENGTH - * ppos; 11
tmp = kmalloc ( count , GFP_KERNEL ); 12
if ( tmp )  13
for (i = 0; i < count; i++) 14
tmp [ i ] = readb ( eisa_eeprom_addr + ( * ppos ) ++ ); 15
if ( copy_to_user ( buf , tmp , count ) )  17
ret = count; 20
kfree ( tmp ); 21
return ret ; 25
------------------------------
171 /home/speedy/test/source2slice/NVD/CVE_2009_2846_VULN_eisa_eeprom_read.c count = * ppos + count < HPEE_MAX_LENGTH ? count : HPEE_MAX_LENGTH - * ppos 11
static ssize_t CVE_2009_2846_VULN_eisa_eeprom_read(struct file * file,
char __user *buf, size_t count, loff_t *ppos ) 2
if ( * ppos >= HPEE_MAX_LENGTH )  8
count = * ppos + count < HPEE_MAX_LENGTH ? count : HPEE_MAX_LENGTH - * ppos; 11
tmp = kmalloc ( count , GFP_KERNEL ); 12
if ( tmp )  13
for (i = 0; i < count; i++) 14
tmp [ i ] = readb ( eisa_eeprom_addr + ( * ppos ) ++ ); 15
if ( copy_to_user ( buf , tmp , count ) )  17
ret = count; 20
kfree ( tmp ); 21
return ret ; 25
------------------------------
172 /home/speedy/test/source2slice/NVD/CVE_2009_2909_PATCHED_ax25_setsockopt.c ax25 -> t3 = opt * HZ 68
static int CVE_2009_2909_PATCHED_ax25_setsockopt(struct socket *sock, int level, int optname,
char __user *optval, int optlen) 2
struct sock * sk = sock -> sk ; 4
ax25_cb * ax25 ; 5
int opt , res = 0 ; 8
if ( level != SOL_AX25 )  10
if ( optlen < ( int ) sizeof ( int ) )  13
if ( get_user ( opt , ( int __user * ) optval ) )  16
ax25 = ax25_sk ( sk ); 20
switch ( optname )  22
if ( opt < 1 )  64
ax25 -> t3 = opt * HZ; 68
------------------------------
173 /home/speedy/test/source2slice/NVD/CVE_2009_2909_PATCHED_ax25_setsockopt.c ax25 -> t2 = opt * HZ 52
static int CVE_2009_2909_PATCHED_ax25_setsockopt(struct socket *sock, int level, int optname,
char __user *optval, int optlen) 2
struct sock * sk = sock -> sk ; 4
ax25_cb * ax25 ; 5
int opt , res = 0 ; 8
if ( level != SOL_AX25 )  10
if ( optlen < ( int ) sizeof ( int ) )  13
if ( get_user ( opt , ( int __user * ) optval ) )  16
ax25 = ax25_sk ( sk ); 20
switch ( optname )  22
if ( opt < 1 )  48
ax25 -> t2 = opt * HZ; 52
------------------------------
174 /home/speedy/test/source2slice/NVD/CVE_2009_2909_PATCHED_ax25_setsockopt.c ax25 -> t1 = opt * HZ 44
static int CVE_2009_2909_PATCHED_ax25_setsockopt(struct socket *sock, int level, int optname,
char __user *optval, int optlen) 2
struct sock * sk = sock -> sk ; 4
ax25_cb * ax25 ; 5
int opt , res = 0 ; 8
if ( level != SOL_AX25 )  10
if ( optlen < ( int ) sizeof ( int ) )  13
if ( get_user ( opt , ( int __user * ) optval ) )  16
ax25 = ax25_sk ( sk ); 20
switch ( optname )  22
if ( opt < 1 )  39
ax25 -> rtt = ( opt * HZ ) >> 1; 43
ax25 -> t1 = opt * HZ; 44
------------------------------
175 /home/speedy/test/source2slice/NVD/CVE_2009_2909_PATCHED_ax25_setsockopt.c ax25 -> rtt = ( opt * HZ ) >> 1 43
static int CVE_2009_2909_PATCHED_ax25_setsockopt(struct socket *sock, int level, int optname,
char __user *optval, int optlen) 2
struct sock * sk = sock -> sk ; 4
ax25_cb * ax25 ; 5
int opt , res = 0 ; 8
if ( level != SOL_AX25 )  10
if ( optlen < ( int ) sizeof ( int ) )  13
if ( get_user ( opt , ( int __user * ) optval ) )  16
ax25 = ax25_sk ( sk ); 20
switch ( optname )  22
if ( opt < 1 )  39
ax25 -> rtt = ( opt * HZ ) >> 1; 43
ax25 -> t1 = opt * HZ; 44
------------------------------
176 /home/speedy/test/source2slice/NVD/CVE_2009_2909_VULN_ax25_setsockopt.c ax25 -> t3 = opt * HZ 68
static int CVE_2009_2909_VULN_ax25_setsockopt(struct socket *sock, int level, int optname,
char __user *optval, int optlen) 2
struct sock * sk = sock -> sk ; 4
ax25_cb * ax25 ; 5
int opt , res = 0 ; 8
if ( level != SOL_AX25 )  10
if ( optlen < sizeof ( int ) )  13
if ( get_user ( opt , ( int __user * ) optval ) )  16
ax25 = ax25_sk ( sk ); 20
switch ( optname )  22
if ( opt < 1 )  64
ax25 -> t3 = opt * HZ; 68
------------------------------
177 /home/speedy/test/source2slice/NVD/CVE_2009_2909_VULN_ax25_setsockopt.c ax25 -> t2 = opt * HZ 52
static int CVE_2009_2909_VULN_ax25_setsockopt(struct socket *sock, int level, int optname,
char __user *optval, int optlen) 2
struct sock * sk = sock -> sk ; 4
ax25_cb * ax25 ; 5
int opt , res = 0 ; 8
if ( level != SOL_AX25 )  10
if ( optlen < sizeof ( int ) )  13
if ( get_user ( opt , ( int __user * ) optval ) )  16
ax25 = ax25_sk ( sk ); 20
switch ( optname )  22
if ( opt < 1 )  48
ax25 -> t2 = opt * HZ; 52
------------------------------
178 /home/speedy/test/source2slice/NVD/CVE_2009_2909_VULN_ax25_setsockopt.c ax25 -> t1 = opt * HZ 44
static int CVE_2009_2909_VULN_ax25_setsockopt(struct socket *sock, int level, int optname,
char __user *optval, int optlen) 2
struct sock * sk = sock -> sk ; 4
ax25_cb * ax25 ; 5
int opt , res = 0 ; 8
if ( level != SOL_AX25 )  10
if ( optlen < sizeof ( int ) )  13
if ( get_user ( opt , ( int __user * ) optval ) )  16
ax25 = ax25_sk ( sk ); 20
switch ( optname )  22
if ( opt < 1 )  39
ax25 -> rtt = ( opt * HZ ) >> 1; 43
ax25 -> t1 = opt * HZ; 44
------------------------------
179 /home/speedy/test/source2slice/NVD/CVE_2009_2909_VULN_ax25_setsockopt.c ax25 -> rtt = ( opt * HZ ) >> 1 43
static int CVE_2009_2909_VULN_ax25_setsockopt(struct socket *sock, int level, int optname,
char __user *optval, int optlen) 2
struct sock * sk = sock -> sk ; 4
ax25_cb * ax25 ; 5
int opt , res = 0 ; 8
if ( level != SOL_AX25 )  10
if ( optlen < sizeof ( int ) )  13
if ( get_user ( opt , ( int __user * ) optval ) )  16
ax25 = ax25_sk ( sk ); 20
switch ( optname )  22
if ( opt < 1 )  39
ax25 -> rtt = ( opt * HZ ) >> 1; 43
ax25 -> t1 = opt * HZ; 44
------------------------------
180 /home/speedy/test/source2slice/NVD/CVE_2009_3288_PATCHED_sg_build_indirect.c ret_sz = 1 << ( PAGE_SHIFT + order ) 40
static int
CVE_2009_3288_PATCHED_sg_build_indirect(Sg_scatter_hold * schp, Sg_fd * sfp, int buff_size) 2
int sg_tablesize = sfp -> parentdp -> sg_tablesize ; 5
int blk_size = buff_size , order ; 6
gfp_t gfp_mask = GFP_ATOMIC | __GFP_COMP | __GFP_NOWARN ; 7
if ( blk_size < 0 )  9
blk_size = ALIGN ( blk_size , SG_SECTOR_SZ ); 14
mx_sc_elems = sg_build_sgat ( schp , sfp , sg_tablesize ); 19
if ( mx_sc_elems < 0 )  20
num = scatter_elem_sz; 23
if ( sfp -> low_dma )  32
gfp_mask |= GFP_DMA; 33
if ( ! capable ( CAP_SYS_ADMIN ) || ! capable ( CAP_SYS_RAWIO ) )  35
gfp_mask |= __GFP_ZERO; 36
order = get_order ( num ); 38
ret_sz = 1 << ( PAGE_SHIFT + order ); 40
for (k = 0, rem_sz = blk_size; rem_sz > 0 && k < mx_sc_elems;
k++, rem_sz -= ret_sz) 43
num = ( rem_sz > scatter_elem_sz_prev ) ? scatter_elem_sz_prev : rem_sz; 45
schp -> pages [ k ] = alloc_pages ( gfp_mask , order ); 48
if ( ! schp -> pages [ k ] )  49
if ( num == scatter_elem_sz_prev )  52
if ( unlikely ( ret_sz > scatter_elem_sz_prev ) )  53
scatter_elem_sz = ret_sz; 54
scatter_elem_sz_prev = ret_sz; 55
schp -> page_order = order; 63
schp -> k_use_sg = k; 64
SCSI_LOG_TIMEOUT ( 5 , printk ( "CVE_2009_3288_PATCHED_sg_build_indirect: k_use_sg=%d, "
"rem_sz=%d\n" , k , rem_sz ) ) 66
schp -> bufflen = blk_size; 68
if ( rem_sz > 0 )  69
for (i = 0; i < k; i++) 73
__free_pages ( schp -> pages [ i ] , order ); 74
if ( -- order >= 0 )  76
------------------------------
181 /home/speedy/test/source2slice/NVD/CVE_2009_3288_VULN_sg_build_indirect.c ret_sz = 1 << ( PAGE_SHIFT + order ) 40
static int
CVE_2009_3288_VULN_sg_build_indirect(Sg_scatter_hold * schp, Sg_fd * sfp, int buff_size) 2
int sg_tablesize = sfp -> parentdp -> sg_tablesize ; 5
int blk_size = buff_size , order ; 6
gfp_t gfp_mask = GFP_ATOMIC | __GFP_COMP | __GFP_NOWARN ; 7
if ( blk_size < 0 )  9
blk_size = ALIGN ( blk_size , SG_SECTOR_SZ ); 14
mx_sc_elems = sg_build_sgat ( schp , sfp , sg_tablesize ); 19
if ( mx_sc_elems < 0 )  20
num = scatter_elem_sz; 23
if ( sfp -> low_dma )  32
gfp_mask |= GFP_DMA; 33
if ( ! capable ( CAP_SYS_ADMIN ) || ! capable ( CAP_SYS_RAWIO ) )  35
gfp_mask |= __GFP_ZERO; 36
order = get_order ( num ); 38
ret_sz = 1 << ( PAGE_SHIFT + order ); 40
for (k = 0, rem_sz = blk_size; rem_sz > 0 && k < mx_sc_elems;
k++, rem_sz -= ret_sz) 43
num = ( rem_sz > scatter_elem_sz_prev ) ? scatter_elem_sz_prev : rem_sz; 45
schp -> pages [ k ] = alloc_pages ( gfp_mask , order ); 48
if ( ! schp -> pages [ k ] )  49
if ( num == scatter_elem_sz_prev )  52
if ( unlikely ( ret_sz > scatter_elem_sz_prev ) )  53
scatter_elem_sz = ret_sz; 54
scatter_elem_sz_prev = ret_sz; 55
schp -> page_order = order; 63
schp -> k_use_sg = k; 64
SCSI_LOG_TIMEOUT ( 5 , printk ( "CVE_2009_3288_VULN_sg_build_indirect: k_use_sg=%d, "
"rem_sz=%d\n" , k , rem_sz ) ) 66
schp -> bufflen = blk_size; 68
if ( rem_sz > 0 )  69
for (i = 0; i < k; i++) 73
__free_pages ( schp -> pages [ k ] , order ); 74
if ( -- order >= 0 )  76
------------------------------
182 /home/speedy/test/source2slice/NVD/CVE_2009_3888_PATCHED_do_mmap_pgoff.c vma -> vm_end = region -> vm_end = addr + len 159
unsigned long CVE_2009_3888_PATCHED_do_mmap_pgoff(struct file *file,
unsigned long addr,
unsigned long len,
unsigned long prot,
unsigned long flags,
unsigned long pgoff) 6
struct vm_area_struct * vma ; 8
struct vm_region * region ; 9
struct rb_node * rb ; 10
unsigned long capabilities , vm_flags , result ; 11
int ret ; 12
if ( ! ( flags & MAP_FIXED ) )  16
addr = round_hint_to_min ( addr ); 17
ret = validate_mmap_request ( file , addr , len , prot , flags , pgoff , & capabilities ); 21
if ( ret < 0 )  23
vm_flags = determine_vm_flags ( file , prot , flags , capabilities ); 30
region = kmem_cache_zalloc ( vm_region_jar , GFP_KERNEL ); 33
if ( ! region )  34
vma = kmem_cache_zalloc ( vm_area_cachep , GFP_KERNEL ); 37
if ( ! vma )  38
region -> vm_flags = vm_flags; 42
region -> vm_pgoff = pgoff; 43
if ( file )  49
region -> vm_file = file; 50
if ( vm_flags & VM_MAYSHARE )  70
struct vm_region * pregion ; 71
unsigned long pglen , rpglen , pgend , rpgend , start ; 72
pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 74
pgend = pgoff + pglen; 75
for (rb = rb_first(&nommu_region_tree); rb; rb = rb_next(rb)) 77
pregion = rb_entry ( rb , struct vm_region , vm_rb ) 78
if ( ! ( pregion -> vm_flags & VM_MAYSHARE ) )  80
if ( pregion -> vm_file -> f_path . dentry -> d_inode != file -> f_path . dentry -> d_inode )  84
if ( pregion -> vm_pgoff >= pgend )  88
rpglen = pregion -> vm_end - pregion -> vm_start; 91
rpglen = ( rpglen + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 92
rpgend = pregion -> vm_pgoff + rpglen; 93
if ( pgoff >= rpgend )  94
if ( ( pregion -> vm_pgoff != pgoff || rpglen != pglen ) && ! ( pgoff >= pregion -> vm_pgoff && pgend <= rpgend ) )  99
if ( ! ( capabilities & BDI_CAP_MAP_DIRECT ) )  102
if ( file && file -> f_op -> get_unmapped_area )  141
addr = file -> f_op -> get_unmapped_area ( file , addr , len , pgoff , flags ); 142
if ( IS_ERR ( ( void * ) addr ) )  144
vma -> vm_start = region -> vm_start = addr; 158
vma -> vm_end = region -> vm_end = addr + len; 159
vma -> vm_region = region; 164
add_nommu_region ( region ); 165
if ( file && vma -> vm_flags & VM_SHARED )  168
ret = do_mmap_shared_file ( vma ); 169
ret = do_mmap_private ( vma , region , len ); 171
if ( ret < 0 )  172
result = vma -> vm_start; 176
add_vma_to_mm ( current -> mm , vma ); 181
flush_icache_range ( result , result + len ); 186
kleave ( " = %lx" , result ); 188
return result ; 189
__put_nommu_region ( region ); 192
if ( vma )  193
if ( vma -> vm_file )  194
fput ( vma -> vm_file ); 195
if ( vma -> vm_flags & VM_EXECUTABLE )  196
removed_exe_file_vma ( vma -> vm_mm ); 197
kmem_cache_free ( vm_area_cachep , vma ); 199
kleave ( " = %d [pr]" , ret ); 201
return ret ; 202
if ( vma -> vm_file )  210
fput ( vma -> vm_file ); 211
if ( vma -> vm_flags & VM_EXECUTABLE )  212
removed_exe_file_vma ( vma -> vm_mm ); 213
kmem_cache_free ( vm_area_cachep , vma ); 214
kleave ( " = %d" , ret ); 215
return ret ; 216
kmem_cache_free ( vm_region_jar , region ); 225
printk ( KERN_WARNING "Allocation of vma for %lu byte allocation"
" from process %d failed\n" ,
len , current -> pid ) 228
printk ( KERN_WARNING "Allocation of vm region for %lu byte allocation"
" from process %d failed\n" ,
len , current -> pid ) 235
------------------------------
183 /home/speedy/test/source2slice/NVD/CVE_2009_3888_PATCHED_do_mmap_pgoff.c vma -> vm_end = start + len 113
unsigned long CVE_2009_3888_PATCHED_do_mmap_pgoff(struct file *file,
unsigned long addr,
unsigned long len,
unsigned long prot,
unsigned long flags,
unsigned long pgoff) 6
struct vm_area_struct * vma ; 8
struct vm_region * region ; 9
struct rb_node * rb ; 10
unsigned long capabilities , vm_flags , result ; 11
int ret ; 12
if ( ! ( flags & MAP_FIXED ) )  16
addr = round_hint_to_min ( addr ); 17
ret = validate_mmap_request ( file , addr , len , prot , flags , pgoff , & capabilities ); 21
if ( ret < 0 )  23
vm_flags = determine_vm_flags ( file , prot , flags , capabilities ); 30
region = kmem_cache_zalloc ( vm_region_jar , GFP_KERNEL ); 33
if ( ! region )  34
vma = kmem_cache_zalloc ( vm_area_cachep , GFP_KERNEL ); 37
if ( ! vma )  38
vma -> vm_flags = vm_flags; 46
vma -> vm_pgoff = pgoff; 47
if ( file )  49
vma -> vm_file = file; 52
if ( vm_flags & VM_EXECUTABLE )  54
vma -> vm_mm = current -> mm; 56
if ( vm_flags & VM_MAYSHARE )  70
struct vm_region * pregion ; 71
unsigned long pglen , rpglen , pgend , rpgend , start ; 72
pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 74
pgend = pgoff + pglen; 75
for (rb = rb_first(&nommu_region_tree); rb; rb = rb_next(rb)) 77
pregion = rb_entry ( rb , struct vm_region , vm_rb ) 78
if ( ! ( pregion -> vm_flags & VM_MAYSHARE ) )  80
if ( pregion -> vm_file -> f_path . dentry -> d_inode != file -> f_path . dentry -> d_inode )  84
if ( pregion -> vm_pgoff >= pgend )  88
rpglen = pregion -> vm_end - pregion -> vm_start; 91
rpglen = ( rpglen + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 92
rpgend = pregion -> vm_pgoff + rpglen; 93
if ( pgoff >= rpgend )  94
if ( ( pregion -> vm_pgoff != pgoff || rpglen != pglen ) && ! ( pgoff >= pregion -> vm_pgoff && pgend <= rpgend ) )  99
if ( ! ( capabilities & BDI_CAP_MAP_DIRECT ) )  102
vma -> vm_region = pregion; 109
start = pregion -> vm_start; 110
start += ( pgoff - pregion -> vm_pgoff ) << PAGE_SHIFT; 111
vma -> vm_start = start; 112
vma -> vm_end = start + len; 113
vma -> vm_flags |= VM_MAPPED_COPY; 117
------------------------------
184 /home/speedy/test/source2slice/NVD/CVE_2009_3888_PATCHED_do_mmap_pgoff.c rpgend = pregion -> vm_pgoff + rpglen 93
unsigned long CVE_2009_3888_PATCHED_do_mmap_pgoff(struct file *file,
unsigned long addr,
unsigned long len,
unsigned long prot,
unsigned long flags,
unsigned long pgoff) 6
struct vm_area_struct * vma ; 8
struct vm_region * region ; 9
struct rb_node * rb ; 10
unsigned long capabilities , vm_flags , result ; 11
int ret ; 12
if ( ! ( flags & MAP_FIXED ) )  16
addr = round_hint_to_min ( addr ); 17
ret = validate_mmap_request ( file , addr , len , prot , flags , pgoff , & capabilities ); 21
if ( ret < 0 )  23
vm_flags = determine_vm_flags ( file , prot , flags , capabilities ); 30
region = kmem_cache_zalloc ( vm_region_jar , GFP_KERNEL ); 33
if ( ! region )  34
vma = kmem_cache_zalloc ( vm_area_cachep , GFP_KERNEL ); 37
if ( ! vma )  38
if ( vm_flags & VM_MAYSHARE )  70
struct vm_region * pregion ; 71
unsigned long pglen , rpglen , pgend , rpgend , start ; 72
pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 74
pgend = pgoff + pglen; 75
for (rb = rb_first(&nommu_region_tree); rb; rb = rb_next(rb)) 77
pregion = rb_entry ( rb , struct vm_region , vm_rb ) 78
if ( ! ( pregion -> vm_flags & VM_MAYSHARE ) )  80
if ( pregion -> vm_file -> f_path . dentry -> d_inode != file -> f_path . dentry -> d_inode )  84
if ( pregion -> vm_pgoff >= pgend )  88
rpglen = pregion -> vm_end - pregion -> vm_start; 91
rpglen = ( rpglen + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 92
rpgend = pregion -> vm_pgoff + rpglen; 93
if ( pgoff >= rpgend )  94
if ( ( pregion -> vm_pgoff != pgoff || rpglen != pglen ) && ! ( pgoff >= pregion -> vm_pgoff && pgend <= rpgend ) )  99
if ( ! ( capabilities & BDI_CAP_MAP_DIRECT ) )  102
------------------------------
185 /home/speedy/test/source2slice/NVD/CVE_2009_3888_PATCHED_do_mmap_pgoff.c rpglen = ( rpglen + PAGE_SIZE - 1 ) >> PAGE_SHIFT 92
unsigned long CVE_2009_3888_PATCHED_do_mmap_pgoff(struct file *file,
unsigned long addr,
unsigned long len,
unsigned long prot,
unsigned long flags,
unsigned long pgoff) 6
struct vm_area_struct * vma ; 8
struct vm_region * region ; 9
struct rb_node * rb ; 10
unsigned long capabilities , vm_flags , result ; 11
int ret ; 12
if ( ! ( flags & MAP_FIXED ) )  16
addr = round_hint_to_min ( addr ); 17
ret = validate_mmap_request ( file , addr , len , prot , flags , pgoff , & capabilities ); 21
if ( ret < 0 )  23
vm_flags = determine_vm_flags ( file , prot , flags , capabilities ); 30
region = kmem_cache_zalloc ( vm_region_jar , GFP_KERNEL ); 33
if ( ! region )  34
vma = kmem_cache_zalloc ( vm_area_cachep , GFP_KERNEL ); 37
if ( ! vma )  38
if ( vm_flags & VM_MAYSHARE )  70
struct vm_region * pregion ; 71
unsigned long pglen , rpglen , pgend , rpgend , start ; 72
pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 74
pgend = pgoff + pglen; 75
for (rb = rb_first(&nommu_region_tree); rb; rb = rb_next(rb)) 77
pregion = rb_entry ( rb , struct vm_region , vm_rb ) 78
if ( ! ( pregion -> vm_flags & VM_MAYSHARE ) )  80
if ( pregion -> vm_file -> f_path . dentry -> d_inode != file -> f_path . dentry -> d_inode )  84
if ( pregion -> vm_pgoff >= pgend )  88
rpglen = pregion -> vm_end - pregion -> vm_start; 91
rpglen = ( rpglen + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 92
rpgend = pregion -> vm_pgoff + rpglen; 93
if ( pgoff >= rpgend )  94
if ( ( pregion -> vm_pgoff != pgoff || rpglen != pglen ) && ! ( pgoff >= pregion -> vm_pgoff && pgend <= rpgend ) )  99
if ( ! ( capabilities & BDI_CAP_MAP_DIRECT ) )  102
------------------------------
186 /home/speedy/test/source2slice/NVD/CVE_2009_3888_PATCHED_do_mmap_pgoff.c rpglen = pregion -> vm_end - pregion -> vm_start 91
unsigned long CVE_2009_3888_PATCHED_do_mmap_pgoff(struct file *file,
unsigned long addr,
unsigned long len,
unsigned long prot,
unsigned long flags,
unsigned long pgoff) 6
struct vm_area_struct * vma ; 8
struct vm_region * region ; 9
struct rb_node * rb ; 10
unsigned long capabilities , vm_flags , result ; 11
int ret ; 12
if ( ! ( flags & MAP_FIXED ) )  16
addr = round_hint_to_min ( addr ); 17
ret = validate_mmap_request ( file , addr , len , prot , flags , pgoff , & capabilities ); 21
if ( ret < 0 )  23
vm_flags = determine_vm_flags ( file , prot , flags , capabilities ); 30
region = kmem_cache_zalloc ( vm_region_jar , GFP_KERNEL ); 33
if ( ! region )  34
vma = kmem_cache_zalloc ( vm_area_cachep , GFP_KERNEL ); 37
if ( ! vma )  38
if ( vm_flags & VM_MAYSHARE )  70
struct vm_region * pregion ; 71
unsigned long pglen , rpglen , pgend , rpgend , start ; 72
pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 74
pgend = pgoff + pglen; 75
for (rb = rb_first(&nommu_region_tree); rb; rb = rb_next(rb)) 77
pregion = rb_entry ( rb , struct vm_region , vm_rb ) 78
if ( ! ( pregion -> vm_flags & VM_MAYSHARE ) )  80
if ( pregion -> vm_file -> f_path . dentry -> d_inode != file -> f_path . dentry -> d_inode )  84
if ( pregion -> vm_pgoff >= pgend )  88
rpglen = pregion -> vm_end - pregion -> vm_start; 91
rpglen = ( rpglen + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 92
rpgend = pregion -> vm_pgoff + rpglen; 93
if ( pgoff >= rpgend )  94
if ( ( pregion -> vm_pgoff != pgoff || rpglen != pglen ) && ! ( pgoff >= pregion -> vm_pgoff && pgend <= rpgend ) )  99
if ( ! ( capabilities & BDI_CAP_MAP_DIRECT ) )  102
------------------------------
187 /home/speedy/test/source2slice/NVD/CVE_2009_3888_PATCHED_do_mmap_pgoff.c pgend = pgoff + pglen 75
unsigned long CVE_2009_3888_PATCHED_do_mmap_pgoff(struct file *file,
unsigned long addr,
unsigned long len,
unsigned long prot,
unsigned long flags,
unsigned long pgoff) 6
struct vm_area_struct * vma ; 8
struct vm_region * region ; 9
unsigned long capabilities , vm_flags , result ; 11
int ret ; 12
if ( ! ( flags & MAP_FIXED ) )  16
addr = round_hint_to_min ( addr ); 17
ret = validate_mmap_request ( file , addr , len , prot , flags , pgoff , & capabilities ); 21
if ( ret < 0 )  23
vm_flags = determine_vm_flags ( file , prot , flags , capabilities ); 30
region = kmem_cache_zalloc ( vm_region_jar , GFP_KERNEL ); 33
if ( ! region )  34
vma = kmem_cache_zalloc ( vm_area_cachep , GFP_KERNEL ); 37
if ( ! vma )  38
if ( vm_flags & VM_MAYSHARE )  70
unsigned long pglen , rpglen , pgend , rpgend , start ; 72
pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 74
pgend = pgoff + pglen; 75
if ( pregion -> vm_pgoff >= pgend )  88
if ( ( pregion -> vm_pgoff != pgoff || rpglen != pglen ) && ! ( pgoff >= pregion -> vm_pgoff && pgend <= rpgend ) )  99
------------------------------
188 /home/speedy/test/source2slice/NVD/CVE_2009_3888_PATCHED_do_mmap_pgoff.c pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT 74
unsigned long CVE_2009_3888_PATCHED_do_mmap_pgoff(struct file *file,
unsigned long addr,
unsigned long len,
unsigned long prot,
unsigned long flags,
unsigned long pgoff) 6
struct vm_area_struct * vma ; 8
struct vm_region * region ; 9
unsigned long capabilities , vm_flags , result ; 11
int ret ; 12
if ( ! ( flags & MAP_FIXED ) )  16
addr = round_hint_to_min ( addr ); 17
ret = validate_mmap_request ( file , addr , len , prot , flags , pgoff , & capabilities ); 21
if ( ret < 0 )  23
vm_flags = determine_vm_flags ( file , prot , flags , capabilities ); 30
region = kmem_cache_zalloc ( vm_region_jar , GFP_KERNEL ); 33
if ( ! region )  34
vma = kmem_cache_zalloc ( vm_area_cachep , GFP_KERNEL ); 37
if ( ! vma )  38
if ( vm_flags & VM_MAYSHARE )  70
unsigned long pglen , rpglen , pgend , rpgend , start ; 72
pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 74
pgend = pgoff + pglen; 75
if ( pregion -> vm_pgoff >= pgend )  88
if ( ( pregion -> vm_pgoff != pgoff || rpglen != pglen ) && ! ( pgoff >= pregion -> vm_pgoff && pgend <= rpgend ) )  99
------------------------------
189 /home/speedy/test/source2slice/NVD/CVE_2009_3888_VULN_do_mmap_pgoff.c vma -> vm_end = region -> vm_end = addr + len 159
unsigned long CVE_2009_3888_VULN_do_mmap_pgoff(struct file *file,
unsigned long addr,
unsigned long len,
unsigned long prot,
unsigned long flags,
unsigned long pgoff) 6
struct vm_area_struct * vma ; 8
struct vm_region * region ; 9
struct rb_node * rb ; 10
unsigned long capabilities , vm_flags , result ; 11
int ret ; 12
if ( ! ( flags & MAP_FIXED ) )  16
addr = round_hint_to_min ( addr ); 17
ret = validate_mmap_request ( file , addr , len , prot , flags , pgoff , & capabilities ); 21
if ( ret < 0 )  23
vm_flags = determine_vm_flags ( file , prot , flags , capabilities ); 30
region = kmem_cache_zalloc ( vm_region_jar , GFP_KERNEL ); 33
if ( ! region )  34
vma = kmem_cache_zalloc ( vm_area_cachep , GFP_KERNEL ); 37
if ( ! vma )  38
region -> vm_flags = vm_flags; 42
region -> vm_pgoff = pgoff; 43
if ( file )  49
region -> vm_file = file; 50
if ( vm_flags & VM_MAYSHARE )  70
struct vm_region * pregion ; 71
unsigned long pglen , rpglen , pgend , rpgend , start ; 72
pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 74
pgend = pgoff + pglen; 75
for (rb = rb_first(&nommu_region_tree); rb; rb = rb_next(rb)) 77
pregion = rb_entry ( rb , struct vm_region , vm_rb ) 78
if ( ! ( pregion -> vm_flags & VM_MAYSHARE ) )  80
if ( pregion -> vm_file -> f_path . dentry -> d_inode != file -> f_path . dentry -> d_inode )  84
if ( pregion -> vm_pgoff >= pgend )  88
rpglen = pregion -> vm_end - pregion -> vm_start; 91
rpglen = ( rpglen + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 92
rpgend = pregion -> vm_pgoff + rpglen; 93
if ( pgoff >= rpgend )  94
if ( ( pregion -> vm_pgoff != pgoff || rpglen != pglen ) && ! ( pgoff >= pregion -> vm_pgoff && pgend <= rpgend ) )  99
if ( ! ( capabilities & BDI_CAP_MAP_DIRECT ) )  102
if ( file && file -> f_op -> get_unmapped_area )  141
addr = file -> f_op -> get_unmapped_area ( file , addr , len , pgoff , flags ); 142
if ( IS_ERR ( ( void * ) addr ) )  144
vma -> vm_start = region -> vm_start = addr; 158
vma -> vm_end = region -> vm_end = addr + len; 159
vma -> vm_region = region; 164
add_nommu_region ( region ); 165
if ( file && vma -> vm_flags & VM_SHARED )  168
ret = do_mmap_shared_file ( vma ); 169
ret = do_mmap_private ( vma , region , len ); 171
if ( ret < 0 )  172
result = vma -> vm_start; 176
flush_icache_range ( result , result + len ); 186
kleave ( " = %lx" , result ); 188
return result ; 189
__put_nommu_region ( region ); 192
if ( vma -> vm_file )  194
fput ( vma -> vm_file ); 195
if ( vma -> vm_flags & VM_EXECUTABLE )  196
removed_exe_file_vma ( vma -> vm_mm ); 197
kleave ( " = %d [pr]" , ret ); 201
return ret ; 202
kmem_cache_free ( vm_region_jar , region ); 223
printk ( KERN_WARNING "Allocation of vm region for %lu byte allocation"
" from process %d failed\n" ,
len , current -> pid ) 233
------------------------------
190 /home/speedy/test/source2slice/NVD/CVE_2009_3888_VULN_do_mmap_pgoff.c vma -> vm_end = start + len 113
unsigned long CVE_2009_3888_VULN_do_mmap_pgoff(struct file *file,
unsigned long addr,
unsigned long len,
unsigned long prot,
unsigned long flags,
unsigned long pgoff) 6
struct vm_area_struct * vma ; 8
struct vm_region * region ; 9
struct rb_node * rb ; 10
unsigned long capabilities , vm_flags , result ; 11
int ret ; 12
if ( ! ( flags & MAP_FIXED ) )  16
addr = round_hint_to_min ( addr ); 17
ret = validate_mmap_request ( file , addr , len , prot , flags , pgoff , & capabilities ); 21
if ( ret < 0 )  23
vm_flags = determine_vm_flags ( file , prot , flags , capabilities ); 30
region = kmem_cache_zalloc ( vm_region_jar , GFP_KERNEL ); 33
if ( ! region )  34
vma = kmem_cache_zalloc ( vm_area_cachep , GFP_KERNEL ); 37
if ( ! vma )  38
vma -> vm_flags = vm_flags; 46
vma -> vm_pgoff = pgoff; 47
if ( file )  49
vma -> vm_file = file; 52
if ( vm_flags & VM_EXECUTABLE )  54
vma -> vm_mm = current -> mm; 56
if ( vm_flags & VM_MAYSHARE )  70
struct vm_region * pregion ; 71
unsigned long pglen , rpglen , pgend , rpgend , start ; 72
pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 74
pgend = pgoff + pglen; 75
for (rb = rb_first(&nommu_region_tree); rb; rb = rb_next(rb)) 77
pregion = rb_entry ( rb , struct vm_region , vm_rb ) 78
if ( ! ( pregion -> vm_flags & VM_MAYSHARE ) )  80
if ( pregion -> vm_file -> f_path . dentry -> d_inode != file -> f_path . dentry -> d_inode )  84
if ( pregion -> vm_pgoff >= pgend )  88
rpglen = pregion -> vm_end - pregion -> vm_start; 91
rpglen = ( rpglen + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 92
rpgend = pregion -> vm_pgoff + rpglen; 93
if ( pgoff >= rpgend )  94
if ( ( pregion -> vm_pgoff != pgoff || rpglen != pglen ) && ! ( pgoff >= pregion -> vm_pgoff && pgend <= rpgend ) )  99
if ( ! ( capabilities & BDI_CAP_MAP_DIRECT ) )  102
vma -> vm_region = pregion; 109
start = pregion -> vm_start; 110
start += ( pgoff - pregion -> vm_pgoff ) << PAGE_SHIFT; 111
vma -> vm_start = start; 112
vma -> vm_end = start + len; 113
vma -> vm_flags |= VM_MAPPED_COPY; 117
------------------------------
191 /home/speedy/test/source2slice/NVD/CVE_2009_3888_VULN_do_mmap_pgoff.c rpgend = pregion -> vm_pgoff + rpglen 93
unsigned long CVE_2009_3888_VULN_do_mmap_pgoff(struct file *file,
unsigned long addr,
unsigned long len,
unsigned long prot,
unsigned long flags,
unsigned long pgoff) 6
struct vm_area_struct * vma ; 8
struct vm_region * region ; 9
struct rb_node * rb ; 10
unsigned long capabilities , vm_flags , result ; 11
int ret ; 12
if ( ! ( flags & MAP_FIXED ) )  16
addr = round_hint_to_min ( addr ); 17
ret = validate_mmap_request ( file , addr , len , prot , flags , pgoff , & capabilities ); 21
if ( ret < 0 )  23
vm_flags = determine_vm_flags ( file , prot , flags , capabilities ); 30
region = kmem_cache_zalloc ( vm_region_jar , GFP_KERNEL ); 33
if ( ! region )  34
vma = kmem_cache_zalloc ( vm_area_cachep , GFP_KERNEL ); 37
if ( ! vma )  38
if ( vm_flags & VM_MAYSHARE )  70
struct vm_region * pregion ; 71
unsigned long pglen , rpglen , pgend , rpgend , start ; 72
pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 74
pgend = pgoff + pglen; 75
for (rb = rb_first(&nommu_region_tree); rb; rb = rb_next(rb)) 77
pregion = rb_entry ( rb , struct vm_region , vm_rb ) 78
if ( ! ( pregion -> vm_flags & VM_MAYSHARE ) )  80
if ( pregion -> vm_file -> f_path . dentry -> d_inode != file -> f_path . dentry -> d_inode )  84
if ( pregion -> vm_pgoff >= pgend )  88
rpglen = pregion -> vm_end - pregion -> vm_start; 91
rpglen = ( rpglen + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 92
rpgend = pregion -> vm_pgoff + rpglen; 93
if ( pgoff >= rpgend )  94
if ( ( pregion -> vm_pgoff != pgoff || rpglen != pglen ) && ! ( pgoff >= pregion -> vm_pgoff && pgend <= rpgend ) )  99
if ( ! ( capabilities & BDI_CAP_MAP_DIRECT ) )  102
------------------------------
192 /home/speedy/test/source2slice/NVD/CVE_2009_3888_VULN_do_mmap_pgoff.c rpglen = ( rpglen + PAGE_SIZE - 1 ) >> PAGE_SHIFT 92
unsigned long CVE_2009_3888_VULN_do_mmap_pgoff(struct file *file,
unsigned long addr,
unsigned long len,
unsigned long prot,
unsigned long flags,
unsigned long pgoff) 6
struct vm_area_struct * vma ; 8
struct vm_region * region ; 9
struct rb_node * rb ; 10
unsigned long capabilities , vm_flags , result ; 11
int ret ; 12
if ( ! ( flags & MAP_FIXED ) )  16
addr = round_hint_to_min ( addr ); 17
ret = validate_mmap_request ( file , addr , len , prot , flags , pgoff , & capabilities ); 21
if ( ret < 0 )  23
vm_flags = determine_vm_flags ( file , prot , flags , capabilities ); 30
region = kmem_cache_zalloc ( vm_region_jar , GFP_KERNEL ); 33
if ( ! region )  34
vma = kmem_cache_zalloc ( vm_area_cachep , GFP_KERNEL ); 37
if ( ! vma )  38
if ( vm_flags & VM_MAYSHARE )  70
struct vm_region * pregion ; 71
unsigned long pglen , rpglen , pgend , rpgend , start ; 72
pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 74
pgend = pgoff + pglen; 75
for (rb = rb_first(&nommu_region_tree); rb; rb = rb_next(rb)) 77
pregion = rb_entry ( rb , struct vm_region , vm_rb ) 78
if ( ! ( pregion -> vm_flags & VM_MAYSHARE ) )  80
if ( pregion -> vm_file -> f_path . dentry -> d_inode != file -> f_path . dentry -> d_inode )  84
if ( pregion -> vm_pgoff >= pgend )  88
rpglen = pregion -> vm_end - pregion -> vm_start; 91
rpglen = ( rpglen + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 92
rpgend = pregion -> vm_pgoff + rpglen; 93
if ( pgoff >= rpgend )  94
if ( ( pregion -> vm_pgoff != pgoff || rpglen != pglen ) && ! ( pgoff >= pregion -> vm_pgoff && pgend <= rpgend ) )  99
if ( ! ( capabilities & BDI_CAP_MAP_DIRECT ) )  102
------------------------------
193 /home/speedy/test/source2slice/NVD/CVE_2009_3888_VULN_do_mmap_pgoff.c rpglen = pregion -> vm_end - pregion -> vm_start 91
unsigned long CVE_2009_3888_VULN_do_mmap_pgoff(struct file *file,
unsigned long addr,
unsigned long len,
unsigned long prot,
unsigned long flags,
unsigned long pgoff) 6
struct vm_area_struct * vma ; 8
struct vm_region * region ; 9
struct rb_node * rb ; 10
unsigned long capabilities , vm_flags , result ; 11
int ret ; 12
if ( ! ( flags & MAP_FIXED ) )  16
addr = round_hint_to_min ( addr ); 17
ret = validate_mmap_request ( file , addr , len , prot , flags , pgoff , & capabilities ); 21
if ( ret < 0 )  23
vm_flags = determine_vm_flags ( file , prot , flags , capabilities ); 30
region = kmem_cache_zalloc ( vm_region_jar , GFP_KERNEL ); 33
if ( ! region )  34
vma = kmem_cache_zalloc ( vm_area_cachep , GFP_KERNEL ); 37
if ( ! vma )  38
if ( vm_flags & VM_MAYSHARE )  70
struct vm_region * pregion ; 71
unsigned long pglen , rpglen , pgend , rpgend , start ; 72
pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 74
pgend = pgoff + pglen; 75
for (rb = rb_first(&nommu_region_tree); rb; rb = rb_next(rb)) 77
pregion = rb_entry ( rb , struct vm_region , vm_rb ) 78
if ( ! ( pregion -> vm_flags & VM_MAYSHARE ) )  80
if ( pregion -> vm_file -> f_path . dentry -> d_inode != file -> f_path . dentry -> d_inode )  84
if ( pregion -> vm_pgoff >= pgend )  88
rpglen = pregion -> vm_end - pregion -> vm_start; 91
rpglen = ( rpglen + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 92
rpgend = pregion -> vm_pgoff + rpglen; 93
if ( pgoff >= rpgend )  94
if ( ( pregion -> vm_pgoff != pgoff || rpglen != pglen ) && ! ( pgoff >= pregion -> vm_pgoff && pgend <= rpgend ) )  99
if ( ! ( capabilities & BDI_CAP_MAP_DIRECT ) )  102
------------------------------
194 /home/speedy/test/source2slice/NVD/CVE_2009_3888_VULN_do_mmap_pgoff.c pgend = pgoff + pglen 75
unsigned long CVE_2009_3888_VULN_do_mmap_pgoff(struct file *file,
unsigned long addr,
unsigned long len,
unsigned long prot,
unsigned long flags,
unsigned long pgoff) 6
struct vm_area_struct * vma ; 8
struct vm_region * region ; 9
unsigned long capabilities , vm_flags , result ; 11
int ret ; 12
if ( ! ( flags & MAP_FIXED ) )  16
addr = round_hint_to_min ( addr ); 17
ret = validate_mmap_request ( file , addr , len , prot , flags , pgoff , & capabilities ); 21
if ( ret < 0 )  23
vm_flags = determine_vm_flags ( file , prot , flags , capabilities ); 30
region = kmem_cache_zalloc ( vm_region_jar , GFP_KERNEL ); 33
if ( ! region )  34
vma = kmem_cache_zalloc ( vm_area_cachep , GFP_KERNEL ); 37
if ( ! vma )  38
if ( vm_flags & VM_MAYSHARE )  70
unsigned long pglen , rpglen , pgend , rpgend , start ; 72
pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 74
pgend = pgoff + pglen; 75
if ( pregion -> vm_pgoff >= pgend )  88
if ( ( pregion -> vm_pgoff != pgoff || rpglen != pglen ) && ! ( pgoff >= pregion -> vm_pgoff && pgend <= rpgend ) )  99
------------------------------
195 /home/speedy/test/source2slice/NVD/CVE_2009_3888_VULN_do_mmap_pgoff.c pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT 74
unsigned long CVE_2009_3888_VULN_do_mmap_pgoff(struct file *file,
unsigned long addr,
unsigned long len,
unsigned long prot,
unsigned long flags,
unsigned long pgoff) 6
struct vm_area_struct * vma ; 8
struct vm_region * region ; 9
unsigned long capabilities , vm_flags , result ; 11
int ret ; 12
if ( ! ( flags & MAP_FIXED ) )  16
addr = round_hint_to_min ( addr ); 17
ret = validate_mmap_request ( file , addr , len , prot , flags , pgoff , & capabilities ); 21
if ( ret < 0 )  23
vm_flags = determine_vm_flags ( file , prot , flags , capabilities ); 30
region = kmem_cache_zalloc ( vm_region_jar , GFP_KERNEL ); 33
if ( ! region )  34
vma = kmem_cache_zalloc ( vm_area_cachep , GFP_KERNEL ); 37
if ( ! vma )  38
if ( vm_flags & VM_MAYSHARE )  70
unsigned long pglen , rpglen , pgend , rpgend , start ; 72
pglen = ( len + PAGE_SIZE - 1 ) >> PAGE_SHIFT; 74
pgend = pgoff + pglen; 75
if ( pregion -> vm_pgoff >= pgend )  88
if ( ( pregion -> vm_pgoff != pgoff || rpglen != pglen ) && ! ( pgoff >= pregion -> vm_pgoff && pgend <= rpgend ) )  99
------------------------------
196 /home/speedy/test/source2slice/NVD/CVE_2009_4138_PATCHED_ohci_queue_iso_receive_dualbuffer.c offset = ( offset + length ) & ~PAGE_MASK 79
static int CVE_2009_4138_PATCHED_ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d ; 8
struct fw_iso_packet * p ; 9
u32 z , header_z , length , rest ; 11
int page , offset , packet_count , header_size ; 12
p = packet; 19
z = 2; 20
packet_count = p -> header_length / ctx -> base . header_size; 26
header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ); 27
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 30
offset = payload & ~PAGE_MASK; 32
rest = p -> payload_length; 33
if ( rest == 0 )  39
while ( rest > 0 )  43
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 44
if ( d == NULL )  46
if ( p -> skip && rest == p -> payload_length )  54
if ( p -> skip && rest == p -> payload_length )  63
length = 4; 64
if ( offset + rest < PAGE_SIZE )  65
length = rest; 66
length = PAGE_SIZE - offset; 68
db -> second_req_count = cpu_to_le16 ( length ); 70
db -> second_res_count = db -> second_req_count; 71
db -> second_buffer = cpu_to_le32 ( page_bus + offset ); 73
if ( p -> interrupt && length == rest )  75
db -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 76
offset = ( offset + length ) & ~PAGE_MASK; 79
rest -= length; 80
if ( offset == 0 )  81
------------------------------
197 /home/speedy/test/source2slice/NVD/CVE_2009_4138_PATCHED_ohci_queue_iso_receive_dualbuffer.c db -> second_buffer = cpu_to_le32 ( page_bus + offset ) 73
static int CVE_2009_4138_PATCHED_ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d ; 8
struct fw_iso_packet * p ; 9
dma_addr_t d_bus , page_bus ; 10
u32 z , header_z , length , rest ; 11
int page , offset , packet_count , header_size ; 12
p = packet; 19
z = 2; 20
packet_count = p -> header_length / ctx -> base . header_size; 26
header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ); 27
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 30
page = payload >> PAGE_SHIFT; 31
offset = payload & ~PAGE_MASK; 32
rest = p -> payload_length; 33
if ( rest == 0 )  39
while ( rest > 0 )  43
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 44
if ( d == NULL )  46
db = ( struct db_descriptor * ) d; 49
db -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_BRANCH_ALWAYS ); 50
db -> first_size = cpu_to_le16 ( max ( ctx -> base . header_size , ( size_t ) 8 ) ); 52
if ( p -> skip && rest == p -> payload_length )  54
db -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 55
db -> first_req_count = db -> first_size; 56
db -> first_req_count = cpu_to_le16 ( header_size ); 58
db -> first_res_count = db -> first_req_count; 60
db -> first_buffer = cpu_to_le32 ( d_bus + sizeof ( * db ) ); 61
if ( p -> skip && rest == p -> payload_length )  63
length = 4; 64
if ( offset + rest < PAGE_SIZE )  65
length = rest; 66
length = PAGE_SIZE - offset; 68
db -> second_req_count = cpu_to_le16 ( length ); 70
db -> second_res_count = db -> second_req_count; 71
page_bus = page_private ( buffer -> pages [ page ] ); 72
db -> second_buffer = cpu_to_le32 ( page_bus + offset ); 73
db -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 76
offset = ( offset + length ) & ~PAGE_MASK; 79
rest -= length; 80
if ( offset == 0 )  81
page ++; 82
------------------------------
198 /home/speedy/test/source2slice/NVD/CVE_2009_4138_PATCHED_ohci_queue_iso_receive_dualbuffer.c length = PAGE_SIZE - offset 68
static int CVE_2009_4138_PATCHED_ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d ; 8
struct fw_iso_packet * p ; 9
u32 z , header_z , length , rest ; 11
int page , offset , packet_count , header_size ; 12
p = packet; 19
z = 2; 20
packet_count = p -> header_length / ctx -> base . header_size; 26
header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ); 27
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 30
offset = payload & ~PAGE_MASK; 32
rest = p -> payload_length; 33
if ( rest == 0 )  39
while ( rest > 0 )  43
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 44
if ( d == NULL )  46
if ( p -> skip && rest == p -> payload_length )  54
if ( p -> skip && rest == p -> payload_length )  63
length = 4; 64
if ( offset + rest < PAGE_SIZE )  65
length = rest; 66
length = PAGE_SIZE - offset; 68
db -> second_req_count = cpu_to_le16 ( length ); 70
db -> second_res_count = db -> second_req_count; 71
db -> second_buffer = cpu_to_le32 ( page_bus + offset ); 73
if ( p -> interrupt && length == rest )  75
db -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 76
offset = ( offset + length ) & ~PAGE_MASK; 79
rest -= length; 80
if ( offset == 0 )  81
------------------------------
199 /home/speedy/test/source2slice/NVD/CVE_2009_4138_PATCHED_ohci_queue_iso_receive_dualbuffer.c db -> first_buffer = cpu_to_le32 ( d_bus + sizeof ( * db ) ) 61
static int CVE_2009_4138_PATCHED_ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d ; 8
struct fw_iso_packet * p ; 9
dma_addr_t d_bus , page_bus ; 10
u32 z , header_z , length , rest ; 11
int page , offset , packet_count , header_size ; 12
p = packet; 19
z = 2; 20
packet_count = p -> header_length / ctx -> base . header_size; 26
header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ); 27
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 30
offset = payload & ~PAGE_MASK; 32
rest = p -> payload_length; 33
if ( rest == 0 )  39
while ( rest > 0 )  43
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 44
if ( d == NULL )  46
db = ( struct db_descriptor * ) d; 49
db -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_BRANCH_ALWAYS ); 50
db -> first_size = cpu_to_le16 ( max ( ctx -> base . header_size , ( size_t ) 8 ) ); 52
if ( p -> skip && rest == p -> payload_length )  54
db -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 55
db -> first_req_count = db -> first_size; 56
db -> first_req_count = cpu_to_le16 ( header_size ); 58
db -> first_res_count = db -> first_req_count; 60
db -> first_buffer = cpu_to_le32 ( d_bus + sizeof ( * db ) ); 61
if ( p -> skip && rest == p -> payload_length )  63
length = 4; 64
if ( offset + rest < PAGE_SIZE )  65
length = rest; 66
length = PAGE_SIZE - offset; 68
db -> second_req_count = cpu_to_le16 ( length ); 70
db -> second_res_count = db -> second_req_count; 71
db -> second_buffer = cpu_to_le32 ( page_bus + offset ); 73
db -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 76
offset = ( offset + length ) & ~PAGE_MASK; 79
rest -= length; 80
------------------------------
200 /home/speedy/test/source2slice/NVD/CVE_2009_4138_PATCHED_ohci_queue_iso_receive_dualbuffer.c d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ) 44
static int CVE_2009_4138_PATCHED_ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d ; 8
struct fw_iso_packet * p ; 9
u32 z , header_z , length , rest ; 11
int page , offset , packet_count , header_size ; 12
p = packet; 19
z = 2; 20
packet_count = p -> header_length / ctx -> base . header_size; 26
header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ); 27
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 30
offset = payload & ~PAGE_MASK; 32
rest = p -> payload_length; 33
if ( rest == 0 )  39
while ( rest > 0 )  43
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 44
if ( d == NULL )  46
db = ( struct db_descriptor * ) d; 49
db -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_BRANCH_ALWAYS ); 50
db -> first_size = cpu_to_le16 ( max ( ctx -> base . header_size , ( size_t ) 8 ) ); 52
db -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 55
db -> first_req_count = db -> first_size; 56
db -> first_req_count = cpu_to_le16 ( header_size ); 58
db -> first_res_count = db -> first_req_count; 60
db -> first_buffer = cpu_to_le32 ( d_bus + sizeof ( * db ) ); 61
if ( p -> skip && rest == p -> payload_length )  63
length = 4; 64
if ( offset + rest < PAGE_SIZE )  65
length = rest; 66
length = PAGE_SIZE - offset; 68
db -> second_req_count = cpu_to_le16 ( length ); 70
db -> second_res_count = db -> second_req_count; 71
db -> second_buffer = cpu_to_le32 ( page_bus + offset ); 73
db -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 76
context_append ( & ctx -> context , d , z , header_z ); 78
offset = ( offset + length ) & ~PAGE_MASK; 79
rest -= length; 80
------------------------------
201 /home/speedy/test/source2slice/NVD/CVE_2009_4138_PATCHED_ohci_queue_iso_receive_dualbuffer.c header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ) 27
static int CVE_2009_4138_PATCHED_ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct fw_iso_packet * p ; 9
int page , offset , packet_count , header_size ; 12
p = packet; 19
packet_count = p -> header_length / ctx -> base . header_size; 26
header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ); 27
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 30
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 44
if ( d == NULL )  46
db = ( struct db_descriptor * ) d; 49
db -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_BRANCH_ALWAYS ); 50
db -> first_size = cpu_to_le16 ( max ( ctx -> base . header_size , ( size_t ) 8 ) ); 52
db -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 55
db -> first_req_count = db -> first_size; 56
db -> first_req_count = cpu_to_le16 ( header_size ); 58
db -> first_res_count = db -> first_req_count; 60
db -> first_buffer = cpu_to_le32 ( d_bus + sizeof ( * db ) ); 61
db -> second_req_count = cpu_to_le16 ( length ); 70
db -> second_res_count = db -> second_req_count; 71
db -> second_buffer = cpu_to_le32 ( page_bus + offset ); 73
db -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 76
context_append ( & ctx -> context , d , z , header_z ); 78
------------------------------
202 /home/speedy/test/source2slice/NVD/CVE_2009_4138_PATCHED_ohci_queue_iso_receive_dualbuffer.c packet_count = p -> header_length / ctx -> base . header_size 26
static int CVE_2009_4138_PATCHED_ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct fw_iso_packet * p ; 9
int page , offset , packet_count , header_size ; 12
p = packet; 19
packet_count = p -> header_length / ctx -> base . header_size; 26
header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ); 27
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 30
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 44
if ( d == NULL )  46
db = ( struct db_descriptor * ) d; 49
db -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_BRANCH_ALWAYS ); 50
db -> first_size = cpu_to_le16 ( max ( ctx -> base . header_size , ( size_t ) 8 ) ); 52
db -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 55
db -> first_req_count = db -> first_size; 56
db -> first_req_count = cpu_to_le16 ( header_size ); 58
db -> first_res_count = db -> first_req_count; 60
db -> first_buffer = cpu_to_le32 ( d_bus + sizeof ( * db ) ); 61
db -> second_req_count = cpu_to_le16 ( length ); 70
db -> second_res_count = db -> second_req_count; 71
db -> second_buffer = cpu_to_le32 ( page_bus + offset ); 73
db -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 76
context_append ( & ctx -> context , d , z , header_z ); 78
------------------------------
203 /home/speedy/test/source2slice/NVD/CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer.c offset = ( offset + length ) & ~PAGE_MASK 62
static int CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d , * pd ; 7
struct fw_iso_packet * p = packet ; 8
u32 z , header_z , rest ; 10
int i , j , length ; 11
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
header_size = max ( ctx -> base . header_size , ( size_t ) 8 ); 19
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 22
offset = payload & ~PAGE_MASK; 24
payload_per_buffer = p -> payload_length / packet_count; 25
for (i = 0; i < packet_count; i++) 27
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
pd = d; 45
for (j = 1; j < z; j++) 46
pd ++; 47
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 48
if ( offset + rest < PAGE_SIZE )  51
length = rest; 52
length = PAGE_SIZE - offset; 54
pd -> req_count = cpu_to_le16 ( length ); 55
pd -> res_count = pd -> req_count; 56
pd -> transfer_status = 0; 57
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 60
offset = ( offset + length ) & ~PAGE_MASK; 62
rest -= length; 63
if ( offset == 0 )  64
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 67
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 71
context_append ( & ctx -> context , d , z , header_z ); 73
------------------------------
204 /home/speedy/test/source2slice/NVD/CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer.c pd -> data_address = cpu_to_le32 ( page_bus + offset ) 60
static int CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d , * pd ; 7
struct fw_iso_packet * p = packet ; 8
dma_addr_t d_bus , page_bus ; 9
u32 z , header_z , rest ; 10
int i , j , length ; 11
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
header_size = max ( ctx -> base . header_size , ( size_t ) 8 ); 19
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 22
page = payload >> PAGE_SHIFT; 23
offset = payload & ~PAGE_MASK; 24
payload_per_buffer = p -> payload_length / packet_count; 25
for (i = 0; i < packet_count; i++) 27
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
if ( p -> skip && i == 0 )  37
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
pd = d; 45
for (j = 1; j < z; j++) 46
pd ++; 47
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 48
if ( offset + rest < PAGE_SIZE )  51
length = rest; 52
length = PAGE_SIZE - offset; 54
pd -> req_count = cpu_to_le16 ( length ); 55
pd -> res_count = pd -> req_count; 56
pd -> transfer_status = 0; 57
page_bus = page_private ( buffer -> pages [ page ] ); 59
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 60
offset = ( offset + length ) & ~PAGE_MASK; 62
rest -= length; 63
if ( offset == 0 )  64
page ++; 65
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 67
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 71
------------------------------
205 /home/speedy/test/source2slice/NVD/CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer.c length = PAGE_SIZE - offset 54
static int CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d , * pd ; 7
struct fw_iso_packet * p = packet ; 8
u32 z , header_z , rest ; 10
int i , j , length ; 11
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
header_size = max ( ctx -> base . header_size , ( size_t ) 8 ); 19
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 22
offset = payload & ~PAGE_MASK; 24
payload_per_buffer = p -> payload_length / packet_count; 25
for (i = 0; i < packet_count; i++) 27
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
pd = d; 45
for (j = 1; j < z; j++) 46
pd ++; 47
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 48
if ( offset + rest < PAGE_SIZE )  51
length = rest; 52
length = PAGE_SIZE - offset; 54
pd -> req_count = cpu_to_le16 ( length ); 55
pd -> res_count = pd -> req_count; 56
pd -> transfer_status = 0; 57
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 60
offset = ( offset + length ) & ~PAGE_MASK; 62
rest -= length; 63
if ( offset == 0 )  64
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 67
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 71
context_append ( & ctx -> context , d , z , header_z ); 73
------------------------------
206 /home/speedy/test/source2slice/NVD/CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer.c d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ) 42
static int CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d , * pd ; 7
struct fw_iso_packet * p = packet ; 8
dma_addr_t d_bus , page_bus ; 9
u32 z , header_z , rest ; 10
int i , j , length ; 11
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
header_size = max ( ctx -> base . header_size , ( size_t ) 8 ); 19
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 22
offset = payload & ~PAGE_MASK; 24
payload_per_buffer = p -> payload_length / packet_count; 25
for (i = 0; i < packet_count; i++) 27
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
if ( p -> skip && i == 0 )  37
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
pd = d; 45
for (j = 1; j < z; j++) 46
pd ++; 47
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 48
if ( offset + rest < PAGE_SIZE )  51
length = rest; 52
length = PAGE_SIZE - offset; 54
pd -> req_count = cpu_to_le16 ( length ); 55
pd -> res_count = pd -> req_count; 56
pd -> transfer_status = 0; 57
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 60
offset = ( offset + length ) & ~PAGE_MASK; 62
rest -= length; 63
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 67
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 71
context_append ( & ctx -> context , d , z , header_z ); 73
------------------------------
207 /home/speedy/test/source2slice/NVD/CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer.c d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ) 30
static int CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d , * pd ; 7
struct fw_iso_packet * p = packet ; 8
u32 z , header_z , rest ; 10
int i , j , length ; 11
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
header_size = max ( ctx -> base . header_size , ( size_t ) 8 ); 19
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 22
offset = payload & ~PAGE_MASK; 24
payload_per_buffer = p -> payload_length / packet_count; 25
for (i = 0; i < packet_count; i++) 27
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
pd = d; 45
for (j = 1; j < z; j++) 46
pd ++; 47
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 48
if ( offset + rest < PAGE_SIZE )  51
length = rest; 52
length = PAGE_SIZE - offset; 54
pd -> req_count = cpu_to_le16 ( length ); 55
pd -> res_count = pd -> req_count; 56
pd -> transfer_status = 0; 57
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 60
offset = ( offset + length ) & ~PAGE_MASK; 62
rest -= length; 63
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 67
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 71
context_append ( & ctx -> context , d , z , header_z ); 73
------------------------------
208 /home/speedy/test/source2slice/NVD/CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer.c z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1 29
static int CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d , * pd ; 7
struct fw_iso_packet * p = packet ; 8
u32 z , header_z , rest ; 10
int i , j , length ; 11
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
header_size = max ( ctx -> base . header_size , ( size_t ) 8 ); 19
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 22
offset = payload & ~PAGE_MASK; 24
payload_per_buffer = p -> payload_length / packet_count; 25
for (i = 0; i < packet_count; i++) 27
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
pd = d; 45
for (j = 1; j < z; j++) 46
pd ++; 47
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 48
if ( offset + rest < PAGE_SIZE )  51
length = rest; 52
length = PAGE_SIZE - offset; 54
pd -> req_count = cpu_to_le16 ( length ); 55
pd -> res_count = pd -> req_count; 56
pd -> transfer_status = 0; 57
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 60
offset = ( offset + length ) & ~PAGE_MASK; 62
rest -= length; 63
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 67
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 71
context_append ( & ctx -> context , d , z , header_z ); 73
------------------------------
209 /home/speedy/test/source2slice/NVD/CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer.c payload_per_buffer = p -> payload_length / packet_count 25
static int CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct fw_iso_packet * p = packet ; 8
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
payload_per_buffer = p -> payload_length / packet_count; 25
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
pd = d; 45
for (j = 1; j < z; j++) 46
pd ++; 47
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 48
if ( offset + rest < PAGE_SIZE )  51
length = rest; 52
length = PAGE_SIZE - offset; 54
pd -> req_count = cpu_to_le16 ( length ); 55
pd -> res_count = pd -> req_count; 56
pd -> transfer_status = 0; 57
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 60
offset = ( offset + length ) & ~PAGE_MASK; 62
rest -= length; 63
if ( offset == 0 )  64
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 67
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 71
context_append ( & ctx -> context , d , z , header_z ); 73
------------------------------
210 /home/speedy/test/source2slice/NVD/CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer.c packet_count = p -> header_length / ctx -> base . header_size 18
static int CVE_2009_4138_PATCHED_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct fw_iso_packet * p = packet ; 8
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
payload_per_buffer = p -> payload_length / packet_count; 25
for (i = 0; i < packet_count; i++) 27
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
pd = d; 45
for (j = 1; j < z; j++) 46
pd ++; 47
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 48
if ( offset + rest < PAGE_SIZE )  51
length = rest; 52
length = PAGE_SIZE - offset; 54
pd -> req_count = cpu_to_le16 ( length ); 55
pd -> res_count = pd -> req_count; 56
pd -> transfer_status = 0; 57
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 60
offset = ( offset + length ) & ~PAGE_MASK; 62
rest -= length; 63
if ( offset == 0 )  64
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 67
if ( p -> interrupt && i == packet_count - 1 )  70
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 71
context_append ( & ctx -> context , d , z , header_z ); 73
------------------------------
211 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_dualbuffer.c offset = ( offset + length ) & ~PAGE_MASK 72
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d ; 8
struct fw_iso_packet * p ; 9
u32 z , header_z , length , rest ; 11
int page , offset , packet_count , header_size ; 12
p = packet; 19
z = 2; 20
packet_count = p -> header_length / ctx -> base . header_size; 26
header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ); 27
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 30
offset = payload & ~PAGE_MASK; 32
rest = p -> payload_length; 33
while ( rest > 0 )  36
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 37
if ( d == NULL )  39
if ( p -> skip && rest == p -> payload_length )  47
if ( p -> skip && rest == p -> payload_length )  56
length = 4; 57
if ( offset + rest < PAGE_SIZE )  58
length = rest; 59
length = PAGE_SIZE - offset; 61
db -> second_req_count = cpu_to_le16 ( length ); 63
db -> second_res_count = db -> second_req_count; 64
db -> second_buffer = cpu_to_le32 ( page_bus + offset ); 66
if ( p -> interrupt && length == rest )  68
db -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 69
offset = ( offset + length ) & ~PAGE_MASK; 72
rest -= length; 73
if ( offset == 0 )  74
------------------------------
212 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_dualbuffer.c db -> second_buffer = cpu_to_le32 ( page_bus + offset ) 66
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d ; 8
struct fw_iso_packet * p ; 9
dma_addr_t d_bus , page_bus ; 10
u32 z , header_z , length , rest ; 11
int page , offset , packet_count , header_size ; 12
p = packet; 19
z = 2; 20
packet_count = p -> header_length / ctx -> base . header_size; 26
header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ); 27
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 30
page = payload >> PAGE_SHIFT; 31
offset = payload & ~PAGE_MASK; 32
rest = p -> payload_length; 33
while ( rest > 0 )  36
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 37
if ( d == NULL )  39
db = ( struct db_descriptor * ) d; 42
db -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_BRANCH_ALWAYS ); 43
db -> first_size = cpu_to_le16 ( max ( ctx -> base . header_size , ( size_t ) 8 ) ); 45
if ( p -> skip && rest == p -> payload_length )  47
db -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 48
db -> first_req_count = db -> first_size; 49
db -> first_req_count = cpu_to_le16 ( header_size ); 51
db -> first_res_count = db -> first_req_count; 53
db -> first_buffer = cpu_to_le32 ( d_bus + sizeof ( * db ) ); 54
if ( p -> skip && rest == p -> payload_length )  56
length = 4; 57
if ( offset + rest < PAGE_SIZE )  58
length = rest; 59
length = PAGE_SIZE - offset; 61
db -> second_req_count = cpu_to_le16 ( length ); 63
db -> second_res_count = db -> second_req_count; 64
page_bus = page_private ( buffer -> pages [ page ] ); 65
db -> second_buffer = cpu_to_le32 ( page_bus + offset ); 66
db -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 69
offset = ( offset + length ) & ~PAGE_MASK; 72
rest -= length; 73
if ( offset == 0 )  74
page ++; 75
------------------------------
213 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_dualbuffer.c length = PAGE_SIZE - offset 61
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d ; 8
struct fw_iso_packet * p ; 9
u32 z , header_z , length , rest ; 11
int page , offset , packet_count , header_size ; 12
p = packet; 19
z = 2; 20
packet_count = p -> header_length / ctx -> base . header_size; 26
header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ); 27
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 30
offset = payload & ~PAGE_MASK; 32
rest = p -> payload_length; 33
while ( rest > 0 )  36
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 37
if ( d == NULL )  39
if ( p -> skip && rest == p -> payload_length )  47
if ( p -> skip && rest == p -> payload_length )  56
length = 4; 57
if ( offset + rest < PAGE_SIZE )  58
length = rest; 59
length = PAGE_SIZE - offset; 61
db -> second_req_count = cpu_to_le16 ( length ); 63
db -> second_res_count = db -> second_req_count; 64
db -> second_buffer = cpu_to_le32 ( page_bus + offset ); 66
if ( p -> interrupt && length == rest )  68
db -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 69
offset = ( offset + length ) & ~PAGE_MASK; 72
rest -= length; 73
if ( offset == 0 )  74
------------------------------
214 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_dualbuffer.c db -> first_buffer = cpu_to_le32 ( d_bus + sizeof ( * db ) ) 54
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d ; 8
struct fw_iso_packet * p ; 9
dma_addr_t d_bus , page_bus ; 10
u32 z , header_z , length , rest ; 11
int page , offset , packet_count , header_size ; 12
p = packet; 19
z = 2; 20
packet_count = p -> header_length / ctx -> base . header_size; 26
header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ); 27
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 30
offset = payload & ~PAGE_MASK; 32
rest = p -> payload_length; 33
while ( rest > 0 )  36
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 37
if ( d == NULL )  39
db = ( struct db_descriptor * ) d; 42
db -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_BRANCH_ALWAYS ); 43
db -> first_size = cpu_to_le16 ( max ( ctx -> base . header_size , ( size_t ) 8 ) ); 45
if ( p -> skip && rest == p -> payload_length )  47
db -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 48
db -> first_req_count = db -> first_size; 49
db -> first_req_count = cpu_to_le16 ( header_size ); 51
db -> first_res_count = db -> first_req_count; 53
db -> first_buffer = cpu_to_le32 ( d_bus + sizeof ( * db ) ); 54
if ( p -> skip && rest == p -> payload_length )  56
length = 4; 57
if ( offset + rest < PAGE_SIZE )  58
length = rest; 59
length = PAGE_SIZE - offset; 61
db -> second_req_count = cpu_to_le16 ( length ); 63
db -> second_res_count = db -> second_req_count; 64
db -> second_buffer = cpu_to_le32 ( page_bus + offset ); 66
db -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 69
offset = ( offset + length ) & ~PAGE_MASK; 72
rest -= length; 73
------------------------------
215 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_dualbuffer.c d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ) 37
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d ; 8
struct fw_iso_packet * p ; 9
u32 z , header_z , length , rest ; 11
int page , offset , packet_count , header_size ; 12
p = packet; 19
z = 2; 20
packet_count = p -> header_length / ctx -> base . header_size; 26
header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ); 27
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 30
offset = payload & ~PAGE_MASK; 32
rest = p -> payload_length; 33
while ( rest > 0 )  36
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 37
if ( d == NULL )  39
db = ( struct db_descriptor * ) d; 42
db -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_BRANCH_ALWAYS ); 43
db -> first_size = cpu_to_le16 ( max ( ctx -> base . header_size , ( size_t ) 8 ) ); 45
db -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 48
db -> first_req_count = db -> first_size; 49
db -> first_req_count = cpu_to_le16 ( header_size ); 51
db -> first_res_count = db -> first_req_count; 53
db -> first_buffer = cpu_to_le32 ( d_bus + sizeof ( * db ) ); 54
if ( p -> skip && rest == p -> payload_length )  56
length = 4; 57
if ( offset + rest < PAGE_SIZE )  58
length = rest; 59
length = PAGE_SIZE - offset; 61
db -> second_req_count = cpu_to_le16 ( length ); 63
db -> second_res_count = db -> second_req_count; 64
db -> second_buffer = cpu_to_le32 ( page_bus + offset ); 66
db -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 69
context_append ( & ctx -> context , d , z , header_z ); 71
offset = ( offset + length ) & ~PAGE_MASK; 72
rest -= length; 73
------------------------------
216 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_dualbuffer.c header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ) 27
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct fw_iso_packet * p ; 9
int page , offset , packet_count , header_size ; 12
p = packet; 19
packet_count = p -> header_length / ctx -> base . header_size; 26
header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ); 27
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 30
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 37
if ( d == NULL )  39
db = ( struct db_descriptor * ) d; 42
db -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_BRANCH_ALWAYS ); 43
db -> first_size = cpu_to_le16 ( max ( ctx -> base . header_size , ( size_t ) 8 ) ); 45
db -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 48
db -> first_req_count = db -> first_size; 49
db -> first_req_count = cpu_to_le16 ( header_size ); 51
db -> first_res_count = db -> first_req_count; 53
db -> first_buffer = cpu_to_le32 ( d_bus + sizeof ( * db ) ); 54
db -> second_req_count = cpu_to_le16 ( length ); 63
db -> second_res_count = db -> second_req_count; 64
db -> second_buffer = cpu_to_le32 ( page_bus + offset ); 66
db -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 69
context_append ( & ctx -> context , d , z , header_z ); 71
------------------------------
217 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_dualbuffer.c packet_count = p -> header_length / ctx -> base . header_size 26
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct fw_iso_packet * p ; 9
int page , offset , packet_count , header_size ; 12
p = packet; 19
packet_count = p -> header_length / ctx -> base . header_size; 26
header_size = packet_count * max ( ctx -> base . header_size , ( size_t ) 8 ); 27
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 30
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 37
if ( d == NULL )  39
db = ( struct db_descriptor * ) d; 42
db -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_BRANCH_ALWAYS ); 43
db -> first_size = cpu_to_le16 ( max ( ctx -> base . header_size , ( size_t ) 8 ) ); 45
db -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 48
db -> first_req_count = db -> first_size; 49
db -> first_req_count = cpu_to_le16 ( header_size ); 51
db -> first_res_count = db -> first_req_count; 53
db -> first_buffer = cpu_to_le32 ( d_bus + sizeof ( * db ) ); 54
db -> second_req_count = cpu_to_le16 ( length ); 63
db -> second_res_count = db -> second_req_count; 64
db -> second_buffer = cpu_to_le32 ( page_bus + offset ); 66
db -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 69
context_append ( & ctx -> context , d , z , header_z ); 71
------------------------------
218 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer.c offset = ( offset + length ) & ~PAGE_MASK 61
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d = NULL , * pd = NULL ; 7
struct fw_iso_packet * p = packet ; 8
u32 z , header_z , rest ; 10
int i , j , length ; 11
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
header_size = max ( ctx -> base . header_size , ( size_t ) 8 ); 19
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 22
offset = payload & ~PAGE_MASK; 24
payload_per_buffer = p -> payload_length / packet_count; 25
for (i = 0; i < packet_count; i++) 27
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
for (j = 1; j < z; j++) 45
pd = d + j; 46
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 47
if ( offset + rest < PAGE_SIZE )  50
length = rest; 51
length = PAGE_SIZE - offset; 53
pd -> req_count = cpu_to_le16 ( length ); 54
pd -> res_count = pd -> req_count; 55
pd -> transfer_status = 0; 56
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 59
offset = ( offset + length ) & ~PAGE_MASK; 61
rest -= length; 62
if ( offset == 0 )  63
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 66
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 70
context_append ( & ctx -> context , d , z , header_z ); 72
------------------------------
219 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer.c pd -> data_address = cpu_to_le32 ( page_bus + offset ) 59
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d = NULL , * pd = NULL ; 7
struct fw_iso_packet * p = packet ; 8
dma_addr_t d_bus , page_bus ; 9
u32 z , header_z , rest ; 10
int i , j , length ; 11
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
header_size = max ( ctx -> base . header_size , ( size_t ) 8 ); 19
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 22
page = payload >> PAGE_SHIFT; 23
offset = payload & ~PAGE_MASK; 24
payload_per_buffer = p -> payload_length / packet_count; 25
for (i = 0; i < packet_count; i++) 27
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
if ( p -> skip && i == 0 )  37
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
for (j = 1; j < z; j++) 45
pd = d + j; 46
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 47
if ( offset + rest < PAGE_SIZE )  50
length = rest; 51
length = PAGE_SIZE - offset; 53
pd -> req_count = cpu_to_le16 ( length ); 54
pd -> res_count = pd -> req_count; 55
pd -> transfer_status = 0; 56
page_bus = page_private ( buffer -> pages [ page ] ); 58
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 59
offset = ( offset + length ) & ~PAGE_MASK; 61
rest -= length; 62
if ( offset == 0 )  63
page ++; 64
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 66
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 70
------------------------------
220 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer.c length = PAGE_SIZE - offset 53
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d = NULL , * pd = NULL ; 7
struct fw_iso_packet * p = packet ; 8
u32 z , header_z , rest ; 10
int i , j , length ; 11
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
header_size = max ( ctx -> base . header_size , ( size_t ) 8 ); 19
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 22
offset = payload & ~PAGE_MASK; 24
payload_per_buffer = p -> payload_length / packet_count; 25
for (i = 0; i < packet_count; i++) 27
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
for (j = 1; j < z; j++) 45
pd = d + j; 46
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 47
if ( offset + rest < PAGE_SIZE )  50
length = rest; 51
length = PAGE_SIZE - offset; 53
pd -> req_count = cpu_to_le16 ( length ); 54
pd -> res_count = pd -> req_count; 55
pd -> transfer_status = 0; 56
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 59
offset = ( offset + length ) & ~PAGE_MASK; 61
rest -= length; 62
if ( offset == 0 )  63
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 66
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 70
context_append ( & ctx -> context , d , z , header_z ); 72
------------------------------
221 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer.c pd = d + j 46
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d = NULL , * pd = NULL ; 7
struct fw_iso_packet * p = packet ; 8
dma_addr_t d_bus , page_bus ; 9
u32 z , header_z , rest ; 10
int i , j , length ; 11
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
header_size = max ( ctx -> base . header_size , ( size_t ) 8 ); 19
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 22
offset = payload & ~PAGE_MASK; 24
payload_per_buffer = p -> payload_length / packet_count; 25
for (i = 0; i < packet_count; i++) 27
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
if ( p -> skip && i == 0 )  37
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
for (j = 1; j < z; j++) 45
pd = d + j; 46
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 47
if ( offset + rest < PAGE_SIZE )  50
length = rest; 51
length = PAGE_SIZE - offset; 53
pd -> req_count = cpu_to_le16 ( length ); 54
pd -> res_count = pd -> req_count; 55
pd -> transfer_status = 0; 56
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 59
offset = ( offset + length ) & ~PAGE_MASK; 61
rest -= length; 62
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 66
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 70
------------------------------
222 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer.c d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ) 42
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d = NULL , * pd = NULL ; 7
struct fw_iso_packet * p = packet ; 8
dma_addr_t d_bus , page_bus ; 9
u32 z , header_z , rest ; 10
int i , j , length ; 11
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
header_size = max ( ctx -> base . header_size , ( size_t ) 8 ); 19
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 22
offset = payload & ~PAGE_MASK; 24
payload_per_buffer = p -> payload_length / packet_count; 25
for (i = 0; i < packet_count; i++) 27
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
if ( p -> skip && i == 0 )  37
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
for (j = 1; j < z; j++) 45
pd = d + j; 46
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 47
if ( offset + rest < PAGE_SIZE )  50
length = rest; 51
length = PAGE_SIZE - offset; 53
pd -> req_count = cpu_to_le16 ( length ); 54
pd -> res_count = pd -> req_count; 55
pd -> transfer_status = 0; 56
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 59
offset = ( offset + length ) & ~PAGE_MASK; 61
rest -= length; 62
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 66
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 70
context_append ( & ctx -> context , d , z , header_z ); 72
------------------------------
223 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer.c d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ) 30
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d = NULL , * pd = NULL ; 7
struct fw_iso_packet * p = packet ; 8
u32 z , header_z , rest ; 10
int i , j , length ; 11
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
header_size = max ( ctx -> base . header_size , ( size_t ) 8 ); 19
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 22
offset = payload & ~PAGE_MASK; 24
payload_per_buffer = p -> payload_length / packet_count; 25
for (i = 0; i < packet_count; i++) 27
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
for (j = 1; j < z; j++) 45
pd = d + j; 46
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 47
if ( offset + rest < PAGE_SIZE )  50
length = rest; 51
length = PAGE_SIZE - offset; 53
pd -> req_count = cpu_to_le16 ( length ); 54
pd -> res_count = pd -> req_count; 55
pd -> transfer_status = 0; 56
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 59
offset = ( offset + length ) & ~PAGE_MASK; 61
rest -= length; 62
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 66
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 70
context_append ( & ctx -> context , d , z , header_z ); 72
------------------------------
224 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer.c z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1 29
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct descriptor * d = NULL , * pd = NULL ; 7
struct fw_iso_packet * p = packet ; 8
u32 z , header_z , rest ; 10
int i , j , length ; 11
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
header_size = max ( ctx -> base . header_size , ( size_t ) 8 ); 19
header_z = DIV_ROUND_UP ( header_size , sizeof ( * d ) ); 22
offset = payload & ~PAGE_MASK; 24
payload_per_buffer = p -> payload_length / packet_count; 25
for (i = 0; i < packet_count; i++) 27
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
for (j = 1; j < z; j++) 45
pd = d + j; 46
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 47
if ( offset + rest < PAGE_SIZE )  50
length = rest; 51
length = PAGE_SIZE - offset; 53
pd -> req_count = cpu_to_le16 ( length ); 54
pd -> res_count = pd -> req_count; 55
pd -> transfer_status = 0; 56
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 59
offset = ( offset + length ) & ~PAGE_MASK; 61
rest -= length; 62
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 66
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 70
context_append ( & ctx -> context , d , z , header_z ); 72
------------------------------
225 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer.c payload_per_buffer = p -> payload_length / packet_count 25
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct fw_iso_packet * p = packet ; 8
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
payload_per_buffer = p -> payload_length / packet_count; 25
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
for (j = 1; j < z; j++) 45
pd = d + j; 46
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 47
if ( offset + rest < PAGE_SIZE )  50
length = rest; 51
length = PAGE_SIZE - offset; 53
pd -> req_count = cpu_to_le16 ( length ); 54
pd -> res_count = pd -> req_count; 55
pd -> transfer_status = 0; 56
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 59
offset = ( offset + length ) & ~PAGE_MASK; 61
rest -= length; 62
if ( offset == 0 )  63
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 66
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 70
context_append ( & ctx -> context , d , z , header_z ); 72
------------------------------
226 /home/speedy/test/source2slice/NVD/CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer.c packet_count = p -> header_length / ctx -> base . header_size 18
static int CVE_2009_4138_VULN_ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,
struct fw_iso_packet *packet,
struct fw_iso_buffer *buffer,
unsigned long payload) 4
struct iso_context * ctx = container_of ( base , struct iso_context , base ) 6
struct fw_iso_packet * p = packet ; 8
int page , offset , packet_count , header_size , payload_per_buffer ; 12
packet_count = p -> header_length / ctx -> base . header_size; 18
payload_per_buffer = p -> payload_length / packet_count; 25
for (i = 0; i < packet_count; i++) 27
z = DIV_ROUND_UP ( payload_per_buffer + offset , PAGE_SIZE ) + 1; 29
d = context_get_descriptors ( & ctx -> context , z + header_z , & d_bus ); 30
if ( d == NULL )  32
d -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 35
d -> control |= cpu_to_le16 ( DESCRIPTOR_WAIT ); 38
d -> req_count = cpu_to_le16 ( header_size ); 39
d -> res_count = d -> req_count; 40
d -> transfer_status = 0; 41
d -> data_address = cpu_to_le32 ( d_bus + ( z * sizeof ( * d ) ) ); 42
rest = payload_per_buffer; 44
for (j = 1; j < z; j++) 45
pd = d + j; 46
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_MORE ); 47
if ( offset + rest < PAGE_SIZE )  50
length = rest; 51
length = PAGE_SIZE - offset; 53
pd -> req_count = cpu_to_le16 ( length ); 54
pd -> res_count = pd -> req_count; 55
pd -> transfer_status = 0; 56
pd -> data_address = cpu_to_le32 ( page_bus + offset ); 59
offset = ( offset + length ) & ~PAGE_MASK; 61
rest -= length; 62
if ( offset == 0 )  63
pd -> control = cpu_to_le16 ( DESCRIPTOR_STATUS | DESCRIPTOR_INPUT_LAST | DESCRIPTOR_BRANCH_ALWAYS ); 66
if ( p -> interrupt && i == packet_count - 1 )  69
pd -> control |= cpu_to_le16 ( DESCRIPTOR_IRQ_ALWAYS ); 70
context_append ( & ctx -> context , d , z , header_z ); 72
------------------------------
227 /home/speedy/test/source2slice/NVD/CVE_2009_4307_PATCHED_ext4_fill_flex_info.c size = flex_group_count * sizeof ( struct flex_groups ) 23
static int CVE_2009_4307_PATCHED_ext4_fill_flex_info(struct super_block *sb) 1
struct ext4_sb_info * sbi = EXT4_SB ( sb ) ; 3
ext4_group_t flex_group_count ; 5
size_t size ; 8
sbi -> s_log_groups_per_flex = sbi -> s_es -> s_log_groups_per_flex; 11
groups_per_flex = 1 << sbi -> s_log_groups_per_flex; 12
if ( groups_per_flex < 2 )  14
flex_group_count = ( ( sbi -> s_groups_count + groups_per_flex - 1 ) + ( ( le16_to_cpu ( sbi -> s_es -> s_reserved_gdt_blocks ) + 1 ) << EXT4_DESC_PER_BLOCK_BITS ( sb ) ) ) / groups_per_flex; 20
size = flex_group_count * sizeof ( struct flex_groups ); 23
sbi -> s_flex_groups = kzalloc ( size , GFP_KERNEL ); 24
if ( sbi -> s_flex_groups == NULL )  25
sbi -> s_flex_groups = vmalloc ( size ); 26
if ( sbi -> s_flex_groups )  27
memset ( sbi -> s_flex_groups , 0 , size ); 28
if ( sbi -> s_flex_groups == NULL )  30
for (i = 0; i < sbi->s_groups_count; i++) 36
flex_group = ext4_flex_group ( sbi , i ); 39
atomic_set ( & sbi -> s_flex_groups [ flex_group ] . free_inodes , ext4_free_inodes_count ( sb , gdp ) ); 40
atomic_set ( & sbi -> s_flex_groups [ flex_group ] . free_blocks , ext4_free_blks_count ( sb , gdp ) ); 42
atomic_set ( & sbi -> s_flex_groups [ flex_group ] . used_dirs , ext4_used_dirs_count ( sb , gdp ) ); 44
------------------------------
228 /home/speedy/test/source2slice/NVD/CVE_2009_4307_PATCHED_ext4_fill_flex_info.c flex_group_count = ( ( sbi -> s_groups_count + groups_per_flex - 1 ) + ( ( le16_to_cpu ( sbi -> s_es -> s_reserved_gdt_blocks ) + 1 ) << EXT4_DESC_PER_BLOCK_BITS ( sb ) ) ) / groups_per_flex 20
static int CVE_2009_4307_PATCHED_ext4_fill_flex_info(struct super_block *sb) 1
struct ext4_sb_info * sbi = EXT4_SB ( sb ) ; 3
ext4_group_t flex_group_count ; 5
sbi -> s_log_groups_per_flex = sbi -> s_es -> s_log_groups_per_flex; 11
groups_per_flex = 1 << sbi -> s_log_groups_per_flex; 12
if ( groups_per_flex < 2 )  14
flex_group_count = ( ( sbi -> s_groups_count + groups_per_flex - 1 ) + ( ( le16_to_cpu ( sbi -> s_es -> s_reserved_gdt_blocks ) + 1 ) << EXT4_DESC_PER_BLOCK_BITS ( sb ) ) ) / groups_per_flex; 20
size = flex_group_count * sizeof ( struct flex_groups ); 23
sbi -> s_flex_groups = kzalloc ( size , GFP_KERNEL ); 24
if ( sbi -> s_flex_groups == NULL )  25
sbi -> s_flex_groups = vmalloc ( size ); 26
if ( sbi -> s_flex_groups )  27
memset ( sbi -> s_flex_groups , 0 , size ); 28
if ( sbi -> s_flex_groups == NULL )  30
ext4_msg ( sb , KERN_ERR , "not enough memory for "
"%u flex groups" , flex_group_count ) 32
for (i = 0; i < sbi->s_groups_count; i++) 36
flex_group = ext4_flex_group ( sbi , i ); 39
atomic_set ( & sbi -> s_flex_groups [ flex_group ] . free_inodes , ext4_free_inodes_count ( sb , gdp ) ); 40
atomic_set ( & sbi -> s_flex_groups [ flex_group ] . free_blocks , ext4_free_blks_count ( sb , gdp ) ); 42
atomic_set ( & sbi -> s_flex_groups [ flex_group ] . used_dirs , ext4_used_dirs_count ( sb , gdp ) ); 44
------------------------------
229 /home/speedy/test/source2slice/NVD/CVE_2009_4307_VULN_ext4_fill_flex_info.c size = flex_group_count * sizeof ( struct flex_groups ) 23
static int CVE_2009_4307_VULN_ext4_fill_flex_info(struct super_block *sb) 1
struct ext4_sb_info * sbi = EXT4_SB ( sb ) ; 3
ext4_group_t flex_group_count ; 5
size_t size ; 8
if ( ! sbi -> s_es -> s_log_groups_per_flex )  11
sbi -> s_log_groups_per_flex = sbi -> s_es -> s_log_groups_per_flex; 16
groups_per_flex = 1 << sbi -> s_log_groups_per_flex; 17
flex_group_count = ( ( sbi -> s_groups_count + groups_per_flex - 1 ) + ( ( le16_to_cpu ( sbi -> s_es -> s_reserved_gdt_blocks ) + 1 ) << EXT4_DESC_PER_BLOCK_BITS ( sb ) ) ) / groups_per_flex; 20
size = flex_group_count * sizeof ( struct flex_groups ); 23
sbi -> s_flex_groups = kzalloc ( size , GFP_KERNEL ); 24
if ( sbi -> s_flex_groups == NULL )  25
sbi -> s_flex_groups = vmalloc ( size ); 26
if ( sbi -> s_flex_groups )  27
memset ( sbi -> s_flex_groups , 0 , size ); 28
if ( sbi -> s_flex_groups == NULL )  30
for (i = 0; i < sbi->s_groups_count; i++) 36
flex_group = ext4_flex_group ( sbi , i ); 39
atomic_set ( & sbi -> s_flex_groups [ flex_group ] . free_inodes , ext4_free_inodes_count ( sb , gdp ) ); 40
atomic_set ( & sbi -> s_flex_groups [ flex_group ] . free_blocks , ext4_free_blks_count ( sb , gdp ) ); 42
atomic_set ( & sbi -> s_flex_groups [ flex_group ] . used_dirs , ext4_used_dirs_count ( sb , gdp ) ); 44
------------------------------
230 /home/speedy/test/source2slice/NVD/CVE_2009_4307_VULN_ext4_fill_flex_info.c flex_group_count = ( ( sbi -> s_groups_count + groups_per_flex - 1 ) + ( ( le16_to_cpu ( sbi -> s_es -> s_reserved_gdt_blocks ) + 1 ) << EXT4_DESC_PER_BLOCK_BITS ( sb ) ) ) / groups_per_flex 20
static int CVE_2009_4307_VULN_ext4_fill_flex_info(struct super_block *sb) 1
struct ext4_sb_info * sbi = EXT4_SB ( sb ) ; 3
ext4_group_t flex_group_count ; 5
if ( ! sbi -> s_es -> s_log_groups_per_flex )  11
sbi -> s_log_groups_per_flex = sbi -> s_es -> s_log_groups_per_flex; 16
groups_per_flex = 1 << sbi -> s_log_groups_per_flex; 17
flex_group_count = ( ( sbi -> s_groups_count + groups_per_flex - 1 ) + ( ( le16_to_cpu ( sbi -> s_es -> s_reserved_gdt_blocks ) + 1 ) << EXT4_DESC_PER_BLOCK_BITS ( sb ) ) ) / groups_per_flex; 20
size = flex_group_count * sizeof ( struct flex_groups ); 23
sbi -> s_flex_groups = kzalloc ( size , GFP_KERNEL ); 24
if ( sbi -> s_flex_groups == NULL )  25
sbi -> s_flex_groups = vmalloc ( size ); 26
if ( sbi -> s_flex_groups )  27
memset ( sbi -> s_flex_groups , 0 , size ); 28
if ( sbi -> s_flex_groups == NULL )  30
ext4_msg ( sb , KERN_ERR , "not enough memory for "
"%u flex groups" , flex_group_count ) 32
for (i = 0; i < sbi->s_groups_count; i++) 36
flex_group = ext4_flex_group ( sbi , i ); 39
atomic_set ( & sbi -> s_flex_groups [ flex_group ] . free_inodes , ext4_free_inodes_count ( sb , gdp ) ); 40
atomic_set ( & sbi -> s_flex_groups [ flex_group ] . free_blocks , ext4_free_blks_count ( sb , gdp ) ); 42
atomic_set ( & sbi -> s_flex_groups [ flex_group ] . used_dirs , ext4_used_dirs_count ( sb , gdp ) ); 44
------------------------------
231 /home/speedy/test/source2slice/NVD/CVE_2010_0006_PATCHED_ipv6_hop_jumbo.c pkt_len = ntohl ( * ( __be32 * ) ( nh + optoff + 2 ) ) 15
static int CVE_2010_0006_PATCHED_ipv6_hop_jumbo(struct sk_buff *skb, int optoff) 1
const unsigned char * nh = skb_network_header ( skb ) ; 3
u32 pkt_len ; 5
if ( nh [ optoff + 1 ] != 4 || ( optoff & 3 ) != 2 )  7
pkt_len = ntohl ( * ( __be32 * ) ( nh + optoff + 2 ) ); 15
if ( pkt_len <= IPV6_MAXPLEN )  16
if ( pkt_len > skb -> len - sizeof ( struct ipv6hdr ) )  29
if ( pskb_trim_rcsum ( skb , pkt_len + sizeof ( struct ipv6hdr ) ) )  35
------------------------------
232 /home/speedy/test/source2slice/NVD/CVE_2010_0006_VULN_ipv6_hop_jumbo.c pkt_len = ntohl ( * ( __be32 * ) ( nh + optoff + 2 ) ) 15
static int CVE_2010_0006_VULN_ipv6_hop_jumbo(struct sk_buff *skb, int optoff) 1
const unsigned char * nh = skb_network_header ( skb ) ; 3
u32 pkt_len ; 4
if ( nh [ optoff + 1 ] != 4 || ( optoff & 3 ) != 2 )  7
pkt_len = ntohl ( * ( __be32 * ) ( nh + optoff + 2 ) ); 15
if ( pkt_len <= IPV6_MAXPLEN )  16
if ( pkt_len > skb -> len - sizeof ( struct ipv6hdr ) )  29
if ( pskb_trim_rcsum ( skb , pkt_len + sizeof ( struct ipv6hdr ) ) )  35
------------------------------
233 /home/speedy/test/source2slice/NVD/CVE_2010_0307_PATCHED_load_elf_binary.c k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz 294
static int CVE_2010_0307_PATCHED_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned long load_addr = 0 , load_bias = 0 ; 4
int load_addr_set = 0 ; 5
char * elf_interpreter = NULL ; 6
unsigned long error ; 7
struct elf_phdr * elf_ppnt , * elf_phdata ; 8
unsigned long elf_bss , elf_brk ; 9
int retval , i ; 10
unsigned int size ; 11
int executable_stack = EXSTACK_DEFAULT ; 16
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
retval = - ENOEXEC; 32
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
retval = - ENOMEM; 51
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
elf_ppnt = elf_phdata; 64
elf_bss = 0; 65
elf_brk = 0; 66
for (i = 0; i < loc->elf_ex.e_phnum; i++) 73
if ( elf_ppnt -> p_type == PT_INTERP )  74
retval = - ENOEXEC; 79
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
retval = - ENOMEM; 84
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
retval = - ENOEXEC; 99
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 103
retval = PTR_ERR ( interpreter ); 104
if ( IS_ERR ( interpreter ) )  105
if ( file_permission ( interpreter , MAY_READ ) < 0 )  113
bprm -> interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP; 114
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 116
if ( retval != BINPRM_BUF_SIZE )  118
loc -> interp_elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 125
elf_ppnt ++; 128
elf_ppnt = elf_phdata; 131
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 132
if ( elf_ppnt -> p_type == PT_GNU_STACK )  133
if ( elf_ppnt -> p_flags & PF_X )  134
executable_stack = EXSTACK_ENABLE_X; 135
executable_stack = EXSTACK_DISABLE_X; 137
if ( elf_interpreter )  142
retval = - ELIBBAD; 143
if ( memcmp ( loc -> interp_elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  145
if ( ! elf_check_arch ( & loc -> interp_elf_ex ) )  148
retval = flush_old_exec ( bprm ); 153
if ( retval )  154
retval = setup_arg_pages ( bprm , randomize_stack_top ( STACK_TOP ) , executable_stack ); 176
if ( retval < 0 )  178
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 188
int elf_prot = 0 , elf_flags ; 189
unsigned long k , vaddr ; 190
if ( elf_ppnt -> p_type != PT_LOAD )  192
if ( unlikely ( elf_brk > elf_bss ) )  195
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 201
if ( retval )  203
if ( nbyte > elf_brk - elf_bss )  210
nbyte = elf_brk - elf_bss; 211
if ( clear_user ( ( void __user * ) elf_bss + load_bias , nbyte ) )  212
if ( elf_ppnt -> p_flags & PF_R )  223
elf_prot |= PROT_READ; 224
if ( elf_ppnt -> p_flags & PF_W )  225
elf_prot |= PROT_WRITE; 226
if ( elf_ppnt -> p_flags & PF_X )  227
elf_prot |= PROT_EXEC; 228
elf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE; 230
vaddr = elf_ppnt -> p_vaddr; 232
if ( loc -> elf_ex . e_type == ET_EXEC || load_addr_set )  233
elf_flags |= MAP_FIXED; 234
if ( loc -> elf_ex . e_type == ET_DYN )  235
load_bias = 0; 241
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 247
if ( BAD_ADDR ( error ) )  249
if ( ! load_addr_set )  256
load_addr_set = 1; 257
if ( loc -> elf_ex . e_type == ET_DYN )  259
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 260
k = elf_ppnt -> p_vaddr; 266
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  277
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 286
if ( k > elf_bss )  288
elf_bss = k; 289
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 294
if ( k > elf_brk )  295
elf_brk = k; 296
elf_brk += load_bias; 301
retval = set_brk ( elf_bss , elf_brk ); 312
if ( retval )  313
if ( likely ( elf_bss != elf_brk ) && unlikely ( padzero ( elf_bss ) ) )  317
if ( retval < 0 )  364
if ( retval < 0 )  374
return retval ; 421
------------------------------
234 /home/speedy/test/source2slice/NVD/CVE_2010_0307_PATCHED_load_elf_binary.c k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz 286
static int CVE_2010_0307_PATCHED_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned long load_addr = 0 , load_bias = 0 ; 4
int load_addr_set = 0 ; 5
char * elf_interpreter = NULL ; 6
unsigned long error ; 7
struct elf_phdr * elf_ppnt , * elf_phdata ; 8
unsigned long elf_bss , elf_brk ; 9
int retval , i ; 10
unsigned int size ; 11
int executable_stack = EXSTACK_DEFAULT ; 16
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
retval = - ENOEXEC; 32
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
retval = - ENOMEM; 51
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
elf_ppnt = elf_phdata; 64
elf_bss = 0; 65
elf_brk = 0; 66
for (i = 0; i < loc->elf_ex.e_phnum; i++) 73
if ( elf_ppnt -> p_type == PT_INTERP )  74
retval = - ENOEXEC; 79
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
retval = - ENOMEM; 84
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
retval = - ENOEXEC; 99
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 103
retval = PTR_ERR ( interpreter ); 104
if ( IS_ERR ( interpreter ) )  105
if ( file_permission ( interpreter , MAY_READ ) < 0 )  113
bprm -> interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP; 114
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 116
if ( retval != BINPRM_BUF_SIZE )  118
loc -> interp_elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 125
elf_ppnt ++; 128
elf_ppnt = elf_phdata; 131
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 132
if ( elf_ppnt -> p_type == PT_GNU_STACK )  133
if ( elf_ppnt -> p_flags & PF_X )  134
executable_stack = EXSTACK_ENABLE_X; 135
executable_stack = EXSTACK_DISABLE_X; 137
if ( elf_interpreter )  142
retval = - ELIBBAD; 143
if ( memcmp ( loc -> interp_elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  145
if ( ! elf_check_arch ( & loc -> interp_elf_ex ) )  148
retval = flush_old_exec ( bprm ); 153
if ( retval )  154
retval = setup_arg_pages ( bprm , randomize_stack_top ( STACK_TOP ) , executable_stack ); 176
if ( retval < 0 )  178
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 188
int elf_prot = 0 , elf_flags ; 189
unsigned long k , vaddr ; 190
if ( elf_ppnt -> p_type != PT_LOAD )  192
if ( unlikely ( elf_brk > elf_bss ) )  195
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 201
if ( retval )  203
nbyte = ELF_PAGEOFFSET ( elf_bss ); 207
if ( nbyte )  208
nbyte = ELF_MIN_ALIGN - nbyte; 209
if ( nbyte > elf_brk - elf_bss )  210
nbyte = elf_brk - elf_bss; 211
if ( clear_user ( ( void __user * ) elf_bss + load_bias , nbyte ) )  212
if ( elf_ppnt -> p_flags & PF_R )  223
elf_prot |= PROT_READ; 224
if ( elf_ppnt -> p_flags & PF_W )  225
elf_prot |= PROT_WRITE; 226
if ( elf_ppnt -> p_flags & PF_X )  227
elf_prot |= PROT_EXEC; 228
elf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE; 230
vaddr = elf_ppnt -> p_vaddr; 232
if ( loc -> elf_ex . e_type == ET_EXEC || load_addr_set )  233
elf_flags |= MAP_FIXED; 234
if ( loc -> elf_ex . e_type == ET_DYN )  235
load_bias = 0; 241
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 247
if ( BAD_ADDR ( error ) )  249
if ( ! load_addr_set )  256
load_addr_set = 1; 257
if ( loc -> elf_ex . e_type == ET_DYN )  259
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 260
k = elf_ppnt -> p_vaddr; 266
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  277
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 286
if ( k > elf_bss )  288
elf_bss = k; 289
if ( ( elf_ppnt -> p_flags & PF_X ) && end_code < k )  290
end_code = k; 291
if ( end_data < k )  292
end_data = k; 293
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 294
if ( k > elf_brk )  295
elf_brk = k; 296
elf_bss += load_bias; 300
elf_brk += load_bias; 301
end_code += load_bias; 303
end_data += load_bias; 305
retval = set_brk ( elf_bss , elf_brk ); 312
if ( retval )  313
if ( likely ( elf_bss != elf_brk ) && unlikely ( padzero ( elf_bss ) ) )  317
if ( retval < 0 )  364
if ( retval < 0 )  374
current -> mm -> end_code = end_code; 379
current -> mm -> start_code = start_code; 380
current -> mm -> start_data = start_data; 381
current -> mm -> end_data = end_data; 382
current -> mm -> start_stack = bprm -> p; 383
if ( ( current -> flags & PF_RANDOMIZE ) && ( randomize_va_space > 1 ) )  386
current -> mm -> brk = current -> mm -> start_brk = arch_randomize_brk ( current -> mm ); 387
if ( current -> personality & MMAP_PAGE_ZERO )  391
down_write ( & current -> mm -> mmap_sem ); 396
up_write ( & current -> mm -> mmap_sem ); 399
return retval ; 421
------------------------------
235 /home/speedy/test/source2slice/NVD/CVE_2010_0307_PATCHED_load_elf_binary.c load_addr = ( elf_ppnt -> p_vaddr - elf_ppnt -> p_offset ) 258
static int CVE_2010_0307_PATCHED_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned long load_addr = 0 , load_bias = 0 ; 4
int load_addr_set = 0 ; 5
char * elf_interpreter = NULL ; 6
unsigned long error ; 7
struct elf_phdr * elf_ppnt , * elf_phdata ; 8
unsigned long elf_bss , elf_brk ; 9
int retval , i ; 10
unsigned int size ; 11
int executable_stack = EXSTACK_DEFAULT ; 16
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
retval = - ENOEXEC; 32
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
retval = - ENOMEM; 51
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
elf_ppnt = elf_phdata; 64
elf_bss = 0; 65
elf_brk = 0; 66
for (i = 0; i < loc->elf_ex.e_phnum; i++) 73
if ( elf_ppnt -> p_type == PT_INTERP )  74
retval = - ENOEXEC; 79
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
retval = - ENOMEM; 84
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
retval = - ENOEXEC; 99
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 103
retval = PTR_ERR ( interpreter ); 104
if ( IS_ERR ( interpreter ) )  105
if ( file_permission ( interpreter , MAY_READ ) < 0 )  113
bprm -> interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP; 114
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 116
if ( retval != BINPRM_BUF_SIZE )  118
loc -> interp_elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 125
elf_ppnt ++; 128
elf_ppnt = elf_phdata; 131
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 132
if ( elf_ppnt -> p_type == PT_GNU_STACK )  133
if ( elf_ppnt -> p_flags & PF_X )  134
executable_stack = EXSTACK_ENABLE_X; 135
executable_stack = EXSTACK_DISABLE_X; 137
if ( elf_interpreter )  142
retval = - ELIBBAD; 143
if ( memcmp ( loc -> interp_elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  145
if ( ! elf_check_arch ( & loc -> interp_elf_ex ) )  148
retval = flush_old_exec ( bprm ); 153
if ( retval )  154
retval = setup_arg_pages ( bprm , randomize_stack_top ( STACK_TOP ) , executable_stack ); 176
if ( retval < 0 )  178
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 188
int elf_prot = 0 , elf_flags ; 189
unsigned long k , vaddr ; 190
if ( elf_ppnt -> p_type != PT_LOAD )  192
if ( unlikely ( elf_brk > elf_bss ) )  195
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 201
if ( retval )  203
if ( elf_ppnt -> p_flags & PF_R )  223
elf_prot |= PROT_READ; 224
if ( elf_ppnt -> p_flags & PF_W )  225
elf_prot |= PROT_WRITE; 226
if ( elf_ppnt -> p_flags & PF_X )  227
elf_prot |= PROT_EXEC; 228
elf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE; 230
vaddr = elf_ppnt -> p_vaddr; 232
if ( loc -> elf_ex . e_type == ET_EXEC || load_addr_set )  233
elf_flags |= MAP_FIXED; 234
if ( loc -> elf_ex . e_type == ET_DYN )  235
load_bias = 0; 241
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 247
if ( BAD_ADDR ( error ) )  249
if ( ! load_addr_set )  256
load_addr_set = 1; 257
load_addr = ( elf_ppnt -> p_vaddr - elf_ppnt -> p_offset ); 258
if ( loc -> elf_ex . e_type == ET_DYN )  259
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 260
load_addr += load_bias; 262
k = elf_ppnt -> p_vaddr; 266
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  277
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 286
if ( k > elf_bss )  288
elf_bss = k; 289
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 294
if ( k > elf_brk )  295
elf_brk = k; 296
retval = create_elf_tables ( bprm , & loc -> elf_ex , load_addr , interp_load_addr ); 372
if ( retval < 0 )  374
return retval ; 421
------------------------------
236 /home/speedy/test/source2slice/NVD/CVE_2010_0307_PATCHED_load_elf_binary.c error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ) 247
static int CVE_2010_0307_PATCHED_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned long load_addr = 0 , load_bias = 0 ; 4
int load_addr_set = 0 ; 5
char * elf_interpreter = NULL ; 6
unsigned long error ; 7
struct elf_phdr * elf_ppnt , * elf_phdata ; 8
unsigned long elf_bss , elf_brk ; 9
int retval , i ; 10
unsigned int size ; 11
int executable_stack = EXSTACK_DEFAULT ; 16
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
retval = - ENOEXEC; 32
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
retval = - ENOMEM; 51
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
elf_ppnt = elf_phdata; 64
elf_bss = 0; 65
elf_brk = 0; 66
for (i = 0; i < loc->elf_ex.e_phnum; i++) 73
if ( elf_ppnt -> p_type == PT_INTERP )  74
retval = - ENOEXEC; 79
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
retval = - ENOMEM; 84
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
retval = - ENOEXEC; 99
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 103
retval = PTR_ERR ( interpreter ); 104
if ( IS_ERR ( interpreter ) )  105
if ( file_permission ( interpreter , MAY_READ ) < 0 )  113
bprm -> interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP; 114
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 116
if ( retval != BINPRM_BUF_SIZE )  118
loc -> interp_elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 125
elf_ppnt ++; 128
elf_ppnt = elf_phdata; 131
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 132
if ( elf_ppnt -> p_type == PT_GNU_STACK )  133
if ( elf_ppnt -> p_flags & PF_X )  134
executable_stack = EXSTACK_ENABLE_X; 135
executable_stack = EXSTACK_DISABLE_X; 137
if ( elf_interpreter )  142
retval = - ELIBBAD; 143
if ( memcmp ( loc -> interp_elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  145
if ( ! elf_check_arch ( & loc -> interp_elf_ex ) )  148
retval = flush_old_exec ( bprm ); 153
if ( retval )  154
retval = setup_arg_pages ( bprm , randomize_stack_top ( STACK_TOP ) , executable_stack ); 176
if ( retval < 0 )  178
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 188
int elf_prot = 0 , elf_flags ; 189
unsigned long k , vaddr ; 190
if ( elf_ppnt -> p_type != PT_LOAD )  192
if ( unlikely ( elf_brk > elf_bss ) )  195
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 201
if ( retval )  203
if ( clear_user ( ( void __user * ) elf_bss + load_bias , nbyte ) )  212
if ( elf_ppnt -> p_flags & PF_R )  223
elf_prot |= PROT_READ; 224
if ( elf_ppnt -> p_flags & PF_W )  225
elf_prot |= PROT_WRITE; 226
if ( elf_ppnt -> p_flags & PF_X )  227
elf_prot |= PROT_EXEC; 228
elf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE; 230
vaddr = elf_ppnt -> p_vaddr; 232
if ( loc -> elf_ex . e_type == ET_EXEC || load_addr_set )  233
elf_flags |= MAP_FIXED; 234
if ( loc -> elf_ex . e_type == ET_DYN )  235
load_bias = 0; 241
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 247
if ( BAD_ADDR ( error ) )  249
retval = IS_ERR ( ( void * ) error ) ? PTR_ERR ( ( void * ) error ) : - EINVAL; 251
if ( ! load_addr_set )  256
load_addr_set = 1; 257
if ( loc -> elf_ex . e_type == ET_DYN )  259
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 260
load_addr += load_bias; 262
reloc_func_desc = load_bias; 263
k = elf_ppnt -> p_vaddr; 266
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  277
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 286
if ( k > elf_bss )  288
elf_bss = k; 289
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 294
if ( k > elf_brk )  295
elf_brk = k; 296
loc -> elf_ex . e_entry += load_bias; 299
elf_bss += load_bias; 300
elf_brk += load_bias; 301
start_code += load_bias; 302
end_code += load_bias; 303
start_data += load_bias; 304
end_data += load_bias; 305
retval = set_brk ( elf_bss , elf_brk ); 312
if ( retval )  313
if ( likely ( elf_bss != elf_brk ) && unlikely ( padzero ( elf_bss ) ) )  317
elf_entry = load_elf_interp ( & loc -> interp_elf_ex , interpreter , & interp_map_addr , load_bias ); 326
if ( ! IS_ERR ( ( void * ) elf_entry ) )  330
interp_load_addr = elf_entry; 335
elf_entry += loc -> interp_elf_ex . e_entry; 336
if ( BAD_ADDR ( elf_entry ) )  338
retval = IS_ERR ( ( void * ) elf_entry ) ? ( int ) elf_entry : - EINVAL; 340
reloc_func_desc = interp_load_addr; 344
elf_entry = loc -> elf_ex . e_entry; 350
if ( BAD_ADDR ( elf_entry ) )  351
if ( retval < 0 )  364
retval = create_elf_tables ( bprm , & loc -> elf_ex , load_addr , interp_load_addr ); 372
if ( retval < 0 )  374
current -> mm -> end_code = end_code; 379
current -> mm -> start_code = start_code; 380
current -> mm -> start_data = start_data; 381
current -> mm -> end_data = end_data; 382
current -> mm -> start_stack = bprm -> p; 383
if ( ( current -> flags & PF_RANDOMIZE ) && ( randomize_va_space > 1 ) )  386
current -> mm -> brk = current -> mm -> start_brk = arch_randomize_brk ( current -> mm ); 387
if ( current -> personality & MMAP_PAGE_ZERO )  391
down_write ( & current -> mm -> mmap_sem ); 396
up_write ( & current -> mm -> mmap_sem ); 399
ELF_PLAT_INIT ( regs , reloc_func_desc ); 413
start_thread ( regs , elf_entry , bprm -> p ); 416
kfree ( loc ); 419
return retval ; 421
------------------------------
237 /home/speedy/test/source2slice/NVD/CVE_2010_0307_PATCHED_load_elf_binary.c nbyte = elf_brk - elf_bss 211
static int CVE_2010_0307_PATCHED_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned long load_addr = 0 , load_bias = 0 ; 4
int load_addr_set = 0 ; 5
char * elf_interpreter = NULL ; 6
unsigned long error ; 7
struct elf_phdr * elf_ppnt , * elf_phdata ; 8
unsigned long elf_bss , elf_brk ; 9
int retval , i ; 10
unsigned int size ; 11
int executable_stack = EXSTACK_DEFAULT ; 16
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
retval = - ENOEXEC; 32
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
retval = - ENOMEM; 51
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
elf_ppnt = elf_phdata; 64
elf_bss = 0; 65
elf_brk = 0; 66
for (i = 0; i < loc->elf_ex.e_phnum; i++) 73
if ( elf_ppnt -> p_type == PT_INTERP )  74
retval = - ENOEXEC; 79
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
retval = - ENOMEM; 84
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
retval = - ENOEXEC; 99
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 103
retval = PTR_ERR ( interpreter ); 104
if ( IS_ERR ( interpreter ) )  105
if ( file_permission ( interpreter , MAY_READ ) < 0 )  113
bprm -> interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP; 114
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 116
if ( retval != BINPRM_BUF_SIZE )  118
loc -> interp_elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 125
elf_ppnt ++; 128
elf_ppnt = elf_phdata; 131
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 132
if ( elf_ppnt -> p_type == PT_GNU_STACK )  133
if ( elf_ppnt -> p_flags & PF_X )  134
executable_stack = EXSTACK_ENABLE_X; 135
executable_stack = EXSTACK_DISABLE_X; 137
if ( elf_interpreter )  142
retval = - ELIBBAD; 143
if ( memcmp ( loc -> interp_elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  145
if ( ! elf_check_arch ( & loc -> interp_elf_ex ) )  148
retval = flush_old_exec ( bprm ); 153
if ( retval )  154
retval = setup_arg_pages ( bprm , randomize_stack_top ( STACK_TOP ) , executable_stack ); 176
if ( retval < 0 )  178
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 188
int elf_prot = 0 , elf_flags ; 189
unsigned long k , vaddr ; 190
if ( elf_ppnt -> p_type != PT_LOAD )  192
if ( unlikely ( elf_brk > elf_bss ) )  195
unsigned long nbyte ; 196
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 201
if ( retval )  203
nbyte = ELF_PAGEOFFSET ( elf_bss ); 207
if ( nbyte )  208
nbyte = ELF_MIN_ALIGN - nbyte; 209
if ( nbyte > elf_brk - elf_bss )  210
nbyte = elf_brk - elf_bss; 211
if ( clear_user ( ( void __user * ) elf_bss + load_bias , nbyte ) )  212
if ( elf_ppnt -> p_flags & PF_R )  223
elf_prot |= PROT_READ; 224
if ( elf_ppnt -> p_flags & PF_W )  225
elf_prot |= PROT_WRITE; 226
if ( elf_ppnt -> p_flags & PF_X )  227
elf_prot |= PROT_EXEC; 228
elf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE; 230
vaddr = elf_ppnt -> p_vaddr; 232
if ( loc -> elf_ex . e_type == ET_EXEC || load_addr_set )  233
elf_flags |= MAP_FIXED; 234
if ( loc -> elf_ex . e_type == ET_DYN )  235
load_bias = 0; 241
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 247
if ( BAD_ADDR ( error ) )  249
if ( ! load_addr_set )  256
load_addr_set = 1; 257
if ( loc -> elf_ex . e_type == ET_DYN )  259
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 260
k = elf_ppnt -> p_vaddr; 266
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  277
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 286
if ( k > elf_bss )  288
elf_bss = k; 289
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 294
if ( k > elf_brk )  295
elf_brk = k; 296
------------------------------
238 /home/speedy/test/source2slice/NVD/CVE_2010_0307_PATCHED_load_elf_binary.c nbyte = ELF_MIN_ALIGN - nbyte 209
static int CVE_2010_0307_PATCHED_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned long load_addr = 0 , load_bias = 0 ; 4
int load_addr_set = 0 ; 5
char * elf_interpreter = NULL ; 6
unsigned long error ; 7
struct elf_phdr * elf_ppnt , * elf_phdata ; 8
unsigned long elf_bss , elf_brk ; 9
int retval , i ; 10
unsigned int size ; 11
int executable_stack = EXSTACK_DEFAULT ; 16
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
retval = - ENOEXEC; 32
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
retval = - ENOMEM; 51
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
elf_ppnt = elf_phdata; 64
elf_bss = 0; 65
elf_brk = 0; 66
for (i = 0; i < loc->elf_ex.e_phnum; i++) 73
if ( elf_ppnt -> p_type == PT_INTERP )  74
retval = - ENOEXEC; 79
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
retval = - ENOMEM; 84
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
retval = - ENOEXEC; 99
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 103
retval = PTR_ERR ( interpreter ); 104
if ( IS_ERR ( interpreter ) )  105
if ( file_permission ( interpreter , MAY_READ ) < 0 )  113
bprm -> interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP; 114
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 116
if ( retval != BINPRM_BUF_SIZE )  118
loc -> interp_elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 125
elf_ppnt ++; 128
elf_ppnt = elf_phdata; 131
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 132
if ( elf_ppnt -> p_type == PT_GNU_STACK )  133
if ( elf_ppnt -> p_flags & PF_X )  134
executable_stack = EXSTACK_ENABLE_X; 135
executable_stack = EXSTACK_DISABLE_X; 137
if ( elf_interpreter )  142
retval = - ELIBBAD; 143
if ( memcmp ( loc -> interp_elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  145
if ( ! elf_check_arch ( & loc -> interp_elf_ex ) )  148
retval = flush_old_exec ( bprm ); 153
if ( retval )  154
retval = setup_arg_pages ( bprm , randomize_stack_top ( STACK_TOP ) , executable_stack ); 176
if ( retval < 0 )  178
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 188
int elf_prot = 0 , elf_flags ; 189
unsigned long k , vaddr ; 190
if ( elf_ppnt -> p_type != PT_LOAD )  192
if ( unlikely ( elf_brk > elf_bss ) )  195
unsigned long nbyte ; 196
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 201
if ( retval )  203
nbyte = ELF_PAGEOFFSET ( elf_bss ); 207
if ( nbyte )  208
nbyte = ELF_MIN_ALIGN - nbyte; 209
if ( nbyte > elf_brk - elf_bss )  210
if ( clear_user ( ( void __user * ) elf_bss + load_bias , nbyte ) )  212
if ( elf_ppnt -> p_flags & PF_R )  223
elf_prot |= PROT_READ; 224
if ( elf_ppnt -> p_flags & PF_W )  225
elf_prot |= PROT_WRITE; 226
if ( elf_ppnt -> p_flags & PF_X )  227
elf_prot |= PROT_EXEC; 228
elf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE; 230
vaddr = elf_ppnt -> p_vaddr; 232
if ( loc -> elf_ex . e_type == ET_EXEC || load_addr_set )  233
elf_flags |= MAP_FIXED; 234
if ( loc -> elf_ex . e_type == ET_DYN )  235
load_bias = 0; 241
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 247
if ( BAD_ADDR ( error ) )  249
if ( ! load_addr_set )  256
load_addr_set = 1; 257
if ( loc -> elf_ex . e_type == ET_DYN )  259
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 260
k = elf_ppnt -> p_vaddr; 266
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  277
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 286
if ( k > elf_bss )  288
elf_bss = k; 289
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 294
if ( k > elf_brk )  295
elf_brk = k; 296
------------------------------
239 /home/speedy/test/source2slice/NVD/CVE_2010_0307_PATCHED_load_elf_binary.c retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ) 201
static int CVE_2010_0307_PATCHED_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned long load_addr = 0 , load_bias = 0 ; 4
int load_addr_set = 0 ; 5
char * elf_interpreter = NULL ; 6
unsigned long error ; 7
struct elf_phdr * elf_ppnt , * elf_phdata ; 8
unsigned long elf_bss , elf_brk ; 9
int retval , i ; 10
unsigned int size ; 11
int executable_stack = EXSTACK_DEFAULT ; 16
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
retval = - ENOEXEC; 32
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
retval = - ENOMEM; 51
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
elf_ppnt = elf_phdata; 64
elf_bss = 0; 65
elf_brk = 0; 66
for (i = 0; i < loc->elf_ex.e_phnum; i++) 73
if ( elf_ppnt -> p_type == PT_INTERP )  74
retval = - ENOEXEC; 79
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
retval = - ENOMEM; 84
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
retval = - ENOEXEC; 99
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 103
retval = PTR_ERR ( interpreter ); 104
if ( IS_ERR ( interpreter ) )  105
if ( file_permission ( interpreter , MAY_READ ) < 0 )  113
bprm -> interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP; 114
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 116
if ( retval != BINPRM_BUF_SIZE )  118
loc -> interp_elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 125
elf_ppnt ++; 128
elf_ppnt = elf_phdata; 131
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 132
if ( elf_ppnt -> p_type == PT_GNU_STACK )  133
if ( elf_ppnt -> p_flags & PF_X )  134
executable_stack = EXSTACK_ENABLE_X; 135
executable_stack = EXSTACK_DISABLE_X; 137
if ( elf_interpreter )  142
retval = - ELIBBAD; 143
if ( memcmp ( loc -> interp_elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  145
if ( ! elf_check_arch ( & loc -> interp_elf_ex ) )  148
retval = flush_old_exec ( bprm ); 153
if ( retval )  154
retval = setup_arg_pages ( bprm , randomize_stack_top ( STACK_TOP ) , executable_stack ); 176
if ( retval < 0 )  178
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 188
int elf_prot = 0 , elf_flags ; 189
unsigned long k , vaddr ; 190
if ( elf_ppnt -> p_type != PT_LOAD )  192
if ( unlikely ( elf_brk > elf_bss ) )  195
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 201
if ( retval )  203
if ( elf_ppnt -> p_flags & PF_R )  223
elf_prot |= PROT_READ; 224
if ( elf_ppnt -> p_flags & PF_W )  225
elf_prot |= PROT_WRITE; 226
if ( elf_ppnt -> p_flags & PF_X )  227
elf_prot |= PROT_EXEC; 228
elf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE; 230
vaddr = elf_ppnt -> p_vaddr; 232
if ( loc -> elf_ex . e_type == ET_EXEC || load_addr_set )  233
elf_flags |= MAP_FIXED; 234
if ( loc -> elf_ex . e_type == ET_DYN )  235
load_bias = 0; 241
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 247
if ( BAD_ADDR ( error ) )  249
if ( ! load_addr_set )  256
load_addr_set = 1; 257
if ( loc -> elf_ex . e_type == ET_DYN )  259
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 260
k = elf_ppnt -> p_vaddr; 266
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  277
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 286
if ( k > elf_bss )  288
elf_bss = k; 289
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 294
if ( k > elf_brk )  295
elf_brk = k; 296
if ( retval )  313
if ( retval < 0 )  364
if ( retval < 0 )  374
return retval ; 421
------------------------------
240 /home/speedy/test/source2slice/NVD/CVE_2010_0307_PATCHED_load_elf_binary.c size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ) 50
static int CVE_2010_0307_PATCHED_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned int size ; 11
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
if ( retval >= 0 )  59
elf_ppnt = elf_phdata; 64
if ( elf_ppnt -> p_type == PT_INTERP )  74
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
if ( retval >= 0 )  94
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 103
retval = PTR_ERR ( interpreter ); 104
if ( IS_ERR ( interpreter ) )  105
if ( file_permission ( interpreter , MAY_READ ) < 0 )  113
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 116
if ( retval != BINPRM_BUF_SIZE )  118
if ( retval >= 0 )  119
elf_ppnt ++; 128
elf_ppnt = elf_phdata; 131
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 132
if ( elf_ppnt -> p_type == PT_GNU_STACK )  133
if ( elf_ppnt -> p_flags & PF_X )  134
if ( elf_interpreter )  142
if ( retval )  154
if ( retval < 0 )  178
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 188
if ( elf_ppnt -> p_type != PT_LOAD )  192
if ( unlikely ( elf_brk > elf_bss ) )  195
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 201
if ( retval )  203
nbyte = ELF_PAGEOFFSET ( elf_bss ); 207
if ( nbyte )  208
nbyte = ELF_MIN_ALIGN - nbyte; 209
if ( nbyte > elf_brk - elf_bss )  210
nbyte = elf_brk - elf_bss; 211
if ( clear_user ( ( void __user * ) elf_bss + load_bias , nbyte ) )  212
if ( elf_ppnt -> p_flags & PF_R )  223
if ( elf_ppnt -> p_flags & PF_W )  225
if ( elf_ppnt -> p_flags & PF_X )  227
vaddr = elf_ppnt -> p_vaddr; 232
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 247
if ( BAD_ADDR ( error ) )  249
retval = IS_ERR ( ( void * ) error ) ? PTR_ERR ( ( void * ) error ) : - EINVAL; 251
load_addr = ( elf_ppnt -> p_vaddr - elf_ppnt -> p_offset ); 258
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 260
load_addr += load_bias; 262
reloc_func_desc = load_bias; 263
k = elf_ppnt -> p_vaddr; 266
if ( k < start_code )  267
start_code = k; 268
if ( start_data < k )  269
start_data = k; 270
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  277
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 286
if ( k > elf_bss )  288
elf_bss = k; 289
if ( ( elf_ppnt -> p_flags & PF_X ) && end_code < k )  290
end_code = k; 291
if ( end_data < k )  292
end_data = k; 293
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 294
if ( k > elf_brk )  295
elf_brk = k; 296
loc -> elf_ex . e_entry += load_bias; 299
elf_bss += load_bias; 300
elf_brk += load_bias; 301
start_code += load_bias; 302
end_code += load_bias; 303
start_data += load_bias; 304
end_data += load_bias; 305
retval = set_brk ( elf_bss , elf_brk ); 312
if ( retval )  313
if ( likely ( elf_bss != elf_brk ) && unlikely ( padzero ( elf_bss ) ) )  317
if ( elf_interpreter )  323
elf_entry = load_elf_interp ( & loc -> interp_elf_ex , interpreter , & interp_map_addr , load_bias ); 326
if ( ! IS_ERR ( ( void * ) elf_entry ) )  330
interp_load_addr = elf_entry; 335
elf_entry += loc -> interp_elf_ex . e_entry; 336
if ( BAD_ADDR ( elf_entry ) )  338
retval = IS_ERR ( ( void * ) elf_entry ) ? ( int ) elf_entry : - EINVAL; 340
reloc_func_desc = interp_load_addr; 344
allow_write_access ( interpreter ); 346
fput ( interpreter ); 347
kfree ( elf_interpreter ); 348
elf_entry = loc -> elf_ex . e_entry; 350
if ( BAD_ADDR ( elf_entry ) )  351
kfree ( elf_phdata ); 358
retval = arch_setup_additional_pages ( bprm , ! ! elf_interpreter ); 363
if ( retval < 0 )  364
retval = create_elf_tables ( bprm , & loc -> elf_ex , load_addr , interp_load_addr ); 372
if ( retval < 0 )  374
current -> mm -> end_code = end_code; 379
current -> mm -> start_code = start_code; 380
current -> mm -> start_data = start_data; 381
current -> mm -> end_data = end_data; 382
current -> mm -> start_stack = bprm -> p; 383
if ( ( current -> flags & PF_RANDOMIZE ) && ( randomize_va_space > 1 ) )  386
current -> mm -> brk = current -> mm -> start_brk = arch_randomize_brk ( current -> mm ); 387
if ( current -> personality & MMAP_PAGE_ZERO )  391
down_write ( & current -> mm -> mmap_sem ); 396
up_write ( & current -> mm -> mmap_sem ); 399
ELF_PLAT_INIT ( regs , reloc_func_desc ); 413
start_thread ( regs , elf_entry , bprm -> p ); 416
kfree ( loc ); 419
return retval ; 421
allow_write_access ( interpreter ); 425
if ( interpreter )  426
fput ( interpreter ); 427
kfree ( elf_interpreter ); 429
kfree ( elf_phdata ); 431
------------------------------
241 /home/speedy/test/source2slice/NVD/CVE_2010_0307_VULN_load_elf_binary.c k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz 317
static int CVE_2010_0307_VULN_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned long load_addr = 0 , load_bias = 0 ; 4
int load_addr_set = 0 ; 5
char * elf_interpreter = NULL ; 6
unsigned long error ; 7
struct elf_phdr * elf_ppnt , * elf_phdata ; 8
unsigned long elf_bss , elf_brk ; 9
int retval , i ; 10
unsigned int size ; 11
int executable_stack = EXSTACK_DEFAULT ; 16
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
retval = - ENOEXEC; 32
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
retval = - ENOMEM; 51
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
elf_ppnt = elf_phdata; 64
elf_bss = 0; 65
elf_brk = 0; 66
for (i = 0; i < loc->elf_ex.e_phnum; i++) 73
if ( elf_ppnt -> p_type == PT_INTERP )  74
retval = - ENOEXEC; 79
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
retval = - ENOMEM; 84
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
retval = - ENOEXEC; 99
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 124
retval = PTR_ERR ( interpreter ); 125
if ( IS_ERR ( interpreter ) )  126
if ( file_permission ( interpreter , MAY_READ ) < 0 )  134
bprm -> interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP; 135
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 137
if ( retval != BINPRM_BUF_SIZE )  139
loc -> interp_elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 146
elf_ppnt ++; 149
elf_ppnt = elf_phdata; 152
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 153
if ( elf_ppnt -> p_type == PT_GNU_STACK )  154
if ( elf_ppnt -> p_flags & PF_X )  155
executable_stack = EXSTACK_ENABLE_X; 156
executable_stack = EXSTACK_DISABLE_X; 158
if ( elf_interpreter )  163
retval = - ELIBBAD; 164
if ( memcmp ( loc -> interp_elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  166
if ( ! elf_check_arch ( & loc -> interp_elf_ex ) )  169
retval = flush_old_exec ( bprm ); 177
if ( retval )  178
retval = setup_arg_pages ( bprm , randomize_stack_top ( STACK_TOP ) , executable_stack ); 199
if ( retval < 0 )  201
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 211
int elf_prot = 0 , elf_flags ; 212
unsigned long k , vaddr ; 213
if ( elf_ppnt -> p_type != PT_LOAD )  215
if ( unlikely ( elf_brk > elf_bss ) )  218
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 224
if ( retval )  226
if ( nbyte > elf_brk - elf_bss )  233
nbyte = elf_brk - elf_bss; 234
if ( clear_user ( ( void __user * ) elf_bss + load_bias , nbyte ) )  235
if ( elf_ppnt -> p_flags & PF_R )  246
elf_prot |= PROT_READ; 247
if ( elf_ppnt -> p_flags & PF_W )  248
elf_prot |= PROT_WRITE; 249
if ( elf_ppnt -> p_flags & PF_X )  250
elf_prot |= PROT_EXEC; 251
elf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE; 253
vaddr = elf_ppnt -> p_vaddr; 255
if ( loc -> elf_ex . e_type == ET_EXEC || load_addr_set )  256
elf_flags |= MAP_FIXED; 257
if ( loc -> elf_ex . e_type == ET_DYN )  258
load_bias = 0; 264
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 270
if ( BAD_ADDR ( error ) )  272
if ( ! load_addr_set )  279
load_addr_set = 1; 280
if ( loc -> elf_ex . e_type == ET_DYN )  282
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 283
k = elf_ppnt -> p_vaddr; 289
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  300
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 309
if ( k > elf_bss )  311
elf_bss = k; 312
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 317
if ( k > elf_brk )  318
elf_brk = k; 319
elf_brk += load_bias; 324
retval = set_brk ( elf_bss , elf_brk ); 335
if ( retval )  336
if ( likely ( elf_bss != elf_brk ) && unlikely ( padzero ( elf_bss ) ) )  340
if ( retval < 0 )  387
if ( retval < 0 )  397
return retval ; 444
------------------------------
242 /home/speedy/test/source2slice/NVD/CVE_2010_0307_VULN_load_elf_binary.c k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz 309
static int CVE_2010_0307_VULN_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned long load_addr = 0 , load_bias = 0 ; 4
int load_addr_set = 0 ; 5
char * elf_interpreter = NULL ; 6
unsigned long error ; 7
struct elf_phdr * elf_ppnt , * elf_phdata ; 8
unsigned long elf_bss , elf_brk ; 9
int retval , i ; 10
unsigned int size ; 11
int executable_stack = EXSTACK_DEFAULT ; 16
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
retval = - ENOEXEC; 32
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
retval = - ENOMEM; 51
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
elf_ppnt = elf_phdata; 64
elf_bss = 0; 65
elf_brk = 0; 66
for (i = 0; i < loc->elf_ex.e_phnum; i++) 73
if ( elf_ppnt -> p_type == PT_INTERP )  74
retval = - ENOEXEC; 79
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
retval = - ENOMEM; 84
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
retval = - ENOEXEC; 99
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 124
retval = PTR_ERR ( interpreter ); 125
if ( IS_ERR ( interpreter ) )  126
if ( file_permission ( interpreter , MAY_READ ) < 0 )  134
bprm -> interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP; 135
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 137
if ( retval != BINPRM_BUF_SIZE )  139
loc -> interp_elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 146
elf_ppnt ++; 149
elf_ppnt = elf_phdata; 152
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 153
if ( elf_ppnt -> p_type == PT_GNU_STACK )  154
if ( elf_ppnt -> p_flags & PF_X )  155
executable_stack = EXSTACK_ENABLE_X; 156
executable_stack = EXSTACK_DISABLE_X; 158
if ( elf_interpreter )  163
retval = - ELIBBAD; 164
if ( memcmp ( loc -> interp_elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  166
if ( ! elf_check_arch ( & loc -> interp_elf_ex ) )  169
retval = flush_old_exec ( bprm ); 177
if ( retval )  178
retval = setup_arg_pages ( bprm , randomize_stack_top ( STACK_TOP ) , executable_stack ); 199
if ( retval < 0 )  201
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 211
int elf_prot = 0 , elf_flags ; 212
unsigned long k , vaddr ; 213
if ( elf_ppnt -> p_type != PT_LOAD )  215
if ( unlikely ( elf_brk > elf_bss ) )  218
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 224
if ( retval )  226
nbyte = ELF_PAGEOFFSET ( elf_bss ); 230
if ( nbyte )  231
nbyte = ELF_MIN_ALIGN - nbyte; 232
if ( nbyte > elf_brk - elf_bss )  233
nbyte = elf_brk - elf_bss; 234
if ( clear_user ( ( void __user * ) elf_bss + load_bias , nbyte ) )  235
if ( elf_ppnt -> p_flags & PF_R )  246
elf_prot |= PROT_READ; 247
if ( elf_ppnt -> p_flags & PF_W )  248
elf_prot |= PROT_WRITE; 249
if ( elf_ppnt -> p_flags & PF_X )  250
elf_prot |= PROT_EXEC; 251
elf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE; 253
vaddr = elf_ppnt -> p_vaddr; 255
if ( loc -> elf_ex . e_type == ET_EXEC || load_addr_set )  256
elf_flags |= MAP_FIXED; 257
if ( loc -> elf_ex . e_type == ET_DYN )  258
load_bias = 0; 264
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 270
if ( BAD_ADDR ( error ) )  272
if ( ! load_addr_set )  279
load_addr_set = 1; 280
if ( loc -> elf_ex . e_type == ET_DYN )  282
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 283
k = elf_ppnt -> p_vaddr; 289
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  300
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 309
if ( k > elf_bss )  311
elf_bss = k; 312
if ( ( elf_ppnt -> p_flags & PF_X ) && end_code < k )  313
end_code = k; 314
if ( end_data < k )  315
end_data = k; 316
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 317
if ( k > elf_brk )  318
elf_brk = k; 319
elf_bss += load_bias; 323
elf_brk += load_bias; 324
end_code += load_bias; 326
end_data += load_bias; 328
retval = set_brk ( elf_bss , elf_brk ); 335
if ( retval )  336
if ( likely ( elf_bss != elf_brk ) && unlikely ( padzero ( elf_bss ) ) )  340
if ( retval < 0 )  387
if ( retval < 0 )  397
current -> mm -> end_code = end_code; 402
current -> mm -> start_code = start_code; 403
current -> mm -> start_data = start_data; 404
current -> mm -> end_data = end_data; 405
current -> mm -> start_stack = bprm -> p; 406
if ( ( current -> flags & PF_RANDOMIZE ) && ( randomize_va_space > 1 ) )  409
current -> mm -> brk = current -> mm -> start_brk = arch_randomize_brk ( current -> mm ); 410
if ( current -> personality & MMAP_PAGE_ZERO )  414
down_write ( & current -> mm -> mmap_sem ); 419
up_write ( & current -> mm -> mmap_sem ); 422
return retval ; 444
------------------------------
243 /home/speedy/test/source2slice/NVD/CVE_2010_0307_VULN_load_elf_binary.c load_addr = ( elf_ppnt -> p_vaddr - elf_ppnt -> p_offset ) 281
static int CVE_2010_0307_VULN_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned long load_addr = 0 , load_bias = 0 ; 4
int load_addr_set = 0 ; 5
char * elf_interpreter = NULL ; 6
unsigned long error ; 7
struct elf_phdr * elf_ppnt , * elf_phdata ; 8
unsigned long elf_bss , elf_brk ; 9
int retval , i ; 10
unsigned int size ; 11
int executable_stack = EXSTACK_DEFAULT ; 16
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
retval = - ENOEXEC; 32
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
retval = - ENOMEM; 51
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
elf_ppnt = elf_phdata; 64
elf_bss = 0; 65
elf_brk = 0; 66
for (i = 0; i < loc->elf_ex.e_phnum; i++) 73
if ( elf_ppnt -> p_type == PT_INTERP )  74
retval = - ENOEXEC; 79
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
retval = - ENOMEM; 84
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
retval = - ENOEXEC; 99
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 124
retval = PTR_ERR ( interpreter ); 125
if ( IS_ERR ( interpreter ) )  126
if ( file_permission ( interpreter , MAY_READ ) < 0 )  134
bprm -> interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP; 135
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 137
if ( retval != BINPRM_BUF_SIZE )  139
loc -> interp_elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 146
elf_ppnt ++; 149
elf_ppnt = elf_phdata; 152
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 153
if ( elf_ppnt -> p_type == PT_GNU_STACK )  154
if ( elf_ppnt -> p_flags & PF_X )  155
executable_stack = EXSTACK_ENABLE_X; 156
executable_stack = EXSTACK_DISABLE_X; 158
if ( elf_interpreter )  163
retval = - ELIBBAD; 164
if ( memcmp ( loc -> interp_elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  166
if ( ! elf_check_arch ( & loc -> interp_elf_ex ) )  169
retval = flush_old_exec ( bprm ); 177
if ( retval )  178
retval = setup_arg_pages ( bprm , randomize_stack_top ( STACK_TOP ) , executable_stack ); 199
if ( retval < 0 )  201
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 211
int elf_prot = 0 , elf_flags ; 212
unsigned long k , vaddr ; 213
if ( elf_ppnt -> p_type != PT_LOAD )  215
if ( unlikely ( elf_brk > elf_bss ) )  218
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 224
if ( retval )  226
if ( elf_ppnt -> p_flags & PF_R )  246
elf_prot |= PROT_READ; 247
if ( elf_ppnt -> p_flags & PF_W )  248
elf_prot |= PROT_WRITE; 249
if ( elf_ppnt -> p_flags & PF_X )  250
elf_prot |= PROT_EXEC; 251
elf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE; 253
vaddr = elf_ppnt -> p_vaddr; 255
if ( loc -> elf_ex . e_type == ET_EXEC || load_addr_set )  256
elf_flags |= MAP_FIXED; 257
if ( loc -> elf_ex . e_type == ET_DYN )  258
load_bias = 0; 264
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 270
if ( BAD_ADDR ( error ) )  272
if ( ! load_addr_set )  279
load_addr_set = 1; 280
load_addr = ( elf_ppnt -> p_vaddr - elf_ppnt -> p_offset ); 281
if ( loc -> elf_ex . e_type == ET_DYN )  282
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 283
load_addr += load_bias; 285
k = elf_ppnt -> p_vaddr; 289
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  300
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 309
if ( k > elf_bss )  311
elf_bss = k; 312
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 317
if ( k > elf_brk )  318
elf_brk = k; 319
retval = create_elf_tables ( bprm , & loc -> elf_ex , load_addr , interp_load_addr ); 395
if ( retval < 0 )  397
return retval ; 444
------------------------------
244 /home/speedy/test/source2slice/NVD/CVE_2010_0307_VULN_load_elf_binary.c error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ) 270
static int CVE_2010_0307_VULN_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned long load_addr = 0 , load_bias = 0 ; 4
int load_addr_set = 0 ; 5
char * elf_interpreter = NULL ; 6
unsigned long error ; 7
struct elf_phdr * elf_ppnt , * elf_phdata ; 8
unsigned long elf_bss , elf_brk ; 9
int retval , i ; 10
unsigned int size ; 11
int executable_stack = EXSTACK_DEFAULT ; 16
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
retval = - ENOEXEC; 32
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
retval = - ENOMEM; 51
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
elf_ppnt = elf_phdata; 64
elf_bss = 0; 65
elf_brk = 0; 66
for (i = 0; i < loc->elf_ex.e_phnum; i++) 73
if ( elf_ppnt -> p_type == PT_INTERP )  74
retval = - ENOEXEC; 79
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
retval = - ENOMEM; 84
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
retval = - ENOEXEC; 99
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 124
retval = PTR_ERR ( interpreter ); 125
if ( IS_ERR ( interpreter ) )  126
if ( file_permission ( interpreter , MAY_READ ) < 0 )  134
bprm -> interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP; 135
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 137
if ( retval != BINPRM_BUF_SIZE )  139
loc -> interp_elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 146
elf_ppnt ++; 149
elf_ppnt = elf_phdata; 152
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 153
if ( elf_ppnt -> p_type == PT_GNU_STACK )  154
if ( elf_ppnt -> p_flags & PF_X )  155
executable_stack = EXSTACK_ENABLE_X; 156
executable_stack = EXSTACK_DISABLE_X; 158
if ( elf_interpreter )  163
retval = - ELIBBAD; 164
if ( memcmp ( loc -> interp_elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  166
if ( ! elf_check_arch ( & loc -> interp_elf_ex ) )  169
retval = flush_old_exec ( bprm ); 177
if ( retval )  178
retval = setup_arg_pages ( bprm , randomize_stack_top ( STACK_TOP ) , executable_stack ); 199
if ( retval < 0 )  201
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 211
int elf_prot = 0 , elf_flags ; 212
unsigned long k , vaddr ; 213
if ( elf_ppnt -> p_type != PT_LOAD )  215
if ( unlikely ( elf_brk > elf_bss ) )  218
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 224
if ( retval )  226
if ( clear_user ( ( void __user * ) elf_bss + load_bias , nbyte ) )  235
if ( elf_ppnt -> p_flags & PF_R )  246
elf_prot |= PROT_READ; 247
if ( elf_ppnt -> p_flags & PF_W )  248
elf_prot |= PROT_WRITE; 249
if ( elf_ppnt -> p_flags & PF_X )  250
elf_prot |= PROT_EXEC; 251
elf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE; 253
vaddr = elf_ppnt -> p_vaddr; 255
if ( loc -> elf_ex . e_type == ET_EXEC || load_addr_set )  256
elf_flags |= MAP_FIXED; 257
if ( loc -> elf_ex . e_type == ET_DYN )  258
load_bias = 0; 264
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 270
if ( BAD_ADDR ( error ) )  272
retval = IS_ERR ( ( void * ) error ) ? PTR_ERR ( ( void * ) error ) : - EINVAL; 274
if ( ! load_addr_set )  279
load_addr_set = 1; 280
if ( loc -> elf_ex . e_type == ET_DYN )  282
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 283
load_addr += load_bias; 285
reloc_func_desc = load_bias; 286
k = elf_ppnt -> p_vaddr; 289
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  300
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 309
if ( k > elf_bss )  311
elf_bss = k; 312
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 317
if ( k > elf_brk )  318
elf_brk = k; 319
loc -> elf_ex . e_entry += load_bias; 322
elf_bss += load_bias; 323
elf_brk += load_bias; 324
start_code += load_bias; 325
end_code += load_bias; 326
start_data += load_bias; 327
end_data += load_bias; 328
retval = set_brk ( elf_bss , elf_brk ); 335
if ( retval )  336
if ( likely ( elf_bss != elf_brk ) && unlikely ( padzero ( elf_bss ) ) )  340
elf_entry = load_elf_interp ( & loc -> interp_elf_ex , interpreter , & interp_map_addr , load_bias ); 349
if ( ! IS_ERR ( ( void * ) elf_entry ) )  353
interp_load_addr = elf_entry; 358
elf_entry += loc -> interp_elf_ex . e_entry; 359
if ( BAD_ADDR ( elf_entry ) )  361
retval = IS_ERR ( ( void * ) elf_entry ) ? ( int ) elf_entry : - EINVAL; 363
reloc_func_desc = interp_load_addr; 367
elf_entry = loc -> elf_ex . e_entry; 373
if ( BAD_ADDR ( elf_entry ) )  374
if ( retval < 0 )  387
retval = create_elf_tables ( bprm , & loc -> elf_ex , load_addr , interp_load_addr ); 395
if ( retval < 0 )  397
current -> mm -> end_code = end_code; 402
current -> mm -> start_code = start_code; 403
current -> mm -> start_data = start_data; 404
current -> mm -> end_data = end_data; 405
current -> mm -> start_stack = bprm -> p; 406
if ( ( current -> flags & PF_RANDOMIZE ) && ( randomize_va_space > 1 ) )  409
current -> mm -> brk = current -> mm -> start_brk = arch_randomize_brk ( current -> mm ); 410
if ( current -> personality & MMAP_PAGE_ZERO )  414
down_write ( & current -> mm -> mmap_sem ); 419
up_write ( & current -> mm -> mmap_sem ); 422
ELF_PLAT_INIT ( regs , reloc_func_desc ); 436
start_thread ( regs , elf_entry , bprm -> p ); 439
kfree ( loc ); 442
return retval ; 444
------------------------------
245 /home/speedy/test/source2slice/NVD/CVE_2010_0307_VULN_load_elf_binary.c nbyte = elf_brk - elf_bss 234
static int CVE_2010_0307_VULN_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned long load_addr = 0 , load_bias = 0 ; 4
int load_addr_set = 0 ; 5
char * elf_interpreter = NULL ; 6
unsigned long error ; 7
struct elf_phdr * elf_ppnt , * elf_phdata ; 8
unsigned long elf_bss , elf_brk ; 9
int retval , i ; 10
unsigned int size ; 11
int executable_stack = EXSTACK_DEFAULT ; 16
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
retval = - ENOEXEC; 32
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
retval = - ENOMEM; 51
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
elf_ppnt = elf_phdata; 64
elf_bss = 0; 65
elf_brk = 0; 66
for (i = 0; i < loc->elf_ex.e_phnum; i++) 73
if ( elf_ppnt -> p_type == PT_INTERP )  74
retval = - ENOEXEC; 79
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
retval = - ENOMEM; 84
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
retval = - ENOEXEC; 99
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 124
retval = PTR_ERR ( interpreter ); 125
if ( IS_ERR ( interpreter ) )  126
if ( file_permission ( interpreter , MAY_READ ) < 0 )  134
bprm -> interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP; 135
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 137
if ( retval != BINPRM_BUF_SIZE )  139
loc -> interp_elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 146
elf_ppnt ++; 149
elf_ppnt = elf_phdata; 152
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 153
if ( elf_ppnt -> p_type == PT_GNU_STACK )  154
if ( elf_ppnt -> p_flags & PF_X )  155
executable_stack = EXSTACK_ENABLE_X; 156
executable_stack = EXSTACK_DISABLE_X; 158
if ( elf_interpreter )  163
retval = - ELIBBAD; 164
if ( memcmp ( loc -> interp_elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  166
if ( ! elf_check_arch ( & loc -> interp_elf_ex ) )  169
retval = flush_old_exec ( bprm ); 177
if ( retval )  178
retval = setup_arg_pages ( bprm , randomize_stack_top ( STACK_TOP ) , executable_stack ); 199
if ( retval < 0 )  201
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 211
int elf_prot = 0 , elf_flags ; 212
unsigned long k , vaddr ; 213
if ( elf_ppnt -> p_type != PT_LOAD )  215
if ( unlikely ( elf_brk > elf_bss ) )  218
unsigned long nbyte ; 219
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 224
if ( retval )  226
nbyte = ELF_PAGEOFFSET ( elf_bss ); 230
if ( nbyte )  231
nbyte = ELF_MIN_ALIGN - nbyte; 232
if ( nbyte > elf_brk - elf_bss )  233
nbyte = elf_brk - elf_bss; 234
if ( clear_user ( ( void __user * ) elf_bss + load_bias , nbyte ) )  235
if ( elf_ppnt -> p_flags & PF_R )  246
elf_prot |= PROT_READ; 247
if ( elf_ppnt -> p_flags & PF_W )  248
elf_prot |= PROT_WRITE; 249
if ( elf_ppnt -> p_flags & PF_X )  250
elf_prot |= PROT_EXEC; 251
elf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE; 253
vaddr = elf_ppnt -> p_vaddr; 255
if ( loc -> elf_ex . e_type == ET_EXEC || load_addr_set )  256
elf_flags |= MAP_FIXED; 257
if ( loc -> elf_ex . e_type == ET_DYN )  258
load_bias = 0; 264
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 270
if ( BAD_ADDR ( error ) )  272
if ( ! load_addr_set )  279
load_addr_set = 1; 280
if ( loc -> elf_ex . e_type == ET_DYN )  282
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 283
k = elf_ppnt -> p_vaddr; 289
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  300
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 309
if ( k > elf_bss )  311
elf_bss = k; 312
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 317
if ( k > elf_brk )  318
elf_brk = k; 319
------------------------------
246 /home/speedy/test/source2slice/NVD/CVE_2010_0307_VULN_load_elf_binary.c nbyte = ELF_MIN_ALIGN - nbyte 232
static int CVE_2010_0307_VULN_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned long load_addr = 0 , load_bias = 0 ; 4
int load_addr_set = 0 ; 5
char * elf_interpreter = NULL ; 6
unsigned long error ; 7
struct elf_phdr * elf_ppnt , * elf_phdata ; 8
unsigned long elf_bss , elf_brk ; 9
int retval , i ; 10
unsigned int size ; 11
int executable_stack = EXSTACK_DEFAULT ; 16
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
retval = - ENOEXEC; 32
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
retval = - ENOMEM; 51
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
elf_ppnt = elf_phdata; 64
elf_bss = 0; 65
elf_brk = 0; 66
for (i = 0; i < loc->elf_ex.e_phnum; i++) 73
if ( elf_ppnt -> p_type == PT_INTERP )  74
retval = - ENOEXEC; 79
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
retval = - ENOMEM; 84
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
retval = - ENOEXEC; 99
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 124
retval = PTR_ERR ( interpreter ); 125
if ( IS_ERR ( interpreter ) )  126
if ( file_permission ( interpreter , MAY_READ ) < 0 )  134
bprm -> interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP; 135
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 137
if ( retval != BINPRM_BUF_SIZE )  139
loc -> interp_elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 146
elf_ppnt ++; 149
elf_ppnt = elf_phdata; 152
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 153
if ( elf_ppnt -> p_type == PT_GNU_STACK )  154
if ( elf_ppnt -> p_flags & PF_X )  155
executable_stack = EXSTACK_ENABLE_X; 156
executable_stack = EXSTACK_DISABLE_X; 158
if ( elf_interpreter )  163
retval = - ELIBBAD; 164
if ( memcmp ( loc -> interp_elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  166
if ( ! elf_check_arch ( & loc -> interp_elf_ex ) )  169
retval = flush_old_exec ( bprm ); 177
if ( retval )  178
retval = setup_arg_pages ( bprm , randomize_stack_top ( STACK_TOP ) , executable_stack ); 199
if ( retval < 0 )  201
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 211
int elf_prot = 0 , elf_flags ; 212
unsigned long k , vaddr ; 213
if ( elf_ppnt -> p_type != PT_LOAD )  215
if ( unlikely ( elf_brk > elf_bss ) )  218
unsigned long nbyte ; 219
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 224
if ( retval )  226
nbyte = ELF_PAGEOFFSET ( elf_bss ); 230
if ( nbyte )  231
nbyte = ELF_MIN_ALIGN - nbyte; 232
if ( nbyte > elf_brk - elf_bss )  233
if ( clear_user ( ( void __user * ) elf_bss + load_bias , nbyte ) )  235
if ( elf_ppnt -> p_flags & PF_R )  246
elf_prot |= PROT_READ; 247
if ( elf_ppnt -> p_flags & PF_W )  248
elf_prot |= PROT_WRITE; 249
if ( elf_ppnt -> p_flags & PF_X )  250
elf_prot |= PROT_EXEC; 251
elf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE; 253
vaddr = elf_ppnt -> p_vaddr; 255
if ( loc -> elf_ex . e_type == ET_EXEC || load_addr_set )  256
elf_flags |= MAP_FIXED; 257
if ( loc -> elf_ex . e_type == ET_DYN )  258
load_bias = 0; 264
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 270
if ( BAD_ADDR ( error ) )  272
if ( ! load_addr_set )  279
load_addr_set = 1; 280
if ( loc -> elf_ex . e_type == ET_DYN )  282
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 283
k = elf_ppnt -> p_vaddr; 289
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  300
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 309
if ( k > elf_bss )  311
elf_bss = k; 312
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 317
if ( k > elf_brk )  318
elf_brk = k; 319
------------------------------
247 /home/speedy/test/source2slice/NVD/CVE_2010_0307_VULN_load_elf_binary.c retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ) 224
static int CVE_2010_0307_VULN_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned long load_addr = 0 , load_bias = 0 ; 4
int load_addr_set = 0 ; 5
char * elf_interpreter = NULL ; 6
unsigned long error ; 7
struct elf_phdr * elf_ppnt , * elf_phdata ; 8
unsigned long elf_bss , elf_brk ; 9
int retval , i ; 10
unsigned int size ; 11
int executable_stack = EXSTACK_DEFAULT ; 16
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
retval = - ENOEXEC; 32
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
retval = - ENOMEM; 51
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
elf_ppnt = elf_phdata; 64
elf_bss = 0; 65
elf_brk = 0; 66
for (i = 0; i < loc->elf_ex.e_phnum; i++) 73
if ( elf_ppnt -> p_type == PT_INTERP )  74
retval = - ENOEXEC; 79
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
retval = - ENOMEM; 84
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
retval = - ENOEXEC; 99
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 124
retval = PTR_ERR ( interpreter ); 125
if ( IS_ERR ( interpreter ) )  126
if ( file_permission ( interpreter , MAY_READ ) < 0 )  134
bprm -> interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP; 135
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 137
if ( retval != BINPRM_BUF_SIZE )  139
loc -> interp_elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 146
elf_ppnt ++; 149
elf_ppnt = elf_phdata; 152
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 153
if ( elf_ppnt -> p_type == PT_GNU_STACK )  154
if ( elf_ppnt -> p_flags & PF_X )  155
executable_stack = EXSTACK_ENABLE_X; 156
executable_stack = EXSTACK_DISABLE_X; 158
if ( elf_interpreter )  163
retval = - ELIBBAD; 164
if ( memcmp ( loc -> interp_elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  166
if ( ! elf_check_arch ( & loc -> interp_elf_ex ) )  169
retval = flush_old_exec ( bprm ); 177
if ( retval )  178
retval = setup_arg_pages ( bprm , randomize_stack_top ( STACK_TOP ) , executable_stack ); 199
if ( retval < 0 )  201
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 211
int elf_prot = 0 , elf_flags ; 212
unsigned long k , vaddr ; 213
if ( elf_ppnt -> p_type != PT_LOAD )  215
if ( unlikely ( elf_brk > elf_bss ) )  218
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 224
if ( retval )  226
if ( elf_ppnt -> p_flags & PF_R )  246
elf_prot |= PROT_READ; 247
if ( elf_ppnt -> p_flags & PF_W )  248
elf_prot |= PROT_WRITE; 249
if ( elf_ppnt -> p_flags & PF_X )  250
elf_prot |= PROT_EXEC; 251
elf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE; 253
vaddr = elf_ppnt -> p_vaddr; 255
if ( loc -> elf_ex . e_type == ET_EXEC || load_addr_set )  256
elf_flags |= MAP_FIXED; 257
if ( loc -> elf_ex . e_type == ET_DYN )  258
load_bias = 0; 264
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 270
if ( BAD_ADDR ( error ) )  272
if ( ! load_addr_set )  279
load_addr_set = 1; 280
if ( loc -> elf_ex . e_type == ET_DYN )  282
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 283
k = elf_ppnt -> p_vaddr; 289
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  300
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 309
if ( k > elf_bss )  311
elf_bss = k; 312
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 317
if ( k > elf_brk )  318
elf_brk = k; 319
if ( retval )  336
if ( retval < 0 )  387
if ( retval < 0 )  397
return retval ; 444
------------------------------
248 /home/speedy/test/source2slice/NVD/CVE_2010_0307_VULN_load_elf_binary.c size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ) 50
static int CVE_2010_0307_VULN_load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs) 1
unsigned int size ; 11
struct { struct elfhdr elf_ex ; struct elfhdr interp_elf_ex ; } * loc ; 18
loc = kmalloc ( sizeof ( * loc ) , GFP_KERNEL ); 23
if ( ! loc )  24
loc -> elf_ex = * ( ( struct elfhdr * ) bprm -> buf ); 30
if ( memcmp ( loc -> elf_ex . e_ident , ELFMAG , SELFMAG ) != 0 )  34
if ( loc -> elf_ex . e_type != ET_EXEC && loc -> elf_ex . e_type != ET_DYN )  37
if ( ! elf_check_arch ( & loc -> elf_ex ) )  39
if ( ! bprm -> file -> f_op || ! bprm -> file -> f_op -> mmap )  41
if ( loc -> elf_ex . e_phentsize != sizeof ( struct elf_phdr ) )  45
if ( loc -> elf_ex . e_phnum < 1 || loc -> elf_ex . e_phnum > 65536U / sizeof ( struct elf_phdr ) )  47
size = loc -> elf_ex . e_phnum * sizeof ( struct elf_phdr ); 50
elf_phdata = kmalloc ( size , GFP_KERNEL ); 52
if ( ! elf_phdata )  53
retval = kernel_read ( bprm -> file , loc -> elf_ex . e_phoff , ( char * ) elf_phdata , size ); 56
if ( retval != size )  58
if ( retval >= 0 )  59
elf_ppnt = elf_phdata; 64
if ( elf_ppnt -> p_type == PT_INTERP )  74
if ( elf_ppnt -> p_filesz > PATH_MAX || elf_ppnt -> p_filesz < 2 )  80
elf_interpreter = kmalloc ( elf_ppnt -> p_filesz , GFP_KERNEL ); 85
if ( ! elf_interpreter )  87
retval = kernel_read ( bprm -> file , elf_ppnt -> p_offset , elf_interpreter , elf_ppnt -> p_filesz ); 90
if ( retval != elf_ppnt -> p_filesz )  93
if ( retval >= 0 )  94
if ( elf_interpreter [ elf_ppnt -> p_filesz - 1 ] != '\0' )  100
interpreter = open_exec ( elf_interpreter ); 124
retval = PTR_ERR ( interpreter ); 125
if ( IS_ERR ( interpreter ) )  126
if ( file_permission ( interpreter , MAY_READ ) < 0 )  134
retval = kernel_read ( interpreter , 0 , bprm -> buf , BINPRM_BUF_SIZE ); 137
if ( retval != BINPRM_BUF_SIZE )  139
if ( retval >= 0 )  140
elf_ppnt ++; 149
elf_ppnt = elf_phdata; 152
for (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 153
if ( elf_ppnt -> p_type == PT_GNU_STACK )  154
if ( elf_ppnt -> p_flags & PF_X )  155
if ( elf_interpreter )  163
if ( retval )  178
if ( retval < 0 )  201
for(i = 0, elf_ppnt = elf_phdata;
i < loc->elf_ex.e_phnum; i++, elf_ppnt++) 211
if ( elf_ppnt -> p_type != PT_LOAD )  215
if ( unlikely ( elf_brk > elf_bss ) )  218
retval = set_brk ( elf_bss + load_bias , elf_brk + load_bias ); 224
if ( retval )  226
nbyte = ELF_PAGEOFFSET ( elf_bss ); 230
if ( nbyte )  231
nbyte = ELF_MIN_ALIGN - nbyte; 232
if ( nbyte > elf_brk - elf_bss )  233
nbyte = elf_brk - elf_bss; 234
if ( clear_user ( ( void __user * ) elf_bss + load_bias , nbyte ) )  235
if ( elf_ppnt -> p_flags & PF_R )  246
if ( elf_ppnt -> p_flags & PF_W )  248
if ( elf_ppnt -> p_flags & PF_X )  250
vaddr = elf_ppnt -> p_vaddr; 255
error = elf_map ( bprm -> file , load_bias + vaddr , elf_ppnt , elf_prot , elf_flags , 0 ); 270
if ( BAD_ADDR ( error ) )  272
retval = IS_ERR ( ( void * ) error ) ? PTR_ERR ( ( void * ) error ) : - EINVAL; 274
load_addr = ( elf_ppnt -> p_vaddr - elf_ppnt -> p_offset ); 281
load_bias += error - ELF_PAGESTART ( load_bias + vaddr ); 283
load_addr += load_bias; 285
reloc_func_desc = load_bias; 286
k = elf_ppnt -> p_vaddr; 289
if ( k < start_code )  290
start_code = k; 291
if ( start_data < k )  292
start_data = k; 293
if ( BAD_ADDR ( k ) || elf_ppnt -> p_filesz > elf_ppnt -> p_memsz || elf_ppnt -> p_memsz > TASK_SIZE || TASK_SIZE - elf_ppnt -> p_memsz < k )  300
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_filesz; 309
if ( k > elf_bss )  311
elf_bss = k; 312
if ( ( elf_ppnt -> p_flags & PF_X ) && end_code < k )  313
end_code = k; 314
if ( end_data < k )  315
end_data = k; 316
k = elf_ppnt -> p_vaddr + elf_ppnt -> p_memsz; 317
if ( k > elf_brk )  318
elf_brk = k; 319
loc -> elf_ex . e_entry += load_bias; 322
elf_bss += load_bias; 323
elf_brk += load_bias; 324
start_code += load_bias; 325
end_code += load_bias; 326
start_data += load_bias; 327
end_data += load_bias; 328
retval = set_brk ( elf_bss , elf_brk ); 335
if ( retval )  336
if ( likely ( elf_bss != elf_brk ) && unlikely ( padzero ( elf_bss ) ) )  340
if ( elf_interpreter )  346
elf_entry = load_elf_interp ( & loc -> interp_elf_ex , interpreter , & interp_map_addr , load_bias ); 349
if ( ! IS_ERR ( ( void * ) elf_entry ) )  353
interp_load_addr = elf_entry; 358
elf_entry += loc -> interp_elf_ex . e_entry; 359
if ( BAD_ADDR ( elf_entry ) )  361
retval = IS_ERR ( ( void * ) elf_entry ) ? ( int ) elf_entry : - EINVAL; 363
reloc_func_desc = interp_load_addr; 367
allow_write_access ( interpreter ); 369
fput ( interpreter ); 370
kfree ( elf_interpreter ); 371
elf_entry = loc -> elf_ex . e_entry; 373
if ( BAD_ADDR ( elf_entry ) )  374
kfree ( elf_phdata ); 381
retval = arch_setup_additional_pages ( bprm , ! ! elf_interpreter ); 386
if ( retval < 0 )  387
retval = create_elf_tables ( bprm , & loc -> elf_ex , load_addr , interp_load_addr ); 395
if ( retval < 0 )  397
current -> mm -> end_code = end_code; 402
current -> mm -> start_code = start_code; 403
current -> mm -> start_data = start_data; 404
current -> mm -> end_data = end_data; 405
current -> mm -> start_stack = bprm -> p; 406
if ( ( current -> flags & PF_RANDOMIZE ) && ( randomize_va_space > 1 ) )  409
current -> mm -> brk = current -> mm -> start_brk = arch_randomize_brk ( current -> mm ); 410
if ( current -> personality & MMAP_PAGE_ZERO )  414
down_write ( & current -> mm -> mmap_sem ); 419
up_write ( & current -> mm -> mmap_sem ); 422
ELF_PLAT_INIT ( regs , reloc_func_desc ); 436
start_thread ( regs , elf_entry , bprm -> p ); 439
kfree ( loc ); 442
return retval ; 444
allow_write_access ( interpreter ); 448
if ( interpreter )  449
fput ( interpreter ); 450
kfree ( elf_interpreter ); 452
kfree ( elf_phdata ); 454
------------------------------
249 /home/speedy/test/source2slice/NVD/CVE_2010_2478_PATCHED_ethtool_get_rxnfc.c rule_buf = kmalloc ( info . rule_cnt * sizeof ( u32 ) , GFP_USER ) 17
static int CVE_2010_2478_PATCHED_ethtool_get_rxnfc(struct net_device *dev, void __user *useraddr) 1
struct ethtool_rxnfc info ; 3
const struct ethtool_ops * ops = dev -> ethtool_ops ; 4
if ( ! ops -> get_rxnfc )  8
if ( copy_from_user ( & info , useraddr , sizeof ( info ) ) )  11
if ( info . cmd == ETHTOOL_GRXCLSRLALL )  14
if ( info . rule_cnt > 0 )  15
if ( info . rule_cnt <= KMALLOC_MAX_SIZE / sizeof ( u32 ) )  16
rule_buf = kmalloc ( info . rule_cnt * sizeof ( u32 ) , GFP_USER ); 17
if ( ! rule_buf )  19
ret = ops -> get_rxnfc ( dev , & info , rule_buf ); 24
if ( ret < 0 )  25
if ( rule_buf )  32
if ( copy_to_user ( useraddr , rule_buf , info . rule_cnt * sizeof ( u32 ) ) )  34
kfree ( rule_buf ); 41
return ret ; 43
------------------------------
250 /home/speedy/test/source2slice/NVD/CVE_2010_2478_VULN_ethtool_get_rxnfc.c rule_buf = kmalloc ( info . rule_cnt * sizeof ( u32 ) , GFP_USER ) 16
static int CVE_2010_2478_VULN_ethtool_get_rxnfc(struct net_device *dev, void __user *useraddr) 1
struct ethtool_rxnfc info ; 3
const struct ethtool_ops * ops = dev -> ethtool_ops ; 4
if ( ! ops -> get_rxnfc )  8
if ( copy_from_user ( & info , useraddr , sizeof ( info ) ) )  11
if ( info . cmd == ETHTOOL_GRXCLSRLALL )  14
if ( info . rule_cnt > 0 )  15
rule_buf = kmalloc ( info . rule_cnt * sizeof ( u32 ) , GFP_USER ); 16
if ( ! rule_buf )  18
ret = ops -> get_rxnfc ( dev , & info , rule_buf ); 23
if ( ret < 0 )  24
if ( rule_buf )  31
if ( copy_to_user ( useraddr , rule_buf , info . rule_cnt * sizeof ( u32 ) ) )  33
kfree ( rule_buf ); 40
return ret ; 42
------------------------------
251 /home/speedy/test/source2slice/NVD/CVE_2010_2495_PATCHED_pppol2tp_sendmsg.c udp_len = hdr_len + sizeof ( ppph ) + total_len 53
static int CVE_2010_2495_PATCHED_pppol2tp_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *m,
size_t total_len) 2
struct sock * sk = sock -> sk ; 5
struct sk_buff * skb ; 8
int hdr_len ; 10
struct pppol2tp_session * session ; 11
struct pppol2tp_tunnel * tunnel ; 12
struct sock * sk_tun ; 15
u16 udp_len ; 16
if ( sock_flag ( sk , SOCK_DEAD ) || ! ( sk -> sk_state & PPPOX_CONNECTED ) )  19
session = pppol2tp_sock_to_session ( sk ); 24
if ( session == NULL )  25
sk_tun = session -> tunnel_sock; 28
tunnel = pppol2tp_sock_to_tunnel ( sk_tun ); 29
if ( tunnel == NULL )  30
hdr_len = pppol2tp_l2tp_header_len ( session ); 34
skb = sock_wmalloc ( sk , NET_SKB_PAD + sizeof ( struct iphdr ) + sizeof ( struct udphdr ) + hdr_len + sizeof ( ppph ) + total_len , 0 , GFP_KERNEL ); 38
if ( ! skb )  42
udp_len = hdr_len + sizeof ( ppph ) + total_len; 53
uh -> len = htons ( udp_len ); 57
uh -> check = 0; 58
csum = skb_checksum ( skb , 0 , udp_len , 0 ); 84
uh -> check = csum_tcpudp_magic ( inet -> inet_saddr , inet -> inet_daddr , udp_len , IPPROTO_UDP , csum ); 85
if ( uh -> check == 0 )  88
uh -> check = CSUM_MANGLED_0; 89
uh -> check = ~csum_tcpudp_magic ( inet -> inet_saddr , inet -> inet_daddr , udp_len , IPPROTO_UDP , 0 ); 94
------------------------------
252 /home/speedy/test/source2slice/NVD/CVE_2010_2495_PATCHED_pppol2tp_sendmsg.c skb = sock_wmalloc ( sk , NET_SKB_PAD + sizeof ( struct iphdr ) + sizeof ( struct udphdr ) + hdr_len + sizeof ( ppph ) + total_len , 0 , GFP_KERNEL ) 38
static int CVE_2010_2495_PATCHED_pppol2tp_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *m,
size_t total_len) 2
struct sock * sk = sock -> sk ; 5
struct sk_buff * skb ; 8
int hdr_len ; 10
struct pppol2tp_session * session ; 11
struct pppol2tp_tunnel * tunnel ; 12
struct sock * sk_tun ; 15
if ( sock_flag ( sk , SOCK_DEAD ) || ! ( sk -> sk_state & PPPOX_CONNECTED ) )  19
session = pppol2tp_sock_to_session ( sk ); 24
if ( session == NULL )  25
sk_tun = session -> tunnel_sock; 28
tunnel = pppol2tp_sock_to_tunnel ( sk_tun ); 29
if ( tunnel == NULL )  30
hdr_len = pppol2tp_l2tp_header_len ( session ); 34
skb = sock_wmalloc ( sk , NET_SKB_PAD + sizeof ( struct iphdr ) + sizeof ( struct udphdr ) + hdr_len + sizeof ( ppph ) + total_len , 0 , GFP_KERNEL ); 38
if ( ! skb )  42
skb_reserve ( skb , NET_SKB_PAD ); 46
skb_reset_network_header ( skb ); 47
skb_reserve ( skb , sizeof ( struct iphdr ) ); 48
skb_reset_transport_header ( skb ); 49
uh = ( struct udphdr * ) skb -> data; 54
uh -> source = inet -> inet_sport; 55
uh -> dest = inet -> inet_dport; 56
uh -> len = htons ( udp_len ); 57
uh -> check = 0; 58
skb_put ( skb , sizeof ( struct udphdr ) ); 59
pppol2tp_build_l2tp_header ( session , skb -> data ); 62
skb_put ( skb , hdr_len ); 63
skb -> data [ 0 ] = ppph [ 0 ]; 66
skb -> data [ 1 ] = ppph [ 1 ]; 67
skb_put ( skb , 2 ); 68
error = memcpy_fromiovec ( skb -> data , m -> msg_iov , total_len ); 71
if ( error < 0 )  72
kfree_skb ( skb ); 73
skb_put ( skb , total_len ); 76
skb -> ip_summed = CHECKSUM_NONE; 80
if ( ( skb_dst ( skb ) && skb_dst ( skb ) -> dev ) && ( ! ( skb_dst ( skb ) -> dev -> features & NETIF_F_V4_CSUM ) ) )  81
skb -> ip_summed = CHECKSUM_COMPLETE; 83
csum = skb_checksum ( skb , 0 , udp_len , 0 ); 84
uh -> check = csum_tcpudp_magic ( inet -> inet_saddr , inet -> inet_daddr , udp_len , IPPROTO_UDP , csum ); 85
if ( uh -> check == 0 )  88
uh -> check = CSUM_MANGLED_0; 89
skb -> ip_summed = CHECKSUM_PARTIAL; 91
skb -> csum_start = skb_transport_header ( skb ) - skb -> head; 92
uh -> check = ~csum_tcpudp_magic ( inet -> inet_saddr , inet -> inet_daddr , udp_len , IPPROTO_UDP , 0 ); 94
unsigned char * datap = skb -> data ; 110
printk ( " %02X" , * datap ++ ); 114
len = skb -> len; 124
error = ip_queue_xmit ( skb , 1 ); 125
if ( error >= 0 )  128
tunnel -> stats . tx_bytes += len; 130
session -> stats . tx_bytes += len; 132
return error ; 138
return error ; 145
------------------------------
253 /home/speedy/test/source2slice/NVD/CVE_2010_2495_VULN_pppol2tp_sendmsg.c udp_len = hdr_len + sizeof ( ppph ) + total_len 53
static int CVE_2010_2495_VULN_pppol2tp_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *m,
size_t total_len) 2
struct sock * sk = sock -> sk ; 5
struct sk_buff * skb ; 8
int hdr_len ; 10
struct pppol2tp_session * session ; 11
struct pppol2tp_tunnel * tunnel ; 12
struct sock * sk_tun ; 15
u16 udp_len ; 16
if ( sock_flag ( sk , SOCK_DEAD ) || ! ( sk -> sk_state & PPPOX_CONNECTED ) )  19
session = pppol2tp_sock_to_session ( sk ); 24
if ( session == NULL )  25
sk_tun = session -> tunnel_sock; 28
tunnel = pppol2tp_sock_to_tunnel ( sk_tun ); 29
if ( tunnel == NULL )  30
hdr_len = pppol2tp_l2tp_header_len ( session ); 34
skb = sock_wmalloc ( sk , NET_SKB_PAD + sizeof ( struct iphdr ) + sizeof ( struct udphdr ) + hdr_len + sizeof ( ppph ) + total_len , 0 , GFP_KERNEL ); 38
if ( ! skb )  42
udp_len = hdr_len + sizeof ( ppph ) + total_len; 53
uh -> len = htons ( udp_len ); 57
uh -> check = 0; 58
csum = skb_checksum ( skb , 0 , udp_len , 0 ); 83
uh -> check = csum_tcpudp_magic ( inet -> inet_saddr , inet -> inet_daddr , udp_len , IPPROTO_UDP , csum ); 84
if ( uh -> check == 0 )  87
uh -> check = CSUM_MANGLED_0; 88
uh -> check = ~csum_tcpudp_magic ( inet -> inet_saddr , inet -> inet_daddr , udp_len , IPPROTO_UDP , 0 ); 93
------------------------------
254 /home/speedy/test/source2slice/NVD/CVE_2010_2495_VULN_pppol2tp_sendmsg.c skb = sock_wmalloc ( sk , NET_SKB_PAD + sizeof ( struct iphdr ) + sizeof ( struct udphdr ) + hdr_len + sizeof ( ppph ) + total_len , 0 , GFP_KERNEL ) 38
static int CVE_2010_2495_VULN_pppol2tp_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *m,
size_t total_len) 2
struct sock * sk = sock -> sk ; 5
struct sk_buff * skb ; 8
int hdr_len ; 10
struct pppol2tp_session * session ; 11
struct pppol2tp_tunnel * tunnel ; 12
struct sock * sk_tun ; 15
if ( sock_flag ( sk , SOCK_DEAD ) || ! ( sk -> sk_state & PPPOX_CONNECTED ) )  19
session = pppol2tp_sock_to_session ( sk ); 24
if ( session == NULL )  25
sk_tun = session -> tunnel_sock; 28
tunnel = pppol2tp_sock_to_tunnel ( sk_tun ); 29
if ( tunnel == NULL )  30
hdr_len = pppol2tp_l2tp_header_len ( session ); 34
skb = sock_wmalloc ( sk , NET_SKB_PAD + sizeof ( struct iphdr ) + sizeof ( struct udphdr ) + hdr_len + sizeof ( ppph ) + total_len , 0 , GFP_KERNEL ); 38
if ( ! skb )  42
skb_reserve ( skb , NET_SKB_PAD ); 46
skb_reset_network_header ( skb ); 47
skb_reserve ( skb , sizeof ( struct iphdr ) ); 48
skb_reset_transport_header ( skb ); 49
uh = ( struct udphdr * ) skb -> data; 54
uh -> source = inet -> inet_sport; 55
uh -> dest = inet -> inet_dport; 56
uh -> len = htons ( udp_len ); 57
uh -> check = 0; 58
skb_put ( skb , sizeof ( struct udphdr ) ); 59
pppol2tp_build_l2tp_header ( session , skb -> data ); 62
skb_put ( skb , hdr_len ); 63
skb -> data [ 0 ] = ppph [ 0 ]; 66
skb -> data [ 1 ] = ppph [ 1 ]; 67
skb_put ( skb , 2 ); 68
error = memcpy_fromiovec ( skb -> data , m -> msg_iov , total_len ); 71
if ( error < 0 )  72
kfree_skb ( skb ); 73
skb_put ( skb , total_len ); 76
skb -> ip_summed = CHECKSUM_NONE; 80
if ( ! ( skb_dst ( skb ) -> dev -> features & NETIF_F_V4_CSUM ) )  81
skb -> ip_summed = CHECKSUM_COMPLETE; 82
csum = skb_checksum ( skb , 0 , udp_len , 0 ); 83
uh -> check = csum_tcpudp_magic ( inet -> inet_saddr , inet -> inet_daddr , udp_len , IPPROTO_UDP , csum ); 84
if ( uh -> check == 0 )  87
uh -> check = CSUM_MANGLED_0; 88
skb -> ip_summed = CHECKSUM_PARTIAL; 90
skb -> csum_start = skb_transport_header ( skb ) - skb -> head; 91
uh -> check = ~csum_tcpudp_magic ( inet -> inet_saddr , inet -> inet_daddr , udp_len , IPPROTO_UDP , 0 ); 93
unsigned char * datap = skb -> data ; 109
printk ( " %02X" , * datap ++ ); 113
len = skb -> len; 123
error = ip_queue_xmit ( skb , 1 ); 124
if ( error >= 0 )  127
tunnel -> stats . tx_bytes += len; 129
session -> stats . tx_bytes += len; 131
return error ; 137
return error ; 144
------------------------------
255 /home/speedy/test/source2slice/NVD/CVE_2010_2498_PATCHED_psh_glyph_find_strong_points.c count = next - first 41
static void
CVE_2010_2498_PATCHED_psh_glyph_find_strong_points( PSH_Glyph  glyph,
FT_Int     dimension ) 4
PSH_Hint_Table table = & glyph -> hint_tables [ dimension ] ; 9
PS_Mask mask = table -> hint_masks -> masks ; 10
FT_UInt num_masks = table -> hint_masks -> num_masks ; 11
if ( num_masks > 1 && glyph -> num_points > 0 )  25
first = mask -> end_point > glyph -> num_points ? glyph -> num_points : mask -> end_point; 28
mask ++; 31
for ( ; num_masks > 1; num_masks--, mask++ ) 32
FT_UInt next ; 34
FT_Int count ; 35
next = mask -> end_point > glyph -> num_points ? glyph -> num_points : mask -> end_point; 38
count = next - first; 41
if ( count > 0 )  42
psh_hint_table_find_strong_points ( table , point , count , threshold , major_dir ); 49
first = next; 52
psh_hint_table_find_strong_points ( table , point , count , threshold , major_dir ); 65
for ( ; count > 0; count--, point++ ) 76
if ( point -> hint && ! psh_point_is_strong ( point ) )  77
psh_point_set_strong ( point ); 78
------------------------------
256 /home/speedy/test/source2slice/NVD/CVE_2010_2498_VULN_psh_glyph_find_strong_points.c count = next - first 36
static void
CVE_2010_2498_VULN_psh_glyph_find_strong_points( PSH_Glyph  glyph,
FT_Int     dimension ) 4
PSH_Hint_Table table = & glyph -> hint_tables [ dimension ] ; 9
PS_Mask mask = table -> hint_masks -> masks ; 10
FT_UInt num_masks = table -> hint_masks -> num_masks ; 11
if ( num_masks > 1 && glyph -> num_points > 0 )  25
first = mask -> end_point; 27
mask ++; 28
for ( ; num_masks > 1; num_masks--, mask++ ) 29
FT_UInt next ; 31
FT_Int count ; 32
next = mask -> end_point; 35
count = next - first; 36
if ( count > 0 )  37
psh_hint_table_find_strong_points ( table , point , count , threshold , major_dir ); 44
first = next; 47
psh_hint_table_find_strong_points ( table , point , count , threshold , major_dir ); 60
for ( ; count > 0; count--, point++ ) 71
if ( point -> hint && ! psh_point_is_strong ( point ) )  72
psh_point_set_strong ( point ); 73
------------------------------
257 /home/speedy/test/source2slice/NVD/CVE_2010_2500_PATCHED_gray_render_span.c p = ( unsigned char * ) map -> buffer - y * map -> pitch 12
static void
CVE_2010_2500_PATCHED_gray_render_span( int             y,
int             count,
const FT_Span*  spans,
PWorker         worker ) 5
unsigned char * p ; 7
FT_Bitmap * map = & worker -> target ; 8
p = ( unsigned char * ) map -> buffer - y * map -> pitch; 12
p += ( unsigned ) ( ( map -> rows - 1 ) * map -> pitch ); 14
FT_MEM_SET ( p + spans -> x , ( unsigned char ) coverage , spans -> len ); 28
unsigned char * q = p + spans -> x ; 31
* q ++ = ( unsigned char ) coverage; 36
* q ++ = ( unsigned char ) coverage; 37
* q ++ = ( unsigned char ) coverage; 38
* q ++ = ( unsigned char ) coverage; 39
* q ++ = ( unsigned char ) coverage; 40
* q ++ = ( unsigned char ) coverage; 41
* q = ( unsigned char ) coverage; 42
------------------------------
258 /home/speedy/test/source2slice/NVD/CVE_2010_2500_VULN_gray_render_span.c p = ( unsigned char * ) map -> buffer - y * map -> pitch 12
static void
CVE_2010_2500_VULN_gray_render_span( int             y,
int             count,
const FT_Span*  spans,
PWorker         worker ) 5
unsigned char * p ; 7
FT_Bitmap * map = & worker -> target ; 8
p = ( unsigned char * ) map -> buffer - y * map -> pitch; 12
p += ( map -> rows - 1 ) * map -> pitch; 14
FT_MEM_SET ( p + spans -> x , ( unsigned char ) coverage , spans -> len ); 28
unsigned char * q = p + spans -> x ; 31
* q ++ = ( unsigned char ) coverage; 36
* q ++ = ( unsigned char ) coverage; 37
* q ++ = ( unsigned char ) coverage; 38
* q ++ = ( unsigned char ) coverage; 39
* q ++ = ( unsigned char ) coverage; 40
* q ++ = ( unsigned char ) coverage; 41
* q = ( unsigned char ) coverage; 42
------------------------------
259 /home/speedy/test/source2slice/NVD/CVE_2010_2519_PATCHED_Mac_Read_POST_Resource.c error = FT_Stream_Read ( stream , ( FT_Byte * ) pfb_data + pfb_pos , rlen ) 98
static FT_Error
CVE_2010_2519_PATCHED_Mac_Read_POST_Resource( FT_Library  library,
FT_Stream   stream,
FT_Long    *offsets,
FT_Long     resource_cnt,
FT_Long     face_index,
FT_Face    *aface ) 8
FT_Byte * pfb_data ; 12
int i , type , flags ; 13
FT_Long pfb_len , pfb_pos , pfb_lenpos ; 15
FT_Long rlen , temp ; 16
if ( face_index == - 1 )  19
face_index = 0; 20
if ( face_index != 0 )  21
pfb_len = 0; 26
for ( i = 0; i < resource_cnt; ++i ) 27
error = FT_Stream_Seek ( stream , offsets [ i ] ); 29
if ( error )  30
if ( FT_READ_LONG ( temp ) )  32
pfb_len += temp + 6; 34
if ( FT_ALLOC ( pfb_data , ( FT_Long ) pfb_len + 2 ) )  37
pfb_pos = 6; 46
type = 1; 50
for ( i = 0; i < resource_cnt; ++i ) 51
error = FT_Stream_Seek ( stream , offsets [ i ] ); 53
if ( error )  54
if ( FT_READ_LONG ( rlen ) )  56
if ( FT_READ_USHORT ( flags ) )  58
if ( ( flags >> 8 ) == 0 )  63
if ( rlen > 2 )  68
rlen -= 2; 69
rlen = 0; 71
if ( ( flags >> 8 ) == type )  73
if ( ( flags >> 8 ) == 5 )  82
pfb_data [ pfb_pos ++ ] = 0x80; 85
type = flags >> 8; 87
pfb_data [ pfb_pos ++ ] = ( FT_Byte ) type; 90
pfb_data [ pfb_pos ++ ] = 0; 92
pfb_data [ pfb_pos ++ ] = 0; 93
pfb_data [ pfb_pos ++ ] = 0; 94
pfb_data [ pfb_pos ++ ] = 0; 95
error = FT_Stream_Read ( stream , ( FT_Byte * ) pfb_data + pfb_pos , rlen ); 98
pfb_pos += rlen; 99
return error ; 121
------------------------------
260 /home/speedy/test/source2slice/NVD/CVE_2010_2519_VULN_Mac_Read_POST_Resource.c error = FT_Stream_Read ( stream , ( FT_Byte * ) pfb_data + pfb_pos , rlen ) 86
static FT_Error
CVE_2010_2519_VULN_Mac_Read_POST_Resource( FT_Library  library,
FT_Stream   stream,
FT_Long    *offsets,
FT_Long     resource_cnt,
FT_Long     face_index,
FT_Face    *aface ) 8
FT_Byte * pfb_data ; 12
int i , type , flags ; 13
FT_Long len ; 14
FT_Long pfb_len , pfb_pos , pfb_lenpos ; 15
FT_Long rlen , temp ; 16
if ( face_index == - 1 )  19
face_index = 0; 20
if ( face_index != 0 )  21
pfb_len = 0; 26
for ( i = 0; i < resource_cnt; ++i ) 27
error = FT_Stream_Seek ( stream , offsets [ i ] ); 29
if ( error )  30
if ( FT_READ_LONG ( temp ) )  32
pfb_len += temp + 6; 34
if ( FT_ALLOC ( pfb_data , ( FT_Long ) pfb_len + 2 ) )  37
pfb_pos = 6; 46
pfb_lenpos = 2; 47
len = 0; 49
type = 1; 50
for ( i = 0; i < resource_cnt; ++i ) 51
error = FT_Stream_Seek ( stream , offsets [ i ] ); 53
if ( error )  54
if ( FT_READ_LONG ( rlen ) )  56
if ( FT_READ_USHORT ( flags ) )  58
rlen -= 2; 60
if ( ( flags >> 8 ) == type )  61
len += rlen; 62
pfb_data [ pfb_lenpos ] = ( FT_Byte ) ( len ); 65
pfb_data [ pfb_lenpos + 1 ] = ( FT_Byte ) ( len >> 8 ); 66
pfb_data [ pfb_lenpos + 2 ] = ( FT_Byte ) ( len >> 16 ); 67
pfb_data [ pfb_lenpos + 3 ] = ( FT_Byte ) ( len >> 24 ); 68
if ( ( flags >> 8 ) == 5 )  70
pfb_data [ pfb_pos ++ ] = 0x80; 73
type = flags >> 8; 75
len = rlen; 76
pfb_data [ pfb_pos ++ ] = ( FT_Byte ) type; 78
pfb_lenpos = pfb_pos; 79
pfb_data [ pfb_pos ++ ] = 0; 80
pfb_data [ pfb_pos ++ ] = 0; 81
pfb_data [ pfb_pos ++ ] = 0; 82
pfb_data [ pfb_pos ++ ] = 0; 83
error = FT_Stream_Read ( stream , ( FT_Byte * ) pfb_data + pfb_pos , rlen ); 86
pfb_pos += rlen; 87
return error ; 109
------------------------------
261 /home/speedy/test/source2slice/NVD/CVE_2010_2521_PATCHED_nfsd4_decode_compound.c argp -> ops = kmalloc ( argp -> opcnt * sizeof ( * argp -> ops ) , GFP_KERNEL ) 28
static __be32
CVE_2010_2521_PATCHED_nfsd4_decode_compound(struct nfsd4_compoundargs *argp) 2
if ( argp -> opcnt > ARRAY_SIZE ( argp -> iops ) )  27
argp -> ops = kmalloc ( argp -> opcnt * sizeof ( * argp -> ops ) , GFP_KERNEL ); 28
if ( ! argp -> ops )  29
argp -> ops = argp -> iops; 30
if ( argp -> minorversion >= ARRAY_SIZE ( nfsd4_minorversion ) )  36
argp -> opcnt = 0; 37
ops = & nfsd4_minorversion [ argp -> minorversion ]; 39
for (i = 0; i < argp->opcnt; i++) 40
op = & argp -> ops [ i ]; 41
op -> replay = NULL; 42
if ( argp -> p == argp -> end )  51
if ( argp -> pagelen < 4 )  52
op -> opnum = OP_WRITE + 1; 54
op -> status = nfserr_bad_xdr; 55
argp -> opcnt = i + 1; 56
argp -> p = page_address ( argp -> pagelist [ 0 ] ); 65
argp -> pagelist ++; 66
if ( argp -> pagelen < PAGE_SIZE )  67
argp -> end = argp -> p + ( argp -> pagelen >> 2 ); 68
argp -> pagelen = 0; 69
argp -> end = argp -> p + ( PAGE_SIZE >> 2 ); 71
argp -> pagelen -= PAGE_SIZE; 72
op -> opnum = ntohl ( * argp -> p ++ ); 75
if ( op -> opnum >= OP_ACCESS && op -> opnum < ops -> nops )  77
op -> status = ops -> decoders [ op -> opnum ] ( argp , & op -> u ); 78
op -> opnum = OP_ILLEGAL; 80
op -> status = nfserr_op_illegal; 81
if ( op -> status )  84
------------------------------
262 /home/speedy/test/source2slice/NVD/CVE_2010_2521_VULN_nfsd4_decode_compound.c argp -> ops = kmalloc ( argp -> opcnt * sizeof ( * argp -> ops ) , GFP_KERNEL ) 28
static __be32
CVE_2010_2521_VULN_nfsd4_decode_compound(struct nfsd4_compoundargs *argp) 2
if ( argp -> opcnt > ARRAY_SIZE ( argp -> iops ) )  27
argp -> ops = kmalloc ( argp -> opcnt * sizeof ( * argp -> ops ) , GFP_KERNEL ); 28
if ( ! argp -> ops )  29
argp -> ops = argp -> iops; 30
if ( argp -> minorversion >= ARRAY_SIZE ( nfsd4_minorversion ) )  36
argp -> opcnt = 0; 37
ops = & nfsd4_minorversion [ argp -> minorversion ]; 39
for (i = 0; i < argp->opcnt; i++) 40
op = & argp -> ops [ i ]; 41
op -> replay = NULL; 42
if ( argp -> p == argp -> end )  51
if ( argp -> pagelen < 4 )  52
op -> opnum = OP_WRITE + 1; 54
op -> status = nfserr_bad_xdr; 55
argp -> opcnt = i + 1; 56
argp -> p = page_address ( argp -> pagelist [ 0 ] ); 65
argp -> pagelist ++; 66
if ( argp -> pagelen < PAGE_SIZE )  67
argp -> end = p + ( argp -> pagelen >> 2 ); 68
argp -> pagelen = 0; 69
argp -> pagelen -= PAGE_SIZE; 72
op -> opnum = ntohl ( * argp -> p ++ ); 75
if ( op -> opnum >= OP_ACCESS && op -> opnum < ops -> nops )  77
op -> status = ops -> decoders [ op -> opnum ] ( argp , & op -> u ); 78
op -> opnum = OP_ILLEGAL; 80
op -> status = nfserr_op_illegal; 81
if ( op -> status )  84
------------------------------
263 /home/speedy/test/source2slice/NVD/CVE_2010_2537_PATCHED_btrfs_ioctl_clone.c trim = key . offset + datal - ( off + len ) 241
static noinline long CVE_2010_2537_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
ret = - EISDIR; 54
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
ret = - EXDEV; 58
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
264 /home/speedy/test/source2slice/NVD/CVE_2010_2537_PATCHED_btrfs_ioctl_clone.c skip = off - key . offset 236
static noinline long CVE_2010_2537_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
ret = - EISDIR; 54
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
ret = - EXDEV; 58
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
if ( skip )  254
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
265 /home/speedy/test/source2slice/NVD/CVE_2010_2537_PATCHED_btrfs_ioctl_clone.c ret = btrfs_inc_extent_ref ( trans , root , disko , diskl , 0 , root -> root_key . objectid , inode -> i_ino , new_key . offset - datao ) 225
static noinline long CVE_2010_2537_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
ret = - EISDIR; 54
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
ret = - EXDEV; 58
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 disko = 0 , diskl = 0 ; 154
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
disko = btrfs_file_extent_disk_bytenr ( leaf , extent ); 169
diskl = btrfs_file_extent_disk_num_bytes ( leaf , extent ); 171
datao = btrfs_file_extent_offset ( leaf , extent ); 173
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( off > key . offset )  207
datao += off - key . offset; 208
if ( ! disko )  216
datao = 0; 217
if ( disko )  223
ret = btrfs_inc_extent_ref ( trans , root , disko , diskl , 0 , root -> root_key . objectid , inode -> i_ino , new_key . offset - datao ); 225
BUG_ON ( ret ); 230
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
return ret ; 299
------------------------------
266 /home/speedy/test/source2slice/NVD/CVE_2010_2537_PATCHED_btrfs_ioctl_clone.c datal = off + len - key . offset 213
static noinline long CVE_2010_2537_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
ret = - EISDIR; 54
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
ret = - EXDEV; 58
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( off > key . offset )  207
datal -= off - key . offset; 209
if ( key . offset + datal > off + len )  212
datal = off + len - key . offset; 213
btrfs_set_file_extent_num_bytes ( leaf , extent , datal ); 221
inode_add_bytes ( inode , datal ); 224
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
key . offset ++; 274
------------------------------
267 /home/speedy/test/source2slice/NVD/CVE_2010_2537_PATCHED_btrfs_ioctl_clone.c new_key . offset = key . offset + destoff - off 189
static noinline long CVE_2010_2537_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
ret = - EISDIR; 54
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
ret = - EXDEV; 58
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
ret = btrfs_inc_extent_ref ( trans , root , disko , diskl , 0 , root -> root_key . objectid , inode -> i_ino , new_key . offset - datao ); 225
BUG_ON ( ret ); 230
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
return ret ; 299
------------------------------
268 /home/speedy/test/source2slice/NVD/CVE_2010_2537_PATCHED_btrfs_ioctl_clone.c ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ) 103
static noinline long CVE_2010_2537_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_path * path ; 9
char * buf ; 11
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
while ( 1 )  100
struct btrfs_ordered_extent * ordered ; 101
ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ); 103
if ( BTRFS_I ( src ) -> delalloc_bytes == 0 && ! ordered )  104
if ( ordered )  107
btrfs_put_ordered_extent ( ordered ); 108
------------------------------
269 /home/speedy/test/source2slice/NVD/CVE_2010_2537_PATCHED_btrfs_ioctl_clone.c len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off 90
static noinline long CVE_2010_2537_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_path * path ; 9
char * buf ; 11
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
lock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 102
ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ); 103
if ( BTRFS_I ( src ) -> delalloc_bytes == 0 && ! ordered )  104
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 106
if ( ordered )  107
btrfs_put_ordered_extent ( ordered ); 108
btrfs_wait_ordered_range ( src , off , off + len ); 109
btrfs_drop_extents ( trans , inode , off , off + len , & hint_byte , 1 ); 116
if ( key . offset + datal < off || key . offset >= off + len )  183
if ( key . offset + datal > off + len )  212
datal = off + len - key . offset; 213
btrfs_set_file_extent_num_bytes ( leaf , extent , datal ); 221
inode_add_bytes ( inode , datal ); 224
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
if ( ret == 0 )  279
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 287
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
270 /home/speedy/test/source2slice/NVD/CVE_2010_2537_PATCHED_btrfs_ioctl_clone.c olen = len = src -> i_size - off 87
static noinline long CVE_2010_2537_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_path * path ; 9
char * buf ; 11
int ret ; 15
u64 len = olen ; 16
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
lock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 102
ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ); 103
if ( BTRFS_I ( src ) -> delalloc_bytes == 0 && ! ordered )  104
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 106
if ( ordered )  107
btrfs_put_ordered_extent ( ordered ); 108
btrfs_wait_ordered_range ( src , off , off + len ); 109
btrfs_drop_extents ( trans , inode , off , off + len , & hint_byte , 1 ); 116
if ( key . offset + datal < off || key . offset >= off + len )  183
if ( key . offset + datal > off + len )  212
datal = off + len - key . offset; 213
btrfs_set_file_extent_num_bytes ( leaf , extent , datal ); 221
inode_add_bytes ( inode , datal ); 224
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
if ( ret == 0 )  279
if ( destoff + olen > inode -> i_size )  281
btrfs_i_size_write ( inode , destoff + olen ); 282
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 287
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
271 /home/speedy/test/source2slice/NVD/CVE_2010_2537_VULN_btrfs_ioctl_clone.c trim = key . offset + datal - ( off + len ) 241
static noinline long CVE_2010_2537_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
272 /home/speedy/test/source2slice/NVD/CVE_2010_2537_VULN_btrfs_ioctl_clone.c skip = off - key . offset 236
static noinline long CVE_2010_2537_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
if ( skip )  254
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
273 /home/speedy/test/source2slice/NVD/CVE_2010_2537_VULN_btrfs_ioctl_clone.c ret = btrfs_inc_extent_ref ( trans , root , disko , diskl , 0 , root -> root_key . objectid , inode -> i_ino , new_key . offset - datao ) 225
static noinline long CVE_2010_2537_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 disko = 0 , diskl = 0 ; 154
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
disko = btrfs_file_extent_disk_bytenr ( leaf , extent ); 169
diskl = btrfs_file_extent_disk_num_bytes ( leaf , extent ); 171
datao = btrfs_file_extent_offset ( leaf , extent ); 173
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( off > key . offset )  207
datao += off - key . offset; 208
if ( ! disko )  216
datao = 0; 217
if ( disko )  223
ret = btrfs_inc_extent_ref ( trans , root , disko , diskl , 0 , root -> root_key . objectid , inode -> i_ino , new_key . offset - datao ); 225
BUG_ON ( ret ); 230
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
return ret ; 299
------------------------------
274 /home/speedy/test/source2slice/NVD/CVE_2010_2537_VULN_btrfs_ioctl_clone.c datal = off + len - key . offset 213
static noinline long CVE_2010_2537_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( off > key . offset )  207
datal -= off - key . offset; 209
if ( key . offset + datal > off + len )  212
datal = off + len - key . offset; 213
btrfs_set_file_extent_num_bytes ( leaf , extent , datal ); 221
inode_add_bytes ( inode , datal ); 224
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
key . offset ++; 274
------------------------------
275 /home/speedy/test/source2slice/NVD/CVE_2010_2537_VULN_btrfs_ioctl_clone.c new_key . offset = key . offset + destoff - off 189
static noinline long CVE_2010_2537_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
ret = btrfs_inc_extent_ref ( trans , root , disko , diskl , 0 , root -> root_key . objectid , inode -> i_ino , new_key . offset - datao ); 225
BUG_ON ( ret ); 230
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
return ret ; 299
------------------------------
276 /home/speedy/test/source2slice/NVD/CVE_2010_2537_VULN_btrfs_ioctl_clone.c ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ) 103
static noinline long CVE_2010_2537_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_path * path ; 9
char * buf ; 11
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
while ( 1 )  100
struct btrfs_ordered_extent * ordered ; 101
ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ); 103
if ( BTRFS_I ( src ) -> delalloc_bytes == 0 && ! ordered )  104
if ( ordered )  107
btrfs_put_ordered_extent ( ordered ); 108
------------------------------
277 /home/speedy/test/source2slice/NVD/CVE_2010_2537_VULN_btrfs_ioctl_clone.c len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off 90
static noinline long CVE_2010_2537_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_path * path ; 9
char * buf ; 11
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
lock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 102
ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ); 103
if ( BTRFS_I ( src ) -> delalloc_bytes == 0 && ! ordered )  104
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 106
if ( ordered )  107
btrfs_put_ordered_extent ( ordered ); 108
btrfs_wait_ordered_range ( src , off , off + len ); 109
btrfs_drop_extents ( trans , inode , off , off + len , & hint_byte , 1 ); 116
if ( key . offset + datal < off || key . offset >= off + len )  183
if ( key . offset + datal > off + len )  212
datal = off + len - key . offset; 213
btrfs_set_file_extent_num_bytes ( leaf , extent , datal ); 221
inode_add_bytes ( inode , datal ); 224
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
if ( ret == 0 )  279
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 287
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
278 /home/speedy/test/source2slice/NVD/CVE_2010_2537_VULN_btrfs_ioctl_clone.c olen = len = src -> i_size - off 87
static noinline long CVE_2010_2537_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_path * path ; 9
char * buf ; 11
int ret ; 15
u64 len = olen ; 16
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
lock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 102
ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ); 103
if ( BTRFS_I ( src ) -> delalloc_bytes == 0 && ! ordered )  104
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 106
if ( ordered )  107
btrfs_put_ordered_extent ( ordered ); 108
btrfs_wait_ordered_range ( src , off , off + len ); 109
btrfs_drop_extents ( trans , inode , off , off + len , & hint_byte , 1 ); 116
if ( key . offset + datal < off || key . offset >= off + len )  183
if ( key . offset + datal > off + len )  212
datal = off + len - key . offset; 213
btrfs_set_file_extent_num_bytes ( leaf , extent , datal ); 221
inode_add_bytes ( inode , datal ); 224
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
if ( ret == 0 )  279
if ( destoff + olen > inode -> i_size )  281
btrfs_i_size_write ( inode , destoff + olen ); 282
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 287
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
279 /home/speedy/test/source2slice/NVD/CVE_2010_2538_PATCHED_btrfs_ioctl_clone.c trim = key . offset + datal - ( off + len ) 241
static noinline long CVE_2010_2538_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
280 /home/speedy/test/source2slice/NVD/CVE_2010_2538_PATCHED_btrfs_ioctl_clone.c skip = off - key . offset 236
static noinline long CVE_2010_2538_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
if ( skip )  254
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
281 /home/speedy/test/source2slice/NVD/CVE_2010_2538_PATCHED_btrfs_ioctl_clone.c ret = btrfs_inc_extent_ref ( trans , root , disko , diskl , 0 , root -> root_key . objectid , inode -> i_ino , new_key . offset - datao ) 225
static noinline long CVE_2010_2538_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 disko = 0 , diskl = 0 ; 154
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
disko = btrfs_file_extent_disk_bytenr ( leaf , extent ); 169
diskl = btrfs_file_extent_disk_num_bytes ( leaf , extent ); 171
datao = btrfs_file_extent_offset ( leaf , extent ); 173
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( off > key . offset )  207
datao += off - key . offset; 208
if ( ! disko )  216
datao = 0; 217
if ( disko )  223
ret = btrfs_inc_extent_ref ( trans , root , disko , diskl , 0 , root -> root_key . objectid , inode -> i_ino , new_key . offset - datao ); 225
BUG_ON ( ret ); 230
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
return ret ; 299
------------------------------
282 /home/speedy/test/source2slice/NVD/CVE_2010_2538_PATCHED_btrfs_ioctl_clone.c datal = off + len - key . offset 213
static noinline long CVE_2010_2538_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( off > key . offset )  207
datal -= off - key . offset; 209
if ( key . offset + datal > off + len )  212
datal = off + len - key . offset; 213
btrfs_set_file_extent_num_bytes ( leaf , extent , datal ); 221
inode_add_bytes ( inode , datal ); 224
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
key . offset ++; 274
------------------------------
283 /home/speedy/test/source2slice/NVD/CVE_2010_2538_PATCHED_btrfs_ioctl_clone.c new_key . offset = key . offset + destoff - off 189
static noinline long CVE_2010_2538_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
ret = btrfs_inc_extent_ref ( trans , root , disko , diskl , 0 , root -> root_key . objectid , inode -> i_ino , new_key . offset - datao ); 225
BUG_ON ( ret ); 230
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
return ret ; 299
------------------------------
284 /home/speedy/test/source2slice/NVD/CVE_2010_2538_PATCHED_btrfs_ioctl_clone.c ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ) 103
static noinline long CVE_2010_2538_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_path * path ; 9
char * buf ; 11
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
while ( 1 )  100
struct btrfs_ordered_extent * ordered ; 101
ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ); 103
if ( BTRFS_I ( src ) -> delalloc_bytes == 0 && ! ordered )  104
if ( ordered )  107
btrfs_put_ordered_extent ( ordered ); 108
------------------------------
285 /home/speedy/test/source2slice/NVD/CVE_2010_2538_PATCHED_btrfs_ioctl_clone.c len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off 90
static noinline long CVE_2010_2538_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_path * path ; 9
char * buf ; 11
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
lock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 102
ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ); 103
if ( BTRFS_I ( src ) -> delalloc_bytes == 0 && ! ordered )  104
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 106
if ( ordered )  107
btrfs_put_ordered_extent ( ordered ); 108
btrfs_wait_ordered_range ( src , off , off + len ); 109
btrfs_drop_extents ( trans , inode , off , off + len , & hint_byte , 1 ); 116
if ( key . offset + datal < off || key . offset >= off + len )  183
if ( key . offset + datal > off + len )  212
datal = off + len - key . offset; 213
btrfs_set_file_extent_num_bytes ( leaf , extent , datal ); 221
inode_add_bytes ( inode , datal ); 224
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
if ( ret == 0 )  279
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 287
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
286 /home/speedy/test/source2slice/NVD/CVE_2010_2538_PATCHED_btrfs_ioctl_clone.c olen = len = src -> i_size - off 87
static noinline long CVE_2010_2538_PATCHED_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_path * path ; 9
char * buf ; 11
int ret ; 15
u64 len = olen ; 16
if ( ! ( file -> f_mode & FMODE_WRITE ) || ( file -> f_flags & O_APPEND ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
if ( off + len > src -> i_size || off + len < off )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
lock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 102
ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ); 103
if ( BTRFS_I ( src ) -> delalloc_bytes == 0 && ! ordered )  104
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 106
if ( ordered )  107
btrfs_put_ordered_extent ( ordered ); 108
btrfs_wait_ordered_range ( src , off , off + len ); 109
btrfs_drop_extents ( trans , inode , off , off + len , & hint_byte , 1 ); 116
if ( key . offset + datal < off || key . offset >= off + len )  183
if ( key . offset + datal > off + len )  212
datal = off + len - key . offset; 213
btrfs_set_file_extent_num_bytes ( leaf , extent , datal ); 221
inode_add_bytes ( inode , datal ); 224
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
if ( ret == 0 )  279
if ( destoff + olen > inode -> i_size )  281
btrfs_i_size_write ( inode , destoff + olen ); 282
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 287
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
287 /home/speedy/test/source2slice/NVD/CVE_2010_2538_VULN_btrfs_ioctl_clone.c trim = key . offset + datal - ( off + len ) 241
static noinline long CVE_2010_2538_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
ret = - EISDIR; 54
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
ret = - EXDEV; 58
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
288 /home/speedy/test/source2slice/NVD/CVE_2010_2538_VULN_btrfs_ioctl_clone.c skip = off - key . offset 236
static noinline long CVE_2010_2538_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
ret = - EISDIR; 54
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
ret = - EXDEV; 58
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
if ( skip )  254
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
289 /home/speedy/test/source2slice/NVD/CVE_2010_2538_VULN_btrfs_ioctl_clone.c ret = btrfs_inc_extent_ref ( trans , root , disko , diskl , 0 , root -> root_key . objectid , inode -> i_ino , new_key . offset - datao ) 225
static noinline long CVE_2010_2538_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
ret = - EISDIR; 54
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
ret = - EXDEV; 58
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 disko = 0 , diskl = 0 ; 154
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
disko = btrfs_file_extent_disk_bytenr ( leaf , extent ); 169
diskl = btrfs_file_extent_disk_num_bytes ( leaf , extent ); 171
datao = btrfs_file_extent_offset ( leaf , extent ); 173
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( off > key . offset )  207
datao += off - key . offset; 208
if ( ! disko )  216
datao = 0; 217
if ( disko )  223
ret = btrfs_inc_extent_ref ( trans , root , disko , diskl , 0 , root -> root_key . objectid , inode -> i_ino , new_key . offset - datao ); 225
BUG_ON ( ret ); 230
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
return ret ; 299
------------------------------
290 /home/speedy/test/source2slice/NVD/CVE_2010_2538_VULN_btrfs_ioctl_clone.c datal = off + len - key . offset 213
static noinline long CVE_2010_2538_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
ret = - EISDIR; 54
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
ret = - EXDEV; 58
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
if ( off > key . offset )  207
datal -= off - key . offset; 209
if ( key . offset + datal > off + len )  212
datal = off + len - key . offset; 213
btrfs_set_file_extent_num_bytes ( leaf , extent , datal ); 221
inode_add_bytes ( inode , datal ); 224
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
key . offset ++; 274
------------------------------
291 /home/speedy/test/source2slice/NVD/CVE_2010_2538_VULN_btrfs_ioctl_clone.c new_key . offset = key . offset + destoff - off 189
static noinline long CVE_2010_2538_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_trans_handle * trans ; 8
struct btrfs_path * path ; 9
struct extent_buffer * leaf ; 10
char * buf ; 11
struct btrfs_key key ; 12
u32 nritems ; 13
int slot ; 14
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
ret = - EISDIR; 54
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
ret = - EXDEV; 58
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
ret = - ENOMEM; 62
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
path -> reada = 2; 72
ret = - EINVAL; 83
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
trans = btrfs_start_transaction ( root , 1 ); 112
key . objectid = src -> i_ino; 119
key . type = BTRFS_EXTENT_DATA_KEY; 120
key . offset = 0; 121
while ( 1 )  123
ret = btrfs_search_slot ( trans , root , & key , path , 0 , 0 ); 128
if ( ret < 0 )  129
nritems = btrfs_header_nritems ( path -> nodes [ 0 ] ); 132
if ( path -> slots [ 0 ] >= nritems )  133
ret = btrfs_next_leaf ( root , path ); 134
if ( ret < 0 )  135
if ( ret > 0 )  137
leaf = path -> nodes [ 0 ]; 141
slot = path -> slots [ 0 ]; 142
if ( btrfs_key_type ( & key ) > BTRFS_EXTENT_DATA_KEY || key . objectid != src -> i_ino )  145
if ( btrfs_key_type ( & key ) == BTRFS_EXTENT_DATA_KEY )  149
struct btrfs_file_extent_item * extent ; 150
int type ; 151
u32 size ; 152
struct btrfs_key new_key ; 153
u64 datao = 0 , datal = 0 ; 155
u8 comp ; 156
size = btrfs_item_size_nr ( leaf , slot ); 158
extent = btrfs_item_ptr ( leaf , slot ,
struct btrfs_file_extent_item ) 164
comp = btrfs_file_extent_compression ( leaf , extent ); 165
type = btrfs_file_extent_type ( leaf , extent ); 166
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  167
datal = btrfs_file_extent_num_bytes ( leaf , extent ); 174
if ( type == BTRFS_FILE_EXTENT_INLINE )  176
datal = btrfs_file_extent_ram_bytes ( leaf , extent ); 178
if ( key . offset + datal < off || key . offset >= off + len )  183
memcpy ( & new_key , & key , sizeof ( new_key ) ); 187
new_key . objectid = inode -> i_ino; 188
new_key . offset = key . offset + destoff - off; 189
if ( type == BTRFS_FILE_EXTENT_REG || type == BTRFS_FILE_EXTENT_PREALLOC )  191
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 193
if ( ret )  195
ret = btrfs_inc_extent_ref ( trans , root , disko , diskl , 0 , root -> root_key . objectid , inode -> i_ino , new_key . offset - datao ); 225
BUG_ON ( ret ); 230
if ( type == BTRFS_FILE_EXTENT_INLINE )  232
u64 skip = 0 ; 233
u64 trim = 0 ; 234
if ( off > key . offset )  235
skip = off - key . offset; 236
new_key . offset += skip; 237
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
key . offset ++; 274
if ( ret == 0 )  279
if ( ret )  288
return ret ; 299
------------------------------
292 /home/speedy/test/source2slice/NVD/CVE_2010_2538_VULN_btrfs_ioctl_clone.c ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ) 103
static noinline long CVE_2010_2538_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_path * path ; 9
char * buf ; 11
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
while ( 1 )  100
struct btrfs_ordered_extent * ordered ; 101
ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ); 103
if ( BTRFS_I ( src ) -> delalloc_bytes == 0 && ! ordered )  104
if ( ordered )  107
btrfs_put_ordered_extent ( ordered ); 108
------------------------------
293 /home/speedy/test/source2slice/NVD/CVE_2010_2538_VULN_btrfs_ioctl_clone.c len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off 90
static noinline long CVE_2010_2538_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_path * path ; 9
char * buf ; 11
int ret ; 15
u64 len = olen ; 16
u64 bs = root -> fs_info -> sb -> s_blocksize ; 17
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
len = ( ( src -> i_size + bs - 1 ) & ~ ( bs - 1 ) ) - off; 90
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
lock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 102
ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ); 103
if ( BTRFS_I ( src ) -> delalloc_bytes == 0 && ! ordered )  104
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 106
if ( ordered )  107
btrfs_put_ordered_extent ( ordered ); 108
btrfs_wait_ordered_range ( src , off , off + len ); 109
btrfs_drop_extents ( trans , inode , off , off + len , & hint_byte , 1 ); 116
if ( key . offset + datal < off || key . offset >= off + len )  183
if ( key . offset + datal > off + len )  212
datal = off + len - key . offset; 213
btrfs_set_file_extent_num_bytes ( leaf , extent , datal ); 221
inode_add_bytes ( inode , datal ); 224
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
if ( ret == 0 )  279
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 287
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
294 /home/speedy/test/source2slice/NVD/CVE_2010_2538_VULN_btrfs_ioctl_clone.c olen = len = src -> i_size - off 87
static noinline long CVE_2010_2538_VULN_btrfs_ioctl_clone(struct file *file, unsigned long srcfd,
u64 off, u64 olen, u64 destoff) 2
struct inode * inode = fdentry ( file ) -> d_inode ; 4
struct btrfs_root * root = BTRFS_I ( inode ) -> root ; 5
struct file * src_file ; 6
struct inode * src ; 7
struct btrfs_path * path ; 9
char * buf ; 11
int ret ; 15
u64 len = olen ; 16
if ( ! ( file -> f_mode & FMODE_WRITE ) )  31
ret = mnt_want_write ( file -> f_path . mnt ); 34
if ( ret )  35
src_file = fget ( srcfd ); 38
if ( ! src_file )  39
src = src_file -> f_dentry -> d_inode; 44
if ( src == inode )  47
if ( ! ( src_file -> f_mode & FMODE_READ ) )  51
if ( S_ISDIR ( src -> i_mode ) || S_ISDIR ( inode -> i_mode ) )  55
if ( src -> i_sb != inode -> i_sb || BTRFS_I ( src ) -> root != root )  59
buf = vmalloc ( btrfs_level_size ( root , 0 ) ); 63
if ( ! buf )  64
path = btrfs_alloc_path ( ); 67
if ( ! path )  68
if ( off >= src -> i_size || off + len > src -> i_size )  84
if ( len == 0 )  86
olen = len = src -> i_size - off; 87
if ( off + len == src -> i_size )  89
if ( ( off & ( bs - 1 ) ) || ( ( off + len ) & ( bs - 1 ) ) )  94
lock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 102
ordered = btrfs_lookup_first_ordered_extent ( inode , off + len ); 103
if ( BTRFS_I ( src ) -> delalloc_bytes == 0 && ! ordered )  104
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 106
if ( ordered )  107
btrfs_put_ordered_extent ( ordered ); 108
btrfs_wait_ordered_range ( src , off , off + len ); 109
btrfs_drop_extents ( trans , inode , off , off + len , & hint_byte , 1 ); 116
if ( key . offset + datal < off || key . offset >= off + len )  183
if ( key . offset + datal > off + len )  212
datal = off + len - key . offset; 213
btrfs_set_file_extent_num_bytes ( leaf , extent , datal ); 221
inode_add_bytes ( inode , datal ); 224
if ( key . offset + datal > off + len )  240
trim = key . offset + datal - ( off + len ); 241
if ( comp && ( skip || trim ) )  243
size -= skip + trim; 247
datal -= skip + trim; 248
ret = btrfs_insert_empty_item ( trans , root , path , & new_key , size ); 249
if ( ret )  251
memmove ( buf + start , buf + start + skip , datal ); 257
write_extent_buffer ( leaf , buf , btrfs_item_ptr_offset ( leaf , slot ) , size ); 263
inode_add_bytes ( inode , datal ); 266
if ( ret == 0 )  279
if ( destoff + olen > inode -> i_size )  281
btrfs_i_size_write ( inode , destoff + olen ); 282
unlock_extent ( & BTRFS_I ( src ) -> io_tree , off , off + len , GFP_NOFS ); 287
if ( ret )  288
vfree ( buf ); 293
return ret ; 299
------------------------------
295 /home/speedy/test/source2slice/NVD/CVE_2010_2803_PATCHED_drm_ioctl.c ioctl = & dev -> driver -> ioctls [ nr - DRM_COMMAND_BASE ] 28
long CVE_2010_2803_PATCHED_drm_ioctl(struct file *filp,
unsigned int cmd, unsigned long arg) 2
struct drm_file * file_priv = filp -> private_data ; 4
struct drm_device * dev ; 5
struct drm_ioctl_desc * ioctl ; 6
unsigned int nr = DRM_IOCTL_NR ( cmd ) ; 8
dev = file_priv -> minor -> dev; 13
if ( ( nr >= DRM_CORE_IOCTL_COUNT ) && ( ( nr < DRM_COMMAND_BASE ) || ( nr >= DRM_COMMAND_END ) ) )  23
if ( ( nr >= DRM_COMMAND_BASE ) && ( nr < DRM_COMMAND_END ) && ( nr < DRM_COMMAND_BASE + dev -> driver -> num_ioctls ) )  26
ioctl = & dev -> driver -> ioctls [ nr - DRM_COMMAND_BASE ]; 28
func = ioctl -> func; 36
if ( ! func )  41
if ( ( ( ioctl -> flags & DRM_ROOT_ONLY ) && ! capable ( CAP_SYS_ADMIN ) ) || ( ( ioctl -> flags & DRM_AUTH ) && ! file_priv -> authenticated ) || ( ( ioctl -> flags & DRM_MASTER ) && ! file_priv -> is_master ) || ( ! ( ioctl -> flags & DRM_CONTROL_ALLOW ) && ( file_priv -> minor -> type == DRM_MINOR_CONTROL ) ) )  44
if ( ioctl -> flags & DRM_UNLOCKED )  71
retcode = func ( dev , kdata , file_priv ); 72
retcode = func ( dev , kdata , file_priv ); 75
if ( retcode )  90
DRM_DEBUG ( "ret = %x\n" , retcode ); 91
return retcode ; 92
------------------------------
296 /home/speedy/test/source2slice/NVD/CVE_2010_2803_VULN_drm_ioctl.c ioctl = & dev -> driver -> ioctls [ nr - DRM_COMMAND_BASE ] 28
long CVE_2010_2803_VULN_drm_ioctl(struct file *filp,
unsigned int cmd, unsigned long arg) 2
struct drm_file * file_priv = filp -> private_data ; 4
struct drm_device * dev ; 5
struct drm_ioctl_desc * ioctl ; 6
unsigned int nr = DRM_IOCTL_NR ( cmd ) ; 8
dev = file_priv -> minor -> dev; 13
if ( ( nr >= DRM_CORE_IOCTL_COUNT ) && ( ( nr < DRM_COMMAND_BASE ) || ( nr >= DRM_COMMAND_END ) ) )  23
if ( ( nr >= DRM_COMMAND_BASE ) && ( nr < DRM_COMMAND_END ) && ( nr < DRM_COMMAND_BASE + dev -> driver -> num_ioctls ) )  26
ioctl = & dev -> driver -> ioctls [ nr - DRM_COMMAND_BASE ]; 28
func = ioctl -> func; 36
if ( ! func )  41
if ( ( ( ioctl -> flags & DRM_ROOT_ONLY ) && ! capable ( CAP_SYS_ADMIN ) ) || ( ( ioctl -> flags & DRM_AUTH ) && ! file_priv -> authenticated ) || ( ( ioctl -> flags & DRM_MASTER ) && ! file_priv -> is_master ) || ( ! ( ioctl -> flags & DRM_CONTROL_ALLOW ) && ( file_priv -> minor -> type == DRM_MINOR_CONTROL ) ) )  44
if ( ioctl -> flags & DRM_UNLOCKED )  69
retcode = func ( dev , kdata , file_priv ); 70
retcode = func ( dev , kdata , file_priv ); 73
if ( retcode )  88
DRM_DEBUG ( "ret = %x\n" , retcode ); 89
return retcode ; 90
------------------------------
297 /home/speedy/test/source2slice/NVD/CVE_2010_2805_PATCHED_FT_Stream_EnterFrame.c stream -> limit = stream -> cursor + count 69
CVE_2010_2805_PATCHED_FT_Stream_EnterFrame( FT_Stream  stream,
FT_ULong   count ) 2
if ( stream -> read )  11
if ( stream -> pos >= stream -> size || stream -> size - stream -> pos < count )  56
stream -> cursor = stream -> base + stream -> pos; 68
stream -> limit = stream -> cursor + count; 69
stream -> pos += count; 70
------------------------------
298 /home/speedy/test/source2slice/NVD/CVE_2010_2805_PATCHED_FT_Stream_EnterFrame.c stream -> cursor = stream -> base + stream -> pos 68
CVE_2010_2805_PATCHED_FT_Stream_EnterFrame( FT_Stream  stream,
FT_ULong   count ) 2
if ( stream -> read )  11
if ( stream -> pos >= stream -> size || stream -> size - stream -> pos < count )  56
stream -> cursor = stream -> base + stream -> pos; 68
stream -> limit = stream -> cursor + count; 69
stream -> pos += count; 70
------------------------------
299 /home/speedy/test/source2slice/NVD/CVE_2010_2805_PATCHED_FT_Stream_EnterFrame.c stream -> limit = stream -> cursor + count 50
CVE_2010_2805_PATCHED_FT_Stream_EnterFrame( FT_Stream  stream,
FT_ULong   count ) 2
FT_Error error = FT_Err_Ok ; 4
if ( stream -> read )  11
FT_Memory memory = stream -> memory ; 14
if ( count > stream -> size )  18
stream -> base = ( unsigned char * ) ft_mem_qalloc ( memory , count , & error ); 30
if ( error )  31
stream -> cursor = stream -> base; 49
stream -> limit = stream -> cursor + count; 50
stream -> pos += read_bytes; 51
------------------------------
300 /home/speedy/test/source2slice/NVD/CVE_2010_2805_VULN_FT_Stream_EnterFrame.c stream -> limit = stream -> cursor + count 69
CVE_2010_2805_VULN_FT_Stream_EnterFrame( FT_Stream  stream,
FT_ULong   count ) 2
if ( stream -> read )  11
if ( stream -> pos >= stream -> size || stream -> pos + count > stream -> size )  56
stream -> cursor = stream -> base + stream -> pos; 68
stream -> limit = stream -> cursor + count; 69
stream -> pos += count; 70
------------------------------
301 /home/speedy/test/source2slice/NVD/CVE_2010_2805_VULN_FT_Stream_EnterFrame.c stream -> cursor = stream -> base + stream -> pos 68
CVE_2010_2805_VULN_FT_Stream_EnterFrame( FT_Stream  stream,
FT_ULong   count ) 2
if ( stream -> read )  11
if ( stream -> pos >= stream -> size || stream -> pos + count > stream -> size )  56
stream -> cursor = stream -> base + stream -> pos; 68
stream -> limit = stream -> cursor + count; 69
stream -> pos += count; 70
------------------------------
302 /home/speedy/test/source2slice/NVD/CVE_2010_2805_VULN_FT_Stream_EnterFrame.c stream -> limit = stream -> cursor + count 50
CVE_2010_2805_VULN_FT_Stream_EnterFrame( FT_Stream  stream,
FT_ULong   count ) 2
FT_Error error = FT_Err_Ok ; 4
if ( stream -> read )  11
FT_Memory memory = stream -> memory ; 14
if ( count > stream -> size )  18
stream -> base = ( unsigned char * ) ft_mem_qalloc ( memory , count , & error ); 30
if ( error )  31
stream -> cursor = stream -> base; 49
stream -> limit = stream -> cursor + count; 50
stream -> pos += read_bytes; 51
------------------------------
303 /home/speedy/test/source2slice/NVD/CVE_2010_2806_PATCHED_t42_parse_sfnts.c string_size = ( FT_Long ) ( ( parser -> root . cursor - cur - 2 + 1 ) / 2 ) 66
static void
CVE_2010_2806_PATCHED_t42_parse_sfnts( T42_Face    face,
T42_Loader  loader ) 3
T42_Parser parser = & loader -> parser ; 5
FT_Byte * cur ; 7
FT_Byte * limit = parser -> root . limit ; 8
FT_Int num_tables = 0 ; 10
FT_ULong count , ttf_size = 0 ; 11
FT_Long n , string_size , old_string_size , real_size ; 13
FT_Byte * string_buf = NULL ; 14
FT_Bool allocated = 0 ; 15
T42_Load_Status status ; 17
if ( parser -> root . cursor >= limit || * parser -> root . cursor ++ != '[' )  36
status = BEFORE_START; 44
string_size = 0; 45
old_string_size = 0; 46
count = 0; 47
while ( parser -> root . cursor < limit )  49
cur = parser -> root . cursor; 51
if ( * cur == ']' )  53
if ( * cur == '<' )  59
if ( parser -> root . error )  62
string_size = ( FT_Long ) ( ( parser -> root . cursor - cur - 2 + 1 ) / 2 ); 66
if ( FT_REALLOC ( string_buf , old_string_size , string_size ) )  67
allocated = 1; 70
parser -> root . cursor = cur; 72
( void ) T1_ToBytes ( parser , string_buf , string_size , & real_size , 1 ); 73
old_string_size = string_size; 74
string_size = real_size; 75
if ( ft_isdigit ( * cur ) )  78
if ( allocated )  80
string_size = T1_ToInt ( parser ); 88
if ( string_size < 0 )  89
if ( parser -> root . error )  97
string_buf = parser -> root . cursor + 1; 100
if ( limit - parser -> root . cursor < string_size )  102
parser -> root . cursor += string_size + 1; 109
if ( ! string_buf )  112
if ( string_buf [ string_size - 1 ] == 0 && ( string_size % 2 == 1 ) )  120
string_size --; 121
if ( ! string_size )  123
for ( n = 0; n < string_size; n++ ) 130
switch ( status )  132
if ( count < 12 )  136
face -> ttf_data [ count ++ ] = string_buf [ n ]; 138
num_tables = 16 * face -> ttf_data [ 4 ] + face -> ttf_data [ 5 ]; 143
status = BEFORE_TABLE_DIR; 144
ttf_size = 12 + 16 * num_tables; 145
if ( FT_REALLOC ( face -> ttf_data , 12 , ttf_size ) )  147
if ( count < ttf_size )  154
face -> ttf_data [ count ++ ] = string_buf [ n ]; 156
int i ; 161
FT_ULong len ; 162
for ( i = 0; i < num_tables; i++ ) 165
FT_Byte * p = face -> ttf_data + 12 + 16 * i + 12 ; 167
len = FT_PEEK_ULONG ( p ); 170
ttf_size += ( len + 3 ) & ~3; 173
status = OTHER_TABLES; 176
face -> ttf_size = ttf_size; 177
if ( FT_REALLOC ( face -> ttf_data , 12 + 16 * num_tables , ttf_size + 1 ) )  180
if ( count >= ttf_size )  188
face -> ttf_data [ count ++ ] = string_buf [ n ]; 194
------------------------------
304 /home/speedy/test/source2slice/NVD/CVE_2010_2806_VULN_t42_parse_sfnts.c string_size = ( FT_Long ) ( ( parser -> root . cursor - cur - 2 + 1 ) / 2 ) 66
static void
CVE_2010_2806_VULN_t42_parse_sfnts( T42_Face    face,
T42_Loader  loader ) 3
T42_Parser parser = & loader -> parser ; 5
FT_Byte * cur ; 7
FT_Byte * limit = parser -> root . limit ; 8
FT_Int num_tables = 0 ; 10
FT_ULong count , ttf_size = 0 ; 11
FT_Long n , string_size , old_string_size , real_size ; 13
FT_Byte * string_buf = NULL ; 14
FT_Bool allocated = 0 ; 15
T42_Load_Status status ; 17
if ( parser -> root . cursor >= limit || * parser -> root . cursor ++ != '[' )  36
status = BEFORE_START; 44
string_size = 0; 45
old_string_size = 0; 46
count = 0; 47
while ( parser -> root . cursor < limit )  49
cur = parser -> root . cursor; 51
if ( * cur == ']' )  53
if ( * cur == '<' )  59
if ( parser -> root . error )  62
string_size = ( FT_Long ) ( ( parser -> root . cursor - cur - 2 + 1 ) / 2 ); 66
if ( FT_REALLOC ( string_buf , old_string_size , string_size ) )  67
allocated = 1; 70
parser -> root . cursor = cur; 72
( void ) T1_ToBytes ( parser , string_buf , string_size , & real_size , 1 ); 73
old_string_size = string_size; 74
string_size = real_size; 75
if ( ft_isdigit ( * cur ) )  78
if ( allocated )  80
string_size = T1_ToInt ( parser ); 88
if ( parser -> root . error )  91
string_buf = parser -> root . cursor + 1; 94
parser -> root . cursor += string_size + 1; 96
if ( parser -> root . cursor >= limit )  97
if ( ! string_buf )  105
if ( string_buf [ string_size - 1 ] == 0 && ( string_size % 2 == 1 ) )  113
string_size --; 114
if ( ! string_size )  116
for ( n = 0; n < string_size; n++ ) 123
switch ( status )  125
if ( count < 12 )  129
face -> ttf_data [ count ++ ] = string_buf [ n ]; 131
num_tables = 16 * face -> ttf_data [ 4 ] + face -> ttf_data [ 5 ]; 136
status = BEFORE_TABLE_DIR; 137
ttf_size = 12 + 16 * num_tables; 138
if ( FT_REALLOC ( face -> ttf_data , 12 , ttf_size ) )  140
if ( count < ttf_size )  147
face -> ttf_data [ count ++ ] = string_buf [ n ]; 149
int i ; 154
FT_ULong len ; 155
for ( i = 0; i < num_tables; i++ ) 158
FT_Byte * p = face -> ttf_data + 12 + 16 * i + 12 ; 160
len = FT_PEEK_ULONG ( p ); 163
ttf_size += ( len + 3 ) & ~3; 166
status = OTHER_TABLES; 169
face -> ttf_size = ttf_size; 170
if ( FT_REALLOC ( face -> ttf_data , 12 + 16 * num_tables , ttf_size + 1 ) )  173
if ( count >= ttf_size )  181
face -> ttf_data [ count ++ ] = string_buf [ n ]; 187
------------------------------
305 /home/speedy/test/source2slice/NVD/CVE_2010_2962_PATCHED_i915_gem_gtt_pwrite_fast.c page_length = PAGE_SIZE - page_offset 42
static int
CVE_2010_2962_PATCHED_i915_gem_gtt_pwrite_fast(struct drm_device *dev, struct drm_gem_object *obj,
struct drm_i915_gem_pwrite *args,
struct drm_file *file_priv) 4
drm_i915_private_t * dev_priv = dev -> dev_private ; 7
ssize_t remain ; 8
loff_t offset , page_base ; 9
char __user * user_data ; 10
int page_offset , page_length ; 11
int ret ; 12
user_data = ( char __user * ) ( uintptr_t ) args -> data_ptr; 14
remain = args -> size; 15
ret = i915_gem_object_pin ( obj , 0 ); 19
if ( ret )  20
ret = i915_gem_object_set_to_gtt_domain ( obj , 1 ); 24
if ( ret )  25
obj_priv = to_intel_bo ( obj ); 28
offset = obj_priv -> gtt_offset + args -> offset; 29
while ( remain > 0 )  31
page_base = ( offset & ~ ( PAGE_SIZE - 1 ) ); 38
page_offset = offset & ( PAGE_SIZE - 1 ); 39
page_length = remain; 40
if ( ( page_offset + remain ) > PAGE_SIZE )  41
page_length = PAGE_SIZE - page_offset; 42
ret = fast_user_write ( dev_priv -> mm . gtt_mapping , page_base , page_offset , user_data , page_length ); 44
if ( ret )  51
remain -= page_length; 54
user_data += page_length; 55
offset += page_length; 56
return ret ; 63
------------------------------
306 /home/speedy/test/source2slice/NVD/CVE_2010_2962_PATCHED_i915_gem_gtt_pwrite_fast.c offset = obj_priv -> gtt_offset + args -> offset 29
static int
CVE_2010_2962_PATCHED_i915_gem_gtt_pwrite_fast(struct drm_device *dev, struct drm_gem_object *obj,
struct drm_i915_gem_pwrite *args,
struct drm_file *file_priv) 4
loff_t offset , page_base ; 9
int ret ; 12
ret = i915_gem_object_pin ( obj , 0 ); 19
if ( ret )  20
ret = i915_gem_object_set_to_gtt_domain ( obj , 1 ); 24
if ( ret )  25
obj_priv = to_intel_bo ( obj ); 28
offset = obj_priv -> gtt_offset + args -> offset; 29
while ( remain > 0 )  31
page_base = ( offset & ~ ( PAGE_SIZE - 1 ) ); 38
page_offset = offset & ( PAGE_SIZE - 1 ); 39
page_length = remain; 40
if ( ( page_offset + remain ) > PAGE_SIZE )  41
page_length = PAGE_SIZE - page_offset; 42
ret = fast_user_write ( dev_priv -> mm . gtt_mapping , page_base , page_offset , user_data , page_length ); 44
if ( ret )  51
remain -= page_length; 54
user_data += page_length; 55
offset += page_length; 56
return ret ; 63
------------------------------
307 /home/speedy/test/source2slice/NVD/CVE_2010_2962_VULN_i915_gem_gtt_pwrite_fast.c page_length = PAGE_SIZE - page_offset 44
static int
CVE_2010_2962_VULN_i915_gem_gtt_pwrite_fast(struct drm_device *dev, struct drm_gem_object *obj,
struct drm_i915_gem_pwrite *args,
struct drm_file *file_priv) 4
drm_i915_private_t * dev_priv = dev -> dev_private ; 7
ssize_t remain ; 8
loff_t offset , page_base ; 9
char __user * user_data ; 10
int page_offset , page_length ; 11
int ret ; 12
user_data = ( char __user * ) ( uintptr_t ) args -> data_ptr; 14
remain = args -> size; 15
if ( ! access_ok ( VERIFY_READ , user_data , remain ) )  16
ret = i915_gem_object_pin ( obj , 0 ); 21
if ( ret )  22
ret = i915_gem_object_set_to_gtt_domain ( obj , 1 ); 26
if ( ret )  27
obj_priv = to_intel_bo ( obj ); 30
offset = obj_priv -> gtt_offset + args -> offset; 31
while ( remain > 0 )  33
page_base = ( offset & ~ ( PAGE_SIZE - 1 ) ); 40
page_offset = offset & ( PAGE_SIZE - 1 ); 41
page_length = remain; 42
if ( ( page_offset + remain ) > PAGE_SIZE )  43
page_length = PAGE_SIZE - page_offset; 44
ret = fast_user_write ( dev_priv -> mm . gtt_mapping , page_base , page_offset , user_data , page_length ); 46
if ( ret )  53
remain -= page_length; 56
user_data += page_length; 57
offset += page_length; 58
return ret ; 65
------------------------------
308 /home/speedy/test/source2slice/NVD/CVE_2010_2962_VULN_i915_gem_gtt_pwrite_fast.c offset = obj_priv -> gtt_offset + args -> offset 31
static int
CVE_2010_2962_VULN_i915_gem_gtt_pwrite_fast(struct drm_device *dev, struct drm_gem_object *obj,
struct drm_i915_gem_pwrite *args,
struct drm_file *file_priv) 4
ssize_t remain ; 8
loff_t offset , page_base ; 9
char __user * user_data ; 10
int ret ; 12
user_data = ( char __user * ) ( uintptr_t ) args -> data_ptr; 14
remain = args -> size; 15
if ( ! access_ok ( VERIFY_READ , user_data , remain ) )  16
ret = i915_gem_object_pin ( obj , 0 ); 21
if ( ret )  22
ret = i915_gem_object_set_to_gtt_domain ( obj , 1 ); 26
if ( ret )  27
obj_priv = to_intel_bo ( obj ); 30
offset = obj_priv -> gtt_offset + args -> offset; 31
while ( remain > 0 )  33
page_base = ( offset & ~ ( PAGE_SIZE - 1 ) ); 40
page_offset = offset & ( PAGE_SIZE - 1 ); 41
page_length = remain; 42
if ( ( page_offset + remain ) > PAGE_SIZE )  43
page_length = PAGE_SIZE - page_offset; 44
ret = fast_user_write ( dev_priv -> mm . gtt_mapping , page_base , page_offset , user_data , page_length ); 46
if ( ret )  53
remain -= page_length; 56
user_data += page_length; 57
offset += page_length; 58
return ret ; 65
------------------------------
309 /home/speedy/test/source2slice/NVD/CVE_2010_3015_PATCHED_ext4_ext_get_blocks.c allocated = ee_len - ( iblock - ee_block ) 84
int CVE_2010_3015_PATCHED_ext4_ext_get_blocks(handle_t *handle, struct inode *inode,
ext4_lblk_t iblock,
unsigned int max_blocks, struct buffer_head *bh_result,
int flags) 4
struct ext4_extent newex , * ex ; 8
cache_type = ext4_ext_in_cache ( inode , iblock , & newex ); 20
if ( cache_type )  21
if ( cache_type == EXT4_EXT_CACHE_GAP )  22
if ( ( flags & EXT4_GET_BLOCKS_CREATE ) == 0 )  23
if ( cache_type == EXT4_EXT_CACHE_EXTENT )  31
path = ext4_ext_find_extent ( inode , iblock , NULL ); 46
if ( IS_ERR ( path ) )  47
depth = ext_depth ( inode ); 53
if ( path [ depth ] . p_ext == NULL && depth != 0 )  60
ex = path [ depth ] . p_ext; 69
if ( ex )  70
ext4_lblk_t ee_block = le32_to_cpu ( ex -> ee_block ) ; 71
unsigned short ee_len ; 73
ee_len = ext4_ext_get_actual_len ( ex ); 79
if ( in_range ( iblock , ee_block , ee_len ) )  81
allocated = ee_len - ( iblock - ee_block ); 84
ret = ext4_ext_handle_uninitialized_extents ( handle , inode , iblock , max_blocks , path , flags , allocated , bh_result , newblock ); 95
return ret ; 98
if ( allocated > max_blocks )  225
return err ? err : allocated ; 236
------------------------------
310 /home/speedy/test/source2slice/NVD/CVE_2010_3015_PATCHED_ext4_ext_get_blocks.c newblock = iblock - ee_block + ee_start 82
int CVE_2010_3015_PATCHED_ext4_ext_get_blocks(handle_t *handle, struct inode *inode,
ext4_lblk_t iblock,
unsigned int max_blocks, struct buffer_head *bh_result,
int flags) 4
struct ext4_extent newex , * ex ; 8
ext4_fsblk_t newblock ; 9
cache_type = ext4_ext_in_cache ( inode , iblock , & newex ); 20
if ( cache_type )  21
if ( cache_type == EXT4_EXT_CACHE_GAP )  22
if ( ( flags & EXT4_GET_BLOCKS_CREATE ) == 0 )  23
if ( cache_type == EXT4_EXT_CACHE_EXTENT )  31
path = ext4_ext_find_extent ( inode , iblock , NULL ); 46
if ( IS_ERR ( path ) )  47
depth = ext_depth ( inode ); 53
if ( path [ depth ] . p_ext == NULL && depth != 0 )  60
ex = path [ depth ] . p_ext; 69
if ( ex )  70
ext4_lblk_t ee_block = le32_to_cpu ( ex -> ee_block ) ; 71
ext4_fsblk_t ee_start = ext_pblock ( ex ) ; 72
unsigned short ee_len ; 73
ee_len = ext4_ext_get_actual_len ( ex ); 79
if ( in_range ( iblock , ee_block , ee_len ) )  81
newblock = iblock - ee_block + ee_start; 82
ext_debug ( "%u fit into %u:%d -> %llu\n" , iblock , ee_block , ee_len , newblock ); 85
ret = ext4_ext_handle_uninitialized_extents ( handle , inode , iblock , max_blocks , path , flags , allocated , bh_result , newblock ); 95
return ret ; 98
bh_result -> b_blocknr = newblock; 230
------------------------------
311 /home/speedy/test/source2slice/NVD/CVE_2010_3015_PATCHED_ext4_ext_get_blocks.c allocated = ext4_ext_get_actual_len ( & newex ) - ( iblock - le32_to_cpu ( newex . ee_block ) ) 37
int CVE_2010_3015_PATCHED_ext4_ext_get_blocks(handle_t *handle, struct inode *inode,
ext4_lblk_t iblock,
unsigned int max_blocks, struct buffer_head *bh_result,
int flags) 4
struct ext4_extent newex , * ex ; 8
cache_type = ext4_ext_in_cache ( inode , iblock , & newex ); 20
if ( cache_type )  21
if ( cache_type == EXT4_EXT_CACHE_GAP )  22
if ( cache_type == EXT4_EXT_CACHE_EXTENT )  31
allocated = ext4_ext_get_actual_len ( & newex ) - ( iblock - le32_to_cpu ( newex . ee_block ) ); 37
if ( allocated > max_blocks )  225
return err ? err : allocated ; 236
------------------------------
312 /home/speedy/test/source2slice/NVD/CVE_2010_3015_PATCHED_ext4_ext_get_blocks.c newblock = iblock - le32_to_cpu ( newex . ee_block ) + ext_pblock ( & newex ) 33
int CVE_2010_3015_PATCHED_ext4_ext_get_blocks(handle_t *handle, struct inode *inode,
ext4_lblk_t iblock,
unsigned int max_blocks, struct buffer_head *bh_result,
int flags) 4
struct ext4_extent newex , * ex ; 8
ext4_fsblk_t newblock ; 9
cache_type = ext4_ext_in_cache ( inode , iblock , & newex ); 20
if ( cache_type )  21
if ( cache_type == EXT4_EXT_CACHE_GAP )  22
if ( cache_type == EXT4_EXT_CACHE_EXTENT )  31
newblock = iblock - le32_to_cpu ( newex . ee_block ) + ext_pblock ( & newex ); 33
bh_result -> b_blocknr = newblock; 230
------------------------------
313 /home/speedy/test/source2slice/NVD/CVE_2010_3015_VULN_ext4_ext_get_blocks.c allocated = ee_len - ( iblock - ee_block ) 84
int CVE_2010_3015_VULN_ext4_ext_get_blocks(handle_t *handle, struct inode *inode,
ext4_lblk_t iblock,
unsigned int max_blocks, struct buffer_head *bh_result,
int flags) 4
struct ext4_extent newex , * ex ; 8
cache_type = ext4_ext_in_cache ( inode , iblock , & newex ); 20
if ( cache_type )  21
if ( cache_type == EXT4_EXT_CACHE_GAP )  22
if ( ( flags & EXT4_GET_BLOCKS_CREATE ) == 0 )  23
if ( cache_type == EXT4_EXT_CACHE_EXTENT )  31
path = ext4_ext_find_extent ( inode , iblock , NULL ); 46
if ( IS_ERR ( path ) )  47
depth = ext_depth ( inode ); 53
if ( path [ depth ] . p_ext == NULL && depth != 0 )  60
ex = path [ depth ] . p_ext; 69
if ( ex )  70
ext4_lblk_t ee_block = le32_to_cpu ( ex -> ee_block ) ; 71
unsigned short ee_len ; 73
ee_len = ext4_ext_get_actual_len ( ex ); 79
if ( iblock >= ee_block && iblock < ee_block + ee_len )  81
allocated = ee_len - ( iblock - ee_block ); 84
ret = ext4_ext_handle_uninitialized_extents ( handle , inode , iblock , max_blocks , path , flags , allocated , bh_result , newblock ); 95
return ret ; 98
if ( allocated > max_blocks )  225
return err ? err : allocated ; 236
------------------------------
314 /home/speedy/test/source2slice/NVD/CVE_2010_3015_VULN_ext4_ext_get_blocks.c newblock = iblock - ee_block + ee_start 82
int CVE_2010_3015_VULN_ext4_ext_get_blocks(handle_t *handle, struct inode *inode,
ext4_lblk_t iblock,
unsigned int max_blocks, struct buffer_head *bh_result,
int flags) 4
struct ext4_extent newex , * ex ; 8
ext4_fsblk_t newblock ; 9
cache_type = ext4_ext_in_cache ( inode , iblock , & newex ); 20
if ( cache_type )  21
if ( cache_type == EXT4_EXT_CACHE_GAP )  22
if ( ( flags & EXT4_GET_BLOCKS_CREATE ) == 0 )  23
if ( cache_type == EXT4_EXT_CACHE_EXTENT )  31
path = ext4_ext_find_extent ( inode , iblock , NULL ); 46
if ( IS_ERR ( path ) )  47
depth = ext_depth ( inode ); 53
if ( path [ depth ] . p_ext == NULL && depth != 0 )  60
ex = path [ depth ] . p_ext; 69
if ( ex )  70
ext4_lblk_t ee_block = le32_to_cpu ( ex -> ee_block ) ; 71
ext4_fsblk_t ee_start = ext_pblock ( ex ) ; 72
unsigned short ee_len ; 73
ee_len = ext4_ext_get_actual_len ( ex ); 79
if ( iblock >= ee_block && iblock < ee_block + ee_len )  81
newblock = iblock - ee_block + ee_start; 82
ext_debug ( "%u fit into %u:%d -> %llu\n" , iblock , ee_block , ee_len , newblock ); 85
ret = ext4_ext_handle_uninitialized_extents ( handle , inode , iblock , max_blocks , path , flags , allocated , bh_result , newblock ); 95
return ret ; 98
bh_result -> b_blocknr = newblock; 230
------------------------------
315 /home/speedy/test/source2slice/NVD/CVE_2010_3015_VULN_ext4_ext_get_blocks.c allocated = ext4_ext_get_actual_len ( & newex ) - ( iblock - le32_to_cpu ( newex . ee_block ) ) 37
int CVE_2010_3015_VULN_ext4_ext_get_blocks(handle_t *handle, struct inode *inode,
ext4_lblk_t iblock,
unsigned int max_blocks, struct buffer_head *bh_result,
int flags) 4
struct ext4_extent newex , * ex ; 8
cache_type = ext4_ext_in_cache ( inode , iblock , & newex ); 20
if ( cache_type )  21
if ( cache_type == EXT4_EXT_CACHE_GAP )  22
if ( cache_type == EXT4_EXT_CACHE_EXTENT )  31
allocated = ext4_ext_get_actual_len ( & newex ) - ( iblock - le32_to_cpu ( newex . ee_block ) ); 37
if ( allocated > max_blocks )  225
return err ? err : allocated ; 236
------------------------------
316 /home/speedy/test/source2slice/NVD/CVE_2010_3015_VULN_ext4_ext_get_blocks.c newblock = iblock - le32_to_cpu ( newex . ee_block ) + ext_pblock ( & newex ) 33
int CVE_2010_3015_VULN_ext4_ext_get_blocks(handle_t *handle, struct inode *inode,
ext4_lblk_t iblock,
unsigned int max_blocks, struct buffer_head *bh_result,
int flags) 4
struct ext4_extent newex , * ex ; 8
ext4_fsblk_t newblock ; 9
cache_type = ext4_ext_in_cache ( inode , iblock , & newex ); 20
if ( cache_type )  21
if ( cache_type == EXT4_EXT_CACHE_GAP )  22
if ( cache_type == EXT4_EXT_CACHE_EXTENT )  31
newblock = iblock - le32_to_cpu ( newex . ee_block ) + ext_pblock ( & newex ); 33
bh_result -> b_blocknr = newblock; 230
------------------------------
317 /home/speedy/test/source2slice/NVD/CVE_2010_3429_PATCHED_flic_decode_frame_15_16BPP.c * ( ( signed short * ) ( & pixels [ y_ptr + pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr + pixel_ptr ] ) 232
static int CVE_2010_3429_PATCHED_flic_decode_frame_15_16BPP(AVCodecContext *avctx,
void *data, int *data_size,
const uint8_t *buf, int buf_size) 3
FlicDecodeContext * s = avctx -> priv_data ; 7
int stream_ptr = 0 ; 9
int pixel_ptr ; 10
unsigned char palette_idx1 ; 11
unsigned int frame_size ; 13
int num_chunks ; 14
unsigned int chunk_size ; 16
int chunk_type ; 17
int i , j ; 19
int lines ; 21
int compressed_lines ; 22
signed short line_packets ; 23
int y_ptr ; 24
int byte_run ; 25
int pixel_skip ; 26
int pixel_countdown ; 27
unsigned char * pixels ; 28
int pixel ; 29
s -> frame . reference = 1; 32
s -> frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE; 33
if ( avctx -> reget_buffer ( avctx , & s -> frame ) < 0 )  34
pixels = s -> frame . data [ 0 ]; 39
frame_size = AV_RL32 ( & buf [ stream_ptr ] ); 42
stream_ptr += 6; 43
num_chunks = AV_RL16 ( & buf [ stream_ptr ] ); 44
stream_ptr += 10; 45
frame_size -= 16; 47
while ( ( frame_size > 0 ) && ( num_chunks > 0 ) )  50
chunk_size = AV_RL32 ( & buf [ stream_ptr ] ); 51
stream_ptr += 4; 52
chunk_type = AV_RL16 ( & buf [ stream_ptr ] ); 53
stream_ptr += 2; 54
switch ( chunk_type )  56
stream_ptr = stream_ptr + chunk_size - 6; 63
y_ptr = 0; 68
compressed_lines = AV_RL16 ( & buf [ stream_ptr ] ); 69
stream_ptr += 2; 70
while ( compressed_lines > 0 )  71
line_packets = AV_RL16 ( & buf [ stream_ptr ] ); 72
stream_ptr += 2; 73
if ( line_packets < 0 )  74
line_packets = - line_packets; 75
y_ptr += line_packets * s -> frame . linesize [ 0 ]; 76
compressed_lines --; 78
pixel_ptr = y_ptr; 79
pixel_countdown = s -> avctx -> width; 81
for (i = 0; i < line_packets; i++) 82
pixel_skip = buf [ stream_ptr ++ ]; 84
pixel_ptr += ( pixel_skip * 2 ); 85
pixel_countdown -= pixel_skip; 86
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 87
if ( byte_run < 0 )  88
byte_run = - byte_run; 89
pixel = AV_RL16 ( & buf [ stream_ptr ] ); 90
stream_ptr += 2; 91
for (j = 0; j < byte_run; j++, pixel_countdown -= 2) 93
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = pixel; 94
pixel_ptr += 2; 95
for (j = 0; j < byte_run; j++, pixel_countdown--) 99
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr ] ); 100
stream_ptr += 2; 101
pixel_ptr += 2; 102
y_ptr += s -> frame . linesize [ 0 ]; 107
stream_ptr = stream_ptr + chunk_size - 6; 114
memset ( pixels , 0x0000 , s -> frame . linesize [ 0 ] * s -> avctx -> height ); 119
y_ptr = 0; 124
for (lines = 0; lines < s->avctx->height; lines++) 125
pixel_ptr = y_ptr; 126
stream_ptr ++; 129
pixel_countdown = ( s -> avctx -> width * 2 ); 130
while ( pixel_countdown > 0 )  132
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 133
if ( byte_run > 0 )  134
palette_idx1 = buf [ stream_ptr ++ ]; 135
for (j = 0; j < byte_run; j++) 137
pixels [ pixel_ptr ++ ] = palette_idx1; 138
pixel_countdown --; 139
byte_run = - byte_run; 145
for (j = 0; j < byte_run; j++) 147
palette_idx1 = buf [ stream_ptr ++ ]; 148
pixels [ pixel_ptr ++ ] = palette_idx1; 149
pixel_countdown --; 150
pixel_ptr = y_ptr; 164
pixel_countdown = s -> avctx -> width; 165
while ( pixel_countdown > 0 )  166
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ pixel_ptr ] ); 167
pixel_ptr += 2; 168
y_ptr += s -> frame . linesize [ 0 ]; 171
y_ptr = 0; 176
for (lines = 0; lines < s->avctx->height; lines++) 177
pixel_ptr = y_ptr; 178
stream_ptr ++; 181
pixel_countdown = s -> avctx -> width; 182
while ( pixel_countdown > 0 )  184
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 185
if ( byte_run > 0 )  186
pixel = AV_RL16 ( & buf [ stream_ptr ] ); 187
stream_ptr += 2; 188
for (j = 0; j < byte_run; j++) 190
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = pixel; 191
pixel_ptr += 2; 192
pixel_countdown --; 193
byte_run = - byte_run; 199
for (j = 0; j < byte_run; j++) 201
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr ] ); 202
stream_ptr += 2; 203
pixel_ptr += 2; 204
pixel_countdown --; 205
y_ptr += s -> frame . linesize [ 0 ]; 213
if ( chunk_size - 6 > ( unsigned int ) ( s -> avctx -> width * s -> avctx -> height ) * 2 )  220
stream_ptr += chunk_size - 6; 223
for (y_ptr = 0; y_ptr < s->frame.linesize[0] * s->avctx->height;
y_ptr += s->frame.linesize[0]) 227
pixel_countdown = s -> avctx -> width; 229
pixel_ptr = 0; 230
while ( pixel_countdown > 0 )  231
* ( ( signed short * ) ( & pixels [ y_ptr + pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr + pixel_ptr ] ); 232
pixel_ptr += 2; 233
pixel_countdown --; 234
stream_ptr += s -> avctx -> width * 2; 236
stream_ptr += chunk_size - 6; 243
frame_size -= chunk_size; 251
num_chunks --; 252
------------------------------
318 /home/speedy/test/source2slice/NVD/CVE_2010_3429_PATCHED_flic_decode_frame_15_16BPP.c stream_ptr = stream_ptr + chunk_size - 6 114
static int CVE_2010_3429_PATCHED_flic_decode_frame_15_16BPP(AVCodecContext *avctx,
void *data, int *data_size,
const uint8_t *buf, int buf_size) 3
FlicDecodeContext * s = avctx -> priv_data ; 7
int stream_ptr = 0 ; 9
unsigned char palette_idx1 ; 11
unsigned int frame_size ; 13
int num_chunks ; 14
unsigned int chunk_size ; 16
int chunk_type ; 17
int i , j ; 19
int lines ; 21
int compressed_lines ; 22
signed short line_packets ; 23
int y_ptr ; 24
int byte_run ; 25
int pixel_skip ; 26
int pixel_countdown ; 27
s -> frame . reference = 1; 32
s -> frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE; 33
if ( avctx -> reget_buffer ( avctx , & s -> frame ) < 0 )  34
frame_size = AV_RL32 ( & buf [ stream_ptr ] ); 42
stream_ptr += 6; 43
num_chunks = AV_RL16 ( & buf [ stream_ptr ] ); 44
stream_ptr += 10; 45
frame_size -= 16; 47
while ( ( frame_size > 0 ) && ( num_chunks > 0 ) )  50
chunk_size = AV_RL32 ( & buf [ stream_ptr ] ); 51
stream_ptr += 4; 52
chunk_type = AV_RL16 ( & buf [ stream_ptr ] ); 53
stream_ptr += 2; 54
switch ( chunk_type )  56
stream_ptr = stream_ptr + chunk_size - 6; 63
y_ptr = 0; 68
compressed_lines = AV_RL16 ( & buf [ stream_ptr ] ); 69
stream_ptr += 2; 70
while ( compressed_lines > 0 )  71
line_packets = AV_RL16 ( & buf [ stream_ptr ] ); 72
stream_ptr += 2; 73
if ( line_packets < 0 )  74
line_packets = - line_packets; 75
y_ptr += line_packets * s -> frame . linesize [ 0 ]; 76
compressed_lines --; 78
pixel_ptr = y_ptr; 79
pixel_countdown = s -> avctx -> width; 81
for (i = 0; i < line_packets; i++) 82
pixel_skip = buf [ stream_ptr ++ ]; 84
pixel_ptr += ( pixel_skip * 2 ); 85
pixel_countdown -= pixel_skip; 86
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 87
if ( byte_run < 0 )  88
byte_run = - byte_run; 89
pixel = AV_RL16 ( & buf [ stream_ptr ] ); 90
stream_ptr += 2; 91
CHECK_PIXEL_PTR ( 2 * byte_run ); 92
for (j = 0; j < byte_run; j++, pixel_countdown -= 2) 93
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = pixel; 94
pixel_ptr += 2; 95
CHECK_PIXEL_PTR ( 2 * byte_run ); 98
for (j = 0; j < byte_run; j++, pixel_countdown--) 99
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr ] ); 100
stream_ptr += 2; 101
pixel_ptr += 2; 102
y_ptr += s -> frame . linesize [ 0 ]; 107
stream_ptr = stream_ptr + chunk_size - 6; 114
memset ( pixels , 0x0000 , s -> frame . linesize [ 0 ] * s -> avctx -> height ); 119
y_ptr = 0; 124
for (lines = 0; lines < s->avctx->height; lines++) 125
pixel_ptr = y_ptr; 126
stream_ptr ++; 129
pixel_countdown = ( s -> avctx -> width * 2 ); 130
while ( pixel_countdown > 0 )  132
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 133
if ( byte_run > 0 )  134
palette_idx1 = buf [ stream_ptr ++ ]; 135
CHECK_PIXEL_PTR ( byte_run ); 136
for (j = 0; j < byte_run; j++) 137
pixels [ pixel_ptr ++ ] = palette_idx1; 138
pixel_countdown --; 139
if ( pixel_countdown < 0 )  140
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d) (linea%d)\n" , pixel_countdown , lines ); 141
byte_run = - byte_run; 145
CHECK_PIXEL_PTR ( byte_run ); 146
for (j = 0; j < byte_run; j++) 147
palette_idx1 = buf [ stream_ptr ++ ]; 148
pixels [ pixel_ptr ++ ] = palette_idx1; 149
pixel_countdown --; 150
if ( pixel_countdown < 0 )  151
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d) at line %d\n" , pixel_countdown , lines ); 152
pixel_ptr = y_ptr; 164
pixel_countdown = s -> avctx -> width; 165
while ( pixel_countdown > 0 )  166
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ pixel_ptr ] ); 167
pixel_ptr += 2; 168
y_ptr += s -> frame . linesize [ 0 ]; 171
y_ptr = 0; 176
for (lines = 0; lines < s->avctx->height; lines++) 177
pixel_ptr = y_ptr; 178
stream_ptr ++; 181
pixel_countdown = s -> avctx -> width; 182
while ( pixel_countdown > 0 )  184
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 185
if ( byte_run > 0 )  186
pixel = AV_RL16 ( & buf [ stream_ptr ] ); 187
stream_ptr += 2; 188
CHECK_PIXEL_PTR ( 2 * byte_run ); 189
for (j = 0; j < byte_run; j++) 190
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = pixel; 191
pixel_ptr += 2; 192
pixel_countdown --; 193
if ( pixel_countdown < 0 )  194
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d)\n" , pixel_countdown ); 195
byte_run = - byte_run; 199
CHECK_PIXEL_PTR ( 2 * byte_run ); 200
for (j = 0; j < byte_run; j++) 201
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr ] ); 202
stream_ptr += 2; 203
pixel_ptr += 2; 204
pixel_countdown --; 205
if ( pixel_countdown < 0 )  206
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d)\n" , pixel_countdown ); 207
y_ptr += s -> frame . linesize [ 0 ]; 213
if ( chunk_size - 6 > ( unsigned int ) ( s -> avctx -> width * s -> avctx -> height ) * 2 )  220
av_log ( avctx , AV_LOG_ERROR , "In chunk FLI_COPY : source data (%d bytes) "
"bigger than image, skipping chunk\n" , chunk_size - 6 ) 222
stream_ptr += chunk_size - 6; 223
for (y_ptr = 0; y_ptr < s->frame.linesize[0] * s->avctx->height;
y_ptr += s->frame.linesize[0]) 227
while ( pixel_countdown > 0 )  231
* ( ( signed short * ) ( & pixels [ y_ptr + pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr + pixel_ptr ] ); 232
pixel_ptr += 2; 233
pixel_countdown --; 234
stream_ptr += s -> avctx -> width * 2; 236
stream_ptr += chunk_size - 6; 243
av_log ( avctx , AV_LOG_ERROR , "Unrecognized chunk type: %d\n" , chunk_type ); 247
frame_size -= chunk_size; 251
num_chunks --; 252
if ( ( stream_ptr != buf_size ) && ( stream_ptr != buf_size - 1 ) )  257
------------------------------
319 /home/speedy/test/source2slice/NVD/CVE_2010_3429_PATCHED_flic_decode_frame_15_16BPP.c stream_ptr = stream_ptr + chunk_size - 6 63
static int CVE_2010_3429_PATCHED_flic_decode_frame_15_16BPP(AVCodecContext *avctx,
void *data, int *data_size,
const uint8_t *buf, int buf_size) 3
FlicDecodeContext * s = avctx -> priv_data ; 7
int stream_ptr = 0 ; 9
unsigned char palette_idx1 ; 11
unsigned int frame_size ; 13
int num_chunks ; 14
unsigned int chunk_size ; 16
int chunk_type ; 17
int i , j ; 19
int lines ; 21
int compressed_lines ; 22
signed short line_packets ; 23
int y_ptr ; 24
int byte_run ; 25
int pixel_skip ; 26
int pixel_countdown ; 27
s -> frame . reference = 1; 32
s -> frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE; 33
if ( avctx -> reget_buffer ( avctx , & s -> frame ) < 0 )  34
frame_size = AV_RL32 ( & buf [ stream_ptr ] ); 42
stream_ptr += 6; 43
num_chunks = AV_RL16 ( & buf [ stream_ptr ] ); 44
stream_ptr += 10; 45
frame_size -= 16; 47
while ( ( frame_size > 0 ) && ( num_chunks > 0 ) )  50
chunk_size = AV_RL32 ( & buf [ stream_ptr ] ); 51
stream_ptr += 4; 52
chunk_type = AV_RL16 ( & buf [ stream_ptr ] ); 53
stream_ptr += 2; 54
switch ( chunk_type )  56
stream_ptr = stream_ptr + chunk_size - 6; 63
y_ptr = 0; 68
compressed_lines = AV_RL16 ( & buf [ stream_ptr ] ); 69
stream_ptr += 2; 70
while ( compressed_lines > 0 )  71
line_packets = AV_RL16 ( & buf [ stream_ptr ] ); 72
stream_ptr += 2; 73
if ( line_packets < 0 )  74
line_packets = - line_packets; 75
y_ptr += line_packets * s -> frame . linesize [ 0 ]; 76
compressed_lines --; 78
pixel_ptr = y_ptr; 79
pixel_countdown = s -> avctx -> width; 81
for (i = 0; i < line_packets; i++) 82
pixel_skip = buf [ stream_ptr ++ ]; 84
pixel_ptr += ( pixel_skip * 2 ); 85
pixel_countdown -= pixel_skip; 86
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 87
if ( byte_run < 0 )  88
byte_run = - byte_run; 89
pixel = AV_RL16 ( & buf [ stream_ptr ] ); 90
stream_ptr += 2; 91
CHECK_PIXEL_PTR ( 2 * byte_run ); 92
for (j = 0; j < byte_run; j++, pixel_countdown -= 2) 93
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = pixel; 94
pixel_ptr += 2; 95
CHECK_PIXEL_PTR ( 2 * byte_run ); 98
for (j = 0; j < byte_run; j++, pixel_countdown--) 99
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr ] ); 100
stream_ptr += 2; 101
pixel_ptr += 2; 102
y_ptr += s -> frame . linesize [ 0 ]; 107
stream_ptr = stream_ptr + chunk_size - 6; 114
memset ( pixels , 0x0000 , s -> frame . linesize [ 0 ] * s -> avctx -> height ); 119
y_ptr = 0; 124
for (lines = 0; lines < s->avctx->height; lines++) 125
pixel_ptr = y_ptr; 126
stream_ptr ++; 129
pixel_countdown = ( s -> avctx -> width * 2 ); 130
while ( pixel_countdown > 0 )  132
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 133
if ( byte_run > 0 )  134
palette_idx1 = buf [ stream_ptr ++ ]; 135
CHECK_PIXEL_PTR ( byte_run ); 136
for (j = 0; j < byte_run; j++) 137
pixels [ pixel_ptr ++ ] = palette_idx1; 138
pixel_countdown --; 139
if ( pixel_countdown < 0 )  140
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d) (linea%d)\n" , pixel_countdown , lines ); 141
byte_run = - byte_run; 145
CHECK_PIXEL_PTR ( byte_run ); 146
for (j = 0; j < byte_run; j++) 147
palette_idx1 = buf [ stream_ptr ++ ]; 148
pixels [ pixel_ptr ++ ] = palette_idx1; 149
pixel_countdown --; 150
if ( pixel_countdown < 0 )  151
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d) at line %d\n" , pixel_countdown , lines ); 152
pixel_ptr = y_ptr; 164
pixel_countdown = s -> avctx -> width; 165
while ( pixel_countdown > 0 )  166
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ pixel_ptr ] ); 167
pixel_ptr += 2; 168
y_ptr += s -> frame . linesize [ 0 ]; 171
y_ptr = 0; 176
for (lines = 0; lines < s->avctx->height; lines++) 177
pixel_ptr = y_ptr; 178
stream_ptr ++; 181
pixel_countdown = s -> avctx -> width; 182
while ( pixel_countdown > 0 )  184
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 185
if ( byte_run > 0 )  186
pixel = AV_RL16 ( & buf [ stream_ptr ] ); 187
stream_ptr += 2; 188
CHECK_PIXEL_PTR ( 2 * byte_run ); 189
for (j = 0; j < byte_run; j++) 190
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = pixel; 191
pixel_ptr += 2; 192
pixel_countdown --; 193
if ( pixel_countdown < 0 )  194
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d)\n" , pixel_countdown ); 195
byte_run = - byte_run; 199
CHECK_PIXEL_PTR ( 2 * byte_run ); 200
for (j = 0; j < byte_run; j++) 201
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr ] ); 202
stream_ptr += 2; 203
pixel_ptr += 2; 204
pixel_countdown --; 205
if ( pixel_countdown < 0 )  206
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d)\n" , pixel_countdown ); 207
y_ptr += s -> frame . linesize [ 0 ]; 213
if ( chunk_size - 6 > ( unsigned int ) ( s -> avctx -> width * s -> avctx -> height ) * 2 )  220
av_log ( avctx , AV_LOG_ERROR , "In chunk FLI_COPY : source data (%d bytes) "
"bigger than image, skipping chunk\n" , chunk_size - 6 ) 222
stream_ptr += chunk_size - 6; 223
for (y_ptr = 0; y_ptr < s->frame.linesize[0] * s->avctx->height;
y_ptr += s->frame.linesize[0]) 227
while ( pixel_countdown > 0 )  231
* ( ( signed short * ) ( & pixels [ y_ptr + pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr + pixel_ptr ] ); 232
pixel_ptr += 2; 233
pixel_countdown --; 234
stream_ptr += s -> avctx -> width * 2; 236
stream_ptr += chunk_size - 6; 243
av_log ( avctx , AV_LOG_ERROR , "Unrecognized chunk type: %d\n" , chunk_type ); 247
frame_size -= chunk_size; 251
num_chunks --; 252
if ( ( stream_ptr != buf_size ) && ( stream_ptr != buf_size - 1 ) )  257
------------------------------
320 /home/speedy/test/source2slice/NVD/CVE_2010_3429_PATCHED_flic_decode_frame_15_16BPP.c pixel_limit = s -> avctx -> height * s -> frame . linesize [ 0 ] 40
static int CVE_2010_3429_PATCHED_flic_decode_frame_15_16BPP(AVCodecContext *avctx,
void *data, int *data_size,
const uint8_t *buf, int buf_size) 3
FlicDecodeContext * s = avctx -> priv_data ; 7
unsigned int pixel_limit ; 30
s -> frame . reference = 1; 32
s -> frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE; 33
if ( avctx -> reget_buffer ( avctx , & s -> frame ) < 0 )  34
pixel_limit = s -> avctx -> height * s -> frame . linesize [ 0 ]; 40
------------------------------
321 /home/speedy/test/source2slice/NVD/CVE_2010_3429_PATCHED_flic_decode_frame_8BPP.c pixel_ptr = y_ptr + s -> frame . linesize [ 0 ] - 1 130
static int CVE_2010_3429_PATCHED_flic_decode_frame_8BPP(AVCodecContext *avctx,
void *data, int *data_size,
const uint8_t *buf, int buf_size) 3
FlicDecodeContext * s = avctx -> priv_data ; 5
int stream_ptr = 0 ; 7
int stream_ptr_after_color_chunk ; 8
int pixel_ptr ; 9
int palette_ptr ; 10
unsigned char palette_idx1 ; 11
unsigned char palette_idx2 ; 12
unsigned int frame_size ; 14
int num_chunks ; 15
unsigned int chunk_size ; 17
int chunk_type ; 18
int i , j ; 20
int color_packets ; 22
int color_changes ; 23
int color_shift ; 24
unsigned char r , g , b ; 25
int lines ; 27
int compressed_lines ; 28
int starting_line ; 29
signed short line_packets ; 30
int y_ptr ; 31
int byte_run ; 32
int pixel_skip ; 33
int pixel_countdown ; 34
s -> frame . reference = 1; 38
s -> frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE; 39
if ( avctx -> reget_buffer ( avctx , & s -> frame ) < 0 )  40
frame_size = AV_RL32 ( & buf [ stream_ptr ] ); 48
stream_ptr += 6; 49
num_chunks = AV_RL16 ( & buf [ stream_ptr ] ); 50
stream_ptr += 10; 51
frame_size -= 16; 53
while ( ( frame_size > 0 ) && ( num_chunks > 0 ) )  56
chunk_size = AV_RL32 ( & buf [ stream_ptr ] ); 57
stream_ptr += 4; 58
chunk_type = AV_RL16 ( & buf [ stream_ptr ] ); 59
stream_ptr += 2; 60
switch ( chunk_type )  62
stream_ptr_after_color_chunk = stream_ptr + chunk_size - 6; 65
if ( ( chunk_type == FLI_256_COLOR ) && ( s -> fli_type != FLC_MAGIC_CARPET_SYNTHETIC_TYPE_CODE ) )  71
color_shift = 0; 72
color_shift = 2; 74
color_packets = AV_RL16 ( & buf [ stream_ptr ] ); 76
stream_ptr += 2; 77
palette_ptr = 0; 78
for (i = 0; i < color_packets; i++) 79
palette_ptr += buf [ stream_ptr ++ ]; 81
color_changes = buf [ stream_ptr ++ ]; 84
if ( color_changes == 0 )  87
color_changes = 256; 88
for (j = 0; j < color_changes; j++) 90
unsigned int entry ; 91
if ( ( unsigned ) palette_ptr >= 256 )  94
palette_ptr = 0; 95
r = buf [ stream_ptr ++ ] << color_shift; 97
g = buf [ stream_ptr ++ ] << color_shift; 98
b = buf [ stream_ptr ++ ] << color_shift; 99
entry = ( r << 16 ) | ( g << 8 ) | b; 100
if ( s -> palette [ palette_ptr ] != entry )  101
s -> new_palette = 1; 102
s -> palette [ palette_ptr ++ ] = entry; 103
stream_ptr = stream_ptr_after_color_chunk; 111
y_ptr = 0; 116
compressed_lines = AV_RL16 ( & buf [ stream_ptr ] ); 117
stream_ptr += 2; 118
while ( compressed_lines > 0 )  119
line_packets = AV_RL16 ( & buf [ stream_ptr ] ); 120
stream_ptr += 2; 121
if ( ( line_packets & 0xC000 ) == 0xC000 )  122
line_packets = - line_packets; 124
y_ptr += line_packets * s -> frame . linesize [ 0 ]; 125
if ( ( line_packets & 0xC000 ) == 0x4000 )  126
if ( ( line_packets & 0xC000 ) == 0x8000 )  128
pixel_ptr = y_ptr + s -> frame . linesize [ 0 ] - 1; 130
pixels [ pixel_ptr ] = line_packets & 0xff; 132
compressed_lines --; 134
pixel_countdown = s -> avctx -> width; 137
for (i = 0; i < line_packets; i++) 138
pixel_skip = buf [ stream_ptr ++ ]; 140
pixel_countdown -= pixel_skip; 142
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 143
if ( byte_run < 0 )  144
byte_run = - byte_run; 145
palette_idx1 = buf [ stream_ptr ++ ]; 146
palette_idx2 = buf [ stream_ptr ++ ]; 147
for (j = 0; j < byte_run; j++, pixel_countdown -= 2) 149
for (j = 0; j < byte_run * 2; j++, pixel_countdown--) 155
palette_idx1 = buf [ stream_ptr ++ ]; 156
y_ptr += s -> frame . linesize [ 0 ]; 162
starting_line = AV_RL16 ( & buf [ stream_ptr ] ); 169
stream_ptr += 2; 170
y_ptr = 0; 171
y_ptr += starting_line * s -> frame . linesize [ 0 ]; 172
compressed_lines = AV_RL16 ( & buf [ stream_ptr ] ); 174
stream_ptr += 2; 175
while ( compressed_lines > 0 )  176
pixel_countdown = s -> avctx -> width; 179
line_packets = buf [ stream_ptr ++ ]; 180
if ( line_packets > 0 )  181
for (i = 0; i < line_packets; i++) 182
pixel_skip = buf [ stream_ptr ++ ]; 184
pixel_countdown -= pixel_skip; 186
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 187
if ( byte_run > 0 )  188
for (j = 0; j < byte_run; j++, pixel_countdown--) 190
palette_idx1 = buf [ stream_ptr ++ ]; 191
if ( byte_run < 0 )  194
byte_run = - byte_run; 195
palette_idx1 = buf [ stream_ptr ++ ]; 196
for (j = 0; j < byte_run; j++, pixel_countdown--) 198
y_ptr += s -> frame . linesize [ 0 ]; 205
compressed_lines --; 206
y_ptr = 0; 219
for (lines = 0; lines < s->avctx->height; lines++) 220
stream_ptr ++; 224
pixel_countdown = s -> avctx -> width; 225
while ( pixel_countdown > 0 )  226
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 227
if ( byte_run > 0 )  228
palette_idx1 = buf [ stream_ptr ++ ]; 229
for (j = 0; j < byte_run; j++) 231
pixel_countdown --; 233
byte_run = - byte_run; 239
for (j = 0; j < byte_run; j++) 241
palette_idx1 = buf [ stream_ptr ++ ]; 242
pixel_countdown --; 244
y_ptr += s -> frame . linesize [ 0 ]; 252
if ( chunk_size - 6 > s -> avctx -> width * s -> avctx -> height )  258
stream_ptr += chunk_size - 6; 261
for (y_ptr = 0; y_ptr < s->frame.linesize[0] * s->avctx->height;
y_ptr += s->frame.linesize[0]) 264
stream_ptr += s -> avctx -> width; 267
stream_ptr += chunk_size - 6; 274
frame_size -= chunk_size; 282
num_chunks --; 283
------------------------------
322 /home/speedy/test/source2slice/NVD/CVE_2010_3429_PATCHED_flic_decode_frame_8BPP.c stream_ptr_after_color_chunk = stream_ptr + chunk_size - 6 65
static int CVE_2010_3429_PATCHED_flic_decode_frame_8BPP(AVCodecContext *avctx,
void *data, int *data_size,
const uint8_t *buf, int buf_size) 3
FlicDecodeContext * s = avctx -> priv_data ; 5
int stream_ptr = 0 ; 7
int stream_ptr_after_color_chunk ; 8
int palette_ptr ; 10
unsigned char palette_idx1 ; 11
unsigned char palette_idx2 ; 12
unsigned int frame_size ; 14
int num_chunks ; 15
unsigned int chunk_size ; 17
int chunk_type ; 18
int i , j ; 20
int color_packets ; 22
int color_changes ; 23
int color_shift ; 24
unsigned char r , g , b ; 25
int lines ; 27
int compressed_lines ; 28
int starting_line ; 29
signed short line_packets ; 30
int y_ptr ; 31
int byte_run ; 32
int pixel_skip ; 33
int pixel_countdown ; 34
s -> frame . reference = 1; 38
s -> frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE; 39
if ( avctx -> reget_buffer ( avctx , & s -> frame ) < 0 )  40
frame_size = AV_RL32 ( & buf [ stream_ptr ] ); 48
stream_ptr += 6; 49
num_chunks = AV_RL16 ( & buf [ stream_ptr ] ); 50
stream_ptr += 10; 51
frame_size -= 16; 53
while ( ( frame_size > 0 ) && ( num_chunks > 0 ) )  56
chunk_size = AV_RL32 ( & buf [ stream_ptr ] ); 57
stream_ptr += 4; 58
chunk_type = AV_RL16 ( & buf [ stream_ptr ] ); 59
stream_ptr += 2; 60
switch ( chunk_type )  62
stream_ptr_after_color_chunk = stream_ptr + chunk_size - 6; 65
if ( ( chunk_type == FLI_256_COLOR ) && ( s -> fli_type != FLC_MAGIC_CARPET_SYNTHETIC_TYPE_CODE ) )  71
color_shift = 0; 72
color_shift = 2; 74
color_packets = AV_RL16 ( & buf [ stream_ptr ] ); 76
stream_ptr += 2; 77
palette_ptr = 0; 78
for (i = 0; i < color_packets; i++) 79
palette_ptr += buf [ stream_ptr ++ ]; 81
color_changes = buf [ stream_ptr ++ ]; 84
if ( color_changes == 0 )  87
color_changes = 256; 88
for (j = 0; j < color_changes; j++) 90
unsigned int entry ; 91
if ( ( unsigned ) palette_ptr >= 256 )  94
palette_ptr = 0; 95
r = buf [ stream_ptr ++ ] << color_shift; 97
g = buf [ stream_ptr ++ ] << color_shift; 98
b = buf [ stream_ptr ++ ] << color_shift; 99
entry = ( r << 16 ) | ( g << 8 ) | b; 100
if ( s -> palette [ palette_ptr ] != entry )  101
s -> new_palette = 1; 102
s -> palette [ palette_ptr ++ ] = entry; 103
stream_ptr = stream_ptr_after_color_chunk; 111
y_ptr = 0; 116
compressed_lines = AV_RL16 ( & buf [ stream_ptr ] ); 117
stream_ptr += 2; 118
while ( compressed_lines > 0 )  119
line_packets = AV_RL16 ( & buf [ stream_ptr ] ); 120
stream_ptr += 2; 121
if ( ( line_packets & 0xC000 ) == 0xC000 )  122
line_packets = - line_packets; 124
y_ptr += line_packets * s -> frame . linesize [ 0 ]; 125
if ( ( line_packets & 0xC000 ) == 0x4000 )  126
av_log ( avctx , AV_LOG_ERROR , "Undefined opcode (%x) in DELTA_FLI\n" , line_packets ); 127
if ( ( line_packets & 0xC000 ) == 0x8000 )  128
pixel_ptr = y_ptr + s -> frame . linesize [ 0 ] - 1; 130
pixels [ pixel_ptr ] = line_packets & 0xff; 132
compressed_lines --; 134
pixel_ptr = y_ptr; 135
pixel_countdown = s -> avctx -> width; 137
for (i = 0; i < line_packets; i++) 138
pixel_skip = buf [ stream_ptr ++ ]; 140
pixel_ptr += pixel_skip; 141
pixel_countdown -= pixel_skip; 142
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 143
if ( byte_run < 0 )  144
byte_run = - byte_run; 145
palette_idx1 = buf [ stream_ptr ++ ]; 146
palette_idx2 = buf [ stream_ptr ++ ]; 147
CHECK_PIXEL_PTR ( byte_run * 2 ); 148
for (j = 0; j < byte_run; j++, pixel_countdown -= 2) 149
pixels [ pixel_ptr ++ ] = palette_idx1; 150
pixels [ pixel_ptr ++ ] = palette_idx2; 151
CHECK_PIXEL_PTR ( byte_run * 2 ); 154
for (j = 0; j < byte_run * 2; j++, pixel_countdown--) 155
palette_idx1 = buf [ stream_ptr ++ ]; 156
pixels [ pixel_ptr ++ ] = palette_idx1; 157
y_ptr += s -> frame . linesize [ 0 ]; 162
starting_line = AV_RL16 ( & buf [ stream_ptr ] ); 169
stream_ptr += 2; 170
y_ptr = 0; 171
y_ptr += starting_line * s -> frame . linesize [ 0 ]; 172
compressed_lines = AV_RL16 ( & buf [ stream_ptr ] ); 174
stream_ptr += 2; 175
while ( compressed_lines > 0 )  176
pixel_ptr = y_ptr; 177
pixel_countdown = s -> avctx -> width; 179
line_packets = buf [ stream_ptr ++ ]; 180
if ( line_packets > 0 )  181
for (i = 0; i < line_packets; i++) 182
pixel_skip = buf [ stream_ptr ++ ]; 184
pixel_ptr += pixel_skip; 185
pixel_countdown -= pixel_skip; 186
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 187
if ( byte_run > 0 )  188
CHECK_PIXEL_PTR ( byte_run ); 189
for (j = 0; j < byte_run; j++, pixel_countdown--) 190
palette_idx1 = buf [ stream_ptr ++ ]; 191
pixels [ pixel_ptr ++ ] = palette_idx1; 192
if ( byte_run < 0 )  194
byte_run = - byte_run; 195
palette_idx1 = buf [ stream_ptr ++ ]; 196
CHECK_PIXEL_PTR ( byte_run ); 197
for (j = 0; j < byte_run; j++, pixel_countdown--) 198
pixels [ pixel_ptr ++ ] = palette_idx1; 199
y_ptr += s -> frame . linesize [ 0 ]; 205
compressed_lines --; 206
memset ( pixels , 0 , s -> frame . linesize [ 0 ] * s -> avctx -> height ); 212
y_ptr = 0; 219
for (lines = 0; lines < s->avctx->height; lines++) 220
pixel_ptr = y_ptr; 221
stream_ptr ++; 224
pixel_countdown = s -> avctx -> width; 225
while ( pixel_countdown > 0 )  226
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 227
if ( byte_run > 0 )  228
palette_idx1 = buf [ stream_ptr ++ ]; 229
CHECK_PIXEL_PTR ( byte_run ); 230
for (j = 0; j < byte_run; j++) 231
pixels [ pixel_ptr ++ ] = palette_idx1; 232
pixel_countdown --; 233
if ( pixel_countdown < 0 )  234
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d) at line %d\n" , pixel_countdown , lines ); 235
byte_run = - byte_run; 239
CHECK_PIXEL_PTR ( byte_run ); 240
for (j = 0; j < byte_run; j++) 241
palette_idx1 = buf [ stream_ptr ++ ]; 242
pixels [ pixel_ptr ++ ] = palette_idx1; 243
pixel_countdown --; 244
if ( pixel_countdown < 0 )  245
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d) at line %d\n" , pixel_countdown , lines ); 246
y_ptr += s -> frame . linesize [ 0 ]; 252
if ( chunk_size - 6 > s -> avctx -> width * s -> avctx -> height )  258
av_log ( avctx , AV_LOG_ERROR , "In chunk FLI_COPY : source data (%d bytes) "
"bigger than image, skipping chunk\n" , chunk_size - 6 ) 260
stream_ptr += chunk_size - 6; 261
for (y_ptr = 0; y_ptr < s->frame.linesize[0] * s->avctx->height;
y_ptr += s->frame.linesize[0]) 264
memcpy ( & pixels [ y_ptr ] , & buf [ stream_ptr ] , s -> avctx -> width ); 265
stream_ptr += s -> avctx -> width; 267
stream_ptr += chunk_size - 6; 274
av_log ( avctx , AV_LOG_ERROR , "Unrecognized chunk type: %d\n" , chunk_type ); 278
frame_size -= chunk_size; 282
num_chunks --; 283
if ( ( stream_ptr != buf_size ) && ( stream_ptr != buf_size - 1 ) )  288
memcpy ( s -> frame . data [ 1 ] , s -> palette , AVPALETTE_SIZE ); 293
if ( s -> new_palette )  294
s -> frame . palette_has_changed = 1; 295
s -> new_palette = 0; 296
* ( AVFrame * ) data = s -> frame; 300
------------------------------
323 /home/speedy/test/source2slice/NVD/CVE_2010_3429_PATCHED_flic_decode_frame_8BPP.c pixel_limit = s -> avctx -> height * s -> frame . linesize [ 0 ] 46
static int CVE_2010_3429_PATCHED_flic_decode_frame_8BPP(AVCodecContext *avctx,
void *data, int *data_size,
const uint8_t *buf, int buf_size) 3
FlicDecodeContext * s = avctx -> priv_data ; 5
unsigned int pixel_limit ; 36
s -> frame . reference = 1; 38
s -> frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE; 39
if ( avctx -> reget_buffer ( avctx , & s -> frame ) < 0 )  40
pixel_limit = s -> avctx -> height * s -> frame . linesize [ 0 ]; 46
------------------------------
324 /home/speedy/test/source2slice/NVD/CVE_2010_3429_VULN_flic_decode_frame_15_16BPP.c * ( ( signed short * ) ( & pixels [ y_ptr + pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr + pixel_ptr ] ) 231
static int CVE_2010_3429_VULN_flic_decode_frame_15_16BPP(AVCodecContext *avctx,
void *data, int *data_size,
const uint8_t *buf, int buf_size) 3
FlicDecodeContext * s = avctx -> priv_data ; 7
int stream_ptr = 0 ; 9
int pixel_ptr ; 10
unsigned char palette_idx1 ; 11
unsigned int frame_size ; 13
int num_chunks ; 14
unsigned int chunk_size ; 16
int chunk_type ; 17
int i , j ; 19
int lines ; 21
int compressed_lines ; 22
signed short line_packets ; 23
int y_ptr ; 24
int byte_run ; 25
int pixel_skip ; 26
int pixel_countdown ; 27
unsigned char * pixels ; 28
int pixel ; 29
s -> frame . reference = 1; 32
s -> frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE; 33
if ( avctx -> reget_buffer ( avctx , & s -> frame ) < 0 )  34
pixels = s -> frame . data [ 0 ]; 39
frame_size = AV_RL32 ( & buf [ stream_ptr ] ); 42
stream_ptr += 6; 43
num_chunks = AV_RL16 ( & buf [ stream_ptr ] ); 44
stream_ptr += 10; 45
frame_size -= 16; 47
while ( ( frame_size > 0 ) && ( num_chunks > 0 ) )  50
chunk_size = AV_RL32 ( & buf [ stream_ptr ] ); 51
stream_ptr += 4; 52
chunk_type = AV_RL16 ( & buf [ stream_ptr ] ); 53
stream_ptr += 2; 54
switch ( chunk_type )  56
stream_ptr = stream_ptr + chunk_size - 6; 63
y_ptr = 0; 68
compressed_lines = AV_RL16 ( & buf [ stream_ptr ] ); 69
stream_ptr += 2; 70
while ( compressed_lines > 0 )  71
line_packets = AV_RL16 ( & buf [ stream_ptr ] ); 72
stream_ptr += 2; 73
if ( line_packets < 0 )  74
line_packets = - line_packets; 75
y_ptr += line_packets * s -> frame . linesize [ 0 ]; 76
compressed_lines --; 78
pixel_ptr = y_ptr; 79
pixel_countdown = s -> avctx -> width; 80
for (i = 0; i < line_packets; i++) 81
pixel_skip = buf [ stream_ptr ++ ]; 83
pixel_ptr += ( pixel_skip * 2 ); 84
pixel_countdown -= pixel_skip; 85
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 86
if ( byte_run < 0 )  87
byte_run = - byte_run; 88
pixel = AV_RL16 ( & buf [ stream_ptr ] ); 89
stream_ptr += 2; 90
for (j = 0; j < byte_run; j++, pixel_countdown -= 2) 92
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = pixel; 93
pixel_ptr += 2; 94
for (j = 0; j < byte_run; j++, pixel_countdown--) 98
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr ] ); 99
stream_ptr += 2; 100
pixel_ptr += 2; 101
y_ptr += s -> frame . linesize [ 0 ]; 106
stream_ptr = stream_ptr + chunk_size - 6; 113
memset ( pixels , 0x0000 , s -> frame . linesize [ 0 ] * s -> avctx -> height ); 118
y_ptr = 0; 123
for (lines = 0; lines < s->avctx->height; lines++) 124
pixel_ptr = y_ptr; 125
stream_ptr ++; 128
pixel_countdown = ( s -> avctx -> width * 2 ); 129
while ( pixel_countdown > 0 )  131
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 132
if ( byte_run > 0 )  133
palette_idx1 = buf [ stream_ptr ++ ]; 134
for (j = 0; j < byte_run; j++) 136
pixels [ pixel_ptr ++ ] = palette_idx1; 137
pixel_countdown --; 138
byte_run = - byte_run; 144
for (j = 0; j < byte_run; j++) 146
palette_idx1 = buf [ stream_ptr ++ ]; 147
pixels [ pixel_ptr ++ ] = palette_idx1; 148
pixel_countdown --; 149
pixel_ptr = y_ptr; 163
pixel_countdown = s -> avctx -> width; 164
while ( pixel_countdown > 0 )  165
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ pixel_ptr ] ); 166
pixel_ptr += 2; 167
y_ptr += s -> frame . linesize [ 0 ]; 170
y_ptr = 0; 175
for (lines = 0; lines < s->avctx->height; lines++) 176
pixel_ptr = y_ptr; 177
stream_ptr ++; 180
pixel_countdown = s -> avctx -> width; 181
while ( pixel_countdown > 0 )  183
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 184
if ( byte_run > 0 )  185
pixel = AV_RL16 ( & buf [ stream_ptr ] ); 186
stream_ptr += 2; 187
for (j = 0; j < byte_run; j++) 189
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = pixel; 190
pixel_ptr += 2; 191
pixel_countdown --; 192
byte_run = - byte_run; 198
for (j = 0; j < byte_run; j++) 200
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr ] ); 201
stream_ptr += 2; 202
pixel_ptr += 2; 203
pixel_countdown --; 204
y_ptr += s -> frame . linesize [ 0 ]; 212
if ( chunk_size - 6 > ( unsigned int ) ( s -> avctx -> width * s -> avctx -> height ) * 2 )  219
stream_ptr += chunk_size - 6; 222
for (y_ptr = 0; y_ptr < s->frame.linesize[0] * s->avctx->height;
y_ptr += s->frame.linesize[0]) 226
pixel_countdown = s -> avctx -> width; 228
pixel_ptr = 0; 229
while ( pixel_countdown > 0 )  230
* ( ( signed short * ) ( & pixels [ y_ptr + pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr + pixel_ptr ] ); 231
pixel_ptr += 2; 232
pixel_countdown --; 233
stream_ptr += s -> avctx -> width * 2; 235
stream_ptr += chunk_size - 6; 242
frame_size -= chunk_size; 250
num_chunks --; 251
------------------------------
325 /home/speedy/test/source2slice/NVD/CVE_2010_3429_VULN_flic_decode_frame_15_16BPP.c stream_ptr = stream_ptr + chunk_size - 6 113
static int CVE_2010_3429_VULN_flic_decode_frame_15_16BPP(AVCodecContext *avctx,
void *data, int *data_size,
const uint8_t *buf, int buf_size) 3
FlicDecodeContext * s = avctx -> priv_data ; 7
int stream_ptr = 0 ; 9
unsigned char palette_idx1 ; 11
unsigned int frame_size ; 13
int num_chunks ; 14
unsigned int chunk_size ; 16
int chunk_type ; 17
int i , j ; 19
int lines ; 21
int compressed_lines ; 22
signed short line_packets ; 23
int y_ptr ; 24
int byte_run ; 25
int pixel_skip ; 26
int pixel_countdown ; 27
s -> frame . reference = 1; 32
s -> frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE; 33
if ( avctx -> reget_buffer ( avctx , & s -> frame ) < 0 )  34
frame_size = AV_RL32 ( & buf [ stream_ptr ] ); 42
stream_ptr += 6; 43
num_chunks = AV_RL16 ( & buf [ stream_ptr ] ); 44
stream_ptr += 10; 45
frame_size -= 16; 47
while ( ( frame_size > 0 ) && ( num_chunks > 0 ) )  50
chunk_size = AV_RL32 ( & buf [ stream_ptr ] ); 51
stream_ptr += 4; 52
chunk_type = AV_RL16 ( & buf [ stream_ptr ] ); 53
stream_ptr += 2; 54
switch ( chunk_type )  56
stream_ptr = stream_ptr + chunk_size - 6; 63
y_ptr = 0; 68
compressed_lines = AV_RL16 ( & buf [ stream_ptr ] ); 69
stream_ptr += 2; 70
while ( compressed_lines > 0 )  71
line_packets = AV_RL16 ( & buf [ stream_ptr ] ); 72
stream_ptr += 2; 73
if ( line_packets < 0 )  74
line_packets = - line_packets; 75
y_ptr += line_packets * s -> frame . linesize [ 0 ]; 76
compressed_lines --; 78
pixel_ptr = y_ptr; 79
pixel_countdown = s -> avctx -> width; 80
for (i = 0; i < line_packets; i++) 81
pixel_skip = buf [ stream_ptr ++ ]; 83
pixel_ptr += ( pixel_skip * 2 ); 84
pixel_countdown -= pixel_skip; 85
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 86
if ( byte_run < 0 )  87
byte_run = - byte_run; 88
pixel = AV_RL16 ( & buf [ stream_ptr ] ); 89
stream_ptr += 2; 90
CHECK_PIXEL_PTR ( byte_run ); 91
for (j = 0; j < byte_run; j++, pixel_countdown -= 2) 92
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = pixel; 93
pixel_ptr += 2; 94
CHECK_PIXEL_PTR ( byte_run ); 97
for (j = 0; j < byte_run; j++, pixel_countdown--) 98
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr ] ); 99
stream_ptr += 2; 100
pixel_ptr += 2; 101
y_ptr += s -> frame . linesize [ 0 ]; 106
stream_ptr = stream_ptr + chunk_size - 6; 113
memset ( pixels , 0x0000 , s -> frame . linesize [ 0 ] * s -> avctx -> height ); 118
y_ptr = 0; 123
for (lines = 0; lines < s->avctx->height; lines++) 124
pixel_ptr = y_ptr; 125
stream_ptr ++; 128
pixel_countdown = ( s -> avctx -> width * 2 ); 129
while ( pixel_countdown > 0 )  131
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 132
if ( byte_run > 0 )  133
palette_idx1 = buf [ stream_ptr ++ ]; 134
CHECK_PIXEL_PTR ( byte_run ); 135
for (j = 0; j < byte_run; j++) 136
pixels [ pixel_ptr ++ ] = palette_idx1; 137
pixel_countdown --; 138
if ( pixel_countdown < 0 )  139
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d) (linea%d)\n" , pixel_countdown , lines ); 140
byte_run = - byte_run; 144
CHECK_PIXEL_PTR ( byte_run ); 145
for (j = 0; j < byte_run; j++) 146
palette_idx1 = buf [ stream_ptr ++ ]; 147
pixels [ pixel_ptr ++ ] = palette_idx1; 148
pixel_countdown --; 149
if ( pixel_countdown < 0 )  150
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d) at line %d\n" , pixel_countdown , lines ); 151
pixel_ptr = y_ptr; 163
pixel_countdown = s -> avctx -> width; 164
while ( pixel_countdown > 0 )  165
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ pixel_ptr ] ); 166
pixel_ptr += 2; 167
y_ptr += s -> frame . linesize [ 0 ]; 170
y_ptr = 0; 175
for (lines = 0; lines < s->avctx->height; lines++) 176
pixel_ptr = y_ptr; 177
stream_ptr ++; 180
pixel_countdown = s -> avctx -> width; 181
while ( pixel_countdown > 0 )  183
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 184
if ( byte_run > 0 )  185
pixel = AV_RL16 ( & buf [ stream_ptr ] ); 186
stream_ptr += 2; 187
CHECK_PIXEL_PTR ( byte_run ); 188
for (j = 0; j < byte_run; j++) 189
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = pixel; 190
pixel_ptr += 2; 191
pixel_countdown --; 192
if ( pixel_countdown < 0 )  193
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d)\n" , pixel_countdown ); 194
byte_run = - byte_run; 198
CHECK_PIXEL_PTR ( byte_run ); 199
for (j = 0; j < byte_run; j++) 200
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr ] ); 201
stream_ptr += 2; 202
pixel_ptr += 2; 203
pixel_countdown --; 204
if ( pixel_countdown < 0 )  205
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d)\n" , pixel_countdown ); 206
y_ptr += s -> frame . linesize [ 0 ]; 212
if ( chunk_size - 6 > ( unsigned int ) ( s -> avctx -> width * s -> avctx -> height ) * 2 )  219
av_log ( avctx , AV_LOG_ERROR , "In chunk FLI_COPY : source data (%d bytes) "
"bigger than image, skipping chunk\n" , chunk_size - 6 ) 221
stream_ptr += chunk_size - 6; 222
for (y_ptr = 0; y_ptr < s->frame.linesize[0] * s->avctx->height;
y_ptr += s->frame.linesize[0]) 226
while ( pixel_countdown > 0 )  230
* ( ( signed short * ) ( & pixels [ y_ptr + pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr + pixel_ptr ] ); 231
pixel_ptr += 2; 232
pixel_countdown --; 233
stream_ptr += s -> avctx -> width * 2; 235
stream_ptr += chunk_size - 6; 242
av_log ( avctx , AV_LOG_ERROR , "Unrecognized chunk type: %d\n" , chunk_type ); 246
frame_size -= chunk_size; 250
num_chunks --; 251
if ( ( stream_ptr != buf_size ) && ( stream_ptr != buf_size - 1 ) )  256
------------------------------
326 /home/speedy/test/source2slice/NVD/CVE_2010_3429_VULN_flic_decode_frame_15_16BPP.c stream_ptr = stream_ptr + chunk_size - 6 63
static int CVE_2010_3429_VULN_flic_decode_frame_15_16BPP(AVCodecContext *avctx,
void *data, int *data_size,
const uint8_t *buf, int buf_size) 3
FlicDecodeContext * s = avctx -> priv_data ; 7
int stream_ptr = 0 ; 9
unsigned char palette_idx1 ; 11
unsigned int frame_size ; 13
int num_chunks ; 14
unsigned int chunk_size ; 16
int chunk_type ; 17
int i , j ; 19
int lines ; 21
int compressed_lines ; 22
signed short line_packets ; 23
int y_ptr ; 24
int byte_run ; 25
int pixel_skip ; 26
int pixel_countdown ; 27
s -> frame . reference = 1; 32
s -> frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE; 33
if ( avctx -> reget_buffer ( avctx , & s -> frame ) < 0 )  34
frame_size = AV_RL32 ( & buf [ stream_ptr ] ); 42
stream_ptr += 6; 43
num_chunks = AV_RL16 ( & buf [ stream_ptr ] ); 44
stream_ptr += 10; 45
frame_size -= 16; 47
while ( ( frame_size > 0 ) && ( num_chunks > 0 ) )  50
chunk_size = AV_RL32 ( & buf [ stream_ptr ] ); 51
stream_ptr += 4; 52
chunk_type = AV_RL16 ( & buf [ stream_ptr ] ); 53
stream_ptr += 2; 54
switch ( chunk_type )  56
stream_ptr = stream_ptr + chunk_size - 6; 63
y_ptr = 0; 68
compressed_lines = AV_RL16 ( & buf [ stream_ptr ] ); 69
stream_ptr += 2; 70
while ( compressed_lines > 0 )  71
line_packets = AV_RL16 ( & buf [ stream_ptr ] ); 72
stream_ptr += 2; 73
if ( line_packets < 0 )  74
line_packets = - line_packets; 75
y_ptr += line_packets * s -> frame . linesize [ 0 ]; 76
compressed_lines --; 78
pixel_ptr = y_ptr; 79
pixel_countdown = s -> avctx -> width; 80
for (i = 0; i < line_packets; i++) 81
pixel_skip = buf [ stream_ptr ++ ]; 83
pixel_ptr += ( pixel_skip * 2 ); 84
pixel_countdown -= pixel_skip; 85
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 86
if ( byte_run < 0 )  87
byte_run = - byte_run; 88
pixel = AV_RL16 ( & buf [ stream_ptr ] ); 89
stream_ptr += 2; 90
CHECK_PIXEL_PTR ( byte_run ); 91
for (j = 0; j < byte_run; j++, pixel_countdown -= 2) 92
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = pixel; 93
pixel_ptr += 2; 94
CHECK_PIXEL_PTR ( byte_run ); 97
for (j = 0; j < byte_run; j++, pixel_countdown--) 98
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr ] ); 99
stream_ptr += 2; 100
pixel_ptr += 2; 101
y_ptr += s -> frame . linesize [ 0 ]; 106
stream_ptr = stream_ptr + chunk_size - 6; 113
memset ( pixels , 0x0000 , s -> frame . linesize [ 0 ] * s -> avctx -> height ); 118
y_ptr = 0; 123
for (lines = 0; lines < s->avctx->height; lines++) 124
pixel_ptr = y_ptr; 125
stream_ptr ++; 128
pixel_countdown = ( s -> avctx -> width * 2 ); 129
while ( pixel_countdown > 0 )  131
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 132
if ( byte_run > 0 )  133
palette_idx1 = buf [ stream_ptr ++ ]; 134
CHECK_PIXEL_PTR ( byte_run ); 135
for (j = 0; j < byte_run; j++) 136
pixels [ pixel_ptr ++ ] = palette_idx1; 137
pixel_countdown --; 138
if ( pixel_countdown < 0 )  139
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d) (linea%d)\n" , pixel_countdown , lines ); 140
byte_run = - byte_run; 144
CHECK_PIXEL_PTR ( byte_run ); 145
for (j = 0; j < byte_run; j++) 146
palette_idx1 = buf [ stream_ptr ++ ]; 147
pixels [ pixel_ptr ++ ] = palette_idx1; 148
pixel_countdown --; 149
if ( pixel_countdown < 0 )  150
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d) at line %d\n" , pixel_countdown , lines ); 151
pixel_ptr = y_ptr; 163
pixel_countdown = s -> avctx -> width; 164
while ( pixel_countdown > 0 )  165
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ pixel_ptr ] ); 166
pixel_ptr += 2; 167
y_ptr += s -> frame . linesize [ 0 ]; 170
y_ptr = 0; 175
for (lines = 0; lines < s->avctx->height; lines++) 176
pixel_ptr = y_ptr; 177
stream_ptr ++; 180
pixel_countdown = s -> avctx -> width; 181
while ( pixel_countdown > 0 )  183
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 184
if ( byte_run > 0 )  185
pixel = AV_RL16 ( & buf [ stream_ptr ] ); 186
stream_ptr += 2; 187
CHECK_PIXEL_PTR ( byte_run ); 188
for (j = 0; j < byte_run; j++) 189
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = pixel; 190
pixel_ptr += 2; 191
pixel_countdown --; 192
if ( pixel_countdown < 0 )  193
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d)\n" , pixel_countdown ); 194
byte_run = - byte_run; 198
CHECK_PIXEL_PTR ( byte_run ); 199
for (j = 0; j < byte_run; j++) 200
* ( ( signed short * ) ( & pixels [ pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr ] ); 201
stream_ptr += 2; 202
pixel_ptr += 2; 203
pixel_countdown --; 204
if ( pixel_countdown < 0 )  205
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d)\n" , pixel_countdown ); 206
y_ptr += s -> frame . linesize [ 0 ]; 212
if ( chunk_size - 6 > ( unsigned int ) ( s -> avctx -> width * s -> avctx -> height ) * 2 )  219
av_log ( avctx , AV_LOG_ERROR , "In chunk FLI_COPY : source data (%d bytes) "
"bigger than image, skipping chunk\n" , chunk_size - 6 ) 221
stream_ptr += chunk_size - 6; 222
for (y_ptr = 0; y_ptr < s->frame.linesize[0] * s->avctx->height;
y_ptr += s->frame.linesize[0]) 226
while ( pixel_countdown > 0 )  230
* ( ( signed short * ) ( & pixels [ y_ptr + pixel_ptr ] ) ) = AV_RL16 ( & buf [ stream_ptr + pixel_ptr ] ); 231
pixel_ptr += 2; 232
pixel_countdown --; 233
stream_ptr += s -> avctx -> width * 2; 235
stream_ptr += chunk_size - 6; 242
av_log ( avctx , AV_LOG_ERROR , "Unrecognized chunk type: %d\n" , chunk_type ); 246
frame_size -= chunk_size; 250
num_chunks --; 251
if ( ( stream_ptr != buf_size ) && ( stream_ptr != buf_size - 1 ) )  256
------------------------------
327 /home/speedy/test/source2slice/NVD/CVE_2010_3429_VULN_flic_decode_frame_15_16BPP.c pixel_limit = s -> avctx -> height * s -> frame . linesize [ 0 ] 40
static int CVE_2010_3429_VULN_flic_decode_frame_15_16BPP(AVCodecContext *avctx,
void *data, int *data_size,
const uint8_t *buf, int buf_size) 3
FlicDecodeContext * s = avctx -> priv_data ; 7
int pixel_limit ; 30
s -> frame . reference = 1; 32
s -> frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE; 33
if ( avctx -> reget_buffer ( avctx , & s -> frame ) < 0 )  34
pixel_limit = s -> avctx -> height * s -> frame . linesize [ 0 ]; 40
------------------------------
328 /home/speedy/test/source2slice/NVD/CVE_2010_3429_VULN_flic_decode_frame_8BPP.c stream_ptr_after_color_chunk = stream_ptr + chunk_size - 6 65
static int CVE_2010_3429_VULN_flic_decode_frame_8BPP(AVCodecContext *avctx,
void *data, int *data_size,
const uint8_t *buf, int buf_size) 3
FlicDecodeContext * s = avctx -> priv_data ; 5
int stream_ptr = 0 ; 7
int stream_ptr_after_color_chunk ; 8
int palette_ptr ; 10
unsigned char palette_idx1 ; 11
unsigned char palette_idx2 ; 12
unsigned int frame_size ; 14
int num_chunks ; 15
unsigned int chunk_size ; 17
int chunk_type ; 18
int i , j ; 20
int color_packets ; 22
int color_changes ; 23
int color_shift ; 24
unsigned char r , g , b ; 25
int lines ; 27
int compressed_lines ; 28
int starting_line ; 29
signed short line_packets ; 30
int y_ptr ; 31
int byte_run ; 32
int pixel_skip ; 33
int pixel_countdown ; 34
unsigned char * pixels ; 35
s -> frame . reference = 1; 38
s -> frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE; 39
if ( avctx -> reget_buffer ( avctx , & s -> frame ) < 0 )  40
pixels = s -> frame . data [ 0 ]; 45
frame_size = AV_RL32 ( & buf [ stream_ptr ] ); 48
stream_ptr += 6; 49
num_chunks = AV_RL16 ( & buf [ stream_ptr ] ); 50
stream_ptr += 10; 51
frame_size -= 16; 53
while ( ( frame_size > 0 ) && ( num_chunks > 0 ) )  56
chunk_size = AV_RL32 ( & buf [ stream_ptr ] ); 57
stream_ptr += 4; 58
chunk_type = AV_RL16 ( & buf [ stream_ptr ] ); 59
stream_ptr += 2; 60
switch ( chunk_type )  62
stream_ptr_after_color_chunk = stream_ptr + chunk_size - 6; 65
if ( ( chunk_type == FLI_256_COLOR ) && ( s -> fli_type != FLC_MAGIC_CARPET_SYNTHETIC_TYPE_CODE ) )  71
color_shift = 0; 72
color_shift = 2; 74
color_packets = AV_RL16 ( & buf [ stream_ptr ] ); 76
stream_ptr += 2; 77
palette_ptr = 0; 78
for (i = 0; i < color_packets; i++) 79
palette_ptr += buf [ stream_ptr ++ ]; 81
color_changes = buf [ stream_ptr ++ ]; 84
if ( color_changes == 0 )  87
color_changes = 256; 88
for (j = 0; j < color_changes; j++) 90
unsigned int entry ; 91
if ( ( unsigned ) palette_ptr >= 256 )  94
palette_ptr = 0; 95
r = buf [ stream_ptr ++ ] << color_shift; 97
g = buf [ stream_ptr ++ ] << color_shift; 98
b = buf [ stream_ptr ++ ] << color_shift; 99
entry = ( r << 16 ) | ( g << 8 ) | b; 100
if ( s -> palette [ palette_ptr ] != entry )  101
s -> new_palette = 1; 102
s -> palette [ palette_ptr ++ ] = entry; 103
stream_ptr = stream_ptr_after_color_chunk; 111
y_ptr = 0; 116
compressed_lines = AV_RL16 ( & buf [ stream_ptr ] ); 117
stream_ptr += 2; 118
while ( compressed_lines > 0 )  119
line_packets = AV_RL16 ( & buf [ stream_ptr ] ); 120
stream_ptr += 2; 121
if ( ( line_packets & 0xC000 ) == 0xC000 )  122
line_packets = - line_packets; 124
y_ptr += line_packets * s -> frame . linesize [ 0 ]; 125
if ( ( line_packets & 0xC000 ) == 0x4000 )  126
av_log ( avctx , AV_LOG_ERROR , "Undefined opcode (%x) in DELTA_FLI\n" , line_packets ); 127
if ( ( line_packets & 0xC000 ) == 0x8000 )  128
pixels [ y_ptr + s -> frame . linesize [ 0 ] - 1 ] = line_packets & 0xff; 130
compressed_lines --; 132
pixel_ptr = y_ptr; 133
pixel_countdown = s -> avctx -> width; 134
for (i = 0; i < line_packets; i++) 135
pixel_skip = buf [ stream_ptr ++ ]; 137
pixel_ptr += pixel_skip; 138
pixel_countdown -= pixel_skip; 139
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 140
if ( byte_run < 0 )  141
byte_run = - byte_run; 142
palette_idx1 = buf [ stream_ptr ++ ]; 143
palette_idx2 = buf [ stream_ptr ++ ]; 144
CHECK_PIXEL_PTR ( byte_run ); 145
for (j = 0; j < byte_run; j++, pixel_countdown -= 2) 146
pixels [ pixel_ptr ++ ] = palette_idx1; 147
pixels [ pixel_ptr ++ ] = palette_idx2; 148
CHECK_PIXEL_PTR ( byte_run * 2 ); 151
for (j = 0; j < byte_run * 2; j++, pixel_countdown--) 152
palette_idx1 = buf [ stream_ptr ++ ]; 153
pixels [ pixel_ptr ++ ] = palette_idx1; 154
y_ptr += s -> frame . linesize [ 0 ]; 159
starting_line = AV_RL16 ( & buf [ stream_ptr ] ); 166
stream_ptr += 2; 167
y_ptr = 0; 168
y_ptr += starting_line * s -> frame . linesize [ 0 ]; 169
compressed_lines = AV_RL16 ( & buf [ stream_ptr ] ); 171
stream_ptr += 2; 172
while ( compressed_lines > 0 )  173
pixel_ptr = y_ptr; 174
pixel_countdown = s -> avctx -> width; 175
line_packets = buf [ stream_ptr ++ ]; 176
if ( line_packets > 0 )  177
for (i = 0; i < line_packets; i++) 178
pixel_skip = buf [ stream_ptr ++ ]; 180
pixel_ptr += pixel_skip; 181
pixel_countdown -= pixel_skip; 182
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 183
if ( byte_run > 0 )  184
CHECK_PIXEL_PTR ( byte_run ); 185
for (j = 0; j < byte_run; j++, pixel_countdown--) 186
palette_idx1 = buf [ stream_ptr ++ ]; 187
pixels [ pixel_ptr ++ ] = palette_idx1; 188
if ( byte_run < 0 )  190
byte_run = - byte_run; 191
palette_idx1 = buf [ stream_ptr ++ ]; 192
CHECK_PIXEL_PTR ( byte_run ); 193
for (j = 0; j < byte_run; j++, pixel_countdown--) 194
pixels [ pixel_ptr ++ ] = palette_idx1; 195
y_ptr += s -> frame . linesize [ 0 ]; 201
compressed_lines --; 202
memset ( pixels , 0 , s -> frame . linesize [ 0 ] * s -> avctx -> height ); 208
y_ptr = 0; 215
for (lines = 0; lines < s->avctx->height; lines++) 216
pixel_ptr = y_ptr; 217
stream_ptr ++; 220
pixel_countdown = s -> avctx -> width; 221
while ( pixel_countdown > 0 )  222
byte_run = ( signed char ) ( buf [ stream_ptr ++ ] ); 223
if ( byte_run > 0 )  224
palette_idx1 = buf [ stream_ptr ++ ]; 225
CHECK_PIXEL_PTR ( byte_run ); 226
for (j = 0; j < byte_run; j++) 227
pixels [ pixel_ptr ++ ] = palette_idx1; 228
pixel_countdown --; 229
if ( pixel_countdown < 0 )  230
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d) at line %d\n" , pixel_countdown , lines ); 231
byte_run = - byte_run; 235
CHECK_PIXEL_PTR ( byte_run ); 236
for (j = 0; j < byte_run; j++) 237
palette_idx1 = buf [ stream_ptr ++ ]; 238
pixels [ pixel_ptr ++ ] = palette_idx1; 239
pixel_countdown --; 240
if ( pixel_countdown < 0 )  241
av_log ( avctx , AV_LOG_ERROR , "pixel_countdown < 0 (%d) at line %d\n" , pixel_countdown , lines ); 242
y_ptr += s -> frame . linesize [ 0 ]; 248
if ( chunk_size - 6 > s -> avctx -> width * s -> avctx -> height )  254
av_log ( avctx , AV_LOG_ERROR , "In chunk FLI_COPY : source data (%d bytes) "
"bigger than image, skipping chunk\n" , chunk_size - 6 ) 256
stream_ptr += chunk_size - 6; 257
for (y_ptr = 0; y_ptr < s->frame.linesize[0] * s->avctx->height;
y_ptr += s->frame.linesize[0]) 260
memcpy ( & pixels [ y_ptr ] , & buf [ stream_ptr ] , s -> avctx -> width ); 261
stream_ptr += s -> avctx -> width; 263
stream_ptr += chunk_size - 6; 270
av_log ( avctx , AV_LOG_ERROR , "Unrecognized chunk type: %d\n" , chunk_type ); 274
frame_size -= chunk_size; 278
num_chunks --; 279
if ( ( stream_ptr != buf_size ) && ( stream_ptr != buf_size - 1 ) )  284
memcpy ( s -> frame . data [ 1 ] , s -> palette , AVPALETTE_SIZE ); 289
if ( s -> new_palette )  290
s -> frame . palette_has_changed = 1; 291
s -> new_palette = 0; 292
* ( AVFrame * ) data = s -> frame; 296
------------------------------
329 /home/speedy/test/source2slice/NVD/CVE_2010_3429_VULN_flic_decode_frame_8BPP.c pixel_limit = s -> avctx -> height * s -> frame . linesize [ 0 ] 46
static int CVE_2010_3429_VULN_flic_decode_frame_8BPP(AVCodecContext *avctx,
void *data, int *data_size,
const uint8_t *buf, int buf_size) 3
FlicDecodeContext * s = avctx -> priv_data ; 5
int pixel_limit ; 36
s -> frame . reference = 1; 38
s -> frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE; 39
if ( avctx -> reget_buffer ( avctx , & s -> frame ) < 0 )  40
pixel_limit = s -> avctx -> height * s -> frame . linesize [ 0 ]; 46
------------------------------
330 /home/speedy/test/source2slice/NVD/CVE_2010_3848_PATCHED_econet_sendmsg.c skb = sock_alloc_send_skb ( sk , len + LL_ALLOCATED_SPACE ( dev ) , msg -> msg_flags & MSG_DONTWAIT , & err ) 81
static int CVE_2010_3848_PATCHED_econet_sendmsg(struct kiocb *iocb, struct socket *sock,
struct msghdr *msg, size_t len) 2
struct sock * sk = sock -> sk ; 4
struct sockaddr_ec * saddr = ( struct sockaddr_ec * ) msg -> msg_name ; 5
struct net_device * dev ; 6
struct ec_addr addr ; 7
struct sk_buff * skb ; 11
if ( msg -> msg_flags & ~ ( MSG_DONTWAIT | MSG_CMSG_COMPAT ) )  28
if ( saddr == NULL )  37
struct econet_sock * eo = ec_sk ( sk ) ; 38
addr . station = eo -> station; 40
addr . net = eo -> net; 41
if ( msg -> msg_namelen < sizeof ( struct sockaddr_ec ) )  45
addr . station = saddr -> addr . station; 49
addr . net = saddr -> addr . net; 50
dev = net2dev_map [ addr . net ]; 56
if ( dev == NULL )  59
dev = net2dev_map [ 0 ]; 60
if ( dev == NULL )  62
if ( dev -> type == ARPHRD_ECONET )  68
if ( len + 15 > dev -> mtu )  74
skb = sock_alloc_send_skb ( sk , len + LL_ALLOCATED_SPACE ( dev ) , msg -> msg_flags & MSG_DONTWAIT , & err ); 81
if ( skb == NULL )  83
skb_reserve ( skb , LL_RESERVED_SPACE ( dev ) ); 86
skb_reset_network_header ( skb ); 87
eb = ( struct ec_cb * ) & skb -> cb; 89
eb -> cookie = saddr -> cookie; 92
eb -> sec = * saddr; 93
eb -> sent = ec_tx_done; 94
res = dev_hard_header ( skb , dev , ntohs ( proto ) , & addr , NULL , len ); 97
if ( res < 0 )  98
if ( res > 0 )  100
fh = ( struct ec_framehdr * ) ( skb -> data ); 104
fh -> cb = cb; 105
fh -> port = port; 106
skb_reset_tail_pointer ( skb ); 108
skb -> len = 0; 109
err = memcpy_fromiovec ( skb_put ( skb , len ) , msg -> msg_iov , len ); 114
skb -> protocol = proto; 115
skb -> dev = dev; 116
skb -> priority = sk -> sk_priority; 117
if ( err )  118
dev_queue_xmit ( skb ); 129
kfree_skb ( skb ); 135
return err ; 144
------------------------------
331 /home/speedy/test/source2slice/NVD/CVE_2010_3848_VULN_econet_sendmsg.c skb = sock_alloc_send_skb ( sk , len + LL_ALLOCATED_SPACE ( dev ) , msg -> msg_flags & MSG_DONTWAIT , & err ) 81
static int CVE_2010_3848_VULN_econet_sendmsg(struct kiocb *iocb, struct socket *sock,
struct msghdr *msg, size_t len) 2
struct sock * sk = sock -> sk ; 4
struct sockaddr_ec * saddr = ( struct sockaddr_ec * ) msg -> msg_name ; 5
struct net_device * dev ; 6
struct ec_addr addr ; 7
struct sk_buff * skb ; 11
if ( msg -> msg_flags & ~ ( MSG_DONTWAIT | MSG_CMSG_COMPAT ) )  28
if ( saddr == NULL )  37
struct econet_sock * eo = ec_sk ( sk ) ; 38
addr . station = eo -> station; 40
addr . net = eo -> net; 41
if ( msg -> msg_namelen < sizeof ( struct sockaddr_ec ) )  45
addr . station = saddr -> addr . station; 49
addr . net = saddr -> addr . net; 50
dev = net2dev_map [ addr . net ]; 56
if ( dev == NULL )  59
dev = net2dev_map [ 0 ]; 60
if ( dev == NULL )  62
if ( len + 15 > dev -> mtu )  68
if ( dev -> type == ARPHRD_ECONET )  73
skb = sock_alloc_send_skb ( sk , len + LL_ALLOCATED_SPACE ( dev ) , msg -> msg_flags & MSG_DONTWAIT , & err ); 81
if ( skb == NULL )  83
skb_reserve ( skb , LL_RESERVED_SPACE ( dev ) ); 86
skb_reset_network_header ( skb ); 87
eb = ( struct ec_cb * ) & skb -> cb; 89
eb -> cookie = saddr -> cookie; 92
eb -> sec = * saddr; 93
eb -> sent = ec_tx_done; 94
res = dev_hard_header ( skb , dev , ntohs ( proto ) , & addr , NULL , len ); 97
if ( res < 0 )  98
if ( res > 0 )  100
fh = ( struct ec_framehdr * ) ( skb -> data ); 104
fh -> cb = cb; 105
fh -> port = port; 106
skb_reset_tail_pointer ( skb ); 108
skb -> len = 0; 109
err = memcpy_fromiovec ( skb_put ( skb , len ) , msg -> msg_iov , len ); 114
skb -> protocol = proto; 115
skb -> dev = dev; 116
skb -> priority = sk -> sk_priority; 117
if ( err )  118
dev_queue_xmit ( skb ); 129
kfree_skb ( skb ); 135
return err ; 144
if ( ( skb = sock_alloc_send_skb ( sk , 0 , msg -> msg_flags & MSG_DONTWAIT , & err ) ) == NULL )  210
return err ; 214
eb = ( struct ec_cb * ) & skb -> cb; 217
eb -> cookie = saddr -> cookie; 219
eb -> timeout = ( 5 * HZ ); 220
eb -> start = jiffies; 221
eb -> seq = ( aun_seq ++ ); 223
eb -> sec = * saddr; 224
skb_queue_tail ( & aun_queue , skb ); 226
return err ; 244
------------------------------
332 /home/speedy/test/source2slice/NVD/CVE_2013_4932_PATCHED_elem_lv_e.c item = proto_tree_add_text ( tree , tvb , curr_offset , parm_len + 2 , "%s%s" , elem_name ? elem_name : "Unknown - aborting dissection" , ( name_add == NULL ) || ( name_add [ 0 ] == '\0' ) ? "" : name_add ) 22
guint16 CVE_2013_4932_PATCHED_elem_lv_e(tvbuff_t *tvb, proto_tree *tree, packet_info *pinfo, gint pdu_type, int idx, guint32 offset, guint len _U_, const gchar *name_add) 1
guint16 parm_len ; 3
guint32 curr_offset ; 5
proto_item * item ; 7
const gchar * elem_name ; 10
curr_offset = offset; 13
parm_len = tvb_get_ntohs ( tvb , curr_offset ); 18
elem_name = try_val_to_str_ext ( idx , & elem_names_ext ); 20
item = proto_tree_add_text ( tree , tvb , curr_offset , parm_len + 2 , "%s%s" , elem_name ? elem_name : "Unknown - aborting dissection" , ( name_add == NULL ) || ( name_add [ 0 ] == '\0' ) ? "" : name_add ); 22
subtree = proto_item_add_subtree ( item , elem_ett [ idx ] ); 30
proto_tree_add_uint ( subtree , hf_gsm_a_length , tvb , curr_offset , 2 , parm_len ); 32
proto_tree_add_text ( subtree , tvb , curr_offset + 2 , parm_len , "Element Value" ); 39
consumed = ( * elem_funcs [ idx ] ) ( tvb , subtree , pinfo , curr_offset + 2 , parm_len , a_add_string , 1024 ); 51
proto_item_append_text ( item , "%s" , a_add_string ); 57
return ( consumed + 2 ) ; 62
------------------------------
333 /home/speedy/test/source2slice/NVD/CVE_2013_4932_PATCHED_elem_telv.c item = proto_tree_add_text ( tree , tvb , curr_offset , parm_len + 1 + lengt_length , "%s%s" , elem_name ? elem_name : "Unknown - aborting dissection" , ( name_add == NULL ) || ( name_add [ 0 ] == '\0' ) ? "" : name_add ) 34
guint16 CVE_2013_4932_PATCHED_elem_telv(tvbuff_t *tvb, proto_tree *tree, packet_info *pinfo, guint8 iei, gint pdu_type, int idx, guint32 offset, guint len _U_, const gchar *name_add) 1
guint8 oct ; 3
guint16 parm_len ; 4
guint8 lengt_length = 1 ; 5
guint32 curr_offset ; 7
proto_item * item ; 9
const gchar * elem_name ; 12
curr_offset = offset; 15
oct = tvb_get_guint8 ( tvb , curr_offset ); 20
if ( oct == iei )  22
parm_len = tvb_get_guint8 ( tvb , curr_offset + 1 ); 23
if ( ( parm_len & 0x80 ) == 0 )  24
parm_len = tvb_get_ntohs ( tvb , curr_offset + 1 ); 26
lengt_length = 2; 27
parm_len = parm_len & 0x7f; 29
elem_name = try_val_to_str_ext ( idx , & elem_names_ext ); 32
item = proto_tree_add_text ( tree , tvb , curr_offset , parm_len + 1 + lengt_length , "%s%s" , elem_name ? elem_name : "Unknown - aborting dissection" , ( name_add == NULL ) || ( name_add [ 0 ] == '\0' ) ? "" : name_add ); 34
subtree = proto_item_add_subtree ( item , elem_ett [ idx ] ); 44
proto_tree_add_uint ( subtree , get_hf_elem_id ( pdu_type ) , tvb , curr_offset , 1 , oct ); 46
proto_tree_add_item ( subtree , hf_gsm_a_l_ext , tvb , curr_offset + 1 , 1 , ENC_BIG_ENDIAN ); 50
proto_tree_add_uint ( subtree , hf_gsm_a_length , tvb , curr_offset + 1 , lengt_length , parm_len ); 52
proto_tree_add_text ( subtree , tvb , curr_offset + 1 + lengt_length , parm_len , "Element Value" ); 59
consumed = ( * elem_funcs [ idx ] ) ( tvb , subtree , pinfo , curr_offset + 1 + lengt_length , parm_len , a_add_string , 1024 ); 71
proto_item_append_text ( item , "%s" , a_add_string ); 77
consumed += 1 + lengt_length; 82
return ( consumed ) ; 85
------------------------------
334 /home/speedy/test/source2slice/NVD/CVE_2013_4932_PATCHED_elem_tlv.c item = proto_tree_add_text ( tree , tvb , curr_offset , parm_len + 1 + lengt_length , "%s%s" , elem_name ? elem_name : "Unknown - aborting dissection" , ( name_add == NULL ) || ( name_add [ 0 ] == '\0' ) ? "" : name_add ) 27
guint16 CVE_2013_4932_PATCHED_elem_tlv(tvbuff_t *tvb, proto_tree *tree, packet_info *pinfo, guint8 iei, gint pdu_type, int idx, guint32 offset, guint len _U_, const gchar *name_add) 1
guint8 oct ; 3
guint16 parm_len ; 4
guint8 lengt_length = 1 ; 5
guint32 curr_offset ; 7
proto_item * item ; 9
const gchar * elem_name ; 12
curr_offset = offset; 15
oct = tvb_get_guint8 ( tvb , curr_offset ); 20
if ( oct == iei )  22
parm_len = tvb_get_guint8 ( tvb , curr_offset + 1 ); 23
elem_name = try_val_to_str_ext ( idx , & elem_names_ext ); 25
item = proto_tree_add_text ( tree , tvb , curr_offset , parm_len + 1 + lengt_length , "%s%s" , elem_name ? elem_name : "Unknown - aborting dissection" , ( name_add == NULL ) || ( name_add [ 0 ] == '\0' ) ? "" : name_add ); 27
subtree = proto_item_add_subtree ( item , elem_ett [ idx ] ); 37
proto_tree_add_uint ( subtree , get_hf_elem_id ( pdu_type ) , tvb , curr_offset , 1 , oct ); 39
proto_tree_add_uint ( subtree , hf_gsm_a_length , tvb , curr_offset + 1 , lengt_length , parm_len ); 43
proto_tree_add_text ( subtree , tvb , curr_offset + 1 + lengt_length , parm_len , "Element Value" ); 50
consumed = ( * elem_funcs [ idx ] ) ( tvb , subtree , pinfo , curr_offset + 2 , parm_len , a_add_string , 1024 ); 62
proto_item_append_text ( item , "%s" , a_add_string ); 68
consumed += 1 + lengt_length; 73
return ( consumed ) ; 76
------------------------------
335 /home/speedy/test/source2slice/NVD/CVE_2013_4932_PATCHED_elem_tlv_e.c item = proto_tree_add_text ( tree , tvb , curr_offset , parm_len + 1 + 2 , "%s%s" , elem_name ? elem_name : "Unknown - aborting dissection" , ( name_add == NULL ) || ( name_add [ 0 ] == '\0' ) ? "" : name_add ) 26
guint16 CVE_2013_4932_PATCHED_elem_tlv_e(tvbuff_t *tvb, proto_tree *tree, packet_info *pinfo, guint8 iei, gint pdu_type, int idx, guint32 offset, guint len _U_, const gchar *name_add) 1
guint8 oct ; 3
guint16 parm_len ; 4
guint32 curr_offset ; 6
proto_item * item ; 8
const gchar * elem_name ; 11
curr_offset = offset; 14
oct = tvb_get_guint8 ( tvb , curr_offset ); 19
if ( oct == iei )  21
parm_len = tvb_get_ntohs ( tvb , curr_offset + 1 ); 22
elem_name = try_val_to_str_ext ( idx , & elem_names_ext ); 24
item = proto_tree_add_text ( tree , tvb , curr_offset , parm_len + 1 + 2 , "%s%s" , elem_name ? elem_name : "Unknown - aborting dissection" , ( name_add == NULL ) || ( name_add [ 0 ] == '\0' ) ? "" : name_add ); 26
subtree = proto_item_add_subtree ( item , elem_ett [ idx ] ); 34
proto_tree_add_uint ( subtree , get_hf_elem_id ( pdu_type ) , tvb , curr_offset , 1 , oct ); 36
proto_tree_add_uint ( subtree , hf_gsm_a_length , tvb , curr_offset + 1 , 2 , parm_len ); 40
proto_tree_add_text ( subtree , tvb , curr_offset + 1 + 2 , parm_len , "Element Value" ); 47
consumed = ( * elem_funcs [ idx ] ) ( tvb , subtree , pinfo , curr_offset + 1 + 2 , parm_len , a_add_string , 1024 ); 59
proto_item_append_text ( item , "%s" , a_add_string ); 65
consumed += 1 + 2; 70
return ( consumed ) ; 73
------------------------------
336 /home/speedy/test/source2slice/NVD/CVE_2013_4932_PATCHED_elem_tv.c item = proto_tree_add_text ( tree , tvb , curr_offset , - 1 , "%s%s" , elem_name ? elem_name : "Unknown - aborting dissection" , ( name_add == NULL ) || ( name_add [ 0 ] == '\0' ) ? "" : name_add ) 24
guint16 CVE_2013_4932_PATCHED_elem_tv(tvbuff_t *tvb, proto_tree *tree, packet_info *pinfo, guint8 iei, gint pdu_type, int idx, guint32 offset, const gchar *name_add) 1
guint8 oct ; 3
guint32 curr_offset ; 5
proto_item * item ; 7
const gchar * elem_name ; 10
curr_offset = offset; 13
oct = tvb_get_guint8 ( tvb , curr_offset ); 18
if ( oct == iei )  20
elem_name = try_val_to_str_ext ( idx , & elem_names_ext ); 22
item = proto_tree_add_text ( tree , tvb , curr_offset , - 1 , "%s%s" , elem_name ? elem_name : "Unknown - aborting dissection" , ( name_add == NULL ) || ( name_add [ 0 ] == '\0' ) ? "" : name_add ); 24
subtree = proto_item_add_subtree ( item , elem_ett [ idx ] ); 33
proto_tree_add_uint ( subtree , get_hf_elem_id ( pdu_type ) , tvb , curr_offset , 1 , oct ); 35
proto_tree_add_text ( subtree , tvb , curr_offset + 1 , 1 , "No element dissector, rest of dissection may be incorrect" ); 43
consumed = ( * elem_funcs [ idx ] ) ( tvb , subtree , pinfo , curr_offset + 1 , - 1 , a_add_string , 1024 ); 55
proto_item_append_text ( item , "%s" , a_add_string ); 59
consumed ++; 63
proto_item_set_len ( item , consumed ); 65
return ( consumed ) ; 68
------------------------------
337 /home/speedy/test/source2slice/NVD/CVE_2013_4932_PATCHED_elem_tv_short.c item = proto_tree_add_text ( tree , tvb , curr_offset , - 1 , "%s%s" , elem_name ? elem_name : "Unknown - aborting dissection" , ( name_add == NULL ) || ( name_add [ 0 ] == '\0' ) ? "" : name_add ) 25
guint16 CVE_2013_4932_PATCHED_elem_tv_short(tvbuff_t *tvb, proto_tree *tree, packet_info *pinfo, guint8 iei, gint pdu_type, int idx, guint32 offset, const gchar *name_add) 1
guint8 oct ; 3
guint32 curr_offset ; 5
proto_item * item ; 7
const gchar * elem_name ; 10
curr_offset = offset; 14
oct = tvb_get_guint8 ( tvb , curr_offset ); 19
if ( ( oct & 0xf0 ) == ( iei & 0xf0 ) )  21
elem_name = try_val_to_str_ext ( idx , & elem_names_ext ); 23
item = proto_tree_add_text ( tree , tvb , curr_offset , - 1 , "%s%s" , elem_name ? elem_name : "Unknown - aborting dissection" , ( name_add == NULL ) || ( name_add [ 0 ] == '\0' ) ? "" : name_add ); 25
subtree = proto_item_add_subtree ( item , elem_ett [ idx ] ); 35
proto_tree_add_text ( subtree , tvb , curr_offset , 1 , "%s = Element ID: 0x%1x-" , buf , oct >> 4 ); 38
proto_tree_add_text ( subtree , tvb , curr_offset , 1 , "No element dissector, rest of dissection may be incorrect" ); 47
consumed = ( * elem_funcs [ idx ] ) ( tvb , subtree , pinfo , curr_offset , RIGHT_NIBBLE , a_add_string , 1024 ); 59
proto_item_append_text ( item , "%s" , a_add_string ); 63
proto_item_set_len ( item , consumed ); 67
return ( consumed ) ; 70
------------------------------
338 /home/speedy/test/source2slice/NVD/CVE_2013_4932_PATCHED_elem_v_short.c item = proto_tree_add_text ( tree , tvb , curr_offset , 0 , "%s%s" , elem_name ? elem_name : "Unknown - aborting dissection" , "" ) 19
guint16 CVE_2013_4932_PATCHED_elem_v_short(tvbuff_t *tvb, proto_tree *tree, packet_info *pinfo, gint pdu_type, int idx, guint32 offset, guint32 nibble) 1
guint32 curr_offset ; 4
proto_item * item ; 6
const gchar * elem_name ; 11
curr_offset = offset; 13
elem_name = try_val_to_str_ext ( idx , & elem_names_ext ); 17
item = proto_tree_add_text ( tree , tvb , curr_offset , 0 , "%s%s" , elem_name ? elem_name : "Unknown - aborting dissection" , "" ); 19
subtree = proto_item_add_subtree ( item , elem_ett [ idx ] ); 28
( void ) de_spare_nibble ( tvb , subtree , pinfo , curr_offset , nibble , a_add_string , 1024 ); 36
( void ) ( * elem_funcs [ idx ] ) ( tvb , subtree , pinfo , curr_offset , nibble , a_add_string , 1024 ); 40
proto_item_append_text ( item , "%s" , a_add_string ); 45
proto_item_set_len ( item , consumed ); 47
------------------------------
339 /home/speedy/test/source2slice/NVD/CVE_2013_4936_PATCHED_IsDFP_Frame.c crc = crc16_plain_tvb_offset_seed ( tvb , u32SubStart , offset - u32SubStart , 0 ) 73
static gboolean
CVE_2013_4936_PATCHED_IsDFP_Frame(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
guint16 u16SFCRC16 ; 4
guint8 u8SFPosition ; 5
int offset = 0 ; 7
guint32 u32SubStart ; 8
guint16 crc ; 9
unsigned char virtualFramebuffer [ 16 ] ; 11
guint16 u16FrameID ; 12
u16FrameID = GPOINTER_TO_UINT ( pinfo -> private_data ); 15
if ( ! pinfo -> src . data || ! pinfo -> dst . data || pinfo -> dst . type != AT_ETHER || pinfo -> src . type != AT_ETHER )  18
virtualFramebuffer [ 12 ] = 0x88; 26
virtualFramebuffer [ 13 ] = 0x92; 27
virtualFramebuffer [ 15 ] = ( unsigned char ) ( u16FrameID & 0xff ); 28
virtualFramebuffer [ 14 ] = ( unsigned char ) ( u16FrameID >> 8 ); 29
crc = crc16_plain_init ( ); 30
crc = crc16_plain_update ( crc , & virtualFramebuffer [ 0 ] , 16 ); 31
crc = crc16_plain_finalize ( crc ); 32
u16SFCRC16 = tvb_get_letohs ( tvb , offset ); 34
if ( u16SFCRC16 != 0 )  35
if ( u16SFCRC16 != crc )  37
offset += 2; 45
tvb_len = tvb_length ( tvb ); 46
if ( offset + 4 > tvb_len )  47
if ( tvb_get_letohs ( tvb , offset ) == 0 )  49
while ( 1 )  51
u32SubStart = offset; 52
u8SFPosition = tvb_get_guint8 ( tvb , offset ); 54
offset += 1; 55
u8SFDataLength = tvb_get_guint8 ( tvb , offset ); 57
offset += 1; 58
if ( u8SFDataLength == 0 )  60
offset += 2; 64
offset += u8SFDataLength; 66
if ( offset > tvb_len )  67
u16SFCRC16 = tvb_get_letohs ( tvb , offset ); 70
if ( u16SFCRC16 != 0 )  71
if ( u8SFPosition & 0x80 )  72
crc = crc16_plain_tvb_offset_seed ( tvb , u32SubStart , offset - u32SubStart , 0 ); 73
if ( crc != u16SFCRC16 )  74
offset += 2; 81
------------------------------
340 /home/speedy/test/source2slice/NVD/CVE_2013_4936_VULN_IsDFP_Frame.c crc = crc16_plain_tvb_offset_seed ( tvb , u32SubStart , offset - u32SubStart , 0 ) 67
static gboolean
CVE_2013_4936_VULN_IsDFP_Frame(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
guint16 u16SFCRC16 ; 4
guint8 u8SFPosition ; 5
int offset = 0 ; 7
guint32 u32SubStart ; 8
guint16 crc ; 9
unsigned char virtualFramebuffer [ 16 ] ; 11
guint16 u16FrameID ; 12
u16FrameID = GPOINTER_TO_UINT ( pinfo -> private_data ); 15
virtualFramebuffer [ 12 ] = 0x88; 20
virtualFramebuffer [ 13 ] = 0x92; 21
virtualFramebuffer [ 15 ] = ( unsigned char ) ( u16FrameID & 0xff ); 22
virtualFramebuffer [ 14 ] = ( unsigned char ) ( u16FrameID >> 8 ); 23
crc = crc16_plain_init ( ); 24
crc = crc16_plain_update ( crc , & virtualFramebuffer [ 0 ] , 16 ); 25
crc = crc16_plain_finalize ( crc ); 26
u16SFCRC16 = tvb_get_letohs ( tvb , offset ); 28
if ( u16SFCRC16 != 0 )  29
if ( u16SFCRC16 != crc )  31
offset += 2; 39
tvb_len = tvb_length ( tvb ); 40
if ( offset + 4 > tvb_len )  41
if ( tvb_get_letohs ( tvb , offset ) == 0 )  43
while ( 1 )  45
u32SubStart = offset; 46
u8SFPosition = tvb_get_guint8 ( tvb , offset ); 48
offset += 1; 49
u8SFDataLength = tvb_get_guint8 ( tvb , offset ); 51
offset += 1; 52
if ( u8SFDataLength == 0 )  54
offset += 2; 58
offset += u8SFDataLength; 60
if ( offset > tvb_len )  61
u16SFCRC16 = tvb_get_letohs ( tvb , offset ); 64
if ( u16SFCRC16 != 0 )  65
if ( u8SFPosition & 0x80 )  66
crc = crc16_plain_tvb_offset_seed ( tvb , u32SubStart , offset - u32SubStart , 0 ); 67
if ( crc != u16SFCRC16 )  68
offset += 2; 75
------------------------------
341 /home/speedy/test/source2slice/NVD/CVE_2013_5593_PATCHED_nsComboboxControlFrame__AbsolutelyPositionDropDown.c dropdownPosition . x = GetRect ( ) . width - dropdownSize . width 45
nsComboboxControlFrame::DropDownPositionState
CVE_2013_5593_PATCHED_nsComboboxControlFrame::AbsolutelyPositionDropDown() 2
nscoord above , below ; 5
if ( above <= 0 && below <= 0 )  8
nsSize dropdownSize = mDropdownFrame -> GetSize ( ) ; 18
nscoord height = std :: max ( above , below ) ; 19
nsListControlFrame * lcf = static_cast < nsListControlFrame * > mDropdownFrame 20
if ( height < dropdownSize . height )  21
if ( lcf -> GetNumDisplayRows ( ) > 1 )  22
if ( height > ( dropdownSize . height + lcf -> GetHeightOfARow ( ) * 1.5 ) && lcf -> GetDropdownCanGrow ( ) )  28
bool b = dropdownSize . height <= below || dropdownSize . height > above ; 41
nsPoint dropdownPosition ( 0 , b ? GetRect ( ) . height : - dropdownSize . height ) ; 42
if ( StyleVisibility ( ) -> mDirection == NS_STYLE_DIRECTION_RTL )  43
dropdownPosition . x = GetRect ( ) . width - dropdownSize . width; 45
const nsPoint newPos = dropdownPosition + translation ; 51
if ( currentPos != newPos )  52
mDropdownFrame -> SetPosition ( newPos ); 53
------------------------------
342 /home/speedy/test/source2slice/NVD/CVE_2013_5593_VULN_nsComboboxControlFrame__AbsolutelyPositionDropDown.c dropdownPosition . x = GetRect ( ) . width - dropdownSize . width 44
nsComboboxControlFrame::DropDownPositionState
CVE_2013_5593_VULN_nsComboboxControlFrame::AbsolutelyPositionDropDown() 2
nscoord above , below ; 5
if ( above <= 0 && below <= 0 )  8
nsSize dropdownSize = mDropdownFrame -> GetSize ( ) ; 18
nscoord height = std :: max ( above , below ) ; 19
nsListControlFrame * lcf = static_cast < nsListControlFrame * > mDropdownFrame 20
if ( height < dropdownSize . height )  21
if ( lcf -> GetNumDisplayRows ( ) > 1 )  22
if ( height > ( dropdownSize . height + lcf -> GetHeightOfARow ( ) * 1.5 ) && lcf -> GetDropdownCanGrow ( ) )  28
bool b = dropdownSize . height <= below || below >= above ; 40
nsPoint dropdownPosition ( 0 , b ? GetRect ( ) . height : - dropdownSize . height ) ; 41
if ( StyleVisibility ( ) -> mDirection == NS_STYLE_DIRECTION_RTL )  42
dropdownPosition . x = GetRect ( ) . width - dropdownSize . width; 44
const nsPoint newPos = dropdownPosition + translation ; 50
if ( currentPos != newPos )  51
mDropdownFrame -> SetPosition ( newPos ); 52
------------------------------
343 /home/speedy/test/source2slice/NVD/CVE_2013_5642_PATCHED_process_sdp.c codecs = m + len 287
static int CVE_2013_5642_PATCHED_process_sdp(struct sip_pvt *p, struct sip_request *req, int t38action) 1
int start = req -> sdp_start ; 6
int next = start ; 7
const char * value = NULL ; 12
struct ast_format_cap * peercapability = ast_format_cap_alloc_nolock ( ) ; 33
struct ast_format_cap * vpeercapability = ast_format_cap_alloc_nolock ( ) ; 34
struct ast_format_cap * tpeercapability = ast_format_cap_alloc_nolock ( ) ; 35
struct ast_rtp_codecs newaudiortp , newvideortp , newtextrtp ; 39
struct ast_format_cap * newjointcapability = ast_format_cap_alloc_nolock ( ) ; 40
struct ast_format_cap * newpeercapability = ast_format_cap_alloc_nolock ( ) ; 41
const char * codecs ; 44
int codec ; 45
int secure_audio = FALSE ; 48
int secure_video = FALSE ; 49
int numberofports ; 53
int numberofmediastreams = 0 ; 54
int red_data_pt [ 10 ] ; 56
char red_fmtp [ 100 ] = "empty" ; 58
if ( ! p -> rtp )  67
if ( ! peercapability || ! vpeercapability || ! tpeercapability || ! newpeercapability || ! newjointcapability )  72
p -> lastrtprx = p -> lastrtptx = time ( NULL ); 83
memset ( p -> offered_media , 0 , sizeof ( p -> offered_media ) ); 85
nextm = get_sdp_iterate ( & next , req , "m" ); 88
if ( ast_strlen_zero ( nextm ) )  89
while ( ( type = get_sdp_line ( & iterator , next - 1 , req , & value ) ) != '\0' )  96
switch ( type )  98
if ( ! process_sdp_o ( value , p ) )  103
p -> novideo = TRUE; 137
p -> notext = TRUE; 138
while ( ! ast_strlen_zero ( nextm ) )  141
int audio = FALSE ; 142
int video = FALSE ; 143
int text = FALSE ; 145
int processed_crypto = FALSE ; 146
char protocol [ 5 ] = 0 , 147
int x ; 148
numberofports = 0; 150
len = - 1; 151
m = nextm; 153
iterator = next; 154
nextm = get_sdp_iterate ( & next , req , "m" ); 155
if ( strncmp ( m , "audio " , 6 ) == 0 )  158
if ( ( sscanf ( m , "audio %30u/%30u RTP/%4s %n" , & x , & numberofports , protocol , & len ) == 3 && len > 0 ) || ( sscanf ( m , "audio %30u RTP/%4s %n" , & x , protocol , & len ) == 2 && len > 0 ) )  159
if ( x == 0 )  161
if ( ! strcmp ( protocol , "SAVP" ) )  171
secure_audio = 1; 172
if ( strcmp ( protocol , "AVP" ) )  173
if ( p -> offered_media [ SDP_AUDIO ] . order_offered )  178
audio = TRUE; 184
p -> offered_media [ SDP_AUDIO ] . order_offered = ++ numberofmediastreams; 185
codecs = m + len; 189
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 191
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  192
if ( strncmp ( m , "video " , 6 ) == 0 )  210
if ( ( sscanf ( m , "video %30u/%30u RTP/%4s %n" , & x , & numberofports , protocol , & len ) == 3 && len > 0 ) || ( sscanf ( m , "video %30u RTP/%4s %n" , & x , protocol , & len ) == 2 && len > 0 ) )  211
if ( x == 0 )  213
if ( ! strcmp ( protocol , "SAVP" ) )  223
secure_video = 1; 224
if ( strcmp ( protocol , "AVP" ) )  225
if ( p -> offered_media [ SDP_VIDEO ] . order_offered )  230
video = TRUE; 236
p -> novideo = FALSE; 237
p -> offered_media [ SDP_VIDEO ] . order_offered = ++ numberofmediastreams; 238
codecs = m + len; 242
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 244
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  245
if ( strncmp ( m , "text " , 5 ) == 0 )  262
if ( ( sscanf ( m , "text %30u/%30u RTP/AVP %n" , & x , & numberofports , & len ) == 2 && len > 0 ) || ( sscanf ( m , "text %30u RTP/AVP %n" , & x , & len ) == 1 && len > 0 ) )  263
if ( x == 0 )  265
if ( p -> offered_media [ SDP_TEXT ] . order_offered )  275
text = TRUE; 281
p -> notext = FALSE; 282
p -> offered_media [ SDP_TEXT ] . order_offered = ++ numberofmediastreams; 283
codecs = m + len; 287
ast_copy_string ( p -> offered_media [ SDP_TEXT ] . codecs , codecs , sizeof ( p -> offered_media [ SDP_TEXT ] . codecs ) ); 288
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 289
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  290
ast_log ( LOG_WARNING , "Invalid syntax in RTP video format list: %s\n" , codecs ); 291
ast_verbose ( "Found RTP text format %d\n" , codec ); 296
ast_rtp_codecs_payloads_set_m_type ( & newtextrtp , NULL , codec ); 298
if ( strncmp ( m , "image " , 6 ) == 0 )  307
if ( ( sscanf ( m , "image %30u udptl t38%n" , & x , & len ) == 1 && len > 0 ) || ( sscanf ( m , "image %30u UDPTL t38%n" , & x , & len ) == 1 && len > 0 ) )  308
if ( x == 0 )  310
if ( initialize_udptl ( p ) )  315
if ( p -> offered_media [ SDP_IMAGE ] . order_offered )  321
p -> offered_media [ SDP_IMAGE ] . order_offered = ++ numberofmediastreams; 332
while ( ( type = get_sdp_line ( & iterator , next - 1 , req , & value ) ) != '\0' )  353
switch ( type )  356
if ( audio )  382
if ( process_sdp_a_sendonly ( value , & sendonly ) )  383
if ( ! processed_crypto && process_crypto ( p , p -> rtp , & p -> srtp , value ) )  385
processed_crypto = TRUE; 386
if ( video )  393
if ( ! processed_crypto && process_crypto ( p , p -> vrtp , & p -> vsrtp , value ) )  394
processed_crypto = TRUE; 395
if ( text )  402
if ( process_sdp_a_text ( value , p , & newtextrtp , red_fmtp , & red_num_gen , red_data_pt , & last_rtpmap_codec ) )  403
if ( ! processed_crypto && process_crypto ( p , p -> trtp , & p -> tsrtp , value ) )  405
processed_crypto = TRUE; 406
if ( audio && secure_audio && ! processed_crypto )  425
if ( video && secure_video && ! processed_crypto )  428
------------------------------
344 /home/speedy/test/source2slice/NVD/CVE_2013_5642_PATCHED_process_sdp.c codecs = m + len 242
static int CVE_2013_5642_PATCHED_process_sdp(struct sip_pvt *p, struct sip_request *req, int t38action) 1
int start = req -> sdp_start ; 6
int next = start ; 7
const char * value = NULL ; 12
struct ast_format_cap * peercapability = ast_format_cap_alloc_nolock ( ) ; 33
struct ast_format_cap * vpeercapability = ast_format_cap_alloc_nolock ( ) ; 34
struct ast_format_cap * tpeercapability = ast_format_cap_alloc_nolock ( ) ; 35
struct ast_rtp_codecs newaudiortp , newvideortp , newtextrtp ; 39
struct ast_format_cap * newjointcapability = ast_format_cap_alloc_nolock ( ) ; 40
struct ast_format_cap * newpeercapability = ast_format_cap_alloc_nolock ( ) ; 41
const char * codecs ; 44
int codec ; 45
int secure_audio = FALSE ; 48
int secure_video = FALSE ; 49
int numberofports ; 53
int numberofmediastreams = 0 ; 54
int red_data_pt [ 10 ] ; 56
char red_fmtp [ 100 ] = "empty" ; 58
if ( ! p -> rtp )  67
if ( ! peercapability || ! vpeercapability || ! tpeercapability || ! newpeercapability || ! newjointcapability )  72
p -> lastrtprx = p -> lastrtptx = time ( NULL ); 83
memset ( p -> offered_media , 0 , sizeof ( p -> offered_media ) ); 85
nextm = get_sdp_iterate ( & next , req , "m" ); 88
if ( ast_strlen_zero ( nextm ) )  89
while ( ( type = get_sdp_line ( & iterator , next - 1 , req , & value ) ) != '\0' )  96
switch ( type )  98
if ( ! process_sdp_o ( value , p ) )  103
p -> novideo = TRUE; 137
p -> notext = TRUE; 138
while ( ! ast_strlen_zero ( nextm ) )  141
int audio = FALSE ; 142
int video = FALSE ; 143
int text = FALSE ; 145
int processed_crypto = FALSE ; 146
char protocol [ 5 ] = 0 , 147
int x ; 148
numberofports = 0; 150
len = - 1; 151
m = nextm; 153
iterator = next; 154
nextm = get_sdp_iterate ( & next , req , "m" ); 155
if ( strncmp ( m , "audio " , 6 ) == 0 )  158
if ( ( sscanf ( m , "audio %30u/%30u RTP/%4s %n" , & x , & numberofports , protocol , & len ) == 3 && len > 0 ) || ( sscanf ( m , "audio %30u RTP/%4s %n" , & x , protocol , & len ) == 2 && len > 0 ) )  159
if ( x == 0 )  161
if ( ! strcmp ( protocol , "SAVP" ) )  171
secure_audio = 1; 172
if ( strcmp ( protocol , "AVP" ) )  173
if ( p -> offered_media [ SDP_AUDIO ] . order_offered )  178
audio = TRUE; 184
p -> offered_media [ SDP_AUDIO ] . order_offered = ++ numberofmediastreams; 185
codecs = m + len; 189
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 191
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  192
if ( strncmp ( m , "video " , 6 ) == 0 )  210
if ( ( sscanf ( m , "video %30u/%30u RTP/%4s %n" , & x , & numberofports , protocol , & len ) == 3 && len > 0 ) || ( sscanf ( m , "video %30u RTP/%4s %n" , & x , protocol , & len ) == 2 && len > 0 ) )  211
if ( x == 0 )  213
if ( ! strcmp ( protocol , "SAVP" ) )  223
secure_video = 1; 224
if ( strcmp ( protocol , "AVP" ) )  225
if ( p -> offered_media [ SDP_VIDEO ] . order_offered )  230
video = TRUE; 236
p -> novideo = FALSE; 237
p -> offered_media [ SDP_VIDEO ] . order_offered = ++ numberofmediastreams; 238
codecs = m + len; 242
ast_copy_string ( p -> offered_media [ SDP_VIDEO ] . codecs , codecs , sizeof ( p -> offered_media [ SDP_VIDEO ] . codecs ) ); 243
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 244
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  245
ast_log ( LOG_WARNING , "Invalid syntax in RTP video format list: %s\n" , codecs ); 246
ast_verbose ( "Found RTP video format %d\n" , codec ); 251
ast_rtp_codecs_payloads_set_m_type ( & newvideortp , NULL , codec ); 253
if ( strncmp ( m , "text " , 5 ) == 0 )  262
if ( ( sscanf ( m , "text %30u/%30u RTP/AVP %n" , & x , & numberofports , & len ) == 2 && len > 0 ) || ( sscanf ( m , "text %30u RTP/AVP %n" , & x , & len ) == 1 && len > 0 ) )  263
if ( x == 0 )  265
if ( p -> offered_media [ SDP_TEXT ] . order_offered )  275
text = TRUE; 281
p -> notext = FALSE; 282
p -> offered_media [ SDP_TEXT ] . order_offered = ++ numberofmediastreams; 283
codecs = m + len; 287
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 289
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  290
if ( strncmp ( m , "image " , 6 ) == 0 )  307
if ( ( sscanf ( m , "image %30u udptl t38%n" , & x , & len ) == 1 && len > 0 ) || ( sscanf ( m , "image %30u UDPTL t38%n" , & x , & len ) == 1 && len > 0 ) )  308
if ( x == 0 )  310
if ( initialize_udptl ( p ) )  315
if ( p -> offered_media [ SDP_IMAGE ] . order_offered )  321
p -> offered_media [ SDP_IMAGE ] . order_offered = ++ numberofmediastreams; 332
while ( ( type = get_sdp_line ( & iterator , next - 1 , req , & value ) ) != '\0' )  353
switch ( type )  356
if ( audio )  382
if ( process_sdp_a_sendonly ( value , & sendonly ) )  383
if ( ! processed_crypto && process_crypto ( p , p -> rtp , & p -> srtp , value ) )  385
processed_crypto = TRUE; 386
if ( video )  393
if ( ! processed_crypto && process_crypto ( p , p -> vrtp , & p -> vsrtp , value ) )  394
processed_crypto = TRUE; 395
if ( text )  402
if ( process_sdp_a_text ( value , p , & newtextrtp , red_fmtp , & red_num_gen , red_data_pt , & last_rtpmap_codec ) )  403
if ( ! processed_crypto && process_crypto ( p , p -> trtp , & p -> tsrtp , value ) )  405
processed_crypto = TRUE; 406
if ( audio && secure_audio && ! processed_crypto )  425
if ( video && secure_video && ! processed_crypto )  428
------------------------------
345 /home/speedy/test/source2slice/NVD/CVE_2013_5642_PATCHED_process_sdp.c codecs = m + len 189
static int CVE_2013_5642_PATCHED_process_sdp(struct sip_pvt *p, struct sip_request *req, int t38action) 1
int start = req -> sdp_start ; 6
int next = start ; 7
const char * value = NULL ; 12
struct ast_format_cap * peercapability = ast_format_cap_alloc_nolock ( ) ; 33
struct ast_format_cap * vpeercapability = ast_format_cap_alloc_nolock ( ) ; 34
struct ast_format_cap * tpeercapability = ast_format_cap_alloc_nolock ( ) ; 35
struct ast_rtp_codecs newaudiortp , newvideortp , newtextrtp ; 39
struct ast_format_cap * newjointcapability = ast_format_cap_alloc_nolock ( ) ; 40
struct ast_format_cap * newpeercapability = ast_format_cap_alloc_nolock ( ) ; 41
const char * codecs ; 44
int codec ; 45
int secure_audio = FALSE ; 48
int secure_video = FALSE ; 49
int numberofports ; 53
int numberofmediastreams = 0 ; 54
int red_data_pt [ 10 ] ; 56
char red_fmtp [ 100 ] = "empty" ; 58
if ( ! p -> rtp )  67
if ( ! peercapability || ! vpeercapability || ! tpeercapability || ! newpeercapability || ! newjointcapability )  72
p -> lastrtprx = p -> lastrtptx = time ( NULL ); 83
memset ( p -> offered_media , 0 , sizeof ( p -> offered_media ) ); 85
nextm = get_sdp_iterate ( & next , req , "m" ); 88
if ( ast_strlen_zero ( nextm ) )  89
while ( ( type = get_sdp_line ( & iterator , next - 1 , req , & value ) ) != '\0' )  96
switch ( type )  98
if ( ! process_sdp_o ( value , p ) )  103
p -> novideo = TRUE; 137
p -> notext = TRUE; 138
while ( ! ast_strlen_zero ( nextm ) )  141
int audio = FALSE ; 142
int video = FALSE ; 143
int text = FALSE ; 145
int processed_crypto = FALSE ; 146
char protocol [ 5 ] = 0 , 147
int x ; 148
numberofports = 0; 150
len = - 1; 151
m = nextm; 153
iterator = next; 154
nextm = get_sdp_iterate ( & next , req , "m" ); 155
if ( strncmp ( m , "audio " , 6 ) == 0 )  158
if ( ( sscanf ( m , "audio %30u/%30u RTP/%4s %n" , & x , & numberofports , protocol , & len ) == 3 && len > 0 ) || ( sscanf ( m , "audio %30u RTP/%4s %n" , & x , protocol , & len ) == 2 && len > 0 ) )  159
if ( x == 0 )  161
if ( ! strcmp ( protocol , "SAVP" ) )  171
secure_audio = 1; 172
if ( strcmp ( protocol , "AVP" ) )  173
if ( p -> offered_media [ SDP_AUDIO ] . order_offered )  178
audio = TRUE; 184
p -> offered_media [ SDP_AUDIO ] . order_offered = ++ numberofmediastreams; 185
codecs = m + len; 189
ast_copy_string ( p -> offered_media [ SDP_AUDIO ] . codecs , codecs , sizeof ( p -> offered_media [ SDP_AUDIO ] . codecs ) ); 190
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 191
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  192
ast_log ( LOG_WARNING , "Invalid syntax in RTP audio format list: %s\n" , codecs ); 193
ast_verbose ( "Found RTP audio format %d\n" , codec ); 198
ast_rtp_codecs_payloads_set_m_type ( & newaudiortp , NULL , codec ); 201
if ( strncmp ( m , "video " , 6 ) == 0 )  210
if ( ( sscanf ( m , "video %30u/%30u RTP/%4s %n" , & x , & numberofports , protocol , & len ) == 3 && len > 0 ) || ( sscanf ( m , "video %30u RTP/%4s %n" , & x , protocol , & len ) == 2 && len > 0 ) )  211
if ( x == 0 )  213
if ( ! strcmp ( protocol , "SAVP" ) )  223
secure_video = 1; 224
if ( strcmp ( protocol , "AVP" ) )  225
if ( p -> offered_media [ SDP_VIDEO ] . order_offered )  230
video = TRUE; 236
p -> novideo = FALSE; 237
p -> offered_media [ SDP_VIDEO ] . order_offered = ++ numberofmediastreams; 238
codecs = m + len; 242
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 244
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  245
if ( strncmp ( m , "text " , 5 ) == 0 )  262
if ( ( sscanf ( m , "text %30u/%30u RTP/AVP %n" , & x , & numberofports , & len ) == 2 && len > 0 ) || ( sscanf ( m , "text %30u RTP/AVP %n" , & x , & len ) == 1 && len > 0 ) )  263
if ( x == 0 )  265
if ( p -> offered_media [ SDP_TEXT ] . order_offered )  275
text = TRUE; 281
p -> notext = FALSE; 282
p -> offered_media [ SDP_TEXT ] . order_offered = ++ numberofmediastreams; 283
codecs = m + len; 287
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 289
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  290
if ( strncmp ( m , "image " , 6 ) == 0 )  307
if ( ( sscanf ( m , "image %30u udptl t38%n" , & x , & len ) == 1 && len > 0 ) || ( sscanf ( m , "image %30u UDPTL t38%n" , & x , & len ) == 1 && len > 0 ) )  308
if ( x == 0 )  310
if ( initialize_udptl ( p ) )  315
if ( p -> offered_media [ SDP_IMAGE ] . order_offered )  321
p -> offered_media [ SDP_IMAGE ] . order_offered = ++ numberofmediastreams; 332
while ( ( type = get_sdp_line ( & iterator , next - 1 , req , & value ) ) != '\0' )  353
switch ( type )  356
if ( audio )  382
if ( process_sdp_a_sendonly ( value , & sendonly ) )  383
if ( ! processed_crypto && process_crypto ( p , p -> rtp , & p -> srtp , value ) )  385
processed_crypto = TRUE; 386
if ( video )  393
if ( ! processed_crypto && process_crypto ( p , p -> vrtp , & p -> vsrtp , value ) )  394
processed_crypto = TRUE; 395
if ( text )  402
if ( process_sdp_a_text ( value , p , & newtextrtp , red_fmtp , & red_num_gen , red_data_pt , & last_rtpmap_codec ) )  403
if ( ! processed_crypto && process_crypto ( p , p -> trtp , & p -> tsrtp , value ) )  405
processed_crypto = TRUE; 406
if ( audio && secure_audio && ! processed_crypto )  425
if ( video && secure_video && ! processed_crypto )  428
------------------------------
346 /home/speedy/test/source2slice/NVD/CVE_2013_5642_VULN_process_sdp.c codecs = m + len 287
static int CVE_2013_5642_VULN_process_sdp(struct sip_pvt *p, struct sip_request *req, int t38action) 1
int start = req -> sdp_start ; 6
int next = start ; 7
const char * value = NULL ; 12
struct ast_format_cap * peercapability = ast_format_cap_alloc_nolock ( ) ; 33
struct ast_format_cap * vpeercapability = ast_format_cap_alloc_nolock ( ) ; 34
struct ast_format_cap * tpeercapability = ast_format_cap_alloc_nolock ( ) ; 35
struct ast_rtp_codecs newaudiortp , newvideortp , newtextrtp ; 39
struct ast_format_cap * newjointcapability = ast_format_cap_alloc_nolock ( ) ; 40
struct ast_format_cap * newpeercapability = ast_format_cap_alloc_nolock ( ) ; 41
const char * codecs ; 44
int codec ; 45
int secure_audio = FALSE ; 48
int secure_video = FALSE ; 49
int numberofports ; 53
int numberofmediastreams = 0 ; 54
int red_data_pt [ 10 ] ; 56
char red_fmtp [ 100 ] = "empty" ; 58
if ( ! p -> rtp )  67
if ( ! peercapability || ! vpeercapability || ! tpeercapability || ! newpeercapability || ! newjointcapability )  72
nextm = get_sdp_iterate ( & next , req , "m" ); 88
if ( ast_strlen_zero ( nextm ) )  89
while ( ( type = get_sdp_line ( & iterator , next - 1 , req , & value ) ) != '\0' )  96
switch ( type )  98
if ( ! process_sdp_o ( value , p ) )  103
p -> novideo = TRUE; 137
p -> notext = TRUE; 138
while ( ! ast_strlen_zero ( nextm ) )  141
int audio = FALSE ; 142
int video = FALSE ; 143
int text = FALSE ; 145
int processed_crypto = FALSE ; 146
char protocol [ 5 ] = 0 , 147
int x ; 148
numberofports = 0; 150
len = - 1; 151
m = nextm; 153
iterator = next; 154
nextm = get_sdp_iterate ( & next , req , "m" ); 155
if ( strncmp ( m , "audio " , 6 ) == 0 )  158
if ( ( sscanf ( m , "audio %30u/%30u RTP/%4s %n" , & x , & numberofports , protocol , & len ) == 3 && len > 0 ) || ( sscanf ( m , "audio %30u RTP/%4s %n" , & x , protocol , & len ) == 2 && len > 0 ) )  159
if ( x == 0 )  161
if ( ! strcmp ( protocol , "SAVP" ) )  171
secure_audio = 1; 172
if ( strcmp ( protocol , "AVP" ) )  173
if ( p -> offered_media [ SDP_AUDIO ] . order_offered )  178
audio = TRUE; 184
p -> offered_media [ SDP_AUDIO ] . order_offered = ++ numberofmediastreams; 185
codecs = m + len; 189
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 191
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  192
if ( strncmp ( m , "video " , 6 ) == 0 )  210
if ( ( sscanf ( m , "video %30u/%30u RTP/%4s %n" , & x , & numberofports , protocol , & len ) == 3 && len > 0 ) || ( sscanf ( m , "video %30u RTP/%4s %n" , & x , protocol , & len ) == 2 && len > 0 ) )  211
if ( x == 0 )  213
if ( ! strcmp ( protocol , "SAVP" ) )  223
secure_video = 1; 224
if ( strcmp ( protocol , "AVP" ) )  225
if ( p -> offered_media [ SDP_VIDEO ] . order_offered )  230
video = TRUE; 236
p -> novideo = FALSE; 237
p -> offered_media [ SDP_VIDEO ] . order_offered = ++ numberofmediastreams; 238
codecs = m + len; 242
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 244
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  245
if ( strncmp ( m , "text " , 5 ) == 0 )  262
if ( ( sscanf ( m , "text %30u/%30u RTP/AVP %n" , & x , & numberofports , & len ) == 2 && len > 0 ) || ( sscanf ( m , "text %30u RTP/AVP %n" , & x , & len ) == 1 && len > 0 ) )  263
if ( x == 0 )  265
if ( p -> offered_media [ SDP_TEXT ] . order_offered )  275
text = TRUE; 281
p -> notext = FALSE; 282
p -> offered_media [ SDP_TEXT ] . order_offered = ++ numberofmediastreams; 283
codecs = m + len; 287
ast_copy_string ( p -> offered_media [ SDP_TEXT ] . codecs , codecs , sizeof ( p -> offered_media [ SDP_TEXT ] . codecs ) ); 288
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 289
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  290
ast_log ( LOG_WARNING , "Invalid syntax in RTP video format list: %s\n" , codecs ); 291
ast_verbose ( "Found RTP text format %d\n" , codec ); 296
ast_rtp_codecs_payloads_set_m_type ( & newtextrtp , NULL , codec ); 298
if ( strncmp ( m , "image " , 6 ) == 0 )  307
if ( ( sscanf ( m , "image %30u udptl t38%n" , & x , & len ) == 1 && len > 0 ) || ( sscanf ( m , "image %30u UDPTL t38%n" , & x , & len ) == 1 && len > 0 ) )  308
if ( x == 0 )  310
if ( initialize_udptl ( p ) )  315
if ( p -> offered_media [ SDP_IMAGE ] . order_offered )  321
p -> offered_media [ SDP_IMAGE ] . order_offered = ++ numberofmediastreams; 332
while ( ( type = get_sdp_line ( & iterator , next - 1 , req , & value ) ) != '\0' )  353
switch ( type )  356
if ( audio )  382
if ( process_sdp_a_sendonly ( value , & sendonly ) )  383
if ( ! processed_crypto && process_crypto ( p , p -> rtp , & p -> srtp , value ) )  385
processed_crypto = TRUE; 386
if ( video )  393
if ( ! processed_crypto && process_crypto ( p , p -> vrtp , & p -> vsrtp , value ) )  394
processed_crypto = TRUE; 395
if ( text )  402
if ( process_sdp_a_text ( value , p , & newtextrtp , red_fmtp , & red_num_gen , red_data_pt , & last_rtpmap_codec ) )  403
if ( ! processed_crypto && process_crypto ( p , p -> trtp , & p -> tsrtp , value ) )  405
processed_crypto = TRUE; 406
if ( audio && secure_audio && ! processed_crypto )  425
if ( video && secure_video && ! processed_crypto )  428
------------------------------
347 /home/speedy/test/source2slice/NVD/CVE_2013_5642_VULN_process_sdp.c codecs = m + len 242
static int CVE_2013_5642_VULN_process_sdp(struct sip_pvt *p, struct sip_request *req, int t38action) 1
int start = req -> sdp_start ; 6
int next = start ; 7
const char * value = NULL ; 12
struct ast_format_cap * peercapability = ast_format_cap_alloc_nolock ( ) ; 33
struct ast_format_cap * vpeercapability = ast_format_cap_alloc_nolock ( ) ; 34
struct ast_format_cap * tpeercapability = ast_format_cap_alloc_nolock ( ) ; 35
struct ast_rtp_codecs newaudiortp , newvideortp , newtextrtp ; 39
struct ast_format_cap * newjointcapability = ast_format_cap_alloc_nolock ( ) ; 40
struct ast_format_cap * newpeercapability = ast_format_cap_alloc_nolock ( ) ; 41
const char * codecs ; 44
int codec ; 45
int secure_audio = FALSE ; 48
int secure_video = FALSE ; 49
int numberofports ; 53
int numberofmediastreams = 0 ; 54
int red_data_pt [ 10 ] ; 56
char red_fmtp [ 100 ] = "empty" ; 58
if ( ! p -> rtp )  67
if ( ! peercapability || ! vpeercapability || ! tpeercapability || ! newpeercapability || ! newjointcapability )  72
nextm = get_sdp_iterate ( & next , req , "m" ); 88
if ( ast_strlen_zero ( nextm ) )  89
while ( ( type = get_sdp_line ( & iterator , next - 1 , req , & value ) ) != '\0' )  96
switch ( type )  98
if ( ! process_sdp_o ( value , p ) )  103
p -> novideo = TRUE; 137
p -> notext = TRUE; 138
while ( ! ast_strlen_zero ( nextm ) )  141
int audio = FALSE ; 142
int video = FALSE ; 143
int text = FALSE ; 145
int processed_crypto = FALSE ; 146
char protocol [ 5 ] = 0 , 147
int x ; 148
numberofports = 0; 150
len = - 1; 151
m = nextm; 153
iterator = next; 154
nextm = get_sdp_iterate ( & next , req , "m" ); 155
if ( strncmp ( m , "audio " , 6 ) == 0 )  158
if ( ( sscanf ( m , "audio %30u/%30u RTP/%4s %n" , & x , & numberofports , protocol , & len ) == 3 && len > 0 ) || ( sscanf ( m , "audio %30u RTP/%4s %n" , & x , protocol , & len ) == 2 && len > 0 ) )  159
if ( x == 0 )  161
if ( ! strcmp ( protocol , "SAVP" ) )  171
secure_audio = 1; 172
if ( strcmp ( protocol , "AVP" ) )  173
if ( p -> offered_media [ SDP_AUDIO ] . order_offered )  178
audio = TRUE; 184
p -> offered_media [ SDP_AUDIO ] . order_offered = ++ numberofmediastreams; 185
codecs = m + len; 189
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 191
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  192
if ( strncmp ( m , "video " , 6 ) == 0 )  210
if ( ( sscanf ( m , "video %30u/%30u RTP/%4s %n" , & x , & numberofports , protocol , & len ) == 3 && len > 0 ) || ( sscanf ( m , "video %30u RTP/%4s %n" , & x , protocol , & len ) == 2 && len > 0 ) )  211
if ( x == 0 )  213
if ( ! strcmp ( protocol , "SAVP" ) )  223
secure_video = 1; 224
if ( strcmp ( protocol , "AVP" ) )  225
if ( p -> offered_media [ SDP_VIDEO ] . order_offered )  230
video = TRUE; 236
p -> novideo = FALSE; 237
p -> offered_media [ SDP_VIDEO ] . order_offered = ++ numberofmediastreams; 238
codecs = m + len; 242
ast_copy_string ( p -> offered_media [ SDP_VIDEO ] . codecs , codecs , sizeof ( p -> offered_media [ SDP_VIDEO ] . codecs ) ); 243
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 244
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  245
ast_log ( LOG_WARNING , "Invalid syntax in RTP video format list: %s\n" , codecs ); 246
ast_verbose ( "Found RTP video format %d\n" , codec ); 251
ast_rtp_codecs_payloads_set_m_type ( & newvideortp , NULL , codec ); 253
if ( strncmp ( m , "text " , 5 ) == 0 )  262
if ( ( sscanf ( m , "text %30u/%30u RTP/AVP %n" , & x , & numberofports , & len ) == 2 && len > 0 ) || ( sscanf ( m , "text %30u RTP/AVP %n" , & x , & len ) == 1 && len > 0 ) )  263
if ( x == 0 )  265
if ( p -> offered_media [ SDP_TEXT ] . order_offered )  275
text = TRUE; 281
p -> notext = FALSE; 282
p -> offered_media [ SDP_TEXT ] . order_offered = ++ numberofmediastreams; 283
codecs = m + len; 287
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 289
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  290
if ( strncmp ( m , "image " , 6 ) == 0 )  307
if ( ( sscanf ( m , "image %30u udptl t38%n" , & x , & len ) == 1 && len > 0 ) || ( sscanf ( m , "image %30u UDPTL t38%n" , & x , & len ) == 1 && len > 0 ) )  308
if ( x == 0 )  310
if ( initialize_udptl ( p ) )  315
if ( p -> offered_media [ SDP_IMAGE ] . order_offered )  321
p -> offered_media [ SDP_IMAGE ] . order_offered = ++ numberofmediastreams; 332
while ( ( type = get_sdp_line ( & iterator , next - 1 , req , & value ) ) != '\0' )  353
switch ( type )  356
if ( audio )  382
if ( process_sdp_a_sendonly ( value , & sendonly ) )  383
if ( ! processed_crypto && process_crypto ( p , p -> rtp , & p -> srtp , value ) )  385
processed_crypto = TRUE; 386
if ( video )  393
if ( ! processed_crypto && process_crypto ( p , p -> vrtp , & p -> vsrtp , value ) )  394
processed_crypto = TRUE; 395
if ( text )  402
if ( process_sdp_a_text ( value , p , & newtextrtp , red_fmtp , & red_num_gen , red_data_pt , & last_rtpmap_codec ) )  403
if ( ! processed_crypto && process_crypto ( p , p -> trtp , & p -> tsrtp , value ) )  405
processed_crypto = TRUE; 406
if ( audio && secure_audio && ! processed_crypto )  425
if ( video && secure_video && ! processed_crypto )  428
------------------------------
348 /home/speedy/test/source2slice/NVD/CVE_2013_5642_VULN_process_sdp.c codecs = m + len 189
static int CVE_2013_5642_VULN_process_sdp(struct sip_pvt *p, struct sip_request *req, int t38action) 1
int start = req -> sdp_start ; 6
int next = start ; 7
const char * value = NULL ; 12
struct ast_format_cap * peercapability = ast_format_cap_alloc_nolock ( ) ; 33
struct ast_format_cap * vpeercapability = ast_format_cap_alloc_nolock ( ) ; 34
struct ast_format_cap * tpeercapability = ast_format_cap_alloc_nolock ( ) ; 35
struct ast_rtp_codecs newaudiortp , newvideortp , newtextrtp ; 39
struct ast_format_cap * newjointcapability = ast_format_cap_alloc_nolock ( ) ; 40
struct ast_format_cap * newpeercapability = ast_format_cap_alloc_nolock ( ) ; 41
const char * codecs ; 44
int codec ; 45
int secure_audio = FALSE ; 48
int secure_video = FALSE ; 49
int numberofports ; 53
int numberofmediastreams = 0 ; 54
int red_data_pt [ 10 ] ; 56
char red_fmtp [ 100 ] = "empty" ; 58
if ( ! p -> rtp )  67
if ( ! peercapability || ! vpeercapability || ! tpeercapability || ! newpeercapability || ! newjointcapability )  72
nextm = get_sdp_iterate ( & next , req , "m" ); 88
if ( ast_strlen_zero ( nextm ) )  89
while ( ( type = get_sdp_line ( & iterator , next - 1 , req , & value ) ) != '\0' )  96
switch ( type )  98
if ( ! process_sdp_o ( value , p ) )  103
p -> novideo = TRUE; 137
p -> notext = TRUE; 138
while ( ! ast_strlen_zero ( nextm ) )  141
int audio = FALSE ; 142
int video = FALSE ; 143
int text = FALSE ; 145
int processed_crypto = FALSE ; 146
char protocol [ 5 ] = 0 , 147
int x ; 148
numberofports = 0; 150
len = - 1; 151
m = nextm; 153
iterator = next; 154
nextm = get_sdp_iterate ( & next , req , "m" ); 155
if ( strncmp ( m , "audio " , 6 ) == 0 )  158
if ( ( sscanf ( m , "audio %30u/%30u RTP/%4s %n" , & x , & numberofports , protocol , & len ) == 3 && len > 0 ) || ( sscanf ( m , "audio %30u RTP/%4s %n" , & x , protocol , & len ) == 2 && len > 0 ) )  159
if ( x == 0 )  161
if ( ! strcmp ( protocol , "SAVP" ) )  171
secure_audio = 1; 172
if ( strcmp ( protocol , "AVP" ) )  173
if ( p -> offered_media [ SDP_AUDIO ] . order_offered )  178
audio = TRUE; 184
p -> offered_media [ SDP_AUDIO ] . order_offered = ++ numberofmediastreams; 185
codecs = m + len; 189
ast_copy_string ( p -> offered_media [ SDP_AUDIO ] . codecs , codecs , sizeof ( p -> offered_media [ SDP_AUDIO ] . codecs ) ); 190
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 191
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  192
ast_log ( LOG_WARNING , "Invalid syntax in RTP audio format list: %s\n" , codecs ); 193
ast_verbose ( "Found RTP audio format %d\n" , codec ); 198
ast_rtp_codecs_payloads_set_m_type ( & newaudiortp , NULL , codec ); 201
if ( strncmp ( m , "video " , 6 ) == 0 )  210
if ( ( sscanf ( m , "video %30u/%30u RTP/%4s %n" , & x , & numberofports , protocol , & len ) == 3 && len > 0 ) || ( sscanf ( m , "video %30u RTP/%4s %n" , & x , protocol , & len ) == 2 && len > 0 ) )  211
if ( x == 0 )  213
if ( ! strcmp ( protocol , "SAVP" ) )  223
secure_video = 1; 224
if ( strcmp ( protocol , "AVP" ) )  225
if ( p -> offered_media [ SDP_VIDEO ] . order_offered )  230
video = TRUE; 236
p -> novideo = FALSE; 237
p -> offered_media [ SDP_VIDEO ] . order_offered = ++ numberofmediastreams; 238
codecs = m + len; 242
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 244
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  245
if ( strncmp ( m , "text " , 5 ) == 0 )  262
if ( ( sscanf ( m , "text %30u/%30u RTP/AVP %n" , & x , & numberofports , & len ) == 2 && len > 0 ) || ( sscanf ( m , "text %30u RTP/AVP %n" , & x , & len ) == 1 && len > 0 ) )  263
if ( x == 0 )  265
if ( p -> offered_media [ SDP_TEXT ] . order_offered )  275
text = TRUE; 281
p -> notext = FALSE; 282
p -> offered_media [ SDP_TEXT ] . order_offered = ++ numberofmediastreams; 283
codecs = m + len; 287
for (; !ast_strlen_zero(codecs); codecs = ast_skip_blanks(codecs + len)) 289
if ( sscanf ( codecs , "%30u%n" , & codec , & len ) != 1 )  290
if ( strncmp ( m , "image " , 6 ) == 0 )  307
if ( ( sscanf ( m , "image %30u udptl t38%n" , & x , & len ) == 1 && len > 0 ) || ( sscanf ( m , "image %30u UDPTL t38%n" , & x , & len ) == 1 && len > 0 ) )  308
if ( x == 0 )  310
if ( initialize_udptl ( p ) )  315
if ( p -> offered_media [ SDP_IMAGE ] . order_offered )  321
p -> offered_media [ SDP_IMAGE ] . order_offered = ++ numberofmediastreams; 332
while ( ( type = get_sdp_line ( & iterator , next - 1 , req , & value ) ) != '\0' )  353
switch ( type )  356
if ( audio )  382
if ( process_sdp_a_sendonly ( value , & sendonly ) )  383
if ( ! processed_crypto && process_crypto ( p , p -> rtp , & p -> srtp , value ) )  385
processed_crypto = TRUE; 386
if ( video )  393
if ( ! processed_crypto && process_crypto ( p , p -> vrtp , & p -> vsrtp , value ) )  394
processed_crypto = TRUE; 395
if ( text )  402
if ( process_sdp_a_text ( value , p , & newtextrtp , red_fmtp , & red_num_gen , red_data_pt , & last_rtpmap_codec ) )  403
if ( ! processed_crypto && process_crypto ( p , p -> trtp , & p -> tsrtp , value ) )  405
processed_crypto = TRUE; 406
if ( audio && secure_audio && ! processed_crypto )  425
if ( video && secure_video && ! processed_crypto )  428
------------------------------
349 /home/speedy/test/source2slice/NVD/CVE_2013_6167_PATCHED_nsCookieService__SetCookieInternal.c cookieAttributes . isSession = GetExpiry ( cookieAttributes , aServerTime , currentTimeInUsec / PR_USEC_PER_SEC ) 31
bool
CVE_2013_6167_PATCHED_nsCookieService::SetCookieInternal(nsIURI                        *aHostURI,
const nsCookieKey             &aKey,
bool                           aRequireHostMatch,
CookieStatus                   aStatus,
nsDependentCString            &aCookieHeader,
int64_t                        aServerTime,
bool                           aFromHttp,
nsIChannel                    *aChannel) 9
nsCookieAttributes cookieAttributes ; 15
cookieAttributes . expiryTime = INT64_MAX; 18
int64_t currentTimeInUsec = PR_Now ( ) ; 28
cookieAttributes . isSession = GetExpiry ( cookieAttributes , aServerTime , currentTimeInUsec / PR_USEC_PER_SEC ); 31
cookieAttributes . isSession = true; 36
if ( ( cookieAttributes . name . Length ( ) + cookieAttributes . value . Length ( ) ) > kMaxBytesPerCookie )  40
if ( cookieAttributes . name . FindChar ( '\t' ) != kNotFound )  45
if ( ContainsControlCharacters ( cookieAttributes . name ) || ContainsControlCharacters ( cookieAttributes . value ) )  51
if ( ! CheckDomain ( cookieAttributes , aHostURI , aKey . mBaseDomain , aRequireHostMatch ) )  57
if ( ! CheckPath ( cookieAttributes , aHostURI ) )  61
nsRefPtr < nsCookie > cookie = nsCookie :: Create ( cookieAttributes . name , cookieAttributes . value , cookieAttributes . host , cookieAttributes . path , cookieAttributes . expiryTime , currentTimeInUsec , nsCookie :: GenerateUniqueCreationTime ( currentTimeInUsec ) , cookieAttributes . isSession , cookieAttributes . isSecure , cookieAttributes . isHttpOnly ) ; 67
if ( ! cookie )  78
mPermissionService -> CanSetCookie ( aHostURI ,
aChannel ,
static_cast < nsICookie2 * > ( static_cast < nsCookie * > ( cookie ) ) ,
& cookieAttributes . isSession ,
& cookieAttributes . expiryTime ,
& permission ) 90
cookie -> SetIsSession ( cookieAttributes . isSession ); 98
cookie -> SetExpiry ( cookieAttributes . expiryTime ); 99
AddInternal ( aKey , cookie , PR_Now ( ) , aHostURI , savedCookieHeader . get ( ) , aFromHttp ); 104
------------------------------
350 /home/speedy/test/source2slice/NVD/CVE_2013_6167_VULN_nsCookieService__SetCookieInternal.c cookieAttributes . isSession = GetExpiry ( cookieAttributes , aServerTime , currentTimeInUsec / PR_USEC_PER_SEC ) 31
bool
CVE_2013_6167_VULN_nsCookieService::SetCookieInternal(nsIURI                        *aHostURI,
const nsCookieKey             &aKey,
bool                           aRequireHostMatch,
CookieStatus                   aStatus,
nsDependentCString            &aCookieHeader,
int64_t                        aServerTime,
bool                           aFromHttp,
nsIChannel                    *aChannel) 9
nsCookieAttributes cookieAttributes ; 15
cookieAttributes . expiryTime = INT64_MAX; 18
int64_t currentTimeInUsec = PR_Now ( ) ; 28
cookieAttributes . isSession = GetExpiry ( cookieAttributes , aServerTime , currentTimeInUsec / PR_USEC_PER_SEC ); 31
cookieAttributes . isSession = true; 36
if ( ( cookieAttributes . name . Length ( ) + cookieAttributes . value . Length ( ) ) > kMaxBytesPerCookie )  40
if ( cookieAttributes . name . FindChar ( '\t' ) != kNotFound )  45
if ( ! CheckDomain ( cookieAttributes , aHostURI , aKey . mBaseDomain , aRequireHostMatch ) )  51
if ( ! CheckPath ( cookieAttributes , aHostURI ) )  55
nsRefPtr < nsCookie > cookie = nsCookie :: Create ( cookieAttributes . name , cookieAttributes . value , cookieAttributes . host , cookieAttributes . path , cookieAttributes . expiryTime , currentTimeInUsec , nsCookie :: GenerateUniqueCreationTime ( currentTimeInUsec ) , cookieAttributes . isSession , cookieAttributes . isSecure , cookieAttributes . isHttpOnly ) ; 61
if ( ! cookie )  72
mPermissionService -> CanSetCookie ( aHostURI ,
aChannel ,
static_cast < nsICookie2 * > ( static_cast < nsCookie * > ( cookie ) ) ,
& cookieAttributes . isSession ,
& cookieAttributes . expiryTime ,
& permission ) 84
cookie -> SetIsSession ( cookieAttributes . isSession ); 92
cookie -> SetExpiry ( cookieAttributes . expiryTime ); 93
AddInternal ( aKey , cookie , PR_Now ( ) , aHostURI , savedCookieHeader . get ( ) , aFromHttp ); 98
------------------------------
351 /home/speedy/test/source2slice/NVD/CVE_2013_6367_PATCHED_apic_get_tmcct.c tmcct = div64_u64 ( ns , ( APIC_BUS_CYCLE_NS * apic -> divide_count ) ) 19
static u32 CVE_2013_6367_PATCHED_apic_get_tmcct(struct kvm_lapic *apic) 1
ktime_t remaining ; 3
s64 ns ; 4
u32 tmcct ; 5
if ( kvm_apic_get_reg ( apic , APIC_TMICT ) == 0 || apic -> lapic_timer . period == 0 )  10
remaining = hrtimer_get_remaining ( & apic -> lapic_timer . timer ); 14
if ( ktime_to_ns ( remaining ) < 0 )  15
remaining = ktime_set ( 0 , 0 ); 16
ns = mod_64 ( ktime_to_ns ( remaining ) , apic -> lapic_timer . period ); 18
tmcct = div64_u64 ( ns , ( APIC_BUS_CYCLE_NS * apic -> divide_count ) ); 19
return tmcct ; 22
------------------------------
352 /home/speedy/test/source2slice/NVD/CVE_2013_6367_VULN_apic_get_tmcct.c tmcct = div64_u64 ( ns , ( APIC_BUS_CYCLE_NS * apic -> divide_count ) ) 18
static u32 CVE_2013_6367_VULN_apic_get_tmcct(struct kvm_lapic *apic) 1
ktime_t remaining ; 3
s64 ns ; 4
u32 tmcct ; 5
if ( kvm_apic_get_reg ( apic , APIC_TMICT ) == 0 )  10
remaining = hrtimer_get_remaining ( & apic -> lapic_timer . timer ); 13
if ( ktime_to_ns ( remaining ) < 0 )  14
remaining = ktime_set ( 0 , 0 ); 15
ns = mod_64 ( ktime_to_ns ( remaining ) , apic -> lapic_timer . period ); 17
tmcct = div64_u64 ( ns , ( APIC_BUS_CYCLE_NS * apic -> divide_count ) ); 18
return tmcct ; 21
------------------------------
353 /home/speedy/test/source2slice/NVD/CVE_2013_6380_PATCHED_aac_send_raw_srb.c usg = kmalloc ( actual_fibsize - sizeof ( struct aac_srb ) + sizeof ( struct sgmap ) , GFP_KERNEL ) 173
static int CVE_2013_6380_PATCHED_aac_send_raw_srb(struct aac_dev* dev, void __user * arg) 1
struct fib * srbfib ; 3
struct user_aac_srb __user * user_srb = arg ; 7
u32 fibsize = 0 ; 10
u32 data_dir ; 13
void * sg_list [ 32 ] ; 15
if ( dev -> in_reset )  22
if ( ! capable ( CAP_SYS_ADMIN ) )  26
if ( ! ( srbfib = aac_fib_alloc ( dev ) ) )  33
memset ( sg_list , 0 , sizeof ( sg_list ) ); 42
if ( copy_from_user ( & fibsize , & user_srb -> count , sizeof ( u32 ) ) )  43
if ( ( fibsize < ( sizeof ( struct user_aac_srb ) - sizeof ( struct user_sgentry ) ) ) || ( fibsize > ( dev -> max_fib_size - sizeof ( struct aac_fibhdr ) ) ) )  49
user_srbcmd = kmalloc ( fibsize , GFP_KERNEL ); 55
if ( ! user_srbcmd )  56
if ( copy_from_user ( user_srbcmd , user_srb , fibsize ) )  61
flags = user_srbcmd -> flags; 69
switch ( flags & ( SRB_DataIn | SRB_DataOut ) )  82
data_dir = DMA_TO_DEVICE; 84
data_dir = DMA_BIDIRECTIONAL; 87
data_dir = DMA_FROM_DEVICE; 90
data_dir = DMA_NONE; 93
if ( user_srbcmd -> sg . count > ARRAY_SIZE ( sg_list ) )  95
actual_fibsize = sizeof ( struct aac_srb ) - sizeof ( struct sgentry ) + ( ( user_srbcmd -> sg . count & 0xff ) * sizeof ( struct sgentry ) ); 101
actual_fibsize64 = actual_fibsize + ( user_srbcmd -> sg . count & 0xff ) * ( sizeof ( struct sgentry64 ) - sizeof ( struct sgentry ) ); 103
if ( ( actual_fibsize != fibsize ) && ( actual_fibsize64 != fibsize ) )  106
if ( ( data_dir == DMA_NONE ) && user_srbcmd -> sg . count )  117
if ( dev -> adapter_info . options & AAC_OPT_SGMAP_HOST64 )  123
if ( actual_fibsize64 == fibsize )  130
struct user_sgmap * usg ; 172
usg = kmalloc ( actual_fibsize - sizeof ( struct aac_srb ) + sizeof ( struct sgmap ) , GFP_KERNEL ); 173
if ( ! usg )  175
memcpy ( usg , upsg , actual_fibsize - sizeof ( struct aac_srb ) + sizeof ( struct sgmap ) ); 180
for (i = 0; i < usg->count; i++) 184
if ( usg -> sg [ i ] . count > ( ( dev -> adapter_info . options & AAC_OPT_NEW_COMM ) ? ( dev -> scsi_host_ptr -> max_sectors << 9 ) : 65536 ) )  187
kfree ( usg ); 192
p = kmalloc ( usg -> sg [ i ] . count , GFP_KERNEL | __GFP_DMA ); 197
if ( ! p )  198
dprintk ( ( KERN_DEBUG "aacraid: Could not allocate SG buffer - size = %d buffer number %d of %d\n" ,
usg -> sg [ i ] . count , i , usg -> count ) ) 200
kfree ( usg ); 201
sg_user [ i ] = ( void __user * ) ( uintptr_t ) usg -> sg [ i ] . addr; 205
sg_list [ i ] = p; 206
sg_indx = i; 207
if ( copy_from_user ( p , sg_user [ i ] , upsg -> sg [ i ] . count ) )  210
kfree ( usg ); 211
addr = pci_map_single ( dev -> pdev , p , usg -> sg [ i ] . count , data_dir ); 217
psg -> sg [ i ] . addr [ 0 ] = cpu_to_le32 ( addr & 0xffffffff ); 219
psg -> sg [ i ] . addr [ 1 ] = cpu_to_le32 ( addr >> 32 ); 220
byte_count += usg -> sg [ i ] . count; 221
psg -> sg [ i ] . count = cpu_to_le32 ( usg -> sg [ i ] . count ); 222
kfree ( usg ); 224
srbcmd -> count = cpu_to_le32 ( byte_count ); 226
psg -> count = cpu_to_le32 ( sg_indx + 1 ); 227
for(i = 0 ; i <= sg_indx; i++) 328
byte_count = le32_to_cpu ( ( dev -> adapter_info . options & AAC_OPT_SGMAP_HOST64 ) ? ( ( struct sgmap64 * ) & srbcmd -> sg ) -> sg [ i ] . count : srbcmd -> sg . sg [ i ] . count ); 329
if ( copy_to_user ( sg_user [ i ] , sg_list [ i ] , byte_count ) )  333
for(i=0; i <= sg_indx; i++) 351
kfree ( sg_list [ i ] ); 352
------------------------------
354 /home/speedy/test/source2slice/NVD/CVE_2013_6380_PATCHED_aac_send_raw_srb.c user_reply = arg + fibsize 67
static int CVE_2013_6380_PATCHED_aac_send_raw_srb(struct aac_dev* dev, void __user * arg) 1
struct fib * srbfib ; 3
struct user_aac_srb __user * user_srb = arg ; 7
struct aac_srb_reply __user * user_reply ; 8
u32 fibsize = 0 ; 10
if ( dev -> in_reset )  22
if ( ! capable ( CAP_SYS_ADMIN ) )  26
if ( ! ( srbfib = aac_fib_alloc ( dev ) ) )  33
if ( copy_from_user ( & fibsize , & user_srb -> count , sizeof ( u32 ) ) )  43
if ( ( fibsize < ( sizeof ( struct user_aac_srb ) - sizeof ( struct user_sgentry ) ) ) || ( fibsize > ( dev -> max_fib_size - sizeof ( struct aac_fibhdr ) ) ) )  49
user_srbcmd = kmalloc ( fibsize , GFP_KERNEL ); 55
if ( ! user_srbcmd )  56
if ( copy_from_user ( user_srbcmd , user_srb , fibsize ) )  61
user_reply = arg + fibsize; 67
if ( copy_to_user ( user_reply , reply , sizeof ( struct aac_srb_reply ) ) )  343
------------------------------
355 /home/speedy/test/source2slice/NVD/CVE_2013_6380_VULN_aac_send_raw_srb.c usg = kmalloc ( actual_fibsize - sizeof ( struct aac_srb ) + sizeof ( struct sgmap ) , GFP_KERNEL ) 172
static int CVE_2013_6380_VULN_aac_send_raw_srb(struct aac_dev* dev, void __user * arg) 1
struct fib * srbfib ; 3
struct user_aac_srb __user * user_srb = arg ; 7
u32 fibsize = 0 ; 10
u32 data_dir ; 13
void * sg_list [ 32 ] ; 15
if ( dev -> in_reset )  22
if ( ! capable ( CAP_SYS_ADMIN ) )  26
if ( ! ( srbfib = aac_fib_alloc ( dev ) ) )  33
memset ( sg_list , 0 , sizeof ( sg_list ) ); 42
if ( copy_from_user ( & fibsize , & user_srb -> count , sizeof ( u32 ) ) )  43
if ( fibsize > ( dev -> max_fib_size - sizeof ( struct aac_fibhdr ) ) )  49
user_srbcmd = kmalloc ( fibsize , GFP_KERNEL ); 54
if ( ! user_srbcmd )  55
if ( copy_from_user ( user_srbcmd , user_srb , fibsize ) )  60
flags = user_srbcmd -> flags; 68
switch ( flags & ( SRB_DataIn | SRB_DataOut ) )  81
data_dir = DMA_TO_DEVICE; 83
data_dir = DMA_BIDIRECTIONAL; 86
data_dir = DMA_FROM_DEVICE; 89
data_dir = DMA_NONE; 92
if ( user_srbcmd -> sg . count > ARRAY_SIZE ( sg_list ) )  94
actual_fibsize = sizeof ( struct aac_srb ) - sizeof ( struct sgentry ) + ( ( user_srbcmd -> sg . count & 0xff ) * sizeof ( struct sgentry ) ); 100
actual_fibsize64 = actual_fibsize + ( user_srbcmd -> sg . count & 0xff ) * ( sizeof ( struct sgentry64 ) - sizeof ( struct sgentry ) ); 102
if ( ( actual_fibsize != fibsize ) && ( actual_fibsize64 != fibsize ) )  105
if ( ( data_dir == DMA_NONE ) && user_srbcmd -> sg . count )  116
if ( dev -> adapter_info . options & AAC_OPT_SGMAP_HOST64 )  122
if ( actual_fibsize64 == fibsize )  129
struct user_sgmap * usg ; 171
usg = kmalloc ( actual_fibsize - sizeof ( struct aac_srb ) + sizeof ( struct sgmap ) , GFP_KERNEL ); 172
if ( ! usg )  174
memcpy ( usg , upsg , actual_fibsize - sizeof ( struct aac_srb ) + sizeof ( struct sgmap ) ); 179
for (i = 0; i < usg->count; i++) 183
if ( usg -> sg [ i ] . count > ( ( dev -> adapter_info . options & AAC_OPT_NEW_COMM ) ? ( dev -> scsi_host_ptr -> max_sectors << 9 ) : 65536 ) )  186
kfree ( usg ); 191
p = kmalloc ( usg -> sg [ i ] . count , GFP_KERNEL | __GFP_DMA ); 196
if ( ! p )  197
dprintk ( ( KERN_DEBUG "aacraid: Could not allocate SG buffer - size = %d buffer number %d of %d\n" ,
usg -> sg [ i ] . count , i , usg -> count ) ) 199
kfree ( usg ); 200
sg_user [ i ] = ( void __user * ) ( uintptr_t ) usg -> sg [ i ] . addr; 204
sg_list [ i ] = p; 205
sg_indx = i; 206
if ( copy_from_user ( p , sg_user [ i ] , upsg -> sg [ i ] . count ) )  209
kfree ( usg ); 210
addr = pci_map_single ( dev -> pdev , p , usg -> sg [ i ] . count , data_dir ); 216
psg -> sg [ i ] . addr [ 0 ] = cpu_to_le32 ( addr & 0xffffffff ); 218
psg -> sg [ i ] . addr [ 1 ] = cpu_to_le32 ( addr >> 32 ); 219
byte_count += usg -> sg [ i ] . count; 220
psg -> sg [ i ] . count = cpu_to_le32 ( usg -> sg [ i ] . count ); 221
kfree ( usg ); 223
srbcmd -> count = cpu_to_le32 ( byte_count ); 225
psg -> count = cpu_to_le32 ( sg_indx + 1 ); 226
dprintk ( ( KERN_DEBUG "aacraid: Could not send raw srb fib to hba\n" ) ) 321
for(i = 0 ; i <= sg_indx; i++) 327
byte_count = le32_to_cpu ( ( dev -> adapter_info . options & AAC_OPT_SGMAP_HOST64 ) ? ( ( struct sgmap64 * ) & srbcmd -> sg ) -> sg [ i ] . count : srbcmd -> sg . sg [ i ] . count ); 328
if ( copy_to_user ( sg_user [ i ] , sg_list [ i ] , byte_count ) )  332
dprintk ( ( KERN_DEBUG "aacraid: Could not copy sg data to user\n" ) ) 333
dprintk ( ( KERN_DEBUG "aacraid: Could not copy reply to user\n" ) ) 343
for(i=0; i <= sg_indx; i++) 350
kfree ( sg_list [ i ] ); 351
------------------------------
356 /home/speedy/test/source2slice/NVD/CVE_2013_6380_VULN_aac_send_raw_srb.c user_reply = arg + fibsize 66
static int CVE_2013_6380_VULN_aac_send_raw_srb(struct aac_dev* dev, void __user * arg) 1
struct fib * srbfib ; 3
struct user_aac_srb __user * user_srb = arg ; 7
struct aac_srb_reply __user * user_reply ; 8
u32 fibsize = 0 ; 10
if ( dev -> in_reset )  22
if ( ! capable ( CAP_SYS_ADMIN ) )  26
if ( ! ( srbfib = aac_fib_alloc ( dev ) ) )  33
if ( copy_from_user ( & fibsize , & user_srb -> count , sizeof ( u32 ) ) )  43
if ( fibsize > ( dev -> max_fib_size - sizeof ( struct aac_fibhdr ) ) )  49
user_srbcmd = kmalloc ( fibsize , GFP_KERNEL ); 54
if ( ! user_srbcmd )  55
if ( copy_from_user ( user_srbcmd , user_srb , fibsize ) )  60
user_reply = arg + fibsize; 66
if ( copy_to_user ( user_reply , reply , sizeof ( struct aac_srb_reply ) ) )  342
------------------------------
357 /home/speedy/test/source2slice/NVD/CVE_2013_6381_PATCHED_qeth_snmp_command.c rc = qeth_send_ipa_snmp_cmd ( card , iob , QETH_SETADP_BASE_LEN + req_len , qeth_snmp_command_cb , ( void * ) & qinfo ) 43
int CVE_2013_6381_PATCHED_qeth_snmp_command(struct qeth_card *card, char __user *udata) 1
struct qeth_cmd_buffer * iob ; 3
struct qeth_snmp_ureq * ureq ; 5
unsigned int req_len ; 6
struct qeth_arp_query_info qinfo = 0 , 7
if ( card -> info . guestlan )  12
if ( ( ! qeth_adp_supported ( card , IPA_SETADP_SET_SNMP_CONTROL ) ) && ( ! card -> options . layer2 ) )  15
if ( copy_from_user ( & req_len , udata + sizeof ( int ) , sizeof ( int ) ) )  20
if ( req_len > ( QETH_BUFSIZE - IPA_PDU_HEADER_SIZE - sizeof ( struct qeth_ipacmd_hdr ) - sizeof ( struct qeth_ipacmd_setadpparms_hdr ) ) )  22
ureq = memdup_user ( udata , req_len + sizeof ( struct qeth_snmp_ureq_hdr ) ); 26
if ( IS_ERR ( ureq ) )  27
qinfo . udata_len = ureq -> hdr . data_len; 31
qinfo . udata = kzalloc ( qinfo . udata_len , GFP_KERNEL ); 32
if ( ! qinfo . udata )  33
qinfo . udata_offset = sizeof ( struct qeth_snmp_ureq_hdr ); 37
iob = qeth_get_adapter_cmd ( card , IPA_SETADP_SET_SNMP_CONTROL , QETH_SNMP_SETADP_CMDLENGTH + req_len ); 39
rc = qeth_send_ipa_snmp_cmd ( card , iob , QETH_SETADP_BASE_LEN + req_len , qeth_snmp_command_cb , ( void * ) & qinfo ); 43
if ( rc )  45
QETH_DBF_MESSAGE ( 2 , "SNMP command failed on %s: (0x%x)\n" , QETH_CARD_IFNAME ( card ) , rc ); 46
return rc ; 55
------------------------------
358 /home/speedy/test/source2slice/NVD/CVE_2013_6381_PATCHED_qeth_snmp_command.c cmd = ( struct qeth_ipa_cmd * ) ( iob -> data + IPA_PDU_HEADER_SIZE ) 41
int CVE_2013_6381_PATCHED_qeth_snmp_command(struct qeth_card *card, char __user *udata) 1
struct qeth_cmd_buffer * iob ; 3
struct qeth_ipa_cmd * cmd ; 4
struct qeth_snmp_ureq * ureq ; 5
unsigned int req_len ; 6
struct qeth_arp_query_info qinfo = 0 , 7
if ( card -> info . guestlan )  12
if ( ( ! qeth_adp_supported ( card , IPA_SETADP_SET_SNMP_CONTROL ) ) && ( ! card -> options . layer2 ) )  15
if ( copy_from_user ( & req_len , udata + sizeof ( int ) , sizeof ( int ) ) )  20
if ( req_len > ( QETH_BUFSIZE - IPA_PDU_HEADER_SIZE - sizeof ( struct qeth_ipacmd_hdr ) - sizeof ( struct qeth_ipacmd_setadpparms_hdr ) ) )  22
ureq = memdup_user ( udata , req_len + sizeof ( struct qeth_snmp_ureq_hdr ) ); 26
if ( IS_ERR ( ureq ) )  27
qinfo . udata_len = ureq -> hdr . data_len; 31
qinfo . udata = kzalloc ( qinfo . udata_len , GFP_KERNEL ); 32
if ( ! qinfo . udata )  33
iob = qeth_get_adapter_cmd ( card , IPA_SETADP_SET_SNMP_CONTROL , QETH_SNMP_SETADP_CMDLENGTH + req_len ); 39
cmd = ( struct qeth_ipa_cmd * ) ( iob -> data + IPA_PDU_HEADER_SIZE ); 41
memcpy ( & cmd -> data . setadapterparms . data . snmp , & ureq -> cmd , req_len ); 42
------------------------------
359 /home/speedy/test/source2slice/NVD/CVE_2013_6381_PATCHED_qeth_snmp_command.c iob = qeth_get_adapter_cmd ( card , IPA_SETADP_SET_SNMP_CONTROL , QETH_SNMP_SETADP_CMDLENGTH + req_len ) 39
int CVE_2013_6381_PATCHED_qeth_snmp_command(struct qeth_card *card, char __user *udata) 1
struct qeth_cmd_buffer * iob ; 3
struct qeth_snmp_ureq * ureq ; 5
unsigned int req_len ; 6
struct qeth_arp_query_info qinfo = 0 , 7
if ( card -> info . guestlan )  12
if ( ( ! qeth_adp_supported ( card , IPA_SETADP_SET_SNMP_CONTROL ) ) && ( ! card -> options . layer2 ) )  15
if ( copy_from_user ( & req_len , udata + sizeof ( int ) , sizeof ( int ) ) )  20
if ( req_len > ( QETH_BUFSIZE - IPA_PDU_HEADER_SIZE - sizeof ( struct qeth_ipacmd_hdr ) - sizeof ( struct qeth_ipacmd_setadpparms_hdr ) ) )  22
ureq = memdup_user ( udata , req_len + sizeof ( struct qeth_snmp_ureq_hdr ) ); 26
if ( IS_ERR ( ureq ) )  27
qinfo . udata_len = ureq -> hdr . data_len; 31
qinfo . udata = kzalloc ( qinfo . udata_len , GFP_KERNEL ); 32
if ( ! qinfo . udata )  33
iob = qeth_get_adapter_cmd ( card , IPA_SETADP_SET_SNMP_CONTROL , QETH_SNMP_SETADP_CMDLENGTH + req_len ); 39
cmd = ( struct qeth_ipa_cmd * ) ( iob -> data + IPA_PDU_HEADER_SIZE ); 41
memcpy ( & cmd -> data . setadapterparms . data . snmp , & ureq -> cmd , req_len ); 42
rc = qeth_send_ipa_snmp_cmd ( card , iob , QETH_SETADP_BASE_LEN + req_len , qeth_snmp_command_cb , ( void * ) & qinfo ); 43
if ( rc )  45
QETH_DBF_MESSAGE ( 2 , "SNMP command failed on %s: (0x%x)\n" , QETH_CARD_IFNAME ( card ) , rc ); 46
return rc ; 55
------------------------------
360 /home/speedy/test/source2slice/NVD/CVE_2013_6381_PATCHED_qeth_snmp_command.c ureq = memdup_user ( udata , req_len + sizeof ( struct qeth_snmp_ureq_hdr ) ) 26
int CVE_2013_6381_PATCHED_qeth_snmp_command(struct qeth_card *card, char __user *udata) 1
struct qeth_snmp_ureq * ureq ; 5
unsigned int req_len ; 6
if ( card -> info . guestlan )  12
if ( ( ! qeth_adp_supported ( card , IPA_SETADP_SET_SNMP_CONTROL ) ) && ( ! card -> options . layer2 ) )  15
if ( copy_from_user ( & req_len , udata + sizeof ( int ) , sizeof ( int ) ) )  20
if ( req_len > ( QETH_BUFSIZE - IPA_PDU_HEADER_SIZE - sizeof ( struct qeth_ipacmd_hdr ) - sizeof ( struct qeth_ipacmd_setadpparms_hdr ) ) )  22
ureq = memdup_user ( udata , req_len + sizeof ( struct qeth_snmp_ureq_hdr ) ); 26
if ( IS_ERR ( ureq ) )  27
return PTR_ERR ( ureq ) ; 29
qinfo . udata_len = ureq -> hdr . data_len; 31
qinfo . udata = kzalloc ( qinfo . udata_len , GFP_KERNEL ); 32
if ( ! qinfo . udata )  33
kfree ( ureq ); 34
qinfo . udata_offset = sizeof ( struct qeth_snmp_ureq_hdr ); 37
memcpy ( & cmd -> data . setadapterparms . data . snmp , & ureq -> cmd , req_len ); 42
rc = qeth_send_ipa_snmp_cmd ( card , iob , QETH_SETADP_BASE_LEN + req_len , qeth_snmp_command_cb , ( void * ) & qinfo ); 43
if ( rc )  45
QETH_DBF_MESSAGE ( 2 , "SNMP command failed on %s: (0x%x)\n" , QETH_CARD_IFNAME ( card ) , rc ); 46
if ( copy_to_user ( udata , qinfo . udata , qinfo . udata_len ) )  49
kfree ( ureq ); 53
kfree ( qinfo . udata ); 54
return rc ; 55
------------------------------
361 /home/speedy/test/source2slice/NVD/CVE_2013_6381_VULN_qeth_snmp_command.c rc = qeth_send_ipa_snmp_cmd ( card , iob , QETH_SETADP_BASE_LEN + req_len , qeth_snmp_command_cb , ( void * ) & qinfo ) 39
int CVE_2013_6381_VULN_qeth_snmp_command(struct qeth_card *card, char __user *udata) 1
struct qeth_cmd_buffer * iob ; 3
struct qeth_snmp_ureq * ureq ; 5
int req_len ; 6
struct qeth_arp_query_info qinfo = 0 , 7
if ( card -> info . guestlan )  12
if ( ( ! qeth_adp_supported ( card , IPA_SETADP_SET_SNMP_CONTROL ) ) && ( ! card -> options . layer2 ) )  15
if ( copy_from_user ( & req_len , udata + sizeof ( int ) , sizeof ( int ) ) )  20
ureq = memdup_user ( udata , req_len + sizeof ( struct qeth_snmp_ureq_hdr ) ); 22
if ( IS_ERR ( ureq ) )  23
qinfo . udata_len = ureq -> hdr . data_len; 27
qinfo . udata = kzalloc ( qinfo . udata_len , GFP_KERNEL ); 28
if ( ! qinfo . udata )  29
qinfo . udata_offset = sizeof ( struct qeth_snmp_ureq_hdr ); 33
iob = qeth_get_adapter_cmd ( card , IPA_SETADP_SET_SNMP_CONTROL , QETH_SNMP_SETADP_CMDLENGTH + req_len ); 35
rc = qeth_send_ipa_snmp_cmd ( card , iob , QETH_SETADP_BASE_LEN + req_len , qeth_snmp_command_cb , ( void * ) & qinfo ); 39
if ( rc )  41
QETH_DBF_MESSAGE ( 2 , "SNMP command failed on %s: (0x%x)\n" , QETH_CARD_IFNAME ( card ) , rc ); 42
return rc ; 51
------------------------------
362 /home/speedy/test/source2slice/NVD/CVE_2013_6381_VULN_qeth_snmp_command.c cmd = ( struct qeth_ipa_cmd * ) ( iob -> data + IPA_PDU_HEADER_SIZE ) 37
int CVE_2013_6381_VULN_qeth_snmp_command(struct qeth_card *card, char __user *udata) 1
struct qeth_cmd_buffer * iob ; 3
struct qeth_ipa_cmd * cmd ; 4
struct qeth_snmp_ureq * ureq ; 5
int req_len ; 6
struct qeth_arp_query_info qinfo = 0 , 7
if ( card -> info . guestlan )  12
if ( ( ! qeth_adp_supported ( card , IPA_SETADP_SET_SNMP_CONTROL ) ) && ( ! card -> options . layer2 ) )  15
if ( copy_from_user ( & req_len , udata + sizeof ( int ) , sizeof ( int ) ) )  20
ureq = memdup_user ( udata , req_len + sizeof ( struct qeth_snmp_ureq_hdr ) ); 22
if ( IS_ERR ( ureq ) )  23
qinfo . udata_len = ureq -> hdr . data_len; 27
qinfo . udata = kzalloc ( qinfo . udata_len , GFP_KERNEL ); 28
if ( ! qinfo . udata )  29
iob = qeth_get_adapter_cmd ( card , IPA_SETADP_SET_SNMP_CONTROL , QETH_SNMP_SETADP_CMDLENGTH + req_len ); 35
cmd = ( struct qeth_ipa_cmd * ) ( iob -> data + IPA_PDU_HEADER_SIZE ); 37
memcpy ( & cmd -> data . setadapterparms . data . snmp , & ureq -> cmd , req_len ); 38
------------------------------
363 /home/speedy/test/source2slice/NVD/CVE_2013_6381_VULN_qeth_snmp_command.c iob = qeth_get_adapter_cmd ( card , IPA_SETADP_SET_SNMP_CONTROL , QETH_SNMP_SETADP_CMDLENGTH + req_len ) 35
int CVE_2013_6381_VULN_qeth_snmp_command(struct qeth_card *card, char __user *udata) 1
struct qeth_cmd_buffer * iob ; 3
struct qeth_snmp_ureq * ureq ; 5
int req_len ; 6
struct qeth_arp_query_info qinfo = 0 , 7
if ( card -> info . guestlan )  12
if ( ( ! qeth_adp_supported ( card , IPA_SETADP_SET_SNMP_CONTROL ) ) && ( ! card -> options . layer2 ) )  15
if ( copy_from_user ( & req_len , udata + sizeof ( int ) , sizeof ( int ) ) )  20
ureq = memdup_user ( udata , req_len + sizeof ( struct qeth_snmp_ureq_hdr ) ); 22
if ( IS_ERR ( ureq ) )  23
qinfo . udata_len = ureq -> hdr . data_len; 27
qinfo . udata = kzalloc ( qinfo . udata_len , GFP_KERNEL ); 28
if ( ! qinfo . udata )  29
iob = qeth_get_adapter_cmd ( card , IPA_SETADP_SET_SNMP_CONTROL , QETH_SNMP_SETADP_CMDLENGTH + req_len ); 35
cmd = ( struct qeth_ipa_cmd * ) ( iob -> data + IPA_PDU_HEADER_SIZE ); 37
memcpy ( & cmd -> data . setadapterparms . data . snmp , & ureq -> cmd , req_len ); 38
rc = qeth_send_ipa_snmp_cmd ( card , iob , QETH_SETADP_BASE_LEN + req_len , qeth_snmp_command_cb , ( void * ) & qinfo ); 39
if ( rc )  41
QETH_DBF_MESSAGE ( 2 , "SNMP command failed on %s: (0x%x)\n" , QETH_CARD_IFNAME ( card ) , rc ); 42
return rc ; 51
------------------------------
364 /home/speedy/test/source2slice/NVD/CVE_2013_6381_VULN_qeth_snmp_command.c ureq = memdup_user ( udata , req_len + sizeof ( struct qeth_snmp_ureq_hdr ) ) 22
int CVE_2013_6381_VULN_qeth_snmp_command(struct qeth_card *card, char __user *udata) 1
struct qeth_snmp_ureq * ureq ; 5
int req_len ; 6
if ( card -> info . guestlan )  12
if ( ( ! qeth_adp_supported ( card , IPA_SETADP_SET_SNMP_CONTROL ) ) && ( ! card -> options . layer2 ) )  15
if ( copy_from_user ( & req_len , udata + sizeof ( int ) , sizeof ( int ) ) )  20
ureq = memdup_user ( udata , req_len + sizeof ( struct qeth_snmp_ureq_hdr ) ); 22
if ( IS_ERR ( ureq ) )  23
return PTR_ERR ( ureq ) ; 25
qinfo . udata_len = ureq -> hdr . data_len; 27
qinfo . udata = kzalloc ( qinfo . udata_len , GFP_KERNEL ); 28
if ( ! qinfo . udata )  29
kfree ( ureq ); 30
qinfo . udata_offset = sizeof ( struct qeth_snmp_ureq_hdr ); 33
memcpy ( & cmd -> data . setadapterparms . data . snmp , & ureq -> cmd , req_len ); 38
rc = qeth_send_ipa_snmp_cmd ( card , iob , QETH_SETADP_BASE_LEN + req_len , qeth_snmp_command_cb , ( void * ) & qinfo ); 39
if ( rc )  41
QETH_DBF_MESSAGE ( 2 , "SNMP command failed on %s: (0x%x)\n" , QETH_CARD_IFNAME ( card ) , rc ); 42
if ( copy_to_user ( udata , qinfo . udata , qinfo . udata_len ) )  45
kfree ( ureq ); 49
kfree ( qinfo . udata ); 50
return rc ; 51
------------------------------
365 /home/speedy/test/source2slice/NVD/CVE_2013_7008_PATCHED_decode_slice_header.c id_list [ i ] = h -> short_ref_count + k 652
static int CVE_2013_7008_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
unsigned int first_mb_in_slice ; 3
unsigned int pps_id ; 4
int num_ref_idx_active_override_flag , ret ; 5
unsigned int slice_type , tmp , i , j ; 6
int last_pic_structure , last_pic_droppable ; 7
int must_reinit ; 8
int needs_reinit = 0 ; 9
h -> me . qpel_put = h -> h264qpel . put_h264_qpel_pixels_tab; 11
h -> me . qpel_avg = h -> h264qpel . avg_h264_qpel_pixels_tab; 12
first_mb_in_slice = get_ue_golomb_long ( & h -> gb ); 14
if ( first_mb_in_slice == 0 )  16
h0 -> current_slice = 0; 21
if ( ! h0 -> first_field )  22
h -> cur_pic_ptr = NULL; 27
slice_type = get_ue_golomb_31 ( & h -> gb ); 31
if ( slice_type > 9 )  32
if ( slice_type > 4 )  38
slice_type -= 5; 39
h -> slice_type_fixed = 0; 42
slice_type = golomb_to_pict_type [ slice_type ]; 44
h -> slice_type = slice_type; 45
h -> slice_type_nos = slice_type & 3; 46
h -> pict_type = h -> slice_type; 49
pps_id = get_ue_golomb ( & h -> gb ); 51
if ( pps_id >= MAX_PPS_COUNT )  52
if ( ! h0 -> pps_buffers [ pps_id ] )  56
h -> pps = * h0 -> pps_buffers [ pps_id ]; 62
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  64
if ( h -> pps . sps_id != h -> current_sps_id ||
h0 -> sps_buffers [ h -> pps . sps_id ] -> new )
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 73
h -> current_sps_id = h -> pps . sps_id; 75
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 76
if ( h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  78
needs_reinit = 1; 83
if ( h -> bit_depth_luma != h -> sps . bit_depth_luma || h -> chroma_format_idc != h -> sps . chroma_format_idc )  85
h -> bit_depth_luma = h -> sps . bit_depth_luma; 87
h -> chroma_format_idc = h -> sps . chroma_format_idc; 88
needs_reinit = 1; 89
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  91
h -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 95
h -> avctx -> level = h -> sps . level_idc; 96
h -> avctx -> refs = h -> sps . ref_frame_count; 97
must_reinit = ( h -> context_initialized && ( 16 * h -> sps . mb_width != h -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != h -> avctx -> coded_height || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , h -> avctx -> sample_aspect_ratio ) || h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) ) ); 99
if ( h0 -> avctx -> pix_fmt != get_pixel_format ( h0 , 0 ) )  108
must_reinit = 1; 109
h -> mb_width = h -> sps . mb_width; 111
h -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 112
h -> mb_num = h -> mb_width * h -> mb_height; 113
h -> mb_stride = h -> mb_width + 1; 114
h -> b_stride = h -> mb_width * 4; 116
h -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 118
h -> width = 16 * h -> mb_width; 120
h -> height = 16 * h -> mb_height; 121
ret = init_dimensions ( h ); 123
if ( ret < 0 )  124
if ( h -> sps . video_signal_type_present_flag )  127
h -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 128
if ( h -> sps . colour_description_present_flag )  130
if ( h -> avctx -> colorspace != h -> sps . colorspace )  131
needs_reinit = 1; 132
h -> avctx -> color_primaries = h -> sps . color_primaries; 133
h -> avctx -> color_trc = h -> sps . color_trc; 134
h -> avctx -> colorspace = h -> sps . colorspace; 135
if ( h -> context_initialized && ( h -> width != h -> avctx -> coded_width || h -> height != h -> avctx -> coded_height || must_reinit || needs_reinit ) )  139
if ( h != h0 )  145
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  153
h -> avctx -> pix_fmt = ret; 155
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  160
if ( ! h -> context_initialized )  166
if ( h != h0 )  167
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  173
h -> avctx -> pix_fmt = ret; 175
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  177
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  184
h -> dequant_coeff_pps = pps_id; 185
h -> frame_num = get_bits ( & h -> gb , h -> sps . log2_max_frame_num ); 189
h -> mb_mbaff = 0; 191
h -> mb_aff_frame = 0; 192
last_pic_structure = h0 -> picture_structure; 193
last_pic_droppable = h0 -> droppable; 194
h -> droppable = h -> nal_ref_idc == 0; 195
if ( h -> sps . frame_mbs_only_flag )  196
h -> picture_structure = PICT_FRAME; 197
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  199
if ( get_bits1 ( & h -> gb ) )  203
h -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & h -> gb ); 204
h -> picture_structure = PICT_FRAME; 206
h -> mb_aff_frame = h -> sps . mb_aff; 207
h -> mb_field_decoding_flag = h -> picture_structure != PICT_FRAME; 210
if ( h0 -> current_slice != 0 )  212
if ( last_pic_structure != h -> picture_structure || last_pic_droppable != h -> droppable )  213
if ( ! h0 -> cur_pic_ptr )  221
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  230
int unwrap_prev_frame_num = h -> prev_frame_num ; 231
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 232
if ( unwrap_prev_frame_num > h -> frame_num )  234
unwrap_prev_frame_num -= max_frame_num; 235
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  237
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 238
if ( unwrap_prev_frame_num < 0 )  239
unwrap_prev_frame_num += max_frame_num; 240
h -> prev_frame_num = unwrap_prev_frame_num; 242
if ( h0 -> first_field )  251
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  263
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  271
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && h -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && h -> picture_structure == PICT_TOP_FIELD ) ) )  282
if ( last_pic_droppable != h -> droppable )  292
h -> picture_structure = last_pic_structure; 295
h -> droppable = last_pic_droppable; 296
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! h0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  303
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 305
if ( ! h -> sps . gaps_in_frame_num_allowed_flag )  308
for(i=0; i<FF_ARRAY_ELEMS(h->last_pocs); i++) 309
h -> last_pocs [ i ] = INT_MIN; 310
if ( h264_frame_start ( h ) < 0 )  311
h -> prev_frame_num ++; 313
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 314
h -> cur_pic_ptr -> frame_num = h -> prev_frame_num; 315
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && h -> avctx -> err_recognition & AV_EF_EXPLODE )  318
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  321
if ( h -> short_ref_count )  330
if ( prev )  331
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 335
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 337
if ( h0 -> first_field )  344
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  350
h0 -> cur_pic_ptr = NULL; 353
h0 -> first_field = FIELD_PICTURE ( h ); 354
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  356
h0 -> first_field = 1; 362
h0 -> cur_pic_ptr = NULL; 363
h0 -> first_field = 0; 366
h0 -> first_field = FIELD_PICTURE ( h ); 371
if ( ! FIELD_PICTURE ( h ) || h0 -> first_field )  374
if ( h264_frame_start ( h ) < 0 )  375
if ( FIELD_PICTURE ( h ) )  384
for(i = (h->picture_structure == PICT_BOTTOM_FIELD); i<h->mb_height; i++) 385
memset ( h -> slice_table , - 1 , ( h -> mb_height * h -> mb_stride - 1 ) * sizeof ( * h -> slice_table ) ); 388
h0 -> last_slice_type = - 1; 391
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  393
for (i = 0; i < h->slice_context_count; i++) 398
if ( h -> thread_context [ i ] )  399
ret = alloc_scratch_buffers ( h -> thread_context [ i ] , h -> linesize ); 400
if ( ret < 0 )  401
h -> cur_pic_ptr -> frame_num = h -> frame_num; 405
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE ( h ) >= h -> mb_num || first_mb_in_slice >= h -> mb_num )  408
h -> resync_mb_x = h -> mb_x = first_mb_in_slice % h -> mb_width; 413
h -> resync_mb_y = h -> mb_y = ( first_mb_in_slice / h -> mb_width ) << FIELD_OR_MBAFF_PICTURE ( h ); 414
if ( h -> picture_structure == PICT_BOTTOM_FIELD )  415
h -> resync_mb_y = h -> mb_y = h -> mb_y + 1; 416
if ( h -> picture_structure == PICT_FRAME )  419
h -> curr_pic_num = h -> frame_num; 420
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 421
h -> curr_pic_num = 2 * h -> frame_num + 1; 423
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 424
if ( h -> sps . poc_type == 0 )  430
h -> poc_lsb = get_bits ( & h -> gb , h -> sps . log2_max_poc_lsb ); 431
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  433
h -> delta_poc_bottom = get_se_golomb ( & h -> gb ); 434
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  437
h -> delta_poc [ 0 ] = get_se_golomb ( & h -> gb ); 438
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  440
h -> delta_poc [ 1 ] = get_se_golomb ( & h -> gb ); 441
if ( h -> pps . redundant_pic_cnt_present )  446
h -> redundant_pic_count = get_ue_golomb ( & h -> gb ); 447
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 450
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 451
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  453
unsigned max [ 2 ] ; 454
max [ 0 ] = max [ 1 ] = h -> picture_structure == PICT_FRAME ? 15 : 31; 455
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> direct_spatial_mv_pred = get_bits1 ( & h -> gb ); 458
num_ref_idx_active_override_flag = get_bits1 ( & h -> gb ); 459
if ( num_ref_idx_active_override_flag )  461
h -> ref_count [ 0 ] = get_ue_golomb ( & h -> gb ) + 1; 462
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  463
h -> ref_count [ 1 ] = get_ue_golomb ( & h -> gb ) + 1; 464
h -> ref_count [ 1 ] = 1; 467
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  470
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 472
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  476
h -> list_count = 2; 477
h -> list_count = 1; 479
h -> list_count = 0; 481
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 482
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  491
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 493
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
h -> use_weight = 0; 505
for (i = 0; i < 2; i++) 506
h -> luma_weight_flag [ i ] = 0; 507
h -> chroma_weight_flag [ i ] = 0; 508
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & h -> gb , ! ( h -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
tmp = get_ue_golomb_31 ( & h -> gb ); 538
if ( tmp > 2 )  539
h -> cabac_init_idc = tmp; 543
h -> last_qscale_diff = 0; 546
tmp = h -> pps . init_qp + get_se_golomb ( & h -> gb ); 547
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  548
h -> qscale = tmp; 552
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , h -> qscale ); 553
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , h -> qscale ); 554
h -> deblocking_filter = 1; 562
h -> slice_alpha_c0_offset = 52; 563
h -> slice_beta_offset = 52; 564
if ( h -> pps . deblocking_filter_parameters_present )  565
tmp = get_ue_golomb_31 ( & h -> gb ); 566
if ( tmp > 2 )  567
h -> deblocking_filter = tmp; 572
if ( h -> deblocking_filter < 2 )  573
h -> deblocking_filter ^= 1; 574
if ( h -> deblocking_filter )  576
h -> slice_alpha_c0_offset += get_se_golomb ( & h -> gb ) << 1; 577
h -> slice_beta_offset += get_se_golomb ( & h -> gb ) << 1; 578
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  579
if ( h -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  589
h -> deblocking_filter = 0; 596
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  598
if ( h -> avctx -> flags2 & CODEC_FLAG2_FAST )  599
h -> deblocking_filter = 2; 602
h0 -> max_contexts = 1; 604
if ( ! h0 -> single_decode_warning )  605
h0 -> single_decode_warning = 1; 608
if ( h != h0 )  610
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 617
h0 -> last_slice_type = slice_type; 624
memcpy ( h0 -> last_ref_count , h0 -> ref_count , sizeof ( h0 -> last_ref_count ) ); 625
h -> slice_num = ++ h0 -> current_slice; 626
if ( h -> slice_num )  628
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = h -> resync_mb_y; 629
for (j = 0; j < 2; j++) 637
int id_list [ 16 ] ; 638
for (i = 0; i < 16; i++) 640
id_list [ i ] = 60; 641
if ( j < h -> list_count && i < h -> ref_count [ j ] && h -> ref_list [ j ] [ i ] . f . buf [ 0 ] )  642
int k ; 643
AVBuffer * buf = h -> ref_list [ j ] [ i ] . f . buf [ 0 ] -> buffer ; 644
for (k = 0; k < h->short_ref_count; k++) 645
if ( h -> short_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  646
id_list [ i ] = k; 647
for (k = 0; k < h->long_ref_count; k++) 650
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  651
id_list [ i ] = h -> short_ref_count + k; 652
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 661
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 663
for (i = 16; i < 48; i++) 665
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 666
------------------------------
366 /home/speedy/test/source2slice/NVD/CVE_2013_7008_PATCHED_decode_slice_header.c tmp = h -> pps . init_qp + get_se_golomb ( & h -> gb ) 547
static int CVE_2013_7008_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
unsigned int first_mb_in_slice ; 3
unsigned int pps_id ; 4
int num_ref_idx_active_override_flag , ret ; 5
unsigned int slice_type , tmp , i , j ; 6
int last_pic_structure , last_pic_droppable ; 7
int must_reinit ; 8
int needs_reinit = 0 ; 9
h -> me . qpel_put = h -> h264qpel . put_h264_qpel_pixels_tab; 11
h -> me . qpel_avg = h -> h264qpel . avg_h264_qpel_pixels_tab; 12
first_mb_in_slice = get_ue_golomb_long ( & h -> gb ); 14
if ( first_mb_in_slice == 0 )  16
h0 -> current_slice = 0; 21
if ( ! h0 -> first_field )  22
h -> cur_pic_ptr = NULL; 27
slice_type = get_ue_golomb_31 ( & h -> gb ); 31
if ( slice_type > 9 )  32
if ( slice_type > 4 )  38
slice_type -= 5; 39
h -> slice_type_fixed = 0; 42
slice_type = golomb_to_pict_type [ slice_type ]; 44
h -> slice_type = slice_type; 45
h -> slice_type_nos = slice_type & 3; 46
h -> pict_type = h -> slice_type; 49
pps_id = get_ue_golomb ( & h -> gb ); 51
if ( pps_id >= MAX_PPS_COUNT )  52
if ( ! h0 -> pps_buffers [ pps_id ] )  56
h -> pps = * h0 -> pps_buffers [ pps_id ]; 62
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  64
if ( h -> pps . sps_id != h -> current_sps_id ||
h0 -> sps_buffers [ h -> pps . sps_id ] -> new )
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 73
h -> current_sps_id = h -> pps . sps_id; 75
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 76
if ( h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  78
needs_reinit = 1; 83
if ( h -> bit_depth_luma != h -> sps . bit_depth_luma || h -> chroma_format_idc != h -> sps . chroma_format_idc )  85
h -> bit_depth_luma = h -> sps . bit_depth_luma; 87
h -> chroma_format_idc = h -> sps . chroma_format_idc; 88
needs_reinit = 1; 89
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  91
h -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 95
h -> avctx -> level = h -> sps . level_idc; 96
h -> avctx -> refs = h -> sps . ref_frame_count; 97
must_reinit = ( h -> context_initialized && ( 16 * h -> sps . mb_width != h -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != h -> avctx -> coded_height || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , h -> avctx -> sample_aspect_ratio ) || h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) ) ); 99
if ( h0 -> avctx -> pix_fmt != get_pixel_format ( h0 , 0 ) )  108
must_reinit = 1; 109
h -> mb_width = h -> sps . mb_width; 111
h -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 112
h -> mb_num = h -> mb_width * h -> mb_height; 113
h -> mb_stride = h -> mb_width + 1; 114
h -> b_stride = h -> mb_width * 4; 116
h -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 118
h -> width = 16 * h -> mb_width; 120
h -> height = 16 * h -> mb_height; 121
ret = init_dimensions ( h ); 123
if ( ret < 0 )  124
if ( h -> sps . video_signal_type_present_flag )  127
h -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 128
if ( h -> sps . colour_description_present_flag )  130
if ( h -> avctx -> colorspace != h -> sps . colorspace )  131
needs_reinit = 1; 132
h -> avctx -> color_primaries = h -> sps . color_primaries; 133
h -> avctx -> color_trc = h -> sps . color_trc; 134
h -> avctx -> colorspace = h -> sps . colorspace; 135
if ( h -> context_initialized && ( h -> width != h -> avctx -> coded_width || h -> height != h -> avctx -> coded_height || must_reinit || needs_reinit ) )  139
if ( h != h0 )  145
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  153
h -> avctx -> pix_fmt = ret; 155
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  160
if ( ! h -> context_initialized )  166
if ( h != h0 )  167
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  173
h -> avctx -> pix_fmt = ret; 175
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  177
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  184
h -> dequant_coeff_pps = pps_id; 185
h -> frame_num = get_bits ( & h -> gb , h -> sps . log2_max_frame_num ); 189
h -> mb_mbaff = 0; 191
h -> mb_aff_frame = 0; 192
last_pic_structure = h0 -> picture_structure; 193
last_pic_droppable = h0 -> droppable; 194
h -> droppable = h -> nal_ref_idc == 0; 195
if ( h -> sps . frame_mbs_only_flag )  196
h -> picture_structure = PICT_FRAME; 197
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  199
if ( get_bits1 ( & h -> gb ) )  203
h -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & h -> gb ); 204
h -> picture_structure = PICT_FRAME; 206
h -> mb_aff_frame = h -> sps . mb_aff; 207
h -> mb_field_decoding_flag = h -> picture_structure != PICT_FRAME; 210
if ( h0 -> current_slice != 0 )  212
if ( last_pic_structure != h -> picture_structure || last_pic_droppable != h -> droppable )  213
if ( ! h0 -> cur_pic_ptr )  221
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  230
int unwrap_prev_frame_num = h -> prev_frame_num ; 231
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 232
if ( unwrap_prev_frame_num > h -> frame_num )  234
unwrap_prev_frame_num -= max_frame_num; 235
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  237
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 238
if ( unwrap_prev_frame_num < 0 )  239
unwrap_prev_frame_num += max_frame_num; 240
h -> prev_frame_num = unwrap_prev_frame_num; 242
if ( h0 -> first_field )  251
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  263
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  271
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && h -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && h -> picture_structure == PICT_TOP_FIELD ) ) )  282
if ( last_pic_droppable != h -> droppable )  292
h -> picture_structure = last_pic_structure; 295
h -> droppable = last_pic_droppable; 296
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! h0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  303
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 305
if ( ! h -> sps . gaps_in_frame_num_allowed_flag )  308
for(i=0; i<FF_ARRAY_ELEMS(h->last_pocs); i++) 309
h -> last_pocs [ i ] = INT_MIN; 310
if ( h264_frame_start ( h ) < 0 )  311
h -> prev_frame_num ++; 313
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 314
h -> cur_pic_ptr -> frame_num = h -> prev_frame_num; 315
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && h -> avctx -> err_recognition & AV_EF_EXPLODE )  318
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  321
if ( h -> short_ref_count )  330
if ( prev )  331
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 335
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 337
if ( h0 -> first_field )  344
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  350
h0 -> cur_pic_ptr = NULL; 353
h0 -> first_field = FIELD_PICTURE ( h ); 354
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  356
h0 -> first_field = 1; 362
h0 -> cur_pic_ptr = NULL; 363
h0 -> first_field = 0; 366
h0 -> first_field = FIELD_PICTURE ( h ); 371
if ( ! FIELD_PICTURE ( h ) || h0 -> first_field )  374
if ( h264_frame_start ( h ) < 0 )  375
if ( FIELD_PICTURE ( h ) )  384
for(i = (h->picture_structure == PICT_BOTTOM_FIELD); i<h->mb_height; i++) 385
memset ( h -> slice_table , - 1 , ( h -> mb_height * h -> mb_stride - 1 ) * sizeof ( * h -> slice_table ) ); 388
h0 -> last_slice_type = - 1; 391
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  393
for (i = 0; i < h->slice_context_count; i++) 398
if ( h -> thread_context [ i ] )  399
ret = alloc_scratch_buffers ( h -> thread_context [ i ] , h -> linesize ); 400
if ( ret < 0 )  401
h -> cur_pic_ptr -> frame_num = h -> frame_num; 405
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE ( h ) >= h -> mb_num || first_mb_in_slice >= h -> mb_num )  408
h -> resync_mb_x = h -> mb_x = first_mb_in_slice % h -> mb_width; 413
h -> resync_mb_y = h -> mb_y = ( first_mb_in_slice / h -> mb_width ) << FIELD_OR_MBAFF_PICTURE ( h ); 414
if ( h -> picture_structure == PICT_BOTTOM_FIELD )  415
h -> resync_mb_y = h -> mb_y = h -> mb_y + 1; 416
if ( h -> picture_structure == PICT_FRAME )  419
h -> curr_pic_num = h -> frame_num; 420
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 421
h -> curr_pic_num = 2 * h -> frame_num + 1; 423
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 424
if ( h -> sps . poc_type == 0 )  430
h -> poc_lsb = get_bits ( & h -> gb , h -> sps . log2_max_poc_lsb ); 431
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  433
h -> delta_poc_bottom = get_se_golomb ( & h -> gb ); 434
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  437
h -> delta_poc [ 0 ] = get_se_golomb ( & h -> gb ); 438
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  440
h -> delta_poc [ 1 ] = get_se_golomb ( & h -> gb ); 441
if ( h -> pps . redundant_pic_cnt_present )  446
h -> redundant_pic_count = get_ue_golomb ( & h -> gb ); 447
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 450
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 451
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  453
unsigned max [ 2 ] ; 454
max [ 0 ] = max [ 1 ] = h -> picture_structure == PICT_FRAME ? 15 : 31; 455
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> direct_spatial_mv_pred = get_bits1 ( & h -> gb ); 458
num_ref_idx_active_override_flag = get_bits1 ( & h -> gb ); 459
if ( num_ref_idx_active_override_flag )  461
h -> ref_count [ 0 ] = get_ue_golomb ( & h -> gb ) + 1; 462
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  463
h -> ref_count [ 1 ] = get_ue_golomb ( & h -> gb ) + 1; 464
h -> ref_count [ 1 ] = 1; 467
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  470
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 472
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  476
h -> list_count = 2; 477
h -> list_count = 1; 479
h -> list_count = 0; 481
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 482
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  491
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 493
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
h -> use_weight = 0; 505
for (i = 0; i < 2; i++) 506
h -> luma_weight_flag [ i ] = 0; 507
h -> chroma_weight_flag [ i ] = 0; 508
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & h -> gb , ! ( h -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
tmp = get_ue_golomb_31 ( & h -> gb ); 538
if ( tmp > 2 )  539
h -> cabac_init_idc = tmp; 543
h -> last_qscale_diff = 0; 546
tmp = h -> pps . init_qp + get_se_golomb ( & h -> gb ); 547
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  548
av_log ( h -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 549
h -> qscale = tmp; 552
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , h -> qscale ); 553
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , h -> qscale ); 554
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  556
get_bits1 ( & h -> gb ); 557
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  558
get_se_golomb ( & h -> gb ); 560
h -> deblocking_filter = 1; 562
h -> slice_alpha_c0_offset = 52; 563
h -> slice_beta_offset = 52; 564
if ( h -> pps . deblocking_filter_parameters_present )  565
tmp = get_ue_golomb_31 ( & h -> gb ); 566
if ( tmp > 2 )  567
av_log ( h -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 568
h -> deblocking_filter = tmp; 572
if ( h -> deblocking_filter < 2 )  573
h -> deblocking_filter ^= 1; 574
if ( h -> deblocking_filter )  576
h -> slice_alpha_c0_offset += get_se_golomb ( & h -> gb ) << 1; 577
h -> slice_beta_offset += get_se_golomb ( & h -> gb ) << 1; 578
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  579
av_log ( h -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 581
if ( h -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  589
h -> deblocking_filter = 0; 596
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  598
if ( h -> avctx -> flags2 & CODEC_FLAG2_FAST )  599
h -> deblocking_filter = 2; 602
av_log ( h -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 606
av_log ( h -> avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 611
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 617
h -> slice_num = ++ h0 -> current_slice; 626
if ( h -> slice_num )  628
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = h -> resync_mb_y; 629
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= h -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= h -> resync_mb_y && h -> slice_num >= MAX_SLICES )  630
av_log ( h -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 634
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 639
if ( j < h -> list_count && i < h -> ref_count [ j ] && h -> ref_list [ j ] [ i ] . f . buf [ 0 ] )  642
AVBuffer * buf = h -> ref_list [ j ] [ i ] . f . buf [ 0 ] -> buffer ; 644
for (k = 0; k < h->short_ref_count; k++) 645
if ( h -> short_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  646
for (k = 0; k < h->long_ref_count; k++) 650
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  651
id_list [ i ] = h -> short_ref_count + k; 652
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 658
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 661
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 663
for (i = 16; i < 48; i++) 665
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 666
if ( h -> ref_count [ 0 ] )  670
h -> er . last_pic = & h -> ref_list [ 0 ] [ 0 ]; 670
if ( h -> ref_count [ 1 ] )  671
h -> er . next_pic = & h -> ref_list [ 1 ] [ 0 ]; 671
h -> er . ref_count = h -> ref_count [ 0 ]; 672
if ( h -> avctx -> debug & FF_DEBUG_PICT_INFO )  674
av_log ( h -> avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( h -> picture_structure == PICT_FRAME ? "F" : h -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , h -> cur_pic_ptr -> field_poc [ 0 ] , h -> cur_pic_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , h -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 675
------------------------------
367 /home/speedy/test/source2slice/NVD/CVE_2013_7008_PATCHED_decode_slice_header.c h -> resync_mb_y = h -> mb_y = ( first_mb_in_slice / h -> mb_width ) << FIELD_OR_MBAFF_PICTURE ( h ) 414
static int CVE_2013_7008_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
unsigned int first_mb_in_slice ; 3
unsigned int pps_id ; 4
int num_ref_idx_active_override_flag , ret ; 5
unsigned int slice_type , tmp , i , j ; 6
int last_pic_structure , last_pic_droppable ; 7
int must_reinit ; 8
int needs_reinit = 0 ; 9
h -> me . qpel_put = h -> h264qpel . put_h264_qpel_pixels_tab; 11
h -> me . qpel_avg = h -> h264qpel . avg_h264_qpel_pixels_tab; 12
first_mb_in_slice = get_ue_golomb_long ( & h -> gb ); 14
if ( first_mb_in_slice == 0 )  16
h0 -> current_slice = 0; 21
if ( ! h0 -> first_field )  22
h -> cur_pic_ptr = NULL; 27
slice_type = get_ue_golomb_31 ( & h -> gb ); 31
if ( slice_type > 9 )  32
if ( slice_type > 4 )  38
slice_type -= 5; 39
h -> slice_type_fixed = 0; 42
slice_type = golomb_to_pict_type [ slice_type ]; 44
h -> slice_type = slice_type; 45
h -> slice_type_nos = slice_type & 3; 46
h -> pict_type = h -> slice_type; 49
pps_id = get_ue_golomb ( & h -> gb ); 51
if ( pps_id >= MAX_PPS_COUNT )  52
if ( ! h0 -> pps_buffers [ pps_id ] )  56
h -> pps = * h0 -> pps_buffers [ pps_id ]; 62
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  64
if ( h -> pps . sps_id != h -> current_sps_id ||
h0 -> sps_buffers [ h -> pps . sps_id ] -> new )
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 73
h -> current_sps_id = h -> pps . sps_id; 75
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 76
if ( h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  78
needs_reinit = 1; 83
if ( h -> bit_depth_luma != h -> sps . bit_depth_luma || h -> chroma_format_idc != h -> sps . chroma_format_idc )  85
h -> bit_depth_luma = h -> sps . bit_depth_luma; 87
h -> chroma_format_idc = h -> sps . chroma_format_idc; 88
needs_reinit = 1; 89
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  91
h -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 95
h -> avctx -> level = h -> sps . level_idc; 96
h -> avctx -> refs = h -> sps . ref_frame_count; 97
must_reinit = ( h -> context_initialized && ( 16 * h -> sps . mb_width != h -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != h -> avctx -> coded_height || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , h -> avctx -> sample_aspect_ratio ) || h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) ) ); 99
if ( h0 -> avctx -> pix_fmt != get_pixel_format ( h0 , 0 ) )  108
must_reinit = 1; 109
h -> mb_width = h -> sps . mb_width; 111
h -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 112
h -> mb_num = h -> mb_width * h -> mb_height; 113
h -> mb_stride = h -> mb_width + 1; 114
h -> b_stride = h -> mb_width * 4; 116
h -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 118
h -> width = 16 * h -> mb_width; 120
h -> height = 16 * h -> mb_height; 121
ret = init_dimensions ( h ); 123
if ( ret < 0 )  124
if ( h -> sps . video_signal_type_present_flag )  127
h -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 128
if ( h -> sps . colour_description_present_flag )  130
if ( h -> avctx -> colorspace != h -> sps . colorspace )  131
needs_reinit = 1; 132
h -> avctx -> color_primaries = h -> sps . color_primaries; 133
h -> avctx -> color_trc = h -> sps . color_trc; 134
h -> avctx -> colorspace = h -> sps . colorspace; 135
if ( h -> context_initialized && ( h -> width != h -> avctx -> coded_width || h -> height != h -> avctx -> coded_height || must_reinit || needs_reinit ) )  139
if ( h != h0 )  145
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  153
h -> avctx -> pix_fmt = ret; 155
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  160
if ( ! h -> context_initialized )  166
if ( h != h0 )  167
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  173
h -> avctx -> pix_fmt = ret; 175
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  177
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  184
h -> dequant_coeff_pps = pps_id; 185
h -> frame_num = get_bits ( & h -> gb , h -> sps . log2_max_frame_num ); 189
h -> mb_mbaff = 0; 191
h -> mb_aff_frame = 0; 192
last_pic_structure = h0 -> picture_structure; 193
last_pic_droppable = h0 -> droppable; 194
h -> droppable = h -> nal_ref_idc == 0; 195
if ( h -> sps . frame_mbs_only_flag )  196
h -> picture_structure = PICT_FRAME; 197
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  199
if ( get_bits1 ( & h -> gb ) )  203
h -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & h -> gb ); 204
h -> picture_structure = PICT_FRAME; 206
h -> mb_aff_frame = h -> sps . mb_aff; 207
h -> mb_field_decoding_flag = h -> picture_structure != PICT_FRAME; 210
if ( h0 -> current_slice != 0 )  212
if ( last_pic_structure != h -> picture_structure || last_pic_droppable != h -> droppable )  213
if ( ! h0 -> cur_pic_ptr )  221
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  230
int unwrap_prev_frame_num = h -> prev_frame_num ; 231
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 232
if ( unwrap_prev_frame_num > h -> frame_num )  234
unwrap_prev_frame_num -= max_frame_num; 235
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  237
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 238
if ( unwrap_prev_frame_num < 0 )  239
unwrap_prev_frame_num += max_frame_num; 240
h -> prev_frame_num = unwrap_prev_frame_num; 242
if ( h0 -> first_field )  251
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  263
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  271
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && h -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && h -> picture_structure == PICT_TOP_FIELD ) ) )  282
if ( last_pic_droppable != h -> droppable )  292
h -> picture_structure = last_pic_structure; 295
h -> droppable = last_pic_droppable; 296
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! h0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  303
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 305
if ( ! h -> sps . gaps_in_frame_num_allowed_flag )  308
for(i=0; i<FF_ARRAY_ELEMS(h->last_pocs); i++) 309
h -> last_pocs [ i ] = INT_MIN; 310
if ( h264_frame_start ( h ) < 0 )  311
h -> prev_frame_num ++; 313
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 314
h -> cur_pic_ptr -> frame_num = h -> prev_frame_num; 315
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && h -> avctx -> err_recognition & AV_EF_EXPLODE )  318
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  321
if ( h -> short_ref_count )  330
if ( prev )  331
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 335
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 337
if ( h0 -> first_field )  344
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  350
h0 -> cur_pic_ptr = NULL; 353
h0 -> first_field = FIELD_PICTURE ( h ); 354
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  356
h0 -> first_field = 1; 362
h0 -> cur_pic_ptr = NULL; 363
h0 -> first_field = 0; 366
h0 -> first_field = FIELD_PICTURE ( h ); 371
if ( ! FIELD_PICTURE ( h ) || h0 -> first_field )  374
if ( h264_frame_start ( h ) < 0 )  375
if ( FIELD_PICTURE ( h ) )  384
for(i = (h->picture_structure == PICT_BOTTOM_FIELD); i<h->mb_height; i++) 385
memset ( h -> slice_table , - 1 , ( h -> mb_height * h -> mb_stride - 1 ) * sizeof ( * h -> slice_table ) ); 388
h0 -> last_slice_type = - 1; 391
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  393
for (i = 0; i < h->slice_context_count; i++) 398
if ( h -> thread_context [ i ] )  399
ret = alloc_scratch_buffers ( h -> thread_context [ i ] , h -> linesize ); 400
if ( ret < 0 )  401
h -> cur_pic_ptr -> frame_num = h -> frame_num; 405
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE ( h ) >= h -> mb_num || first_mb_in_slice >= h -> mb_num )  408
h -> resync_mb_x = h -> mb_x = first_mb_in_slice % h -> mb_width; 413
h -> resync_mb_y = h -> mb_y = ( first_mb_in_slice / h -> mb_width ) << FIELD_OR_MBAFF_PICTURE ( h ); 414
if ( h -> picture_structure == PICT_BOTTOM_FIELD )  415
h -> resync_mb_y = h -> mb_y = h -> mb_y + 1; 416
av_assert1 ( h -> mb_y < h -> mb_height ); 417
if ( h -> picture_structure == PICT_FRAME )  419
h -> curr_pic_num = h -> frame_num; 420
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 421
h -> curr_pic_num = 2 * h -> frame_num + 1; 423
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 424
if ( h -> nal_unit_type == NAL_IDR_SLICE )  427
get_ue_golomb ( & h -> gb ); 428
if ( h -> sps . poc_type == 0 )  430
h -> poc_lsb = get_bits ( & h -> gb , h -> sps . log2_max_poc_lsb ); 431
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  433
h -> delta_poc_bottom = get_se_golomb ( & h -> gb ); 434
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  437
h -> delta_poc [ 0 ] = get_se_golomb ( & h -> gb ); 438
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  440
h -> delta_poc [ 1 ] = get_se_golomb ( & h -> gb ); 441
ff_init_poc ( h , h -> cur_pic_ptr -> field_poc , & h -> cur_pic_ptr -> poc ); 444
if ( h -> pps . redundant_pic_cnt_present )  446
h -> redundant_pic_count = get_ue_golomb ( & h -> gb ); 447
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 450
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 451
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  453
max [ 0 ] = max [ 1 ] = h -> picture_structure == PICT_FRAME ? 15 : 31; 455
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> direct_spatial_mv_pred = get_bits1 ( & h -> gb ); 458
num_ref_idx_active_override_flag = get_bits1 ( & h -> gb ); 459
if ( num_ref_idx_active_override_flag )  461
h -> ref_count [ 0 ] = get_ue_golomb ( & h -> gb ) + 1; 462
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  463
h -> ref_count [ 1 ] = get_ue_golomb ( & h -> gb ) + 1; 464
h -> ref_count [ 1 ] = 1; 467
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  470
av_log ( h -> avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 471
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 472
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  476
h -> list_count = 2; 477
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  491
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 493
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
pred_weight_table ( h ); 500
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
implicit_weight_table ( h , - 1 ); 503
h -> use_weight = 0; 505
h -> luma_weight_flag [ i ] = 0; 507
h -> chroma_weight_flag [ i ] = 0; 508
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & h -> gb , ! ( h -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
if ( FRAME_MBAFF ( h ) )  524
ff_h264_fill_mbaff_ref_list ( h ); 525
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  527
implicit_weight_table ( h , 0 ); 528
implicit_weight_table ( h , 1 ); 529
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  533
ff_h264_direct_dist_scale_factor ( h ); 534
ff_h264_direct_ref_list_init ( h ); 535
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
tmp = get_ue_golomb_31 ( & h -> gb ); 538
if ( tmp > 2 )  539
av_log ( h -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 540
h -> cabac_init_idc = tmp; 543
h -> last_qscale_diff = 0; 546
tmp = h -> pps . init_qp + get_se_golomb ( & h -> gb ); 547
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  548
av_log ( h -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 549
h -> qscale = tmp; 552
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , h -> qscale ); 553
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , h -> qscale ); 554
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  556
get_bits1 ( & h -> gb ); 557
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  558
get_se_golomb ( & h -> gb ); 560
h -> deblocking_filter = 1; 562
h -> slice_alpha_c0_offset = 52; 563
h -> slice_beta_offset = 52; 564
if ( h -> pps . deblocking_filter_parameters_present )  565
tmp = get_ue_golomb_31 ( & h -> gb ); 566
if ( tmp > 2 )  567
av_log ( h -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 568
h -> deblocking_filter = tmp; 572
if ( h -> deblocking_filter < 2 )  573
h -> deblocking_filter ^= 1; 574
if ( h -> deblocking_filter )  576
h -> slice_alpha_c0_offset += get_se_golomb ( & h -> gb ) << 1; 577
h -> slice_beta_offset += get_se_golomb ( & h -> gb ) << 1; 578
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  579
av_log ( h -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 581
if ( h -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  589
h -> deblocking_filter = 0; 596
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  598
if ( h -> avctx -> flags2 & CODEC_FLAG2_FAST )  599
h -> deblocking_filter = 2; 602
av_log ( h -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 606
av_log ( h -> avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 611
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 617
h -> slice_num = ++ h0 -> current_slice; 626
if ( h -> slice_num )  628
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = h -> resync_mb_y; 629
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= h -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= h -> resync_mb_y && h -> slice_num >= MAX_SLICES )  630
av_log ( h -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 634
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 639
for (i = 0; i < 16; i++) 640
id_list [ i ] = 60; 641
if ( j < h -> list_count && i < h -> ref_count [ j ] && h -> ref_list [ j ] [ i ] . f . buf [ 0 ] )  642
AVBuffer * buf = h -> ref_list [ j ] [ i ] . f . buf [ 0 ] -> buffer ; 644
for (k = 0; k < h->short_ref_count; k++) 645
if ( h -> short_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  646
id_list [ i ] = k; 647
for (k = 0; k < h->long_ref_count; k++) 650
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  651
id_list [ i ] = h -> short_ref_count + k; 652
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 658
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 661
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 663
for (i = 16; i < 48; i++) 665
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 666
if ( h -> ref_count [ 0 ] )  670
h -> er . last_pic = & h -> ref_list [ 0 ] [ 0 ]; 670
if ( h -> ref_count [ 1 ] )  671
h -> er . next_pic = & h -> ref_list [ 1 ] [ 0 ]; 671
h -> er . ref_count = h -> ref_count [ 0 ]; 672
if ( h -> avctx -> debug & FF_DEBUG_PICT_INFO )  674
av_log ( h -> avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( h -> picture_structure == PICT_FRAME ? "F" : h -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , h -> cur_pic_ptr -> field_poc [ 0 ] , h -> cur_pic_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , h -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 675
------------------------------
368 /home/speedy/test/source2slice/NVD/CVE_2013_7008_PATCHED_decode_slice_header.c unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1 238
static int CVE_2013_7008_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
unsigned int first_mb_in_slice ; 3
unsigned int pps_id ; 4
int num_ref_idx_active_override_flag , ret ; 5
unsigned int slice_type , tmp , i , j ; 6
int must_reinit ; 8
int needs_reinit = 0 ; 9
h -> me . qpel_put = h -> h264qpel . put_h264_qpel_pixels_tab; 11
h -> me . qpel_avg = h -> h264qpel . avg_h264_qpel_pixels_tab; 12
first_mb_in_slice = get_ue_golomb_long ( & h -> gb ); 14
if ( first_mb_in_slice == 0 )  16
h0 -> current_slice = 0; 21
if ( ! h0 -> first_field )  22
h -> cur_pic_ptr = NULL; 27
slice_type = get_ue_golomb_31 ( & h -> gb ); 31
if ( slice_type > 9 )  32
if ( slice_type > 4 )  38
slice_type -= 5; 39
h -> slice_type_fixed = 0; 42
slice_type = golomb_to_pict_type [ slice_type ]; 44
h -> slice_type = slice_type; 45
h -> slice_type_nos = slice_type & 3; 46
h -> pict_type = h -> slice_type; 49
pps_id = get_ue_golomb ( & h -> gb ); 51
if ( pps_id >= MAX_PPS_COUNT )  52
if ( ! h0 -> pps_buffers [ pps_id ] )  56
h -> pps = * h0 -> pps_buffers [ pps_id ]; 62
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  64
if ( h -> pps . sps_id != h -> current_sps_id ||
h0 -> sps_buffers [ h -> pps . sps_id ] -> new )
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 73
h -> current_sps_id = h -> pps . sps_id; 75
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 76
if ( h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  78
needs_reinit = 1; 83
if ( h -> bit_depth_luma != h -> sps . bit_depth_luma || h -> chroma_format_idc != h -> sps . chroma_format_idc )  85
h -> bit_depth_luma = h -> sps . bit_depth_luma; 87
h -> chroma_format_idc = h -> sps . chroma_format_idc; 88
needs_reinit = 1; 89
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  91
h -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 95
h -> avctx -> level = h -> sps . level_idc; 96
h -> avctx -> refs = h -> sps . ref_frame_count; 97
must_reinit = ( h -> context_initialized && ( 16 * h -> sps . mb_width != h -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != h -> avctx -> coded_height || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , h -> avctx -> sample_aspect_ratio ) || h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) ) ); 99
if ( h0 -> avctx -> pix_fmt != get_pixel_format ( h0 , 0 ) )  108
must_reinit = 1; 109
h -> mb_width = h -> sps . mb_width; 111
h -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 112
h -> mb_num = h -> mb_width * h -> mb_height; 113
h -> mb_stride = h -> mb_width + 1; 114
h -> b_stride = h -> mb_width * 4; 116
h -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 118
h -> width = 16 * h -> mb_width; 120
h -> height = 16 * h -> mb_height; 121
ret = init_dimensions ( h ); 123
if ( ret < 0 )  124
if ( h -> sps . video_signal_type_present_flag )  127
h -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 128
if ( h -> sps . colour_description_present_flag )  130
if ( h -> avctx -> colorspace != h -> sps . colorspace )  131
needs_reinit = 1; 132
h -> avctx -> color_primaries = h -> sps . color_primaries; 133
h -> avctx -> color_trc = h -> sps . color_trc; 134
h -> avctx -> colorspace = h -> sps . colorspace; 135
if ( h -> context_initialized && ( h -> width != h -> avctx -> coded_width || h -> height != h -> avctx -> coded_height || must_reinit || needs_reinit ) )  139
if ( h != h0 )  145
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  153
h -> avctx -> pix_fmt = ret; 155
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  160
if ( ! h -> context_initialized )  166
if ( h != h0 )  167
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  173
h -> avctx -> pix_fmt = ret; 175
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  177
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  184
h -> dequant_coeff_pps = pps_id; 185
h -> frame_num = get_bits ( & h -> gb , h -> sps . log2_max_frame_num ); 189
h -> mb_mbaff = 0; 191
h -> mb_aff_frame = 0; 192
h -> droppable = h -> nal_ref_idc == 0; 195
if ( h -> sps . frame_mbs_only_flag )  196
h -> picture_structure = PICT_FRAME; 197
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  199
if ( get_bits1 ( & h -> gb ) )  203
h -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & h -> gb ); 204
h -> picture_structure = PICT_FRAME; 206
h -> mb_aff_frame = h -> sps . mb_aff; 207
h -> mb_field_decoding_flag = h -> picture_structure != PICT_FRAME; 210
if ( h0 -> current_slice != 0 )  212
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  230
int unwrap_prev_frame_num = h -> prev_frame_num ; 231
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 232
if ( unwrap_prev_frame_num > h -> frame_num )  234
unwrap_prev_frame_num -= max_frame_num; 235
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  237
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 238
if ( unwrap_prev_frame_num < 0 )  239
unwrap_prev_frame_num += max_frame_num; 240
h -> prev_frame_num = unwrap_prev_frame_num; 242
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  263
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  271
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && h -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && h -> picture_structure == PICT_TOP_FIELD ) ) )  282
av_log ( h -> avctx , AV_LOG_ERROR , "Invalid field mode combination %d/%d\n" , last_pic_structure , h -> picture_structure ); 286
h -> picture_structure = last_pic_structure; 289
h -> droppable = last_pic_droppable; 290
if ( last_pic_droppable != h -> droppable )  292
avpriv_request_sample ( h -> avctx , "Found reference and non-reference fields in the same frame, which" ); 293
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! h0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  303
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 305
av_log ( h -> avctx , AV_LOG_DEBUG , "Frame num gap %d %d\n" , h -> frame_num , h -> prev_frame_num ); 306
if ( ! h -> sps . gaps_in_frame_num_allowed_flag )  308
for(i=0; i<FF_ARRAY_ELEMS(h->last_pocs); i++) 309
h -> last_pocs [ i ] = INT_MIN; 310
if ( h264_frame_start ( h ) < 0 )  311
h -> prev_frame_num ++; 313
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 314
h -> cur_pic_ptr -> frame_num = h -> prev_frame_num; 315
ff_thread_report_progress ( & h -> cur_pic_ptr -> tf , INT_MAX , 0 ); 316
ff_thread_report_progress ( & h -> cur_pic_ptr -> tf , INT_MAX , 1 ); 317
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && h -> avctx -> err_recognition & AV_EF_EXPLODE )  318
return ret ; 320
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  321
if ( h -> short_ref_count )  330
if ( prev )  331
av_image_copy ( h -> short_ref [ 0 ] -> f . data , h -> short_ref [ 0 ] -> f . linesize , ( const uint8_t * * ) prev -> f . data , prev -> f . linesize , h -> avctx -> pix_fmt , h -> mb_width * 16 , h -> mb_height * 16 ); 332
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 335
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 337
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  350
h0 -> first_field = FIELD_PICTURE ( h ); 354
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  356
h0 -> first_field = FIELD_PICTURE ( h ); 371
if ( ! FIELD_PICTURE ( h ) || h0 -> first_field )  374
if ( h264_frame_start ( h ) < 0 )  375
h0 -> first_field = 0; 376
release_unused_pictures ( h , 0 ); 380
if ( FIELD_PICTURE ( h ) )  384
for(i = (h->picture_structure == PICT_BOTTOM_FIELD); i<h->mb_height; i++) 385
memset ( h -> slice_table + i * h -> mb_stride , - 1 , ( h -> mb_stride - ( i + 1 == h -> mb_height ) ) * sizeof ( * h -> slice_table ) ); 386
memset ( h -> slice_table , - 1 , ( h -> mb_height * h -> mb_stride - 1 ) * sizeof ( * h -> slice_table ) ); 388
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  393
return ret ; 394
for (i = 0; i < h->slice_context_count; i++) 398
if ( h -> thread_context [ i ] )  399
ret = alloc_scratch_buffers ( h -> thread_context [ i ] , h -> linesize ); 400
if ( ret < 0 )  401
return ret ; 402
h -> cur_pic_ptr -> frame_num = h -> frame_num; 405
av_assert1 ( h -> mb_num == h -> mb_width * h -> mb_height ); 407
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE ( h ) >= h -> mb_num || first_mb_in_slice >= h -> mb_num )  408
av_log ( h -> avctx , AV_LOG_ERROR , "first_mb_in_slice overflow\n" ); 410
h -> resync_mb_x = h -> mb_x = first_mb_in_slice % h -> mb_width; 413
h -> resync_mb_y = h -> mb_y = ( first_mb_in_slice / h -> mb_width ) << FIELD_OR_MBAFF_PICTURE ( h ); 414
if ( h -> picture_structure == PICT_BOTTOM_FIELD )  415
h -> resync_mb_y = h -> mb_y = h -> mb_y + 1; 416
av_assert1 ( h -> mb_y < h -> mb_height ); 417
if ( h -> picture_structure == PICT_FRAME )  419
h -> curr_pic_num = h -> frame_num; 420
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 421
h -> curr_pic_num = 2 * h -> frame_num + 1; 423
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 424
if ( h -> nal_unit_type == NAL_IDR_SLICE )  427
get_ue_golomb ( & h -> gb ); 428
if ( h -> sps . poc_type == 0 )  430
h -> poc_lsb = get_bits ( & h -> gb , h -> sps . log2_max_poc_lsb ); 431
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  433
h -> delta_poc_bottom = get_se_golomb ( & h -> gb ); 434
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  437
h -> delta_poc [ 0 ] = get_se_golomb ( & h -> gb ); 438
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  440
h -> delta_poc [ 1 ] = get_se_golomb ( & h -> gb ); 441
ff_init_poc ( h , h -> cur_pic_ptr -> field_poc , & h -> cur_pic_ptr -> poc ); 444
if ( h -> pps . redundant_pic_cnt_present )  446
h -> redundant_pic_count = get_ue_golomb ( & h -> gb ); 447
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 450
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 451
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  453
max [ 0 ] = max [ 1 ] = h -> picture_structure == PICT_FRAME ? 15 : 31; 455
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> direct_spatial_mv_pred = get_bits1 ( & h -> gb ); 458
num_ref_idx_active_override_flag = get_bits1 ( & h -> gb ); 459
if ( num_ref_idx_active_override_flag )  461
h -> ref_count [ 0 ] = get_ue_golomb ( & h -> gb ) + 1; 462
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  463
h -> ref_count [ 1 ] = get_ue_golomb ( & h -> gb ) + 1; 464
h -> ref_count [ 1 ] = 1; 467
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  470
av_log ( h -> avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 471
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 472
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  476
h -> list_count = 2; 477
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  491
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 493
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
pred_weight_table ( h ); 500
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
implicit_weight_table ( h , - 1 ); 503
h -> use_weight = 0; 505
for (i = 0; i < 2; i++) 506
h -> luma_weight_flag [ i ] = 0; 507
h -> chroma_weight_flag [ i ] = 0; 508
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & h -> gb , ! ( h -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
if ( FRAME_MBAFF ( h ) )  524
ff_h264_fill_mbaff_ref_list ( h ); 525
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  527
implicit_weight_table ( h , 0 ); 528
implicit_weight_table ( h , 1 ); 529
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  533
ff_h264_direct_dist_scale_factor ( h ); 534
ff_h264_direct_ref_list_init ( h ); 535
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
tmp = get_ue_golomb_31 ( & h -> gb ); 538
if ( tmp > 2 )  539
av_log ( h -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 540
h -> cabac_init_idc = tmp; 543
h -> last_qscale_diff = 0; 546
tmp = h -> pps . init_qp + get_se_golomb ( & h -> gb ); 547
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  548
av_log ( h -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 549
h -> qscale = tmp; 552
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , h -> qscale ); 553
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , h -> qscale ); 554
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  556
get_bits1 ( & h -> gb ); 557
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  558
get_se_golomb ( & h -> gb ); 560
h -> deblocking_filter = 1; 562
h -> slice_alpha_c0_offset = 52; 563
h -> slice_beta_offset = 52; 564
if ( h -> pps . deblocking_filter_parameters_present )  565
tmp = get_ue_golomb_31 ( & h -> gb ); 566
if ( tmp > 2 )  567
av_log ( h -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 568
h -> deblocking_filter = tmp; 572
if ( h -> deblocking_filter < 2 )  573
h -> deblocking_filter ^= 1; 574
if ( h -> deblocking_filter )  576
h -> slice_alpha_c0_offset += get_se_golomb ( & h -> gb ) << 1; 577
h -> slice_beta_offset += get_se_golomb ( & h -> gb ) << 1; 578
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  579
av_log ( h -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 581
if ( h -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  589
h -> deblocking_filter = 0; 596
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  598
if ( h -> avctx -> flags2 & CODEC_FLAG2_FAST )  599
h -> deblocking_filter = 2; 602
av_log ( h -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 606
av_log ( h -> avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 611
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 617
h -> slice_num = ++ h0 -> current_slice; 626
if ( h -> slice_num )  628
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = h -> resync_mb_y; 629
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= h -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= h -> resync_mb_y && h -> slice_num >= MAX_SLICES )  630
av_log ( h -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 634
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 639
for (i = 0; i < 16; i++) 640
id_list [ i ] = 60; 641
if ( j < h -> list_count && i < h -> ref_count [ j ] && h -> ref_list [ j ] [ i ] . f . buf [ 0 ] )  642
AVBuffer * buf = h -> ref_list [ j ] [ i ] . f . buf [ 0 ] -> buffer ; 644
for (k = 0; k < h->short_ref_count; k++) 645
if ( h -> short_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  646
id_list [ i ] = k; 647
for (k = 0; k < h->long_ref_count; k++) 650
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  651
id_list [ i ] = h -> short_ref_count + k; 652
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 658
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 661
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 663
for (i = 16; i < 48; i++) 665
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 666
if ( h -> ref_count [ 0 ] )  670
h -> er . last_pic = & h -> ref_list [ 0 ] [ 0 ]; 670
if ( h -> ref_count [ 1 ] )  671
h -> er . next_pic = & h -> ref_list [ 1 ] [ 0 ]; 671
h -> er . ref_count = h -> ref_count [ 0 ]; 672
if ( h -> avctx -> debug & FF_DEBUG_PICT_INFO )  674
av_log ( h -> avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( h -> picture_structure == PICT_FRAME ? "F" : h -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , h -> cur_pic_ptr -> field_poc [ 0 ] , h -> cur_pic_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , h -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 675
------------------------------
369 /home/speedy/test/source2slice/NVD/CVE_2013_7008_PATCHED_decode_slice_header.c h -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & h -> gb ) 204
static int CVE_2013_7008_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
unsigned int first_mb_in_slice ; 3
unsigned int pps_id ; 4
int num_ref_idx_active_override_flag , ret ; 5
unsigned int slice_type , tmp , i , j ; 6
int must_reinit ; 8
int needs_reinit = 0 ; 9
h -> me . qpel_put = h -> h264qpel . put_h264_qpel_pixels_tab; 11
h -> me . qpel_avg = h -> h264qpel . avg_h264_qpel_pixels_tab; 12
first_mb_in_slice = get_ue_golomb_long ( & h -> gb ); 14
if ( first_mb_in_slice == 0 )  16
h0 -> current_slice = 0; 21
if ( ! h0 -> first_field )  22
h -> cur_pic_ptr = NULL; 27
slice_type = get_ue_golomb_31 ( & h -> gb ); 31
if ( slice_type > 9 )  32
if ( slice_type > 4 )  38
slice_type -= 5; 39
h -> slice_type_fixed = 0; 42
slice_type = golomb_to_pict_type [ slice_type ]; 44
h -> slice_type = slice_type; 45
h -> slice_type_nos = slice_type & 3; 46
h -> pict_type = h -> slice_type; 49
pps_id = get_ue_golomb ( & h -> gb ); 51
if ( pps_id >= MAX_PPS_COUNT )  52
if ( ! h0 -> pps_buffers [ pps_id ] )  56
h -> pps = * h0 -> pps_buffers [ pps_id ]; 62
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  64
if ( h -> pps . sps_id != h -> current_sps_id ||
h0 -> sps_buffers [ h -> pps . sps_id ] -> new )
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 73
h -> current_sps_id = h -> pps . sps_id; 75
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 76
if ( h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  78
needs_reinit = 1; 83
if ( h -> bit_depth_luma != h -> sps . bit_depth_luma || h -> chroma_format_idc != h -> sps . chroma_format_idc )  85
h -> bit_depth_luma = h -> sps . bit_depth_luma; 87
h -> chroma_format_idc = h -> sps . chroma_format_idc; 88
needs_reinit = 1; 89
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  91
h -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 95
h -> avctx -> level = h -> sps . level_idc; 96
h -> avctx -> refs = h -> sps . ref_frame_count; 97
must_reinit = ( h -> context_initialized && ( 16 * h -> sps . mb_width != h -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != h -> avctx -> coded_height || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , h -> avctx -> sample_aspect_ratio ) || h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) ) ); 99
if ( h0 -> avctx -> pix_fmt != get_pixel_format ( h0 , 0 ) )  108
must_reinit = 1; 109
h -> mb_width = h -> sps . mb_width; 111
h -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 112
h -> mb_num = h -> mb_width * h -> mb_height; 113
h -> mb_stride = h -> mb_width + 1; 114
h -> b_stride = h -> mb_width * 4; 116
h -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 118
h -> width = 16 * h -> mb_width; 120
h -> height = 16 * h -> mb_height; 121
ret = init_dimensions ( h ); 123
if ( ret < 0 )  124
if ( h -> sps . video_signal_type_present_flag )  127
h -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 128
if ( h -> sps . colour_description_present_flag )  130
if ( h -> avctx -> colorspace != h -> sps . colorspace )  131
needs_reinit = 1; 132
h -> avctx -> color_primaries = h -> sps . color_primaries; 133
h -> avctx -> color_trc = h -> sps . color_trc; 134
h -> avctx -> colorspace = h -> sps . colorspace; 135
if ( h -> context_initialized && ( h -> width != h -> avctx -> coded_width || h -> height != h -> avctx -> coded_height || must_reinit || needs_reinit ) )  139
if ( h != h0 )  145
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  153
h -> avctx -> pix_fmt = ret; 155
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  160
if ( ! h -> context_initialized )  166
if ( h != h0 )  167
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  173
h -> avctx -> pix_fmt = ret; 175
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  177
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  184
h -> dequant_coeff_pps = pps_id; 185
h -> frame_num = get_bits ( & h -> gb , h -> sps . log2_max_frame_num ); 189
h -> mb_mbaff = 0; 191
h -> mb_aff_frame = 0; 192
h -> droppable = h -> nal_ref_idc == 0; 195
if ( h -> sps . frame_mbs_only_flag )  196
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  199
if ( get_bits1 ( & h -> gb ) )  203
h -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & h -> gb ); 204
h -> mb_field_decoding_flag = h -> picture_structure != PICT_FRAME; 210
if ( last_pic_structure != h -> picture_structure || last_pic_droppable != h -> droppable )  213
av_log ( h -> avctx , AV_LOG_ERROR , "Changing field mode (%d -> %d) between slices is not allowed\n" , last_pic_structure , h -> picture_structure ); 215
h -> picture_structure = last_pic_structure; 218
h -> droppable = last_pic_droppable; 219
av_log ( h -> avctx , AV_LOG_ERROR , "unset cur_pic_ptr on %d. slice\n" , h0 -> current_slice + 1 ); 222
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  230
int unwrap_prev_frame_num = h -> prev_frame_num ; 231
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 232
if ( unwrap_prev_frame_num > h -> frame_num )  234
unwrap_prev_frame_num -= max_frame_num; 235
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  237
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 238
if ( unwrap_prev_frame_num < 0 )  239
unwrap_prev_frame_num += max_frame_num; 240
h -> prev_frame_num = unwrap_prev_frame_num; 242
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  263
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  271
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && h -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && h -> picture_structure == PICT_TOP_FIELD ) ) )  282
av_log ( h -> avctx , AV_LOG_ERROR , "Invalid field mode combination %d/%d\n" , last_pic_structure , h -> picture_structure ); 286
h -> picture_structure = last_pic_structure; 289
h -> droppable = last_pic_droppable; 290
if ( last_pic_droppable != h -> droppable )  292
avpriv_request_sample ( h -> avctx , "Found reference and non-reference fields in the same frame, which" ); 293
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! h0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  303
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 305
av_log ( h -> avctx , AV_LOG_DEBUG , "Frame num gap %d %d\n" , h -> frame_num , h -> prev_frame_num ); 306
if ( ! h -> sps . gaps_in_frame_num_allowed_flag )  308
for(i=0; i<FF_ARRAY_ELEMS(h->last_pocs); i++) 309
h -> last_pocs [ i ] = INT_MIN; 310
if ( h264_frame_start ( h ) < 0 )  311
h -> prev_frame_num ++; 313
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 314
h -> cur_pic_ptr -> frame_num = h -> prev_frame_num; 315
ff_thread_report_progress ( & h -> cur_pic_ptr -> tf , INT_MAX , 0 ); 316
ff_thread_report_progress ( & h -> cur_pic_ptr -> tf , INT_MAX , 1 ); 317
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && h -> avctx -> err_recognition & AV_EF_EXPLODE )  318
return ret ; 320
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  321
if ( h -> short_ref_count )  330
if ( prev )  331
av_image_copy ( h -> short_ref [ 0 ] -> f . data , h -> short_ref [ 0 ] -> f . linesize , ( const uint8_t * * ) prev -> f . data , prev -> f . linesize , h -> avctx -> pix_fmt , h -> mb_width * 16 , h -> mb_height * 16 ); 332
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 335
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 337
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  350
h0 -> first_field = FIELD_PICTURE ( h ); 354
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  356
h0 -> first_field = FIELD_PICTURE ( h ); 371
if ( ! FIELD_PICTURE ( h ) || h0 -> first_field )  374
if ( h264_frame_start ( h ) < 0 )  375
h0 -> first_field = 0; 376
release_unused_pictures ( h , 0 ); 380
if ( FIELD_PICTURE ( h ) )  384
for(i = (h->picture_structure == PICT_BOTTOM_FIELD); i<h->mb_height; i++) 385
memset ( h -> slice_table + i * h -> mb_stride , - 1 , ( h -> mb_stride - ( i + 1 == h -> mb_height ) ) * sizeof ( * h -> slice_table ) ); 386
memset ( h -> slice_table , - 1 , ( h -> mb_height * h -> mb_stride - 1 ) * sizeof ( * h -> slice_table ) ); 388
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  393
return ret ; 394
for (i = 0; i < h->slice_context_count; i++) 398
if ( h -> thread_context [ i ] )  399
ret = alloc_scratch_buffers ( h -> thread_context [ i ] , h -> linesize ); 400
if ( ret < 0 )  401
return ret ; 402
h -> cur_pic_ptr -> frame_num = h -> frame_num; 405
av_assert1 ( h -> mb_num == h -> mb_width * h -> mb_height ); 407
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE ( h ) >= h -> mb_num || first_mb_in_slice >= h -> mb_num )  408
av_log ( h -> avctx , AV_LOG_ERROR , "first_mb_in_slice overflow\n" ); 410
h -> resync_mb_x = h -> mb_x = first_mb_in_slice % h -> mb_width; 413
h -> resync_mb_y = h -> mb_y = ( first_mb_in_slice / h -> mb_width ) << FIELD_OR_MBAFF_PICTURE ( h ); 414
if ( h -> picture_structure == PICT_BOTTOM_FIELD )  415
h -> resync_mb_y = h -> mb_y = h -> mb_y + 1; 416
av_assert1 ( h -> mb_y < h -> mb_height ); 417
if ( h -> picture_structure == PICT_FRAME )  419
h -> curr_pic_num = h -> frame_num; 420
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 421
h -> curr_pic_num = 2 * h -> frame_num + 1; 423
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 424
if ( h -> nal_unit_type == NAL_IDR_SLICE )  427
get_ue_golomb ( & h -> gb ); 428
if ( h -> sps . poc_type == 0 )  430
h -> poc_lsb = get_bits ( & h -> gb , h -> sps . log2_max_poc_lsb ); 431
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  433
h -> delta_poc_bottom = get_se_golomb ( & h -> gb ); 434
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  437
h -> delta_poc [ 0 ] = get_se_golomb ( & h -> gb ); 438
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  440
h -> delta_poc [ 1 ] = get_se_golomb ( & h -> gb ); 441
ff_init_poc ( h , h -> cur_pic_ptr -> field_poc , & h -> cur_pic_ptr -> poc ); 444
if ( h -> pps . redundant_pic_cnt_present )  446
h -> redundant_pic_count = get_ue_golomb ( & h -> gb ); 447
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 450
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 451
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  453
max [ 0 ] = max [ 1 ] = h -> picture_structure == PICT_FRAME ? 15 : 31; 455
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> direct_spatial_mv_pred = get_bits1 ( & h -> gb ); 458
num_ref_idx_active_override_flag = get_bits1 ( & h -> gb ); 459
if ( num_ref_idx_active_override_flag )  461
h -> ref_count [ 0 ] = get_ue_golomb ( & h -> gb ) + 1; 462
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  463
h -> ref_count [ 1 ] = get_ue_golomb ( & h -> gb ) + 1; 464
h -> ref_count [ 1 ] = 1; 467
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  470
av_log ( h -> avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 471
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 472
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  476
h -> list_count = 2; 477
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  491
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 493
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
pred_weight_table ( h ); 500
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
implicit_weight_table ( h , - 1 ); 503
h -> use_weight = 0; 505
for (i = 0; i < 2; i++) 506
h -> luma_weight_flag [ i ] = 0; 507
h -> chroma_weight_flag [ i ] = 0; 508
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & h -> gb , ! ( h -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
if ( FRAME_MBAFF ( h ) )  524
ff_h264_fill_mbaff_ref_list ( h ); 525
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  527
implicit_weight_table ( h , 0 ); 528
implicit_weight_table ( h , 1 ); 529
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  533
ff_h264_direct_dist_scale_factor ( h ); 534
ff_h264_direct_ref_list_init ( h ); 535
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
tmp = get_ue_golomb_31 ( & h -> gb ); 538
if ( tmp > 2 )  539
av_log ( h -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 540
h -> cabac_init_idc = tmp; 543
h -> last_qscale_diff = 0; 546
tmp = h -> pps . init_qp + get_se_golomb ( & h -> gb ); 547
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  548
av_log ( h -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 549
h -> qscale = tmp; 552
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , h -> qscale ); 553
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , h -> qscale ); 554
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  556
get_bits1 ( & h -> gb ); 557
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  558
get_se_golomb ( & h -> gb ); 560
h -> deblocking_filter = 1; 562
h -> slice_alpha_c0_offset = 52; 563
h -> slice_beta_offset = 52; 564
if ( h -> pps . deblocking_filter_parameters_present )  565
tmp = get_ue_golomb_31 ( & h -> gb ); 566
if ( tmp > 2 )  567
av_log ( h -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 568
h -> deblocking_filter = tmp; 572
if ( h -> deblocking_filter < 2 )  573
h -> deblocking_filter ^= 1; 574
if ( h -> deblocking_filter )  576
h -> slice_alpha_c0_offset += get_se_golomb ( & h -> gb ) << 1; 577
h -> slice_beta_offset += get_se_golomb ( & h -> gb ) << 1; 578
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  579
av_log ( h -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 581
if ( h -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  589
h -> deblocking_filter = 0; 596
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  598
if ( h -> avctx -> flags2 & CODEC_FLAG2_FAST )  599
h -> deblocking_filter = 2; 602
av_log ( h -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 606
av_log ( h -> avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 611
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 617
h -> slice_num = ++ h0 -> current_slice; 626
if ( h -> slice_num )  628
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = h -> resync_mb_y; 629
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= h -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= h -> resync_mb_y && h -> slice_num >= MAX_SLICES )  630
av_log ( h -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 634
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 639
for (i = 0; i < 16; i++) 640
id_list [ i ] = 60; 641
if ( j < h -> list_count && i < h -> ref_count [ j ] && h -> ref_list [ j ] [ i ] . f . buf [ 0 ] )  642
AVBuffer * buf = h -> ref_list [ j ] [ i ] . f . buf [ 0 ] -> buffer ; 644
for (k = 0; k < h->short_ref_count; k++) 645
if ( h -> short_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  646
id_list [ i ] = k; 647
for (k = 0; k < h->long_ref_count; k++) 650
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  651
id_list [ i ] = h -> short_ref_count + k; 652
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 658
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 661
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 663
for (i = 16; i < 48; i++) 665
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 666
if ( h -> ref_count [ 0 ] )  670
h -> er . last_pic = & h -> ref_list [ 0 ] [ 0 ]; 670
if ( h -> ref_count [ 1 ] )  671
h -> er . next_pic = & h -> ref_list [ 1 ] [ 0 ]; 671
h -> er . ref_count = h -> ref_count [ 0 ]; 672
if ( h -> avctx -> debug & FF_DEBUG_PICT_INFO )  674
av_log ( h -> avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( h -> picture_structure == PICT_FRAME ? "F" : h -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , h -> cur_pic_ptr -> field_poc [ 0 ] , h -> cur_pic_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , h -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 675
------------------------------
370 /home/speedy/test/source2slice/NVD/CVE_2013_7008_PATCHED_decode_slice_header.c h -> mb_num = h -> mb_width * h -> mb_height 113
static int CVE_2013_7008_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
unsigned int first_mb_in_slice ; 3
unsigned int pps_id ; 4
int num_ref_idx_active_override_flag , ret ; 5
unsigned int slice_type , tmp , i , j ; 6
h -> me . qpel_put = h -> h264qpel . put_h264_qpel_pixels_tab; 11
h -> me . qpel_avg = h -> h264qpel . avg_h264_qpel_pixels_tab; 12
first_mb_in_slice = get_ue_golomb_long ( & h -> gb ); 14
if ( first_mb_in_slice == 0 )  16
h0 -> current_slice = 0; 21
if ( ! h0 -> first_field )  22
h -> cur_pic_ptr = NULL; 27
slice_type = get_ue_golomb_31 ( & h -> gb ); 31
if ( slice_type > 9 )  32
if ( slice_type > 4 )  38
slice_type -= 5; 39
h -> slice_type_fixed = 0; 42
slice_type = golomb_to_pict_type [ slice_type ]; 44
h -> slice_type = slice_type; 45
h -> slice_type_nos = slice_type & 3; 46
h -> pict_type = h -> slice_type; 49
pps_id = get_ue_golomb ( & h -> gb ); 51
if ( pps_id >= MAX_PPS_COUNT )  52
if ( ! h0 -> pps_buffers [ pps_id ] )  56
h -> pps = * h0 -> pps_buffers [ pps_id ]; 62
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  64
if ( h -> pps . sps_id != h -> current_sps_id ||
h0 -> sps_buffers [ h -> pps . sps_id ] -> new )
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 73
h -> current_sps_id = h -> pps . sps_id; 75
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 76
if ( h -> bit_depth_luma != h -> sps . bit_depth_luma || h -> chroma_format_idc != h -> sps . chroma_format_idc )  85
h -> bit_depth_luma = h -> sps . bit_depth_luma; 87
h -> chroma_format_idc = h -> sps . chroma_format_idc; 88
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  91
h -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 95
h -> avctx -> level = h -> sps . level_idc; 96
h -> avctx -> refs = h -> sps . ref_frame_count; 97
h -> mb_width = h -> sps . mb_width; 111
h -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 112
h -> mb_num = h -> mb_width * h -> mb_height; 113
h -> mb_stride = h -> mb_width + 1; 114
h -> b_stride = h -> mb_width * 4; 116
h -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 118
h -> width = 16 * h -> mb_width; 120
h -> height = 16 * h -> mb_height; 121
ret = init_dimensions ( h ); 123
if ( ret < 0 )  124
return ret ; 125
if ( h -> sps . video_signal_type_present_flag )  127
h -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 128
if ( h -> sps . colour_description_present_flag )  130
if ( h -> avctx -> colorspace != h -> sps . colorspace )  131
h -> avctx -> color_primaries = h -> sps . color_primaries; 133
h -> avctx -> color_trc = h -> sps . color_trc; 134
h -> avctx -> colorspace = h -> sps . colorspace; 135
if ( h -> context_initialized && ( h -> width != h -> avctx -> coded_width || h -> height != h -> avctx -> coded_height || must_reinit || needs_reinit ) )  139
if ( h != h0 )  145
av_log ( h -> avctx , AV_LOG_ERROR , "changing width/height on "
"slice %d\n" , h0 -> current_slice + 1 ) 147
flush_change ( h ); 151
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  153
return ret ; 154
h -> avctx -> pix_fmt = ret; 155
av_log ( h -> avctx , AV_LOG_INFO , "Reinit context to %dx%d, "
"pix_fmt: %d\n" , h -> width , h -> height , h -> avctx -> pix_fmt ) 158
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  160
av_log ( h -> avctx , AV_LOG_ERROR , "h264_slice_header_init() failed\n" ); 161
return ret ; 163
if ( ! h -> context_initialized )  166
if ( h != h0 )  167
av_log ( h -> avctx , AV_LOG_ERROR , "Cannot (re-)initialize context during parallel decoding.\n" ); 168
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  173
return ret ; 174
h -> avctx -> pix_fmt = ret; 175
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  177
av_log ( h -> avctx , AV_LOG_ERROR , "h264_slice_header_init() failed\n" ); 178
return ret ; 180
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  184
h -> dequant_coeff_pps = pps_id; 185
init_dequant_tables ( h ); 186
h -> frame_num = get_bits ( & h -> gb , h -> sps . log2_max_frame_num ); 189
h -> mb_mbaff = 0; 191
h -> mb_aff_frame = 0; 192
h -> droppable = h -> nal_ref_idc == 0; 195
if ( h -> sps . frame_mbs_only_flag )  196
h -> picture_structure = PICT_FRAME; 197
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  199
av_log ( h -> avctx , AV_LOG_ERROR , "This stream was generated by a broken encoder, invalid 8x8 inference\n" ); 200
h -> mb_field_decoding_flag = h -> picture_structure != PICT_FRAME; 210
if ( last_pic_structure != h -> picture_structure || last_pic_droppable != h -> droppable )  213
av_log ( h -> avctx , AV_LOG_ERROR , "Changing field mode (%d -> %d) between slices is not allowed\n" , last_pic_structure , h -> picture_structure ); 215
h -> picture_structure = last_pic_structure; 218
h -> droppable = last_pic_droppable; 219
av_log ( h -> avctx , AV_LOG_ERROR , "unset cur_pic_ptr on %d. slice\n" , h0 -> current_slice + 1 ); 222
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  230
int unwrap_prev_frame_num = h -> prev_frame_num ; 231
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 232
if ( unwrap_prev_frame_num > h -> frame_num )  234
unwrap_prev_frame_num -= max_frame_num; 235
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  237
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 238
if ( unwrap_prev_frame_num < 0 )  239
unwrap_prev_frame_num += max_frame_num; 240
h -> prev_frame_num = unwrap_prev_frame_num; 242
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  263
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  271
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && h -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && h -> picture_structure == PICT_TOP_FIELD ) ) )  282
av_log ( h -> avctx , AV_LOG_ERROR , "Invalid field mode combination %d/%d\n" , last_pic_structure , h -> picture_structure ); 286
h -> picture_structure = last_pic_structure; 289
h -> droppable = last_pic_droppable; 290
if ( last_pic_droppable != h -> droppable )  292
avpriv_request_sample ( h -> avctx , "Found reference and non-reference fields in the same frame, which" ); 293
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! h0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  303
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 305
av_log ( h -> avctx , AV_LOG_DEBUG , "Frame num gap %d %d\n" , h -> frame_num , h -> prev_frame_num ); 306
if ( ! h -> sps . gaps_in_frame_num_allowed_flag )  308
for(i=0; i<FF_ARRAY_ELEMS(h->last_pocs); i++) 309
h -> last_pocs [ i ] = INT_MIN; 310
if ( h264_frame_start ( h ) < 0 )  311
h -> prev_frame_num ++; 313
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 314
h -> cur_pic_ptr -> frame_num = h -> prev_frame_num; 315
ff_thread_report_progress ( & h -> cur_pic_ptr -> tf , INT_MAX , 0 ); 316
ff_thread_report_progress ( & h -> cur_pic_ptr -> tf , INT_MAX , 1 ); 317
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && h -> avctx -> err_recognition & AV_EF_EXPLODE )  318
return ret ; 320
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  321
if ( h -> short_ref_count )  330
if ( prev )  331
av_image_copy ( h -> short_ref [ 0 ] -> f . data , h -> short_ref [ 0 ] -> f . linesize , ( const uint8_t * * ) prev -> f . data , prev -> f . linesize , h -> avctx -> pix_fmt , h -> mb_width * 16 , h -> mb_height * 16 ); 332
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 335
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 337
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  350
h0 -> first_field = FIELD_PICTURE ( h ); 354
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  356
h0 -> first_field = FIELD_PICTURE ( h ); 371
if ( ! FIELD_PICTURE ( h ) || h0 -> first_field )  374
if ( h264_frame_start ( h ) < 0 )  375
h0 -> first_field = 0; 376
release_unused_pictures ( h , 0 ); 380
if ( FIELD_PICTURE ( h ) )  384
for(i = (h->picture_structure == PICT_BOTTOM_FIELD); i<h->mb_height; i++) 385
memset ( h -> slice_table + i * h -> mb_stride , - 1 , ( h -> mb_stride - ( i + 1 == h -> mb_height ) ) * sizeof ( * h -> slice_table ) ); 386
memset ( h -> slice_table , - 1 , ( h -> mb_height * h -> mb_stride - 1 ) * sizeof ( * h -> slice_table ) ); 388
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  393
return ret ; 394
for (i = 0; i < h->slice_context_count; i++) 398
if ( h -> thread_context [ i ] )  399
ret = alloc_scratch_buffers ( h -> thread_context [ i ] , h -> linesize ); 400
if ( ret < 0 )  401
return ret ; 402
h -> cur_pic_ptr -> frame_num = h -> frame_num; 405
av_assert1 ( h -> mb_num == h -> mb_width * h -> mb_height ); 407
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE ( h ) >= h -> mb_num || first_mb_in_slice >= h -> mb_num )  408
av_log ( h -> avctx , AV_LOG_ERROR , "first_mb_in_slice overflow\n" ); 410
h -> resync_mb_x = h -> mb_x = first_mb_in_slice % h -> mb_width; 413
h -> resync_mb_y = h -> mb_y = ( first_mb_in_slice / h -> mb_width ) << FIELD_OR_MBAFF_PICTURE ( h ); 414
if ( h -> picture_structure == PICT_BOTTOM_FIELD )  415
h -> resync_mb_y = h -> mb_y = h -> mb_y + 1; 416
av_assert1 ( h -> mb_y < h -> mb_height ); 417
if ( h -> picture_structure == PICT_FRAME )  419
h -> curr_pic_num = h -> frame_num; 420
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 421
h -> curr_pic_num = 2 * h -> frame_num + 1; 423
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 424
if ( h -> nal_unit_type == NAL_IDR_SLICE )  427
get_ue_golomb ( & h -> gb ); 428
if ( h -> sps . poc_type == 0 )  430
h -> poc_lsb = get_bits ( & h -> gb , h -> sps . log2_max_poc_lsb ); 431
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  433
h -> delta_poc_bottom = get_se_golomb ( & h -> gb ); 434
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  437
h -> delta_poc [ 0 ] = get_se_golomb ( & h -> gb ); 438
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  440
h -> delta_poc [ 1 ] = get_se_golomb ( & h -> gb ); 441
ff_init_poc ( h , h -> cur_pic_ptr -> field_poc , & h -> cur_pic_ptr -> poc ); 444
if ( h -> pps . redundant_pic_cnt_present )  446
h -> redundant_pic_count = get_ue_golomb ( & h -> gb ); 447
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 450
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 451
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  453
max [ 0 ] = max [ 1 ] = h -> picture_structure == PICT_FRAME ? 15 : 31; 455
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> direct_spatial_mv_pred = get_bits1 ( & h -> gb ); 458
num_ref_idx_active_override_flag = get_bits1 ( & h -> gb ); 459
if ( num_ref_idx_active_override_flag )  461
h -> ref_count [ 0 ] = get_ue_golomb ( & h -> gb ) + 1; 462
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  463
h -> ref_count [ 1 ] = get_ue_golomb ( & h -> gb ) + 1; 464
h -> ref_count [ 1 ] = 1; 467
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  470
av_log ( h -> avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 471
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 472
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  476
h -> list_count = 2; 477
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  491
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 493
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
pred_weight_table ( h ); 500
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
implicit_weight_table ( h , - 1 ); 503
h -> use_weight = 0; 505
for (i = 0; i < 2; i++) 506
h -> luma_weight_flag [ i ] = 0; 507
h -> chroma_weight_flag [ i ] = 0; 508
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & h -> gb , ! ( h -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
if ( FRAME_MBAFF ( h ) )  524
ff_h264_fill_mbaff_ref_list ( h ); 525
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  527
implicit_weight_table ( h , 0 ); 528
implicit_weight_table ( h , 1 ); 529
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  533
ff_h264_direct_dist_scale_factor ( h ); 534
ff_h264_direct_ref_list_init ( h ); 535
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
tmp = get_ue_golomb_31 ( & h -> gb ); 538
if ( tmp > 2 )  539
av_log ( h -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 540
h -> cabac_init_idc = tmp; 543
h -> last_qscale_diff = 0; 546
tmp = h -> pps . init_qp + get_se_golomb ( & h -> gb ); 547
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  548
av_log ( h -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 549
h -> qscale = tmp; 552
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , h -> qscale ); 553
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , h -> qscale ); 554
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  556
get_bits1 ( & h -> gb ); 557
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  558
get_se_golomb ( & h -> gb ); 560
h -> deblocking_filter = 1; 562
h -> slice_alpha_c0_offset = 52; 563
h -> slice_beta_offset = 52; 564
if ( h -> pps . deblocking_filter_parameters_present )  565
tmp = get_ue_golomb_31 ( & h -> gb ); 566
if ( tmp > 2 )  567
av_log ( h -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 568
h -> deblocking_filter = tmp; 572
if ( h -> deblocking_filter < 2 )  573
h -> deblocking_filter ^= 1; 574
if ( h -> deblocking_filter )  576
h -> slice_alpha_c0_offset += get_se_golomb ( & h -> gb ) << 1; 577
h -> slice_beta_offset += get_se_golomb ( & h -> gb ) << 1; 578
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  579
av_log ( h -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 581
if ( h -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  589
h -> deblocking_filter = 0; 596
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  598
if ( h -> avctx -> flags2 & CODEC_FLAG2_FAST )  599
h -> deblocking_filter = 2; 602
av_log ( h -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 606
av_log ( h -> avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 611
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 617
h -> slice_num = ++ h0 -> current_slice; 626
if ( h -> slice_num )  628
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = h -> resync_mb_y; 629
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= h -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= h -> resync_mb_y && h -> slice_num >= MAX_SLICES )  630
av_log ( h -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 634
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 639
for (i = 0; i < 16; i++) 640
id_list [ i ] = 60; 641
if ( j < h -> list_count && i < h -> ref_count [ j ] && h -> ref_list [ j ] [ i ] . f . buf [ 0 ] )  642
AVBuffer * buf = h -> ref_list [ j ] [ i ] . f . buf [ 0 ] -> buffer ; 644
for (k = 0; k < h->short_ref_count; k++) 645
if ( h -> short_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  646
id_list [ i ] = k; 647
for (k = 0; k < h->long_ref_count; k++) 650
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  651
id_list [ i ] = h -> short_ref_count + k; 652
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 658
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 661
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 663
for (i = 16; i < 48; i++) 665
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 666
if ( h -> ref_count [ 0 ] )  670
h -> er . last_pic = & h -> ref_list [ 0 ] [ 0 ]; 670
if ( h -> ref_count [ 1 ] )  671
h -> er . next_pic = & h -> ref_list [ 1 ] [ 0 ]; 671
h -> er . ref_count = h -> ref_count [ 0 ]; 672
if ( h -> avctx -> debug & FF_DEBUG_PICT_INFO )  674
av_log ( h -> avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( h -> picture_structure == PICT_FRAME ? "F" : h -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , h -> cur_pic_ptr -> field_poc [ 0 ] , h -> cur_pic_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , h -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 675
------------------------------
371 /home/speedy/test/source2slice/NVD/CVE_2013_7008_VULN_decode_slice_header.c id_list [ i ] = h -> short_ref_count + k 652
static int CVE_2013_7008_VULN_decode_slice_header(H264Context *h, H264Context *h0) 1
unsigned int first_mb_in_slice ; 3
unsigned int pps_id ; 4
int num_ref_idx_active_override_flag , ret ; 5
unsigned int slice_type , tmp , i , j ; 6
int last_pic_structure , last_pic_droppable ; 7
int must_reinit ; 8
int needs_reinit = 0 ; 9
h -> me . qpel_put = h -> h264qpel . put_h264_qpel_pixels_tab; 11
h -> me . qpel_avg = h -> h264qpel . avg_h264_qpel_pixels_tab; 12
first_mb_in_slice = get_ue_golomb_long ( & h -> gb ); 14
if ( first_mb_in_slice == 0 )  16
h0 -> current_slice = 0; 21
if ( ! h0 -> first_field )  22
h -> cur_pic_ptr = NULL; 27
slice_type = get_ue_golomb_31 ( & h -> gb ); 31
if ( slice_type > 9 )  32
if ( slice_type > 4 )  38
slice_type -= 5; 39
h -> slice_type_fixed = 0; 42
slice_type = golomb_to_pict_type [ slice_type ]; 44
h -> slice_type = slice_type; 45
h -> slice_type_nos = slice_type & 3; 46
h -> pict_type = h -> slice_type; 49
pps_id = get_ue_golomb ( & h -> gb ); 51
if ( pps_id >= MAX_PPS_COUNT )  52
if ( ! h0 -> pps_buffers [ pps_id ] )  56
h -> pps = * h0 -> pps_buffers [ pps_id ]; 62
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  64
if ( h -> pps . sps_id != h -> current_sps_id ||
h0 -> sps_buffers [ h -> pps . sps_id ] -> new )
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 73
h -> current_sps_id = h -> pps . sps_id; 75
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 76
if ( h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  78
needs_reinit = 1; 83
if ( h -> bit_depth_luma != h -> sps . bit_depth_luma || h -> chroma_format_idc != h -> sps . chroma_format_idc )  85
h -> bit_depth_luma = h -> sps . bit_depth_luma; 87
h -> chroma_format_idc = h -> sps . chroma_format_idc; 88
needs_reinit = 1; 89
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  91
h -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 95
h -> avctx -> level = h -> sps . level_idc; 96
h -> avctx -> refs = h -> sps . ref_frame_count; 97
must_reinit = ( h -> context_initialized && ( 16 * h -> sps . mb_width != h -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != h -> avctx -> coded_height || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , h -> avctx -> sample_aspect_ratio ) || h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) ) ); 99
if ( h0 -> avctx -> pix_fmt != get_pixel_format ( h0 , 0 ) )  108
must_reinit = 1; 109
h -> mb_width = h -> sps . mb_width; 111
h -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 112
h -> mb_num = h -> mb_width * h -> mb_height; 113
h -> mb_stride = h -> mb_width + 1; 114
h -> b_stride = h -> mb_width * 4; 116
h -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 118
h -> width = 16 * h -> mb_width; 120
h -> height = 16 * h -> mb_height; 121
ret = init_dimensions ( h ); 123
if ( ret < 0 )  124
if ( h -> sps . video_signal_type_present_flag )  127
h -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 128
if ( h -> sps . colour_description_present_flag )  130
if ( h -> avctx -> colorspace != h -> sps . colorspace )  131
needs_reinit = 1; 132
h -> avctx -> color_primaries = h -> sps . color_primaries; 133
h -> avctx -> color_trc = h -> sps . color_trc; 134
h -> avctx -> colorspace = h -> sps . colorspace; 135
if ( h -> context_initialized && ( h -> width != h -> avctx -> coded_width || h -> height != h -> avctx -> coded_height || must_reinit || needs_reinit ) )  139
if ( h != h0 )  145
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  153
h -> avctx -> pix_fmt = ret; 155
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  160
if ( ! h -> context_initialized )  166
if ( h != h0 )  167
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  173
h -> avctx -> pix_fmt = ret; 175
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  177
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  184
h -> dequant_coeff_pps = pps_id; 185
h -> frame_num = get_bits ( & h -> gb , h -> sps . log2_max_frame_num ); 189
h -> mb_mbaff = 0; 191
h -> mb_aff_frame = 0; 192
last_pic_structure = h0 -> picture_structure; 193
last_pic_droppable = h0 -> droppable; 194
h -> droppable = h -> nal_ref_idc == 0; 195
if ( h -> sps . frame_mbs_only_flag )  196
h -> picture_structure = PICT_FRAME; 197
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  199
if ( get_bits1 ( & h -> gb ) )  203
h -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & h -> gb ); 204
h -> picture_structure = PICT_FRAME; 206
h -> mb_aff_frame = h -> sps . mb_aff; 207
h -> mb_field_decoding_flag = h -> picture_structure != PICT_FRAME; 210
if ( h0 -> current_slice != 0 )  212
if ( last_pic_structure != h -> picture_structure || last_pic_droppable != h -> droppable )  213
if ( ! h0 -> cur_pic_ptr )  221
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  230
int unwrap_prev_frame_num = h -> prev_frame_num ; 231
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 232
if ( unwrap_prev_frame_num > h -> frame_num )  234
unwrap_prev_frame_num -= max_frame_num; 235
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  237
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 238
if ( unwrap_prev_frame_num < 0 )  239
unwrap_prev_frame_num += max_frame_num; 240
h -> prev_frame_num = unwrap_prev_frame_num; 242
if ( h0 -> first_field )  251
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  263
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  271
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && h -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && h -> picture_structure == PICT_TOP_FIELD ) ) )  282
if ( last_pic_droppable != h -> droppable )  292
h -> picture_structure = last_pic_structure; 295
h -> droppable = last_pic_droppable; 296
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! h0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  303
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 305
if ( ! h -> sps . gaps_in_frame_num_allowed_flag )  308
for(i=0; i<FF_ARRAY_ELEMS(h->last_pocs); i++) 309
h -> last_pocs [ i ] = INT_MIN; 310
if ( h264_frame_start ( h ) < 0 )  311
h -> prev_frame_num ++; 313
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 314
h -> cur_pic_ptr -> frame_num = h -> prev_frame_num; 315
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && h -> avctx -> err_recognition & AV_EF_EXPLODE )  318
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  321
if ( h -> short_ref_count )  330
if ( prev )  331
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 335
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 337
if ( h0 -> first_field )  344
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  350
h0 -> cur_pic_ptr = NULL; 353
h0 -> first_field = FIELD_PICTURE ( h ); 354
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  356
h0 -> first_field = 1; 362
h0 -> cur_pic_ptr = NULL; 363
h0 -> first_field = 0; 366
h0 -> first_field = FIELD_PICTURE ( h ); 371
if ( ! FIELD_PICTURE ( h ) || h0 -> first_field )  374
if ( h264_frame_start ( h ) < 0 )  375
if ( FIELD_PICTURE ( h ) )  384
for(i = (h->picture_structure == PICT_BOTTOM_FIELD); i<h->mb_height; i++) 385
memset ( h -> slice_table , - 1 , ( h -> mb_height * h -> mb_stride - 1 ) * sizeof ( * h -> slice_table ) ); 388
h0 -> last_slice_type = - 1; 391
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  393
for (i = 0; i < h->slice_context_count; i++) 398
if ( h -> thread_context [ i ] )  399
ret = alloc_scratch_buffers ( h -> thread_context [ i ] , h -> linesize ); 400
if ( ret < 0 )  401
h -> cur_pic_ptr -> frame_num = h -> frame_num; 405
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE ( h ) >= h -> mb_num || first_mb_in_slice >= h -> mb_num )  408
h -> resync_mb_x = h -> mb_x = first_mb_in_slice % h -> mb_width; 413
h -> resync_mb_y = h -> mb_y = ( first_mb_in_slice / h -> mb_width ) << FIELD_OR_MBAFF_PICTURE ( h ); 414
if ( h -> picture_structure == PICT_BOTTOM_FIELD )  415
h -> resync_mb_y = h -> mb_y = h -> mb_y + 1; 416
if ( h -> picture_structure == PICT_FRAME )  419
h -> curr_pic_num = h -> frame_num; 420
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 421
h -> curr_pic_num = 2 * h -> frame_num + 1; 423
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 424
if ( h -> sps . poc_type == 0 )  430
h -> poc_lsb = get_bits ( & h -> gb , h -> sps . log2_max_poc_lsb ); 431
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  433
h -> delta_poc_bottom = get_se_golomb ( & h -> gb ); 434
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  437
h -> delta_poc [ 0 ] = get_se_golomb ( & h -> gb ); 438
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  440
h -> delta_poc [ 1 ] = get_se_golomb ( & h -> gb ); 441
if ( h -> pps . redundant_pic_cnt_present )  446
h -> redundant_pic_count = get_ue_golomb ( & h -> gb ); 447
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 450
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 451
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  453
unsigned max [ 2 ] ; 454
max [ 0 ] = max [ 1 ] = h -> picture_structure == PICT_FRAME ? 15 : 31; 455
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> direct_spatial_mv_pred = get_bits1 ( & h -> gb ); 458
num_ref_idx_active_override_flag = get_bits1 ( & h -> gb ); 459
if ( num_ref_idx_active_override_flag )  461
h -> ref_count [ 0 ] = get_ue_golomb ( & h -> gb ) + 1; 462
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  463
h -> ref_count [ 1 ] = get_ue_golomb ( & h -> gb ) + 1; 464
h -> ref_count [ 1 ] = 1; 467
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  470
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 472
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  476
h -> list_count = 2; 477
h -> list_count = 1; 479
h -> list_count = 0; 481
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 482
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  491
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
h -> use_weight = 0; 505
for (i = 0; i < 2; i++) 506
h -> luma_weight_flag [ i ] = 0; 507
h -> chroma_weight_flag [ i ] = 0; 508
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & h -> gb , ! ( h -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
tmp = get_ue_golomb_31 ( & h -> gb ); 538
if ( tmp > 2 )  539
h -> cabac_init_idc = tmp; 543
h -> last_qscale_diff = 0; 546
tmp = h -> pps . init_qp + get_se_golomb ( & h -> gb ); 547
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  548
h -> qscale = tmp; 552
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , h -> qscale ); 553
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , h -> qscale ); 554
h -> deblocking_filter = 1; 562
h -> slice_alpha_c0_offset = 52; 563
h -> slice_beta_offset = 52; 564
if ( h -> pps . deblocking_filter_parameters_present )  565
tmp = get_ue_golomb_31 ( & h -> gb ); 566
if ( tmp > 2 )  567
h -> deblocking_filter = tmp; 572
if ( h -> deblocking_filter < 2 )  573
h -> deblocking_filter ^= 1; 574
if ( h -> deblocking_filter )  576
h -> slice_alpha_c0_offset += get_se_golomb ( & h -> gb ) << 1; 577
h -> slice_beta_offset += get_se_golomb ( & h -> gb ) << 1; 578
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  579
if ( h -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  589
h -> deblocking_filter = 0; 596
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  598
if ( h -> avctx -> flags2 & CODEC_FLAG2_FAST )  599
h -> deblocking_filter = 2; 602
h0 -> max_contexts = 1; 604
if ( ! h0 -> single_decode_warning )  605
h0 -> single_decode_warning = 1; 608
if ( h != h0 )  610
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 617
h0 -> last_slice_type = slice_type; 624
memcpy ( h0 -> last_ref_count , h0 -> ref_count , sizeof ( h0 -> last_ref_count ) ); 625
h -> slice_num = ++ h0 -> current_slice; 626
if ( h -> slice_num )  628
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = h -> resync_mb_y; 629
for (j = 0; j < 2; j++) 637
int id_list [ 16 ] ; 638
for (i = 0; i < 16; i++) 640
id_list [ i ] = 60; 641
if ( j < h -> list_count && i < h -> ref_count [ j ] && h -> ref_list [ j ] [ i ] . f . buf [ 0 ] )  642
int k ; 643
AVBuffer * buf = h -> ref_list [ j ] [ i ] . f . buf [ 0 ] -> buffer ; 644
for (k = 0; k < h->short_ref_count; k++) 645
if ( h -> short_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  646
id_list [ i ] = k; 647
for (k = 0; k < h->long_ref_count; k++) 650
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  651
id_list [ i ] = h -> short_ref_count + k; 652
for (i = 0; i < 16; i++) 660
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 661
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 663
for (i = 16; i < 48; i++) 665
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 666
------------------------------
372 /home/speedy/test/source2slice/NVD/CVE_2013_7008_VULN_decode_slice_header.c tmp = h -> pps . init_qp + get_se_golomb ( & h -> gb ) 547
static int CVE_2013_7008_VULN_decode_slice_header(H264Context *h, H264Context *h0) 1
unsigned int first_mb_in_slice ; 3
unsigned int pps_id ; 4
int num_ref_idx_active_override_flag , ret ; 5
unsigned int slice_type , tmp , i , j ; 6
int last_pic_structure , last_pic_droppable ; 7
int must_reinit ; 8
int needs_reinit = 0 ; 9
h -> me . qpel_put = h -> h264qpel . put_h264_qpel_pixels_tab; 11
h -> me . qpel_avg = h -> h264qpel . avg_h264_qpel_pixels_tab; 12
first_mb_in_slice = get_ue_golomb_long ( & h -> gb ); 14
if ( first_mb_in_slice == 0 )  16
h0 -> current_slice = 0; 21
if ( ! h0 -> first_field )  22
h -> cur_pic_ptr = NULL; 27
slice_type = get_ue_golomb_31 ( & h -> gb ); 31
if ( slice_type > 9 )  32
if ( slice_type > 4 )  38
slice_type -= 5; 39
h -> slice_type_fixed = 0; 42
slice_type = golomb_to_pict_type [ slice_type ]; 44
h -> slice_type = slice_type; 45
h -> slice_type_nos = slice_type & 3; 46
h -> pict_type = h -> slice_type; 49
pps_id = get_ue_golomb ( & h -> gb ); 51
if ( pps_id >= MAX_PPS_COUNT )  52
if ( ! h0 -> pps_buffers [ pps_id ] )  56
h -> pps = * h0 -> pps_buffers [ pps_id ]; 62
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  64
if ( h -> pps . sps_id != h -> current_sps_id ||
h0 -> sps_buffers [ h -> pps . sps_id ] -> new )
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 73
h -> current_sps_id = h -> pps . sps_id; 75
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 76
if ( h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  78
needs_reinit = 1; 83
if ( h -> bit_depth_luma != h -> sps . bit_depth_luma || h -> chroma_format_idc != h -> sps . chroma_format_idc )  85
h -> bit_depth_luma = h -> sps . bit_depth_luma; 87
h -> chroma_format_idc = h -> sps . chroma_format_idc; 88
needs_reinit = 1; 89
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  91
h -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 95
h -> avctx -> level = h -> sps . level_idc; 96
h -> avctx -> refs = h -> sps . ref_frame_count; 97
must_reinit = ( h -> context_initialized && ( 16 * h -> sps . mb_width != h -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != h -> avctx -> coded_height || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , h -> avctx -> sample_aspect_ratio ) || h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) ) ); 99
if ( h0 -> avctx -> pix_fmt != get_pixel_format ( h0 , 0 ) )  108
must_reinit = 1; 109
h -> mb_width = h -> sps . mb_width; 111
h -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 112
h -> mb_num = h -> mb_width * h -> mb_height; 113
h -> mb_stride = h -> mb_width + 1; 114
h -> b_stride = h -> mb_width * 4; 116
h -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 118
h -> width = 16 * h -> mb_width; 120
h -> height = 16 * h -> mb_height; 121
ret = init_dimensions ( h ); 123
if ( ret < 0 )  124
if ( h -> sps . video_signal_type_present_flag )  127
h -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 128
if ( h -> sps . colour_description_present_flag )  130
if ( h -> avctx -> colorspace != h -> sps . colorspace )  131
needs_reinit = 1; 132
h -> avctx -> color_primaries = h -> sps . color_primaries; 133
h -> avctx -> color_trc = h -> sps . color_trc; 134
h -> avctx -> colorspace = h -> sps . colorspace; 135
if ( h -> context_initialized && ( h -> width != h -> avctx -> coded_width || h -> height != h -> avctx -> coded_height || must_reinit || needs_reinit ) )  139
if ( h != h0 )  145
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  153
h -> avctx -> pix_fmt = ret; 155
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  160
if ( ! h -> context_initialized )  166
if ( h != h0 )  167
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  173
h -> avctx -> pix_fmt = ret; 175
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  177
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  184
h -> dequant_coeff_pps = pps_id; 185
h -> frame_num = get_bits ( & h -> gb , h -> sps . log2_max_frame_num ); 189
h -> mb_mbaff = 0; 191
h -> mb_aff_frame = 0; 192
last_pic_structure = h0 -> picture_structure; 193
last_pic_droppable = h0 -> droppable; 194
h -> droppable = h -> nal_ref_idc == 0; 195
if ( h -> sps . frame_mbs_only_flag )  196
h -> picture_structure = PICT_FRAME; 197
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  199
if ( get_bits1 ( & h -> gb ) )  203
h -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & h -> gb ); 204
h -> picture_structure = PICT_FRAME; 206
h -> mb_aff_frame = h -> sps . mb_aff; 207
h -> mb_field_decoding_flag = h -> picture_structure != PICT_FRAME; 210
if ( h0 -> current_slice != 0 )  212
if ( last_pic_structure != h -> picture_structure || last_pic_droppable != h -> droppable )  213
if ( ! h0 -> cur_pic_ptr )  221
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  230
int unwrap_prev_frame_num = h -> prev_frame_num ; 231
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 232
if ( unwrap_prev_frame_num > h -> frame_num )  234
unwrap_prev_frame_num -= max_frame_num; 235
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  237
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 238
if ( unwrap_prev_frame_num < 0 )  239
unwrap_prev_frame_num += max_frame_num; 240
h -> prev_frame_num = unwrap_prev_frame_num; 242
if ( h0 -> first_field )  251
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  263
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  271
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && h -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && h -> picture_structure == PICT_TOP_FIELD ) ) )  282
if ( last_pic_droppable != h -> droppable )  292
h -> picture_structure = last_pic_structure; 295
h -> droppable = last_pic_droppable; 296
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! h0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  303
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 305
if ( ! h -> sps . gaps_in_frame_num_allowed_flag )  308
for(i=0; i<FF_ARRAY_ELEMS(h->last_pocs); i++) 309
h -> last_pocs [ i ] = INT_MIN; 310
if ( h264_frame_start ( h ) < 0 )  311
h -> prev_frame_num ++; 313
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 314
h -> cur_pic_ptr -> frame_num = h -> prev_frame_num; 315
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && h -> avctx -> err_recognition & AV_EF_EXPLODE )  318
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  321
if ( h -> short_ref_count )  330
if ( prev )  331
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 335
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 337
if ( h0 -> first_field )  344
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  350
h0 -> cur_pic_ptr = NULL; 353
h0 -> first_field = FIELD_PICTURE ( h ); 354
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  356
h0 -> first_field = 1; 362
h0 -> cur_pic_ptr = NULL; 363
h0 -> first_field = 0; 366
h0 -> first_field = FIELD_PICTURE ( h ); 371
if ( ! FIELD_PICTURE ( h ) || h0 -> first_field )  374
if ( h264_frame_start ( h ) < 0 )  375
if ( FIELD_PICTURE ( h ) )  384
for(i = (h->picture_structure == PICT_BOTTOM_FIELD); i<h->mb_height; i++) 385
memset ( h -> slice_table , - 1 , ( h -> mb_height * h -> mb_stride - 1 ) * sizeof ( * h -> slice_table ) ); 388
h0 -> last_slice_type = - 1; 391
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  393
for (i = 0; i < h->slice_context_count; i++) 398
if ( h -> thread_context [ i ] )  399
ret = alloc_scratch_buffers ( h -> thread_context [ i ] , h -> linesize ); 400
if ( ret < 0 )  401
h -> cur_pic_ptr -> frame_num = h -> frame_num; 405
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE ( h ) >= h -> mb_num || first_mb_in_slice >= h -> mb_num )  408
h -> resync_mb_x = h -> mb_x = first_mb_in_slice % h -> mb_width; 413
h -> resync_mb_y = h -> mb_y = ( first_mb_in_slice / h -> mb_width ) << FIELD_OR_MBAFF_PICTURE ( h ); 414
if ( h -> picture_structure == PICT_BOTTOM_FIELD )  415
h -> resync_mb_y = h -> mb_y = h -> mb_y + 1; 416
if ( h -> picture_structure == PICT_FRAME )  419
h -> curr_pic_num = h -> frame_num; 420
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 421
h -> curr_pic_num = 2 * h -> frame_num + 1; 423
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 424
if ( h -> sps . poc_type == 0 )  430
h -> poc_lsb = get_bits ( & h -> gb , h -> sps . log2_max_poc_lsb ); 431
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  433
h -> delta_poc_bottom = get_se_golomb ( & h -> gb ); 434
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  437
h -> delta_poc [ 0 ] = get_se_golomb ( & h -> gb ); 438
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  440
h -> delta_poc [ 1 ] = get_se_golomb ( & h -> gb ); 441
if ( h -> pps . redundant_pic_cnt_present )  446
h -> redundant_pic_count = get_ue_golomb ( & h -> gb ); 447
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 450
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 451
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  453
unsigned max [ 2 ] ; 454
max [ 0 ] = max [ 1 ] = h -> picture_structure == PICT_FRAME ? 15 : 31; 455
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> direct_spatial_mv_pred = get_bits1 ( & h -> gb ); 458
num_ref_idx_active_override_flag = get_bits1 ( & h -> gb ); 459
if ( num_ref_idx_active_override_flag )  461
h -> ref_count [ 0 ] = get_ue_golomb ( & h -> gb ) + 1; 462
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  463
h -> ref_count [ 1 ] = get_ue_golomb ( & h -> gb ) + 1; 464
h -> ref_count [ 1 ] = 1; 467
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  470
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 472
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  476
h -> list_count = 2; 477
h -> list_count = 1; 479
h -> list_count = 0; 481
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 482
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  491
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
h -> use_weight = 0; 505
for (i = 0; i < 2; i++) 506
h -> luma_weight_flag [ i ] = 0; 507
h -> chroma_weight_flag [ i ] = 0; 508
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & h -> gb , ! ( h -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
tmp = get_ue_golomb_31 ( & h -> gb ); 538
if ( tmp > 2 )  539
h -> cabac_init_idc = tmp; 543
h -> last_qscale_diff = 0; 546
tmp = h -> pps . init_qp + get_se_golomb ( & h -> gb ); 547
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  548
av_log ( h -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 549
h -> qscale = tmp; 552
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , h -> qscale ); 553
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , h -> qscale ); 554
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  556
get_bits1 ( & h -> gb ); 557
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  558
get_se_golomb ( & h -> gb ); 560
h -> deblocking_filter = 1; 562
h -> slice_alpha_c0_offset = 52; 563
h -> slice_beta_offset = 52; 564
if ( h -> pps . deblocking_filter_parameters_present )  565
tmp = get_ue_golomb_31 ( & h -> gb ); 566
if ( tmp > 2 )  567
av_log ( h -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 568
h -> deblocking_filter = tmp; 572
if ( h -> deblocking_filter < 2 )  573
h -> deblocking_filter ^= 1; 574
if ( h -> deblocking_filter )  576
h -> slice_alpha_c0_offset += get_se_golomb ( & h -> gb ) << 1; 577
h -> slice_beta_offset += get_se_golomb ( & h -> gb ) << 1; 578
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  579
av_log ( h -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 581
if ( h -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  589
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  598
if ( h -> avctx -> flags2 & CODEC_FLAG2_FAST )  599
av_log ( h -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 606
av_log ( h -> avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 611
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 617
h -> slice_num = ++ h0 -> current_slice; 626
if ( h -> slice_num )  628
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = h -> resync_mb_y; 629
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= h -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= h -> resync_mb_y && h -> slice_num >= MAX_SLICES )  630
av_log ( h -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 634
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 639
if ( j < h -> list_count && i < h -> ref_count [ j ] && h -> ref_list [ j ] [ i ] . f . buf [ 0 ] )  642
AVBuffer * buf = h -> ref_list [ j ] [ i ] . f . buf [ 0 ] -> buffer ; 644
for (k = 0; k < h->short_ref_count; k++) 645
if ( h -> short_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  646
for (k = 0; k < h->long_ref_count; k++) 650
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  651
id_list [ i ] = h -> short_ref_count + k; 652
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 658
for (i = 0; i < 16; i++) 660
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 661
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 663
for (i = 16; i < 48; i++) 665
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 666
if ( h -> ref_count [ 0 ] )  670
h -> er . last_pic = & h -> ref_list [ 0 ] [ 0 ]; 670
if ( h -> ref_count [ 1 ] )  671
h -> er . next_pic = & h -> ref_list [ 1 ] [ 0 ]; 671
h -> er . ref_count = h -> ref_count [ 0 ]; 672
if ( h -> avctx -> debug & FF_DEBUG_PICT_INFO )  674
av_log ( h -> avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( h -> picture_structure == PICT_FRAME ? "F" : h -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , h -> cur_pic_ptr -> field_poc [ 0 ] , h -> cur_pic_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , h -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 675
------------------------------
373 /home/speedy/test/source2slice/NVD/CVE_2013_7008_VULN_decode_slice_header.c h -> resync_mb_y = h -> mb_y = ( first_mb_in_slice / h -> mb_width ) << FIELD_OR_MBAFF_PICTURE ( h ) 414
static int CVE_2013_7008_VULN_decode_slice_header(H264Context *h, H264Context *h0) 1
unsigned int first_mb_in_slice ; 3
unsigned int pps_id ; 4
int num_ref_idx_active_override_flag , ret ; 5
unsigned int slice_type , tmp , i , j ; 6
int last_pic_structure , last_pic_droppable ; 7
int must_reinit ; 8
int needs_reinit = 0 ; 9
h -> me . qpel_put = h -> h264qpel . put_h264_qpel_pixels_tab; 11
h -> me . qpel_avg = h -> h264qpel . avg_h264_qpel_pixels_tab; 12
first_mb_in_slice = get_ue_golomb_long ( & h -> gb ); 14
if ( first_mb_in_slice == 0 )  16
h0 -> current_slice = 0; 21
if ( ! h0 -> first_field )  22
h -> cur_pic_ptr = NULL; 27
slice_type = get_ue_golomb_31 ( & h -> gb ); 31
if ( slice_type > 9 )  32
if ( slice_type > 4 )  38
slice_type -= 5; 39
h -> slice_type_fixed = 0; 42
slice_type = golomb_to_pict_type [ slice_type ]; 44
h -> slice_type = slice_type; 45
h -> slice_type_nos = slice_type & 3; 46
h -> pict_type = h -> slice_type; 49
pps_id = get_ue_golomb ( & h -> gb ); 51
if ( pps_id >= MAX_PPS_COUNT )  52
if ( ! h0 -> pps_buffers [ pps_id ] )  56
h -> pps = * h0 -> pps_buffers [ pps_id ]; 62
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  64
if ( h -> pps . sps_id != h -> current_sps_id ||
h0 -> sps_buffers [ h -> pps . sps_id ] -> new )
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 73
h -> current_sps_id = h -> pps . sps_id; 75
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 76
if ( h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  78
needs_reinit = 1; 83
if ( h -> bit_depth_luma != h -> sps . bit_depth_luma || h -> chroma_format_idc != h -> sps . chroma_format_idc )  85
h -> bit_depth_luma = h -> sps . bit_depth_luma; 87
h -> chroma_format_idc = h -> sps . chroma_format_idc; 88
needs_reinit = 1; 89
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  91
h -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 95
h -> avctx -> level = h -> sps . level_idc; 96
h -> avctx -> refs = h -> sps . ref_frame_count; 97
must_reinit = ( h -> context_initialized && ( 16 * h -> sps . mb_width != h -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != h -> avctx -> coded_height || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , h -> avctx -> sample_aspect_ratio ) || h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) ) ); 99
if ( h0 -> avctx -> pix_fmt != get_pixel_format ( h0 , 0 ) )  108
must_reinit = 1; 109
h -> mb_width = h -> sps . mb_width; 111
h -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 112
h -> mb_num = h -> mb_width * h -> mb_height; 113
h -> mb_stride = h -> mb_width + 1; 114
h -> b_stride = h -> mb_width * 4; 116
h -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 118
h -> width = 16 * h -> mb_width; 120
h -> height = 16 * h -> mb_height; 121
ret = init_dimensions ( h ); 123
if ( ret < 0 )  124
if ( h -> sps . video_signal_type_present_flag )  127
h -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 128
if ( h -> sps . colour_description_present_flag )  130
if ( h -> avctx -> colorspace != h -> sps . colorspace )  131
needs_reinit = 1; 132
h -> avctx -> color_primaries = h -> sps . color_primaries; 133
h -> avctx -> color_trc = h -> sps . color_trc; 134
h -> avctx -> colorspace = h -> sps . colorspace; 135
if ( h -> context_initialized && ( h -> width != h -> avctx -> coded_width || h -> height != h -> avctx -> coded_height || must_reinit || needs_reinit ) )  139
if ( h != h0 )  145
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  153
h -> avctx -> pix_fmt = ret; 155
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  160
if ( ! h -> context_initialized )  166
if ( h != h0 )  167
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  173
h -> avctx -> pix_fmt = ret; 175
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  177
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  184
h -> dequant_coeff_pps = pps_id; 185
h -> frame_num = get_bits ( & h -> gb , h -> sps . log2_max_frame_num ); 189
h -> mb_mbaff = 0; 191
h -> mb_aff_frame = 0; 192
last_pic_structure = h0 -> picture_structure; 193
last_pic_droppable = h0 -> droppable; 194
h -> droppable = h -> nal_ref_idc == 0; 195
if ( h -> sps . frame_mbs_only_flag )  196
h -> picture_structure = PICT_FRAME; 197
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  199
if ( get_bits1 ( & h -> gb ) )  203
h -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & h -> gb ); 204
h -> picture_structure = PICT_FRAME; 206
h -> mb_aff_frame = h -> sps . mb_aff; 207
h -> mb_field_decoding_flag = h -> picture_structure != PICT_FRAME; 210
if ( h0 -> current_slice != 0 )  212
if ( last_pic_structure != h -> picture_structure || last_pic_droppable != h -> droppable )  213
if ( ! h0 -> cur_pic_ptr )  221
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  230
int unwrap_prev_frame_num = h -> prev_frame_num ; 231
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 232
if ( unwrap_prev_frame_num > h -> frame_num )  234
unwrap_prev_frame_num -= max_frame_num; 235
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  237
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 238
if ( unwrap_prev_frame_num < 0 )  239
unwrap_prev_frame_num += max_frame_num; 240
h -> prev_frame_num = unwrap_prev_frame_num; 242
if ( h0 -> first_field )  251
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  263
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  271
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && h -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && h -> picture_structure == PICT_TOP_FIELD ) ) )  282
if ( last_pic_droppable != h -> droppable )  292
h -> picture_structure = last_pic_structure; 295
h -> droppable = last_pic_droppable; 296
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! h0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  303
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 305
if ( ! h -> sps . gaps_in_frame_num_allowed_flag )  308
for(i=0; i<FF_ARRAY_ELEMS(h->last_pocs); i++) 309
h -> last_pocs [ i ] = INT_MIN; 310
if ( h264_frame_start ( h ) < 0 )  311
h -> prev_frame_num ++; 313
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 314
h -> cur_pic_ptr -> frame_num = h -> prev_frame_num; 315
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && h -> avctx -> err_recognition & AV_EF_EXPLODE )  318
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  321
if ( h -> short_ref_count )  330
if ( prev )  331
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 335
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 337
if ( h0 -> first_field )  344
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  350
h0 -> cur_pic_ptr = NULL; 353
h0 -> first_field = FIELD_PICTURE ( h ); 354
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  356
h0 -> first_field = 1; 362
h0 -> cur_pic_ptr = NULL; 363
h0 -> first_field = 0; 366
h0 -> first_field = FIELD_PICTURE ( h ); 371
if ( ! FIELD_PICTURE ( h ) || h0 -> first_field )  374
if ( h264_frame_start ( h ) < 0 )  375
if ( FIELD_PICTURE ( h ) )  384
for(i = (h->picture_structure == PICT_BOTTOM_FIELD); i<h->mb_height; i++) 385
memset ( h -> slice_table , - 1 , ( h -> mb_height * h -> mb_stride - 1 ) * sizeof ( * h -> slice_table ) ); 388
h0 -> last_slice_type = - 1; 391
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  393
for (i = 0; i < h->slice_context_count; i++) 398
if ( h -> thread_context [ i ] )  399
ret = alloc_scratch_buffers ( h -> thread_context [ i ] , h -> linesize ); 400
if ( ret < 0 )  401
h -> cur_pic_ptr -> frame_num = h -> frame_num; 405
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE ( h ) >= h -> mb_num || first_mb_in_slice >= h -> mb_num )  408
h -> resync_mb_x = h -> mb_x = first_mb_in_slice % h -> mb_width; 413
h -> resync_mb_y = h -> mb_y = ( first_mb_in_slice / h -> mb_width ) << FIELD_OR_MBAFF_PICTURE ( h ); 414
if ( h -> picture_structure == PICT_BOTTOM_FIELD )  415
h -> resync_mb_y = h -> mb_y = h -> mb_y + 1; 416
av_assert1 ( h -> mb_y < h -> mb_height ); 417
if ( h -> picture_structure == PICT_FRAME )  419
h -> curr_pic_num = h -> frame_num; 420
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 421
h -> curr_pic_num = 2 * h -> frame_num + 1; 423
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 424
if ( h -> nal_unit_type == NAL_IDR_SLICE )  427
get_ue_golomb ( & h -> gb ); 428
if ( h -> sps . poc_type == 0 )  430
h -> poc_lsb = get_bits ( & h -> gb , h -> sps . log2_max_poc_lsb ); 431
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  433
h -> delta_poc_bottom = get_se_golomb ( & h -> gb ); 434
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  437
h -> delta_poc [ 0 ] = get_se_golomb ( & h -> gb ); 438
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  440
h -> delta_poc [ 1 ] = get_se_golomb ( & h -> gb ); 441
ff_init_poc ( h , h -> cur_pic_ptr -> field_poc , & h -> cur_pic_ptr -> poc ); 444
if ( h -> pps . redundant_pic_cnt_present )  446
h -> redundant_pic_count = get_ue_golomb ( & h -> gb ); 447
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 450
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 451
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  453
max [ 0 ] = max [ 1 ] = h -> picture_structure == PICT_FRAME ? 15 : 31; 455
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> direct_spatial_mv_pred = get_bits1 ( & h -> gb ); 458
num_ref_idx_active_override_flag = get_bits1 ( & h -> gb ); 459
if ( num_ref_idx_active_override_flag )  461
h -> ref_count [ 0 ] = get_ue_golomb ( & h -> gb ) + 1; 462
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  463
h -> ref_count [ 1 ] = get_ue_golomb ( & h -> gb ) + 1; 464
h -> ref_count [ 1 ] = 1; 467
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  470
av_log ( h -> avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 471
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 472
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  476
h -> list_count = 2; 477
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  491
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 493
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & h -> gb , ! ( h -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  527
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  533
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
av_log ( h -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 540
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = h -> resync_mb_y; 629
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= h -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= h -> resync_mb_y && h -> slice_num >= MAX_SLICES )  630
av_log ( h -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 634
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 639
if ( j < h -> list_count && i < h -> ref_count [ j ] && h -> ref_list [ j ] [ i ] . f . buf [ 0 ] )  642
AVBuffer * buf = h -> ref_list [ j ] [ i ] . f . buf [ 0 ] -> buffer ; 644
for (k = 0; k < h->short_ref_count; k++) 645
if ( h -> short_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  646
for (k = 0; k < h->long_ref_count; k++) 650
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  651
id_list [ i ] = h -> short_ref_count + k; 652
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 658
for (i = 0; i < 16; i++) 660
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 661
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 663
for (i = 16; i < 48; i++) 665
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 666
if ( h -> ref_count [ 0 ] )  670
h -> er . last_pic = & h -> ref_list [ 0 ] [ 0 ]; 670
if ( h -> ref_count [ 1 ] )  671
h -> er . next_pic = & h -> ref_list [ 1 ] [ 0 ]; 671
h -> er . ref_count = h -> ref_count [ 0 ]; 672
if ( h -> avctx -> debug & FF_DEBUG_PICT_INFO )  674
av_log ( h -> avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( h -> picture_structure == PICT_FRAME ? "F" : h -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , h -> cur_pic_ptr -> field_poc [ 0 ] , h -> cur_pic_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , h -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 675
------------------------------
374 /home/speedy/test/source2slice/NVD/CVE_2013_7008_VULN_decode_slice_header.c unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1 238
static int CVE_2013_7008_VULN_decode_slice_header(H264Context *h, H264Context *h0) 1
unsigned int first_mb_in_slice ; 3
unsigned int pps_id ; 4
int num_ref_idx_active_override_flag , ret ; 5
unsigned int slice_type , tmp , i , j ; 6
int must_reinit ; 8
int needs_reinit = 0 ; 9
h -> me . qpel_put = h -> h264qpel . put_h264_qpel_pixels_tab; 11
h -> me . qpel_avg = h -> h264qpel . avg_h264_qpel_pixels_tab; 12
first_mb_in_slice = get_ue_golomb_long ( & h -> gb ); 14
if ( first_mb_in_slice == 0 )  16
h0 -> current_slice = 0; 21
if ( ! h0 -> first_field )  22
h -> cur_pic_ptr = NULL; 27
slice_type = get_ue_golomb_31 ( & h -> gb ); 31
if ( slice_type > 9 )  32
if ( slice_type > 4 )  38
slice_type -= 5; 39
h -> slice_type_fixed = 0; 42
slice_type = golomb_to_pict_type [ slice_type ]; 44
h -> slice_type = slice_type; 45
h -> slice_type_nos = slice_type & 3; 46
h -> pict_type = h -> slice_type; 49
pps_id = get_ue_golomb ( & h -> gb ); 51
if ( pps_id >= MAX_PPS_COUNT )  52
if ( ! h0 -> pps_buffers [ pps_id ] )  56
h -> pps = * h0 -> pps_buffers [ pps_id ]; 62
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  64
if ( h -> pps . sps_id != h -> current_sps_id ||
h0 -> sps_buffers [ h -> pps . sps_id ] -> new )
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 73
h -> current_sps_id = h -> pps . sps_id; 75
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 76
if ( h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  78
needs_reinit = 1; 83
if ( h -> bit_depth_luma != h -> sps . bit_depth_luma || h -> chroma_format_idc != h -> sps . chroma_format_idc )  85
h -> bit_depth_luma = h -> sps . bit_depth_luma; 87
h -> chroma_format_idc = h -> sps . chroma_format_idc; 88
needs_reinit = 1; 89
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  91
h -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 95
h -> avctx -> level = h -> sps . level_idc; 96
h -> avctx -> refs = h -> sps . ref_frame_count; 97
must_reinit = ( h -> context_initialized && ( 16 * h -> sps . mb_width != h -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != h -> avctx -> coded_height || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , h -> avctx -> sample_aspect_ratio ) || h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) ) ); 99
if ( h0 -> avctx -> pix_fmt != get_pixel_format ( h0 , 0 ) )  108
must_reinit = 1; 109
h -> mb_width = h -> sps . mb_width; 111
h -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 112
h -> mb_num = h -> mb_width * h -> mb_height; 113
h -> mb_stride = h -> mb_width + 1; 114
h -> b_stride = h -> mb_width * 4; 116
h -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 118
h -> width = 16 * h -> mb_width; 120
h -> height = 16 * h -> mb_height; 121
ret = init_dimensions ( h ); 123
if ( ret < 0 )  124
if ( h -> sps . video_signal_type_present_flag )  127
h -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 128
if ( h -> sps . colour_description_present_flag )  130
if ( h -> avctx -> colorspace != h -> sps . colorspace )  131
needs_reinit = 1; 132
h -> avctx -> color_primaries = h -> sps . color_primaries; 133
h -> avctx -> color_trc = h -> sps . color_trc; 134
h -> avctx -> colorspace = h -> sps . colorspace; 135
if ( h -> context_initialized && ( h -> width != h -> avctx -> coded_width || h -> height != h -> avctx -> coded_height || must_reinit || needs_reinit ) )  139
if ( h != h0 )  145
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  153
h -> avctx -> pix_fmt = ret; 155
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  160
if ( ! h -> context_initialized )  166
if ( h != h0 )  167
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  173
h -> avctx -> pix_fmt = ret; 175
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  177
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  184
h -> dequant_coeff_pps = pps_id; 185
h -> frame_num = get_bits ( & h -> gb , h -> sps . log2_max_frame_num ); 189
h -> mb_mbaff = 0; 191
h -> mb_aff_frame = 0; 192
h -> droppable = h -> nal_ref_idc == 0; 195
if ( h -> sps . frame_mbs_only_flag )  196
h -> picture_structure = PICT_FRAME; 197
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  199
if ( get_bits1 ( & h -> gb ) )  203
h -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & h -> gb ); 204
h -> picture_structure = PICT_FRAME; 206
h -> mb_aff_frame = h -> sps . mb_aff; 207
h -> mb_field_decoding_flag = h -> picture_structure != PICT_FRAME; 210
if ( h0 -> current_slice != 0 )  212
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  230
int unwrap_prev_frame_num = h -> prev_frame_num ; 231
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 232
if ( unwrap_prev_frame_num > h -> frame_num )  234
unwrap_prev_frame_num -= max_frame_num; 235
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  237
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 238
if ( unwrap_prev_frame_num < 0 )  239
unwrap_prev_frame_num += max_frame_num; 240
h -> prev_frame_num = unwrap_prev_frame_num; 242
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  263
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  271
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && h -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && h -> picture_structure == PICT_TOP_FIELD ) ) )  282
av_log ( h -> avctx , AV_LOG_ERROR , "Invalid field mode combination %d/%d\n" , last_pic_structure , h -> picture_structure ); 286
h -> picture_structure = last_pic_structure; 289
h -> droppable = last_pic_droppable; 290
if ( last_pic_droppable != h -> droppable )  292
avpriv_request_sample ( h -> avctx , "Found reference and non-reference fields in the same frame, which" ); 293
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! h0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  303
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 305
av_log ( h -> avctx , AV_LOG_DEBUG , "Frame num gap %d %d\n" , h -> frame_num , h -> prev_frame_num ); 306
if ( ! h -> sps . gaps_in_frame_num_allowed_flag )  308
for(i=0; i<FF_ARRAY_ELEMS(h->last_pocs); i++) 309
h -> last_pocs [ i ] = INT_MIN; 310
if ( h264_frame_start ( h ) < 0 )  311
h -> prev_frame_num ++; 313
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 314
h -> cur_pic_ptr -> frame_num = h -> prev_frame_num; 315
ff_thread_report_progress ( & h -> cur_pic_ptr -> tf , INT_MAX , 0 ); 316
ff_thread_report_progress ( & h -> cur_pic_ptr -> tf , INT_MAX , 1 ); 317
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && h -> avctx -> err_recognition & AV_EF_EXPLODE )  318
return ret ; 320
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  321
if ( h -> short_ref_count )  330
if ( prev )  331
av_image_copy ( h -> short_ref [ 0 ] -> f . data , h -> short_ref [ 0 ] -> f . linesize , ( const uint8_t * * ) prev -> f . data , prev -> f . linesize , h -> avctx -> pix_fmt , h -> mb_width * 16 , h -> mb_height * 16 ); 332
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 335
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 337
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  350
h0 -> first_field = FIELD_PICTURE ( h ); 354
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  356
h0 -> first_field = FIELD_PICTURE ( h ); 371
if ( ! FIELD_PICTURE ( h ) || h0 -> first_field )  374
if ( h264_frame_start ( h ) < 0 )  375
h0 -> first_field = 0; 376
for(i = (h->picture_structure == PICT_BOTTOM_FIELD); i<h->mb_height; i++) 385
memset ( h -> slice_table + i * h -> mb_stride , - 1 , ( h -> mb_stride - ( i + 1 == h -> mb_height ) ) * sizeof ( * h -> slice_table ) ); 386
memset ( h -> slice_table , - 1 , ( h -> mb_height * h -> mb_stride - 1 ) * sizeof ( * h -> slice_table ) ); 388
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  393
return ret ; 394
for (i = 0; i < h->slice_context_count; i++) 398
if ( h -> thread_context [ i ] )  399
ret = alloc_scratch_buffers ( h -> thread_context [ i ] , h -> linesize ); 400
if ( ret < 0 )  401
return ret ; 402
h -> cur_pic_ptr -> frame_num = h -> frame_num; 405
av_assert1 ( h -> mb_num == h -> mb_width * h -> mb_height ); 407
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE ( h ) >= h -> mb_num || first_mb_in_slice >= h -> mb_num )  408
av_log ( h -> avctx , AV_LOG_ERROR , "first_mb_in_slice overflow\n" ); 410
h -> resync_mb_x = h -> mb_x = first_mb_in_slice % h -> mb_width; 413
h -> resync_mb_y = h -> mb_y = ( first_mb_in_slice / h -> mb_width ) << FIELD_OR_MBAFF_PICTURE ( h ); 414
if ( h -> picture_structure == PICT_BOTTOM_FIELD )  415
h -> resync_mb_y = h -> mb_y = h -> mb_y + 1; 416
av_assert1 ( h -> mb_y < h -> mb_height ); 417
if ( h -> picture_structure == PICT_FRAME )  419
h -> curr_pic_num = h -> frame_num; 420
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 421
h -> curr_pic_num = 2 * h -> frame_num + 1; 423
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 424
if ( h -> nal_unit_type == NAL_IDR_SLICE )  427
get_ue_golomb ( & h -> gb ); 428
if ( h -> sps . poc_type == 0 )  430
h -> poc_lsb = get_bits ( & h -> gb , h -> sps . log2_max_poc_lsb ); 431
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  433
h -> delta_poc_bottom = get_se_golomb ( & h -> gb ); 434
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  437
h -> delta_poc [ 0 ] = get_se_golomb ( & h -> gb ); 438
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  440
h -> delta_poc [ 1 ] = get_se_golomb ( & h -> gb ); 441
ff_init_poc ( h , h -> cur_pic_ptr -> field_poc , & h -> cur_pic_ptr -> poc ); 444
if ( h -> pps . redundant_pic_cnt_present )  446
h -> redundant_pic_count = get_ue_golomb ( & h -> gb ); 447
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 450
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 451
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  453
max [ 0 ] = max [ 1 ] = h -> picture_structure == PICT_FRAME ? 15 : 31; 455
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> direct_spatial_mv_pred = get_bits1 ( & h -> gb ); 458
num_ref_idx_active_override_flag = get_bits1 ( & h -> gb ); 459
if ( num_ref_idx_active_override_flag )  461
h -> ref_count [ 0 ] = get_ue_golomb ( & h -> gb ) + 1; 462
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  463
h -> ref_count [ 1 ] = get_ue_golomb ( & h -> gb ) + 1; 464
h -> ref_count [ 1 ] = 1; 467
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  470
av_log ( h -> avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 471
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 472
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  476
h -> list_count = 2; 477
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  491
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 493
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & h -> gb , ! ( h -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  527
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  533
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
av_log ( h -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 540
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = h -> resync_mb_y; 629
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= h -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= h -> resync_mb_y && h -> slice_num >= MAX_SLICES )  630
av_log ( h -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 634
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 639
if ( j < h -> list_count && i < h -> ref_count [ j ] && h -> ref_list [ j ] [ i ] . f . buf [ 0 ] )  642
AVBuffer * buf = h -> ref_list [ j ] [ i ] . f . buf [ 0 ] -> buffer ; 644
for (k = 0; k < h->short_ref_count; k++) 645
if ( h -> short_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  646
for (k = 0; k < h->long_ref_count; k++) 650
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  651
id_list [ i ] = h -> short_ref_count + k; 652
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 658
for (i = 0; i < 16; i++) 660
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 661
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 663
for (i = 16; i < 48; i++) 665
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 666
if ( h -> ref_count [ 0 ] )  670
h -> er . last_pic = & h -> ref_list [ 0 ] [ 0 ]; 670
if ( h -> ref_count [ 1 ] )  671
h -> er . next_pic = & h -> ref_list [ 1 ] [ 0 ]; 671
h -> er . ref_count = h -> ref_count [ 0 ]; 672
if ( h -> avctx -> debug & FF_DEBUG_PICT_INFO )  674
av_log ( h -> avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( h -> picture_structure == PICT_FRAME ? "F" : h -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , h -> cur_pic_ptr -> field_poc [ 0 ] , h -> cur_pic_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , h -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 675
------------------------------
375 /home/speedy/test/source2slice/NVD/CVE_2013_7008_VULN_decode_slice_header.c h -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & h -> gb ) 204
static int CVE_2013_7008_VULN_decode_slice_header(H264Context *h, H264Context *h0) 1
unsigned int first_mb_in_slice ; 3
unsigned int pps_id ; 4
int num_ref_idx_active_override_flag , ret ; 5
unsigned int slice_type , tmp , i , j ; 6
int must_reinit ; 8
int needs_reinit = 0 ; 9
h -> me . qpel_put = h -> h264qpel . put_h264_qpel_pixels_tab; 11
h -> me . qpel_avg = h -> h264qpel . avg_h264_qpel_pixels_tab; 12
first_mb_in_slice = get_ue_golomb_long ( & h -> gb ); 14
if ( first_mb_in_slice == 0 )  16
h0 -> current_slice = 0; 21
if ( ! h0 -> first_field )  22
h -> cur_pic_ptr = NULL; 27
slice_type = get_ue_golomb_31 ( & h -> gb ); 31
if ( slice_type > 9 )  32
if ( slice_type > 4 )  38
slice_type -= 5; 39
h -> slice_type_fixed = 0; 42
slice_type = golomb_to_pict_type [ slice_type ]; 44
h -> slice_type = slice_type; 45
h -> slice_type_nos = slice_type & 3; 46
h -> pict_type = h -> slice_type; 49
pps_id = get_ue_golomb ( & h -> gb ); 51
if ( pps_id >= MAX_PPS_COUNT )  52
if ( ! h0 -> pps_buffers [ pps_id ] )  56
h -> pps = * h0 -> pps_buffers [ pps_id ]; 62
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  64
if ( h -> pps . sps_id != h -> current_sps_id ||
h0 -> sps_buffers [ h -> pps . sps_id ] -> new )
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 73
h -> current_sps_id = h -> pps . sps_id; 75
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 76
if ( h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  78
needs_reinit = 1; 83
if ( h -> bit_depth_luma != h -> sps . bit_depth_luma || h -> chroma_format_idc != h -> sps . chroma_format_idc )  85
h -> bit_depth_luma = h -> sps . bit_depth_luma; 87
h -> chroma_format_idc = h -> sps . chroma_format_idc; 88
needs_reinit = 1; 89
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  91
h -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 95
h -> avctx -> level = h -> sps . level_idc; 96
h -> avctx -> refs = h -> sps . ref_frame_count; 97
must_reinit = ( h -> context_initialized && ( 16 * h -> sps . mb_width != h -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != h -> avctx -> coded_height || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , h -> avctx -> sample_aspect_ratio ) || h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) ) ); 99
if ( h0 -> avctx -> pix_fmt != get_pixel_format ( h0 , 0 ) )  108
must_reinit = 1; 109
h -> mb_width = h -> sps . mb_width; 111
h -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 112
h -> mb_num = h -> mb_width * h -> mb_height; 113
h -> mb_stride = h -> mb_width + 1; 114
h -> b_stride = h -> mb_width * 4; 116
h -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 118
h -> width = 16 * h -> mb_width; 120
h -> height = 16 * h -> mb_height; 121
ret = init_dimensions ( h ); 123
if ( ret < 0 )  124
if ( h -> sps . video_signal_type_present_flag )  127
h -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 128
if ( h -> sps . colour_description_present_flag )  130
if ( h -> avctx -> colorspace != h -> sps . colorspace )  131
needs_reinit = 1; 132
h -> avctx -> color_primaries = h -> sps . color_primaries; 133
h -> avctx -> color_trc = h -> sps . color_trc; 134
h -> avctx -> colorspace = h -> sps . colorspace; 135
if ( h -> context_initialized && ( h -> width != h -> avctx -> coded_width || h -> height != h -> avctx -> coded_height || must_reinit || needs_reinit ) )  139
if ( h != h0 )  145
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  153
h -> avctx -> pix_fmt = ret; 155
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  160
if ( ! h -> context_initialized )  166
if ( h != h0 )  167
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  173
h -> avctx -> pix_fmt = ret; 175
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  177
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  184
h -> dequant_coeff_pps = pps_id; 185
h -> frame_num = get_bits ( & h -> gb , h -> sps . log2_max_frame_num ); 189
h -> mb_mbaff = 0; 191
h -> mb_aff_frame = 0; 192
h -> droppable = h -> nal_ref_idc == 0; 195
if ( h -> sps . frame_mbs_only_flag )  196
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  199
if ( get_bits1 ( & h -> gb ) )  203
h -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & h -> gb ); 204
h -> mb_field_decoding_flag = h -> picture_structure != PICT_FRAME; 210
if ( last_pic_structure != h -> picture_structure || last_pic_droppable != h -> droppable )  213
av_log ( h -> avctx , AV_LOG_ERROR , "Changing field mode (%d -> %d) between slices is not allowed\n" , last_pic_structure , h -> picture_structure ); 215
h -> picture_structure = last_pic_structure; 218
h -> droppable = last_pic_droppable; 219
av_log ( h -> avctx , AV_LOG_ERROR , "unset cur_pic_ptr on %d. slice\n" , h0 -> current_slice + 1 ); 222
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  230
int unwrap_prev_frame_num = h -> prev_frame_num ; 231
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 232
if ( unwrap_prev_frame_num > h -> frame_num )  234
unwrap_prev_frame_num -= max_frame_num; 235
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  237
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 238
if ( unwrap_prev_frame_num < 0 )  239
unwrap_prev_frame_num += max_frame_num; 240
h -> prev_frame_num = unwrap_prev_frame_num; 242
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  263
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  271
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && h -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && h -> picture_structure == PICT_TOP_FIELD ) ) )  282
av_log ( h -> avctx , AV_LOG_ERROR , "Invalid field mode combination %d/%d\n" , last_pic_structure , h -> picture_structure ); 286
h -> picture_structure = last_pic_structure; 289
h -> droppable = last_pic_droppable; 290
if ( last_pic_droppable != h -> droppable )  292
avpriv_request_sample ( h -> avctx , "Found reference and non-reference fields in the same frame, which" ); 293
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! h0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  303
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 305
av_log ( h -> avctx , AV_LOG_DEBUG , "Frame num gap %d %d\n" , h -> frame_num , h -> prev_frame_num ); 306
if ( ! h -> sps . gaps_in_frame_num_allowed_flag )  308
for(i=0; i<FF_ARRAY_ELEMS(h->last_pocs); i++) 309
h -> last_pocs [ i ] = INT_MIN; 310
if ( h264_frame_start ( h ) < 0 )  311
h -> prev_frame_num ++; 313
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 314
h -> cur_pic_ptr -> frame_num = h -> prev_frame_num; 315
ff_thread_report_progress ( & h -> cur_pic_ptr -> tf , INT_MAX , 0 ); 316
ff_thread_report_progress ( & h -> cur_pic_ptr -> tf , INT_MAX , 1 ); 317
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && h -> avctx -> err_recognition & AV_EF_EXPLODE )  318
return ret ; 320
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  321
if ( h -> short_ref_count )  330
if ( prev )  331
av_image_copy ( h -> short_ref [ 0 ] -> f . data , h -> short_ref [ 0 ] -> f . linesize , ( const uint8_t * * ) prev -> f . data , prev -> f . linesize , h -> avctx -> pix_fmt , h -> mb_width * 16 , h -> mb_height * 16 ); 332
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 335
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 337
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  350
h0 -> first_field = FIELD_PICTURE ( h ); 354
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  356
h0 -> first_field = FIELD_PICTURE ( h ); 371
if ( ! FIELD_PICTURE ( h ) || h0 -> first_field )  374
if ( h264_frame_start ( h ) < 0 )  375
h0 -> first_field = 0; 376
for(i = (h->picture_structure == PICT_BOTTOM_FIELD); i<h->mb_height; i++) 385
memset ( h -> slice_table + i * h -> mb_stride , - 1 , ( h -> mb_stride - ( i + 1 == h -> mb_height ) ) * sizeof ( * h -> slice_table ) ); 386
memset ( h -> slice_table , - 1 , ( h -> mb_height * h -> mb_stride - 1 ) * sizeof ( * h -> slice_table ) ); 388
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  393
return ret ; 394
for (i = 0; i < h->slice_context_count; i++) 398
if ( h -> thread_context [ i ] )  399
ret = alloc_scratch_buffers ( h -> thread_context [ i ] , h -> linesize ); 400
if ( ret < 0 )  401
return ret ; 402
h -> cur_pic_ptr -> frame_num = h -> frame_num; 405
av_assert1 ( h -> mb_num == h -> mb_width * h -> mb_height ); 407
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE ( h ) >= h -> mb_num || first_mb_in_slice >= h -> mb_num )  408
av_log ( h -> avctx , AV_LOG_ERROR , "first_mb_in_slice overflow\n" ); 410
h -> resync_mb_x = h -> mb_x = first_mb_in_slice % h -> mb_width; 413
h -> resync_mb_y = h -> mb_y = ( first_mb_in_slice / h -> mb_width ) << FIELD_OR_MBAFF_PICTURE ( h ); 414
if ( h -> picture_structure == PICT_BOTTOM_FIELD )  415
h -> resync_mb_y = h -> mb_y = h -> mb_y + 1; 416
av_assert1 ( h -> mb_y < h -> mb_height ); 417
if ( h -> picture_structure == PICT_FRAME )  419
h -> curr_pic_num = h -> frame_num; 420
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 421
h -> curr_pic_num = 2 * h -> frame_num + 1; 423
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 424
if ( h -> nal_unit_type == NAL_IDR_SLICE )  427
get_ue_golomb ( & h -> gb ); 428
if ( h -> sps . poc_type == 0 )  430
h -> poc_lsb = get_bits ( & h -> gb , h -> sps . log2_max_poc_lsb ); 431
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  433
h -> delta_poc_bottom = get_se_golomb ( & h -> gb ); 434
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  437
h -> delta_poc [ 0 ] = get_se_golomb ( & h -> gb ); 438
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  440
h -> delta_poc [ 1 ] = get_se_golomb ( & h -> gb ); 441
ff_init_poc ( h , h -> cur_pic_ptr -> field_poc , & h -> cur_pic_ptr -> poc ); 444
if ( h -> pps . redundant_pic_cnt_present )  446
h -> redundant_pic_count = get_ue_golomb ( & h -> gb ); 447
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 450
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 451
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  453
max [ 0 ] = max [ 1 ] = h -> picture_structure == PICT_FRAME ? 15 : 31; 455
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> direct_spatial_mv_pred = get_bits1 ( & h -> gb ); 458
num_ref_idx_active_override_flag = get_bits1 ( & h -> gb ); 459
if ( num_ref_idx_active_override_flag )  461
h -> ref_count [ 0 ] = get_ue_golomb ( & h -> gb ) + 1; 462
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  463
h -> ref_count [ 1 ] = get_ue_golomb ( & h -> gb ) + 1; 464
h -> ref_count [ 1 ] = 1; 467
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  470
av_log ( h -> avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 471
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 472
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  476
h -> list_count = 2; 477
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  491
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 493
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & h -> gb , ! ( h -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  527
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  533
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
av_log ( h -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 540
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = h -> resync_mb_y; 629
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= h -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= h -> resync_mb_y && h -> slice_num >= MAX_SLICES )  630
av_log ( h -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 634
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 639
if ( j < h -> list_count && i < h -> ref_count [ j ] && h -> ref_list [ j ] [ i ] . f . buf [ 0 ] )  642
AVBuffer * buf = h -> ref_list [ j ] [ i ] . f . buf [ 0 ] -> buffer ; 644
for (k = 0; k < h->short_ref_count; k++) 645
if ( h -> short_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  646
for (k = 0; k < h->long_ref_count; k++) 650
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  651
id_list [ i ] = h -> short_ref_count + k; 652
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 658
for (i = 0; i < 16; i++) 660
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 661
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 663
for (i = 16; i < 48; i++) 665
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 666
if ( h -> ref_count [ 0 ] )  670
h -> er . last_pic = & h -> ref_list [ 0 ] [ 0 ]; 670
if ( h -> ref_count [ 1 ] )  671
h -> er . next_pic = & h -> ref_list [ 1 ] [ 0 ]; 671
h -> er . ref_count = h -> ref_count [ 0 ]; 672
if ( h -> avctx -> debug & FF_DEBUG_PICT_INFO )  674
av_log ( h -> avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( h -> picture_structure == PICT_FRAME ? "F" : h -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , h -> cur_pic_ptr -> field_poc [ 0 ] , h -> cur_pic_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , h -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 675
------------------------------
376 /home/speedy/test/source2slice/NVD/CVE_2013_7008_VULN_decode_slice_header.c h -> mb_num = h -> mb_width * h -> mb_height 113
static int CVE_2013_7008_VULN_decode_slice_header(H264Context *h, H264Context *h0) 1
unsigned int first_mb_in_slice ; 3
unsigned int pps_id ; 4
int num_ref_idx_active_override_flag , ret ; 5
unsigned int slice_type , tmp , i , j ; 6
h -> me . qpel_put = h -> h264qpel . put_h264_qpel_pixels_tab; 11
h -> me . qpel_avg = h -> h264qpel . avg_h264_qpel_pixels_tab; 12
first_mb_in_slice = get_ue_golomb_long ( & h -> gb ); 14
if ( first_mb_in_slice == 0 )  16
h0 -> current_slice = 0; 21
if ( ! h0 -> first_field )  22
h -> cur_pic_ptr = NULL; 27
slice_type = get_ue_golomb_31 ( & h -> gb ); 31
if ( slice_type > 9 )  32
if ( slice_type > 4 )  38
slice_type -= 5; 39
h -> slice_type_fixed = 0; 42
slice_type = golomb_to_pict_type [ slice_type ]; 44
h -> slice_type = slice_type; 45
h -> slice_type_nos = slice_type & 3; 46
h -> pict_type = h -> slice_type; 49
pps_id = get_ue_golomb ( & h -> gb ); 51
if ( pps_id >= MAX_PPS_COUNT )  52
if ( ! h0 -> pps_buffers [ pps_id ] )  56
h -> pps = * h0 -> pps_buffers [ pps_id ]; 62
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  64
if ( h -> pps . sps_id != h -> current_sps_id ||
h0 -> sps_buffers [ h -> pps . sps_id ] -> new )
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 73
h -> current_sps_id = h -> pps . sps_id; 75
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 76
if ( h -> bit_depth_luma != h -> sps . bit_depth_luma || h -> chroma_format_idc != h -> sps . chroma_format_idc )  85
h -> bit_depth_luma = h -> sps . bit_depth_luma; 87
h -> chroma_format_idc = h -> sps . chroma_format_idc; 88
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  91
h -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 95
h -> avctx -> level = h -> sps . level_idc; 96
h -> avctx -> refs = h -> sps . ref_frame_count; 97
h -> mb_width = h -> sps . mb_width; 111
h -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 112
h -> mb_num = h -> mb_width * h -> mb_height; 113
h -> mb_stride = h -> mb_width + 1; 114
h -> b_stride = h -> mb_width * 4; 116
h -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 118
h -> width = 16 * h -> mb_width; 120
h -> height = 16 * h -> mb_height; 121
ret = init_dimensions ( h ); 123
if ( ret < 0 )  124
return ret ; 125
if ( h -> sps . video_signal_type_present_flag )  127
h -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 128
if ( h -> sps . colour_description_present_flag )  130
if ( h -> avctx -> colorspace != h -> sps . colorspace )  131
h -> avctx -> color_primaries = h -> sps . color_primaries; 133
h -> avctx -> color_trc = h -> sps . color_trc; 134
h -> avctx -> colorspace = h -> sps . colorspace; 135
if ( h -> context_initialized && ( h -> width != h -> avctx -> coded_width || h -> height != h -> avctx -> coded_height || must_reinit || needs_reinit ) )  139
if ( h != h0 )  145
av_log ( h -> avctx , AV_LOG_ERROR , "changing width/height on "
"slice %d\n" , h0 -> current_slice + 1 ) 147
flush_change ( h ); 151
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  153
return ret ; 154
h -> avctx -> pix_fmt = ret; 155
av_log ( h -> avctx , AV_LOG_INFO , "Reinit context to %dx%d, "
"pix_fmt: %d\n" , h -> width , h -> height , h -> avctx -> pix_fmt ) 158
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  160
av_log ( h -> avctx , AV_LOG_ERROR , "h264_slice_header_init() failed\n" ); 161
return ret ; 163
if ( ! h -> context_initialized )  166
if ( h != h0 )  167
av_log ( h -> avctx , AV_LOG_ERROR , "Cannot (re-)initialize context during parallel decoding.\n" ); 168
if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 )  173
return ret ; 174
h -> avctx -> pix_fmt = ret; 175
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  177
av_log ( h -> avctx , AV_LOG_ERROR , "h264_slice_header_init() failed\n" ); 178
return ret ; 180
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  184
h -> dequant_coeff_pps = pps_id; 185
init_dequant_tables ( h ); 186
h -> frame_num = get_bits ( & h -> gb , h -> sps . log2_max_frame_num ); 189
h -> mb_mbaff = 0; 191
h -> mb_aff_frame = 0; 192
h -> droppable = h -> nal_ref_idc == 0; 195
if ( h -> sps . frame_mbs_only_flag )  196
h -> picture_structure = PICT_FRAME; 197
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  199
av_log ( h -> avctx , AV_LOG_ERROR , "This stream was generated by a broken encoder, invalid 8x8 inference\n" ); 200
h -> mb_field_decoding_flag = h -> picture_structure != PICT_FRAME; 210
if ( last_pic_structure != h -> picture_structure || last_pic_droppable != h -> droppable )  213
av_log ( h -> avctx , AV_LOG_ERROR , "Changing field mode (%d -> %d) between slices is not allowed\n" , last_pic_structure , h -> picture_structure ); 215
h -> picture_structure = last_pic_structure; 218
h -> droppable = last_pic_droppable; 219
av_log ( h -> avctx , AV_LOG_ERROR , "unset cur_pic_ptr on %d. slice\n" , h0 -> current_slice + 1 ); 222
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  230
int unwrap_prev_frame_num = h -> prev_frame_num ; 231
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 232
if ( unwrap_prev_frame_num > h -> frame_num )  234
unwrap_prev_frame_num -= max_frame_num; 235
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  237
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 238
if ( unwrap_prev_frame_num < 0 )  239
unwrap_prev_frame_num += max_frame_num; 240
h -> prev_frame_num = unwrap_prev_frame_num; 242
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  263
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  271
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && h -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && h -> picture_structure == PICT_TOP_FIELD ) ) )  282
av_log ( h -> avctx , AV_LOG_ERROR , "Invalid field mode combination %d/%d\n" , last_pic_structure , h -> picture_structure ); 286
h -> picture_structure = last_pic_structure; 289
h -> droppable = last_pic_droppable; 290
if ( last_pic_droppable != h -> droppable )  292
avpriv_request_sample ( h -> avctx , "Found reference and non-reference fields in the same frame, which" ); 293
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! h0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  303
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 305
av_log ( h -> avctx , AV_LOG_DEBUG , "Frame num gap %d %d\n" , h -> frame_num , h -> prev_frame_num ); 306
if ( ! h -> sps . gaps_in_frame_num_allowed_flag )  308
for(i=0; i<FF_ARRAY_ELEMS(h->last_pocs); i++) 309
h -> last_pocs [ i ] = INT_MIN; 310
if ( h264_frame_start ( h ) < 0 )  311
h -> prev_frame_num ++; 313
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 314
h -> cur_pic_ptr -> frame_num = h -> prev_frame_num; 315
ff_thread_report_progress ( & h -> cur_pic_ptr -> tf , INT_MAX , 0 ); 316
ff_thread_report_progress ( & h -> cur_pic_ptr -> tf , INT_MAX , 1 ); 317
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && h -> avctx -> err_recognition & AV_EF_EXPLODE )  318
return ret ; 320
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  321
if ( h -> short_ref_count )  330
if ( prev )  331
av_image_copy ( h -> short_ref [ 0 ] -> f . data , h -> short_ref [ 0 ] -> f . linesize , ( const uint8_t * * ) prev -> f . data , prev -> f . linesize , h -> avctx -> pix_fmt , h -> mb_width * 16 , h -> mb_height * 16 ); 332
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 335
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 337
if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure )  350
h0 -> first_field = FIELD_PICTURE ( h ); 354
if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num )  356
h0 -> first_field = FIELD_PICTURE ( h ); 371
if ( ! FIELD_PICTURE ( h ) || h0 -> first_field )  374
if ( h264_frame_start ( h ) < 0 )  375
h0 -> first_field = 0; 376
for(i = (h->picture_structure == PICT_BOTTOM_FIELD); i<h->mb_height; i++) 385
memset ( h -> slice_table + i * h -> mb_stride , - 1 , ( h -> mb_stride - ( i + 1 == h -> mb_height ) ) * sizeof ( * h -> slice_table ) ); 386
memset ( h -> slice_table , - 1 , ( h -> mb_height * h -> mb_stride - 1 ) * sizeof ( * h -> slice_table ) ); 388
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  393
return ret ; 394
for (i = 0; i < h->slice_context_count; i++) 398
if ( h -> thread_context [ i ] )  399
ret = alloc_scratch_buffers ( h -> thread_context [ i ] , h -> linesize ); 400
if ( ret < 0 )  401
return ret ; 402
h -> cur_pic_ptr -> frame_num = h -> frame_num; 405
av_assert1 ( h -> mb_num == h -> mb_width * h -> mb_height ); 407
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE ( h ) >= h -> mb_num || first_mb_in_slice >= h -> mb_num )  408
av_log ( h -> avctx , AV_LOG_ERROR , "first_mb_in_slice overflow\n" ); 410
h -> resync_mb_x = h -> mb_x = first_mb_in_slice % h -> mb_width; 413
h -> resync_mb_y = h -> mb_y = ( first_mb_in_slice / h -> mb_width ) << FIELD_OR_MBAFF_PICTURE ( h ); 414
if ( h -> picture_structure == PICT_BOTTOM_FIELD )  415
h -> resync_mb_y = h -> mb_y = h -> mb_y + 1; 416
av_assert1 ( h -> mb_y < h -> mb_height ); 417
if ( h -> picture_structure == PICT_FRAME )  419
h -> curr_pic_num = h -> frame_num; 420
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 421
h -> curr_pic_num = 2 * h -> frame_num + 1; 423
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 424
if ( h -> nal_unit_type == NAL_IDR_SLICE )  427
get_ue_golomb ( & h -> gb ); 428
if ( h -> sps . poc_type == 0 )  430
h -> poc_lsb = get_bits ( & h -> gb , h -> sps . log2_max_poc_lsb ); 431
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  433
h -> delta_poc_bottom = get_se_golomb ( & h -> gb ); 434
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  437
h -> delta_poc [ 0 ] = get_se_golomb ( & h -> gb ); 438
if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME )  440
h -> delta_poc [ 1 ] = get_se_golomb ( & h -> gb ); 441
ff_init_poc ( h , h -> cur_pic_ptr -> field_poc , & h -> cur_pic_ptr -> poc ); 444
if ( h -> pps . redundant_pic_cnt_present )  446
h -> redundant_pic_count = get_ue_golomb ( & h -> gb ); 447
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 450
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 451
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  453
max [ 0 ] = max [ 1 ] = h -> picture_structure == PICT_FRAME ? 15 : 31; 455
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> direct_spatial_mv_pred = get_bits1 ( & h -> gb ); 458
num_ref_idx_active_override_flag = get_bits1 ( & h -> gb ); 459
if ( num_ref_idx_active_override_flag )  461
h -> ref_count [ 0 ] = get_ue_golomb ( & h -> gb ) + 1; 462
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  463
h -> ref_count [ 1 ] = get_ue_golomb ( & h -> gb ) + 1; 464
h -> ref_count [ 1 ] = 1; 467
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  470
av_log ( h -> avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 471
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 0; 472
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  476
h -> list_count = 2; 477
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  491
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 493
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & h -> gb , ! ( h -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  527
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  533
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
av_log ( h -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 540
av_log ( h -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 549
av_log ( h -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 568
av_log ( h -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 581
if ( h -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  589
if ( h -> avctx -> flags2 & CODEC_FLAG2_FAST )  599
av_log ( h -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 606
av_log ( h -> avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 611
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = h -> resync_mb_y; 629
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= h -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= h -> resync_mb_y && h -> slice_num >= MAX_SLICES )  630
av_log ( h -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 634
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 639
if ( j < h -> list_count && i < h -> ref_count [ j ] && h -> ref_list [ j ] [ i ] . f . buf [ 0 ] )  642
AVBuffer * buf = h -> ref_list [ j ] [ i ] . f . buf [ 0 ] -> buffer ; 644
for (k = 0; k < h->short_ref_count; k++) 645
if ( h -> short_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  646
for (k = 0; k < h->long_ref_count; k++) 650
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . buf [ 0 ] -> buffer == buf )  651
id_list [ i ] = h -> short_ref_count + k; 652
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 658
for (i = 0; i < 16; i++) 660
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 661
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 663
for (i = 16; i < 48; i++) 665
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ); 666
if ( h -> ref_count [ 0 ] )  670
h -> er . last_pic = & h -> ref_list [ 0 ] [ 0 ]; 670
if ( h -> ref_count [ 1 ] )  671
h -> er . next_pic = & h -> ref_list [ 1 ] [ 0 ]; 671
h -> er . ref_count = h -> ref_count [ 0 ]; 672
if ( h -> avctx -> debug & FF_DEBUG_PICT_INFO )  674
av_log ( h -> avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( h -> picture_structure == PICT_FRAME ? "F" : h -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , h -> cur_pic_ptr -> field_poc [ 0 ] , h -> cur_pic_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , h -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 675
------------------------------
377 /home/speedy/test/source2slice/NVD/CVE_2013_7009_PATCHED_rpza_decode_stream.c block_ptr = row_ptr + pixel_ptr 139
static void CVE_2013_7009_PATCHED_rpza_decode_stream(RpzaContext *s) 1
int stream_ptr = 0 ; 6
int chunk_size ; 7
unsigned char opcode ; 8
int n_blocks ; 9
unsigned char index , idx ; 12
int row_ptr = 0 ; 16
int pixel_ptr = - 4 ; 17
int block_ptr ; 18
int pixel_x , pixel_y ; 19
chunk_size = AV_RB32 ( & s -> buf [ stream_ptr ] ) & 0x00FFFFFF; 28
stream_ptr += 4; 29
chunk_size = s -> size; 35
while ( stream_ptr < chunk_size )  41
opcode = s -> buf [ stream_ptr ++ ]; 42
n_blocks = ( opcode & 0x1f ) + 1; 44
if ( ( opcode & 0x80 ) == 0 )  47
colorA = ( opcode << 8 ) | ( s -> buf [ stream_ptr ++ ] ); 48
opcode = 0; 49
if ( ( s -> buf [ stream_ptr ] & 0x80 ) != 0 )  50
opcode = 0x20; 54
n_blocks = 1; 55
switch ( opcode & 0xe0 )  59
while ( n_blocks -- )  63
stream_ptr += 2; 71
while ( n_blocks -- )  72
for (pixel_y = 0; pixel_y < 4; pixel_y++) 75
for (pixel_x = 0; pixel_x < 4; pixel_x++) 76
stream_ptr += 2; 88
stream_ptr += 2; 91
if ( s -> size - stream_ptr < n_blocks * 4 )  117
while ( n_blocks -- )  119
for (pixel_y = 0; pixel_y < 4; pixel_y++) 122
index = s -> buf [ stream_ptr ++ ]; 123
for (pixel_x = 0; pixel_x < 4; pixel_x++) 124
if ( s -> size - stream_ptr < 16 )  136
block_ptr = row_ptr + pixel_ptr; 139
for (pixel_y = 0; pixel_y < 4; pixel_y++) 140
for (pixel_x = 0; pixel_x < 4; pixel_x++) 141
if ( ( pixel_y != 0 ) || ( pixel_x != 0 ) )  143
stream_ptr += 2; 145
pixels [ block_ptr ] = colorA; 147
block_ptr ++; 148
block_ptr += row_inc; 150
------------------------------
378 /home/speedy/test/source2slice/NVD/CVE_2013_7009_PATCHED_rpza_decode_stream.c block_ptr = row_ptr + pixel_ptr 121
static void CVE_2013_7009_PATCHED_rpza_decode_stream(RpzaContext *s) 1
int stream_ptr = 0 ; 6
int chunk_size ; 7
unsigned char opcode ; 8
int n_blocks ; 9
unsigned char index , idx ; 12
int row_ptr = 0 ; 16
int pixel_ptr = - 4 ; 17
int block_ptr ; 18
int pixel_x , pixel_y ; 19
chunk_size = AV_RB32 ( & s -> buf [ stream_ptr ] ) & 0x00FFFFFF; 28
stream_ptr += 4; 29
chunk_size = s -> size; 35
while ( stream_ptr < chunk_size )  41
opcode = s -> buf [ stream_ptr ++ ]; 42
n_blocks = ( opcode & 0x1f ) + 1; 44
if ( ( opcode & 0x80 ) == 0 )  47
colorA = ( opcode << 8 ) | ( s -> buf [ stream_ptr ++ ] ); 48
opcode = 0; 49
if ( ( s -> buf [ stream_ptr ] & 0x80 ) != 0 )  50
opcode = 0x20; 54
n_blocks = 1; 55
switch ( opcode & 0xe0 )  59
while ( n_blocks -- )  63
stream_ptr += 2; 71
while ( n_blocks -- )  72
for (pixel_y = 0; pixel_y < 4; pixel_y++) 75
for (pixel_x = 0; pixel_x < 4; pixel_x++) 76
stream_ptr += 2; 88
stream_ptr += 2; 91
if ( s -> size - stream_ptr < n_blocks * 4 )  117
while ( n_blocks -- )  119
block_ptr = row_ptr + pixel_ptr; 121
for (pixel_y = 0; pixel_y < 4; pixel_y++) 122
index = s -> buf [ stream_ptr ++ ]; 123
for (pixel_x = 0; pixel_x < 4; pixel_x++) 124
pixels [ block_ptr ] = color4 [ idx ]; 126
block_ptr ++; 127
block_ptr += row_inc; 129
if ( s -> size - stream_ptr < 16 )  136
for (pixel_y = 0; pixel_y < 4; pixel_y++) 140
for (pixel_x = 0; pixel_x < 4; pixel_x++) 141
if ( ( pixel_y != 0 ) || ( pixel_x != 0 ) )  143
stream_ptr += 2; 145
pixels [ block_ptr ] = colorA; 147
block_ptr ++; 148
block_ptr += row_inc; 150
------------------------------
379 /home/speedy/test/source2slice/NVD/CVE_2013_7009_PATCHED_rpza_decode_stream.c block_ptr = row_ptr + pixel_ptr 74
static void CVE_2013_7009_PATCHED_rpza_decode_stream(RpzaContext *s) 1
int stream_ptr = 0 ; 6
int chunk_size ; 7
unsigned char opcode ; 8
int n_blocks ; 9
unsigned char index , idx ; 12
int row_ptr = 0 ; 16
int pixel_ptr = - 4 ; 17
int block_ptr ; 18
int pixel_x , pixel_y ; 19
chunk_size = AV_RB32 ( & s -> buf [ stream_ptr ] ) & 0x00FFFFFF; 28
stream_ptr += 4; 29
chunk_size = s -> size; 35
while ( stream_ptr < chunk_size )  41
opcode = s -> buf [ stream_ptr ++ ]; 42
n_blocks = ( opcode & 0x1f ) + 1; 44
if ( ( opcode & 0x80 ) == 0 )  47
colorA = ( opcode << 8 ) | ( s -> buf [ stream_ptr ++ ] ); 48
opcode = 0; 49
if ( ( s -> buf [ stream_ptr ] & 0x80 ) != 0 )  50
opcode = 0x20; 54
n_blocks = 1; 55
switch ( opcode & 0xe0 )  59
while ( n_blocks -- )  63
stream_ptr += 2; 71
while ( n_blocks -- )  72
block_ptr = row_ptr + pixel_ptr; 74
for (pixel_y = 0; pixel_y < 4; pixel_y++) 75
for (pixel_x = 0; pixel_x < 4; pixel_x++) 76
pixels [ block_ptr ] = colorA; 77
block_ptr ++; 78
block_ptr += row_inc; 80
stream_ptr += 2; 88
stream_ptr += 2; 91
if ( s -> size - stream_ptr < n_blocks * 4 )  117
while ( n_blocks -- )  119
for (pixel_y = 0; pixel_y < 4; pixel_y++) 122
index = s -> buf [ stream_ptr ++ ]; 123
for (pixel_x = 0; pixel_x < 4; pixel_x++) 124
pixels [ block_ptr ] = color4 [ idx ]; 126
block_ptr ++; 127
block_ptr += row_inc; 129
if ( s -> size - stream_ptr < 16 )  136
for (pixel_y = 0; pixel_y < 4; pixel_y++) 140
for (pixel_x = 0; pixel_x < 4; pixel_x++) 141
if ( ( pixel_y != 0 ) || ( pixel_x != 0 ) )  143
stream_ptr += 2; 145
pixels [ block_ptr ] = colorA; 147
block_ptr ++; 148
block_ptr += row_inc; 150
------------------------------
380 /home/speedy/test/source2slice/NVD/CVE_2013_7009_VULN_rpza_decode_stream.c block_ptr = row_ptr + pixel_ptr 138
static void CVE_2013_7009_VULN_rpza_decode_stream(RpzaContext *s) 1
int stream_ptr = 0 ; 6
int chunk_size ; 7
unsigned char opcode ; 8
int n_blocks ; 9
unsigned char index , idx ; 12
int row_ptr = 0 ; 16
int pixel_ptr = 0 ; 17
int block_ptr ; 18
int pixel_x , pixel_y ; 19
chunk_size = AV_RB32 ( & s -> buf [ stream_ptr ] ) & 0x00FFFFFF; 28
stream_ptr += 4; 29
chunk_size = s -> size; 35
while ( stream_ptr < chunk_size )  41
opcode = s -> buf [ stream_ptr ++ ]; 42
n_blocks = ( opcode & 0x1f ) + 1; 44
if ( ( opcode & 0x80 ) == 0 )  47
colorA = ( opcode << 8 ) | ( s -> buf [ stream_ptr ++ ] ); 48
opcode = 0; 49
if ( ( s -> buf [ stream_ptr ] & 0x80 ) != 0 )  50
opcode = 0x20; 54
n_blocks = 1; 55
switch ( opcode & 0xe0 )  59
while ( n_blocks -- )  63
stream_ptr += 2; 71
while ( n_blocks -- )  72
for (pixel_y = 0; pixel_y < 4; pixel_y++) 74
for (pixel_x = 0; pixel_x < 4; pixel_x++) 75
stream_ptr += 2; 88
stream_ptr += 2; 91
if ( s -> size - stream_ptr < n_blocks * 4 )  117
while ( n_blocks -- )  119
for (pixel_y = 0; pixel_y < 4; pixel_y++) 121
index = s -> buf [ stream_ptr ++ ]; 122
for (pixel_x = 0; pixel_x < 4; pixel_x++) 123
if ( s -> size - stream_ptr < 16 )  136
block_ptr = row_ptr + pixel_ptr; 138
for (pixel_y = 0; pixel_y < 4; pixel_y++) 139
for (pixel_x = 0; pixel_x < 4; pixel_x++) 140
if ( ( pixel_y != 0 ) || ( pixel_x != 0 ) )  142
stream_ptr += 2; 144
pixels [ block_ptr ] = colorA; 146
block_ptr ++; 147
block_ptr += row_inc; 149
------------------------------
381 /home/speedy/test/source2slice/NVD/CVE_2013_7009_VULN_rpza_decode_stream.c block_ptr = row_ptr + pixel_ptr 120
static void CVE_2013_7009_VULN_rpza_decode_stream(RpzaContext *s) 1
int stream_ptr = 0 ; 6
int chunk_size ; 7
unsigned char opcode ; 8
int n_blocks ; 9
unsigned char index , idx ; 12
int row_ptr = 0 ; 16
int pixel_ptr = 0 ; 17
int block_ptr ; 18
int pixel_x , pixel_y ; 19
chunk_size = AV_RB32 ( & s -> buf [ stream_ptr ] ) & 0x00FFFFFF; 28
stream_ptr += 4; 29
chunk_size = s -> size; 35
while ( stream_ptr < chunk_size )  41
opcode = s -> buf [ stream_ptr ++ ]; 42
n_blocks = ( opcode & 0x1f ) + 1; 44
if ( ( opcode & 0x80 ) == 0 )  47
colorA = ( opcode << 8 ) | ( s -> buf [ stream_ptr ++ ] ); 48
opcode = 0; 49
if ( ( s -> buf [ stream_ptr ] & 0x80 ) != 0 )  50
opcode = 0x20; 54
n_blocks = 1; 55
switch ( opcode & 0xe0 )  59
while ( n_blocks -- )  63
stream_ptr += 2; 71
while ( n_blocks -- )  72
for (pixel_y = 0; pixel_y < 4; pixel_y++) 74
for (pixel_x = 0; pixel_x < 4; pixel_x++) 75
stream_ptr += 2; 88
stream_ptr += 2; 91
if ( s -> size - stream_ptr < n_blocks * 4 )  117
while ( n_blocks -- )  119
block_ptr = row_ptr + pixel_ptr; 120
for (pixel_y = 0; pixel_y < 4; pixel_y++) 121
index = s -> buf [ stream_ptr ++ ]; 122
for (pixel_x = 0; pixel_x < 4; pixel_x++) 123
pixels [ block_ptr ] = color4 [ idx ]; 125
block_ptr ++; 126
block_ptr += row_inc; 128
if ( s -> size - stream_ptr < 16 )  136
for (pixel_y = 0; pixel_y < 4; pixel_y++) 139
for (pixel_x = 0; pixel_x < 4; pixel_x++) 140
if ( ( pixel_y != 0 ) || ( pixel_x != 0 ) )  142
stream_ptr += 2; 144
pixels [ block_ptr ] = colorA; 146
block_ptr ++; 147
block_ptr += row_inc; 149
------------------------------
382 /home/speedy/test/source2slice/NVD/CVE_2013_7009_VULN_rpza_decode_stream.c block_ptr = row_ptr + pixel_ptr 73
static void CVE_2013_7009_VULN_rpza_decode_stream(RpzaContext *s) 1
int stream_ptr = 0 ; 6
int chunk_size ; 7
unsigned char opcode ; 8
int n_blocks ; 9
unsigned char index , idx ; 12
int row_ptr = 0 ; 16
int pixel_ptr = 0 ; 17
int block_ptr ; 18
int pixel_x , pixel_y ; 19
chunk_size = AV_RB32 ( & s -> buf [ stream_ptr ] ) & 0x00FFFFFF; 28
stream_ptr += 4; 29
chunk_size = s -> size; 35
while ( stream_ptr < chunk_size )  41
opcode = s -> buf [ stream_ptr ++ ]; 42
n_blocks = ( opcode & 0x1f ) + 1; 44
if ( ( opcode & 0x80 ) == 0 )  47
colorA = ( opcode << 8 ) | ( s -> buf [ stream_ptr ++ ] ); 48
opcode = 0; 49
if ( ( s -> buf [ stream_ptr ] & 0x80 ) != 0 )  50
opcode = 0x20; 54
n_blocks = 1; 55
switch ( opcode & 0xe0 )  59
while ( n_blocks -- )  63
stream_ptr += 2; 71
while ( n_blocks -- )  72
block_ptr = row_ptr + pixel_ptr; 73
for (pixel_y = 0; pixel_y < 4; pixel_y++) 74
for (pixel_x = 0; pixel_x < 4; pixel_x++) 75
pixels [ block_ptr ] = colorA; 76
block_ptr ++; 77
block_ptr += row_inc; 79
stream_ptr += 2; 88
stream_ptr += 2; 91
if ( s -> size - stream_ptr < n_blocks * 4 )  117
while ( n_blocks -- )  119
for (pixel_y = 0; pixel_y < 4; pixel_y++) 121
index = s -> buf [ stream_ptr ++ ]; 122
for (pixel_x = 0; pixel_x < 4; pixel_x++) 123
pixels [ block_ptr ] = color4 [ idx ]; 125
block_ptr ++; 126
block_ptr += row_inc; 128
if ( s -> size - stream_ptr < 16 )  136
for (pixel_y = 0; pixel_y < 4; pixel_y++) 139
for (pixel_x = 0; pixel_x < 4; pixel_x++) 140
if ( ( pixel_y != 0 ) || ( pixel_x != 0 ) )  142
stream_ptr += 2; 144
pixels [ block_ptr ] = colorA; 146
block_ptr ++; 147
block_ptr += row_inc; 149
------------------------------
383 /home/speedy/test/source2slice/NVD/CVE_2013_7011_PATCHED_read_header.c fs -> slice_height = fs -> slice_height / f -> num_v_slices - fs -> slice_y 173
static int CVE_2013_7011_PATCHED_read_header(FFV1Context *f) 1
uint8_t state [ CONTEXT_SIZE ] ; 3
RangeCoder * const c = & f -> slice_context [ 0 ] -> c 5
memset ( state , 128 , sizeof ( state ) ); 7
if ( f -> version < 2 )  9
int chroma_planes , chroma_h_shift , chroma_v_shift , transparency ; 10
unsigned v = get_symbol ( c , state , 0 ) ; 11
if ( v >= 2 )  12
f -> version = v; 16
f -> ac = f -> avctx -> coder_type = get_symbol ( c , state , 0 ); 17
if ( f -> ac > 1 )  18
for (i = 1; i < 256; i++) 19
f -> state_transition [ i ] = get_symbol ( c , state , 1 ) + c -> one_state [ i ]; 20
f -> colorspace = get_symbol ( c , state , 0 ); 23
if ( f -> version > 0 )  25
f -> avctx -> bits_per_raw_sample = get_symbol ( c , state , 0 ); 26
chroma_planes = get_rac ( c , state ); 28
chroma_h_shift = get_symbol ( c , state , 0 ); 29
chroma_v_shift = get_symbol ( c , state , 0 ); 30
transparency = get_rac ( c , state ); 31
if ( f -> plane_count )  33
if ( chroma_planes != f -> chroma_planes || chroma_h_shift != f -> chroma_h_shift || chroma_v_shift != f -> chroma_v_shift || transparency != f -> transparency )  34
f -> chroma_planes = chroma_planes; 43
f -> chroma_h_shift = chroma_h_shift; 44
f -> chroma_v_shift = chroma_v_shift; 45
f -> transparency = transparency; 46
f -> plane_count = 2 + f -> transparency; 48
if ( f -> colorspace == 0 )  51
if ( ! f -> transparency && ! f -> chroma_planes )  52
if ( f -> avctx -> bits_per_raw_sample <= 8 )  53
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 54
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 56
if ( f -> avctx -> bits_per_raw_sample <= 8 && ! f -> transparency )  57
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  58
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P; 59
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV440P; 60
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P; 61
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P; 62
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV411P; 63
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV410P; 64
if ( f -> avctx -> bits_per_raw_sample <= 8 && f -> transparency )  69
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  70
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA444P; 71
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA422P; 72
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P; 73
if ( f -> avctx -> bits_per_raw_sample == 9 )  78
f -> packed_at_lsb = 1; 79
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  80
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P9; 81
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P9; 82
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P9; 83
if ( f -> avctx -> bits_per_raw_sample == 10 )  88
f -> packed_at_lsb = 1; 89
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  90
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P10; 91
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P10; 92
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P10; 93
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  99
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P16; 100
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P16; 101
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P16; 102
if ( f -> colorspace == 1 )  108
if ( f -> chroma_h_shift || f -> chroma_v_shift )  109
if ( f -> avctx -> bits_per_raw_sample == 9 )  114
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP9; 115
if ( f -> avctx -> bits_per_raw_sample == 10 )  116
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP10; 117
if ( f -> avctx -> bits_per_raw_sample == 12 )  118
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP12; 119
if ( f -> avctx -> bits_per_raw_sample == 14 )  120
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP14; 121
if ( f -> transparency )  123
f -> avctx -> pix_fmt = AV_PIX_FMT_RGB32; 123
f -> avctx -> pix_fmt = AV_PIX_FMT_0RGB32; 124
if ( f -> version < 2 )  132
context_count = read_quant_tables ( c , f -> quant_table ); 133
if ( context_count < 0 )  134
if ( f -> version < 3 )  138
f -> slice_count = get_symbol ( c , state , 0 ); 139
const uint8_t * p = c -> bytestream_end ; 141
for (f->slice_count = 0;
f->slice_count < MAX_SLICES && 3 < p - c->bytestream_start;
f->slice_count++) 144
int trailer = 3 + 5 * ! ! f -> ec ; 145
int size = AV_RB24 ( p - trailer ) ; 146
if ( size + trailer > p - c -> bytestream_start )  147
p -= size + trailer; 149
if ( f -> slice_count > ( unsigned ) MAX_SLICES || f -> slice_count <= 0 )  152
for (j = 0; j < f->slice_count; j++) 157
FFV1Context * fs = f -> slice_context [ j ] ; 158
fs -> ac = f -> ac; 159
fs -> packed_at_lsb = f -> packed_at_lsb; 160
fs -> slice_damaged = 0; 162
if ( f -> version == 2 )  164
fs -> slice_x = get_symbol ( c , state , 0 ) * f -> width; 165
fs -> slice_y = get_symbol ( c , state , 0 ) * f -> height; 166
fs -> slice_width = ( get_symbol ( c , state , 0 ) + 1 ) * f -> width + fs -> slice_x; 167
fs -> slice_height = ( get_symbol ( c , state , 0 ) + 1 ) * f -> height + fs -> slice_y; 168
fs -> slice_x /= f -> num_h_slices; 170
fs -> slice_y /= f -> num_v_slices; 171
fs -> slice_width = fs -> slice_width / f -> num_h_slices - fs -> slice_x; 172
fs -> slice_height = fs -> slice_height / f -> num_v_slices - fs -> slice_y; 173
if ( ( unsigned ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_height > f -> height )  174
if ( ( unsigned ) fs -> slice_x + ( uint64_t ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_y + ( uint64_t ) fs -> slice_height > f -> height )  177
for (i = 0; i < f->plane_count; i++) 182
PlaneContext * const p = & fs -> plane [ i ] 183
if ( f -> version == 2 )  185
int idx = get_symbol ( c , state , 0 ) ; 186
if ( idx > ( unsigned ) f -> quant_table_count )  187
p -> quant_table_index = idx; 192
memcpy ( p -> quant_table , f -> quant_tables [ idx ] , sizeof ( p -> quant_table ) ); 193
memcpy ( p -> quant_table , f -> quant_table , sizeof ( p -> quant_table ) ); 197
if ( p -> context_count < context_count )  202
av_freep ( & p -> state ); 203
av_freep ( & p -> vlc_state ); 204
p -> context_count = context_count; 206
------------------------------
384 /home/speedy/test/source2slice/NVD/CVE_2013_7011_PATCHED_read_header.c fs -> slice_width = fs -> slice_width / f -> num_h_slices - fs -> slice_x 172
static int CVE_2013_7011_PATCHED_read_header(FFV1Context *f) 1
uint8_t state [ CONTEXT_SIZE ] ; 3
RangeCoder * const c = & f -> slice_context [ 0 ] -> c 5
memset ( state , 128 , sizeof ( state ) ); 7
if ( f -> version < 2 )  9
int chroma_planes , chroma_h_shift , chroma_v_shift , transparency ; 10
unsigned v = get_symbol ( c , state , 0 ) ; 11
if ( v >= 2 )  12
f -> version = v; 16
f -> ac = f -> avctx -> coder_type = get_symbol ( c , state , 0 ); 17
if ( f -> ac > 1 )  18
for (i = 1; i < 256; i++) 19
f -> state_transition [ i ] = get_symbol ( c , state , 1 ) + c -> one_state [ i ]; 20
f -> colorspace = get_symbol ( c , state , 0 ); 23
if ( f -> version > 0 )  25
f -> avctx -> bits_per_raw_sample = get_symbol ( c , state , 0 ); 26
chroma_planes = get_rac ( c , state ); 28
chroma_h_shift = get_symbol ( c , state , 0 ); 29
chroma_v_shift = get_symbol ( c , state , 0 ); 30
transparency = get_rac ( c , state ); 31
if ( f -> plane_count )  33
if ( chroma_planes != f -> chroma_planes || chroma_h_shift != f -> chroma_h_shift || chroma_v_shift != f -> chroma_v_shift || transparency != f -> transparency )  34
f -> chroma_planes = chroma_planes; 43
f -> chroma_h_shift = chroma_h_shift; 44
f -> chroma_v_shift = chroma_v_shift; 45
f -> transparency = transparency; 46
f -> plane_count = 2 + f -> transparency; 48
if ( f -> colorspace == 0 )  51
if ( ! f -> transparency && ! f -> chroma_planes )  52
if ( f -> avctx -> bits_per_raw_sample <= 8 )  53
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 54
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 56
if ( f -> avctx -> bits_per_raw_sample <= 8 && ! f -> transparency )  57
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  58
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P; 59
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV440P; 60
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P; 61
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P; 62
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV411P; 63
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV410P; 64
if ( f -> avctx -> bits_per_raw_sample <= 8 && f -> transparency )  69
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  70
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA444P; 71
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA422P; 72
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P; 73
if ( f -> avctx -> bits_per_raw_sample == 9 )  78
f -> packed_at_lsb = 1; 79
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  80
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P9; 81
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P9; 82
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P9; 83
if ( f -> avctx -> bits_per_raw_sample == 10 )  88
f -> packed_at_lsb = 1; 89
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  90
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P10; 91
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P10; 92
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P10; 93
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  99
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P16; 100
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P16; 101
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P16; 102
if ( f -> colorspace == 1 )  108
if ( f -> chroma_h_shift || f -> chroma_v_shift )  109
if ( f -> avctx -> bits_per_raw_sample == 9 )  114
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP9; 115
if ( f -> avctx -> bits_per_raw_sample == 10 )  116
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP10; 117
if ( f -> avctx -> bits_per_raw_sample == 12 )  118
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP12; 119
if ( f -> avctx -> bits_per_raw_sample == 14 )  120
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP14; 121
if ( f -> transparency )  123
f -> avctx -> pix_fmt = AV_PIX_FMT_RGB32; 123
f -> avctx -> pix_fmt = AV_PIX_FMT_0RGB32; 124
if ( f -> version < 2 )  132
context_count = read_quant_tables ( c , f -> quant_table ); 133
if ( context_count < 0 )  134
if ( f -> version < 3 )  138
f -> slice_count = get_symbol ( c , state , 0 ); 139
const uint8_t * p = c -> bytestream_end ; 141
for (f->slice_count = 0;
f->slice_count < MAX_SLICES && 3 < p - c->bytestream_start;
f->slice_count++) 144
int trailer = 3 + 5 * ! ! f -> ec ; 145
int size = AV_RB24 ( p - trailer ) ; 146
if ( size + trailer > p - c -> bytestream_start )  147
p -= size + trailer; 149
if ( f -> slice_count > ( unsigned ) MAX_SLICES || f -> slice_count <= 0 )  152
for (j = 0; j < f->slice_count; j++) 157
FFV1Context * fs = f -> slice_context [ j ] ; 158
fs -> ac = f -> ac; 159
fs -> packed_at_lsb = f -> packed_at_lsb; 160
fs -> slice_damaged = 0; 162
if ( f -> version == 2 )  164
fs -> slice_x = get_symbol ( c , state , 0 ) * f -> width; 165
fs -> slice_y = get_symbol ( c , state , 0 ) * f -> height; 166
fs -> slice_width = ( get_symbol ( c , state , 0 ) + 1 ) * f -> width + fs -> slice_x; 167
fs -> slice_height = ( get_symbol ( c , state , 0 ) + 1 ) * f -> height + fs -> slice_y; 168
fs -> slice_x /= f -> num_h_slices; 170
fs -> slice_y /= f -> num_v_slices; 171
fs -> slice_width = fs -> slice_width / f -> num_h_slices - fs -> slice_x; 172
fs -> slice_height = fs -> slice_height / f -> num_v_slices - fs -> slice_y; 173
if ( ( unsigned ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_height > f -> height )  174
if ( ( unsigned ) fs -> slice_x + ( uint64_t ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_y + ( uint64_t ) fs -> slice_height > f -> height )  177
for (i = 0; i < f->plane_count; i++) 182
PlaneContext * const p = & fs -> plane [ i ] 183
if ( f -> version == 2 )  185
int idx = get_symbol ( c , state , 0 ) ; 186
if ( idx > ( unsigned ) f -> quant_table_count )  187
p -> quant_table_index = idx; 192
memcpy ( p -> quant_table , f -> quant_tables [ idx ] , sizeof ( p -> quant_table ) ); 193
memcpy ( p -> quant_table , f -> quant_table , sizeof ( p -> quant_table ) ); 197
if ( p -> context_count < context_count )  202
av_freep ( & p -> state ); 203
av_freep ( & p -> vlc_state ); 204
p -> context_count = context_count; 206
------------------------------
385 /home/speedy/test/source2slice/NVD/CVE_2013_7011_PATCHED_read_header.c fs -> slice_height = ( get_symbol ( c , state , 0 ) + 1 ) * f -> height + fs -> slice_y 168
static int CVE_2013_7011_PATCHED_read_header(FFV1Context *f) 1
uint8_t state [ CONTEXT_SIZE ] ; 3
RangeCoder * const c = & f -> slice_context [ 0 ] -> c 5
memset ( state , 128 , sizeof ( state ) ); 7
if ( f -> version < 2 )  9
int chroma_planes , chroma_h_shift , chroma_v_shift , transparency ; 10
unsigned v = get_symbol ( c , state , 0 ) ; 11
if ( v >= 2 )  12
f -> version = v; 16
f -> ac = f -> avctx -> coder_type = get_symbol ( c , state , 0 ); 17
if ( f -> ac > 1 )  18
for (i = 1; i < 256; i++) 19
f -> state_transition [ i ] = get_symbol ( c , state , 1 ) + c -> one_state [ i ]; 20
f -> colorspace = get_symbol ( c , state , 0 ); 23
if ( f -> version > 0 )  25
f -> avctx -> bits_per_raw_sample = get_symbol ( c , state , 0 ); 26
chroma_planes = get_rac ( c , state ); 28
chroma_h_shift = get_symbol ( c , state , 0 ); 29
chroma_v_shift = get_symbol ( c , state , 0 ); 30
transparency = get_rac ( c , state ); 31
if ( f -> plane_count )  33
if ( chroma_planes != f -> chroma_planes || chroma_h_shift != f -> chroma_h_shift || chroma_v_shift != f -> chroma_v_shift || transparency != f -> transparency )  34
f -> chroma_planes = chroma_planes; 43
f -> chroma_h_shift = chroma_h_shift; 44
f -> chroma_v_shift = chroma_v_shift; 45
f -> transparency = transparency; 46
f -> plane_count = 2 + f -> transparency; 48
if ( f -> colorspace == 0 )  51
if ( ! f -> transparency && ! f -> chroma_planes )  52
if ( f -> avctx -> bits_per_raw_sample <= 8 )  53
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 54
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 56
if ( f -> avctx -> bits_per_raw_sample <= 8 && ! f -> transparency )  57
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  58
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P; 59
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV440P; 60
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P; 61
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P; 62
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV411P; 63
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV410P; 64
if ( f -> avctx -> bits_per_raw_sample <= 8 && f -> transparency )  69
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  70
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA444P; 71
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA422P; 72
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P; 73
if ( f -> avctx -> bits_per_raw_sample == 9 )  78
f -> packed_at_lsb = 1; 79
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  80
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P9; 81
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P9; 82
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P9; 83
if ( f -> avctx -> bits_per_raw_sample == 10 )  88
f -> packed_at_lsb = 1; 89
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  90
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P10; 91
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P10; 92
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P10; 93
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  99
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P16; 100
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P16; 101
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P16; 102
if ( f -> colorspace == 1 )  108
if ( f -> chroma_h_shift || f -> chroma_v_shift )  109
if ( f -> avctx -> bits_per_raw_sample == 9 )  114
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP9; 115
if ( f -> avctx -> bits_per_raw_sample == 10 )  116
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP10; 117
if ( f -> avctx -> bits_per_raw_sample == 12 )  118
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP12; 119
if ( f -> avctx -> bits_per_raw_sample == 14 )  120
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP14; 121
if ( f -> transparency )  123
f -> avctx -> pix_fmt = AV_PIX_FMT_RGB32; 123
f -> avctx -> pix_fmt = AV_PIX_FMT_0RGB32; 124
if ( f -> version < 2 )  132
context_count = read_quant_tables ( c , f -> quant_table ); 133
if ( context_count < 0 )  134
if ( f -> version < 3 )  138
f -> slice_count = get_symbol ( c , state , 0 ); 139
const uint8_t * p = c -> bytestream_end ; 141
for (f->slice_count = 0;
f->slice_count < MAX_SLICES && 3 < p - c->bytestream_start;
f->slice_count++) 144
int trailer = 3 + 5 * ! ! f -> ec ; 145
int size = AV_RB24 ( p - trailer ) ; 146
if ( size + trailer > p - c -> bytestream_start )  147
p -= size + trailer; 149
if ( f -> slice_count > ( unsigned ) MAX_SLICES || f -> slice_count <= 0 )  152
for (j = 0; j < f->slice_count; j++) 157
FFV1Context * fs = f -> slice_context [ j ] ; 158
fs -> ac = f -> ac; 159
fs -> packed_at_lsb = f -> packed_at_lsb; 160
fs -> slice_damaged = 0; 162
if ( f -> version == 2 )  164
fs -> slice_x = get_symbol ( c , state , 0 ) * f -> width; 165
fs -> slice_y = get_symbol ( c , state , 0 ) * f -> height; 166
fs -> slice_width = ( get_symbol ( c , state , 0 ) + 1 ) * f -> width + fs -> slice_x; 167
fs -> slice_height = ( get_symbol ( c , state , 0 ) + 1 ) * f -> height + fs -> slice_y; 168
fs -> slice_x /= f -> num_h_slices; 170
fs -> slice_y /= f -> num_v_slices; 171
fs -> slice_width = fs -> slice_width / f -> num_h_slices - fs -> slice_x; 172
fs -> slice_height = fs -> slice_height / f -> num_v_slices - fs -> slice_y; 173
if ( ( unsigned ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_height > f -> height )  174
if ( ( unsigned ) fs -> slice_x + ( uint64_t ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_y + ( uint64_t ) fs -> slice_height > f -> height )  177
for (i = 0; i < f->plane_count; i++) 182
PlaneContext * const p = & fs -> plane [ i ] 183
if ( f -> version == 2 )  185
int idx = get_symbol ( c , state , 0 ) ; 186
if ( idx > ( unsigned ) f -> quant_table_count )  187
p -> quant_table_index = idx; 192
memcpy ( p -> quant_table , f -> quant_tables [ idx ] , sizeof ( p -> quant_table ) ); 193
memcpy ( p -> quant_table , f -> quant_table , sizeof ( p -> quant_table ) ); 197
if ( p -> context_count < context_count )  202
av_freep ( & p -> state ); 203
av_freep ( & p -> vlc_state ); 204
p -> context_count = context_count; 206
------------------------------
386 /home/speedy/test/source2slice/NVD/CVE_2013_7011_PATCHED_read_header.c fs -> slice_width = ( get_symbol ( c , state , 0 ) + 1 ) * f -> width + fs -> slice_x 167
static int CVE_2013_7011_PATCHED_read_header(FFV1Context *f) 1
uint8_t state [ CONTEXT_SIZE ] ; 3
RangeCoder * const c = & f -> slice_context [ 0 ] -> c 5
memset ( state , 128 , sizeof ( state ) ); 7
if ( f -> version < 2 )  9
int chroma_planes , chroma_h_shift , chroma_v_shift , transparency ; 10
unsigned v = get_symbol ( c , state , 0 ) ; 11
if ( v >= 2 )  12
f -> version = v; 16
f -> ac = f -> avctx -> coder_type = get_symbol ( c , state , 0 ); 17
if ( f -> ac > 1 )  18
for (i = 1; i < 256; i++) 19
f -> state_transition [ i ] = get_symbol ( c , state , 1 ) + c -> one_state [ i ]; 20
f -> colorspace = get_symbol ( c , state , 0 ); 23
if ( f -> version > 0 )  25
f -> avctx -> bits_per_raw_sample = get_symbol ( c , state , 0 ); 26
chroma_planes = get_rac ( c , state ); 28
chroma_h_shift = get_symbol ( c , state , 0 ); 29
chroma_v_shift = get_symbol ( c , state , 0 ); 30
transparency = get_rac ( c , state ); 31
if ( f -> plane_count )  33
if ( chroma_planes != f -> chroma_planes || chroma_h_shift != f -> chroma_h_shift || chroma_v_shift != f -> chroma_v_shift || transparency != f -> transparency )  34
f -> chroma_planes = chroma_planes; 43
f -> chroma_h_shift = chroma_h_shift; 44
f -> chroma_v_shift = chroma_v_shift; 45
f -> transparency = transparency; 46
f -> plane_count = 2 + f -> transparency; 48
if ( f -> colorspace == 0 )  51
if ( ! f -> transparency && ! f -> chroma_planes )  52
if ( f -> avctx -> bits_per_raw_sample <= 8 )  53
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 54
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 56
if ( f -> avctx -> bits_per_raw_sample <= 8 && ! f -> transparency )  57
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  58
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P; 59
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV440P; 60
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P; 61
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P; 62
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV411P; 63
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV410P; 64
if ( f -> avctx -> bits_per_raw_sample <= 8 && f -> transparency )  69
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  70
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA444P; 71
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA422P; 72
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P; 73
if ( f -> avctx -> bits_per_raw_sample == 9 )  78
f -> packed_at_lsb = 1; 79
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  80
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P9; 81
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P9; 82
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P9; 83
if ( f -> avctx -> bits_per_raw_sample == 10 )  88
f -> packed_at_lsb = 1; 89
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  90
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P10; 91
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P10; 92
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P10; 93
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  99
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P16; 100
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P16; 101
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P16; 102
if ( f -> colorspace == 1 )  108
if ( f -> chroma_h_shift || f -> chroma_v_shift )  109
if ( f -> avctx -> bits_per_raw_sample == 9 )  114
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP9; 115
if ( f -> avctx -> bits_per_raw_sample == 10 )  116
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP10; 117
if ( f -> avctx -> bits_per_raw_sample == 12 )  118
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP12; 119
if ( f -> avctx -> bits_per_raw_sample == 14 )  120
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP14; 121
if ( f -> transparency )  123
f -> avctx -> pix_fmt = AV_PIX_FMT_RGB32; 123
f -> avctx -> pix_fmt = AV_PIX_FMT_0RGB32; 124
if ( f -> version < 2 )  132
context_count = read_quant_tables ( c , f -> quant_table ); 133
if ( context_count < 0 )  134
if ( f -> version < 3 )  138
f -> slice_count = get_symbol ( c , state , 0 ); 139
const uint8_t * p = c -> bytestream_end ; 141
for (f->slice_count = 0;
f->slice_count < MAX_SLICES && 3 < p - c->bytestream_start;
f->slice_count++) 144
int trailer = 3 + 5 * ! ! f -> ec ; 145
int size = AV_RB24 ( p - trailer ) ; 146
if ( size + trailer > p - c -> bytestream_start )  147
p -= size + trailer; 149
if ( f -> slice_count > ( unsigned ) MAX_SLICES || f -> slice_count <= 0 )  152
for (j = 0; j < f->slice_count; j++) 157
FFV1Context * fs = f -> slice_context [ j ] ; 158
fs -> ac = f -> ac; 159
fs -> packed_at_lsb = f -> packed_at_lsb; 160
fs -> slice_damaged = 0; 162
if ( f -> version == 2 )  164
fs -> slice_x = get_symbol ( c , state , 0 ) * f -> width; 165
fs -> slice_y = get_symbol ( c , state , 0 ) * f -> height; 166
fs -> slice_width = ( get_symbol ( c , state , 0 ) + 1 ) * f -> width + fs -> slice_x; 167
fs -> slice_height = ( get_symbol ( c , state , 0 ) + 1 ) * f -> height + fs -> slice_y; 168
fs -> slice_x /= f -> num_h_slices; 170
fs -> slice_y /= f -> num_v_slices; 171
fs -> slice_width = fs -> slice_width / f -> num_h_slices - fs -> slice_x; 172
fs -> slice_height = fs -> slice_height / f -> num_v_slices - fs -> slice_y; 173
if ( ( unsigned ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_height > f -> height )  174
if ( ( unsigned ) fs -> slice_x + ( uint64_t ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_y + ( uint64_t ) fs -> slice_height > f -> height )  177
for (i = 0; i < f->plane_count; i++) 182
PlaneContext * const p = & fs -> plane [ i ] 183
if ( f -> version == 2 )  185
int idx = get_symbol ( c , state , 0 ) ; 186
if ( idx > ( unsigned ) f -> quant_table_count )  187
p -> quant_table_index = idx; 192
memcpy ( p -> quant_table , f -> quant_tables [ idx ] , sizeof ( p -> quant_table ) ); 193
memcpy ( p -> quant_table , f -> quant_table , sizeof ( p -> quant_table ) ); 197
if ( p -> context_count < context_count )  202
av_freep ( & p -> state ); 203
av_freep ( & p -> vlc_state ); 204
p -> context_count = context_count; 206
------------------------------
387 /home/speedy/test/source2slice/NVD/CVE_2013_7011_VULN_read_header.c fs -> slice_height = fs -> slice_height / f -> num_v_slices - fs -> slice_y 156
static int CVE_2013_7011_VULN_read_header(FFV1Context *f) 1
uint8_t state [ CONTEXT_SIZE ] ; 3
RangeCoder * const c = & f -> slice_context [ 0 ] -> c 5
memset ( state , 128 , sizeof ( state ) ); 7
if ( f -> version < 2 )  9
unsigned v = get_symbol ( c , state , 0 ) ; 10
if ( v >= 2 )  11
f -> version = v; 15
f -> ac = f -> avctx -> coder_type = get_symbol ( c , state , 0 ); 16
if ( f -> ac > 1 )  17
for (i = 1; i < 256; i++) 18
f -> state_transition [ i ] = get_symbol ( c , state , 1 ) + c -> one_state [ i ]; 19
f -> colorspace = get_symbol ( c , state , 0 ); 22
if ( f -> version > 0 )  24
f -> avctx -> bits_per_raw_sample = get_symbol ( c , state , 0 ); 25
f -> chroma_planes = get_rac ( c , state ); 27
f -> chroma_h_shift = get_symbol ( c , state , 0 ); 28
f -> chroma_v_shift = get_symbol ( c , state , 0 ); 29
f -> transparency = get_rac ( c , state ); 30
f -> plane_count = 2 + f -> transparency; 31
if ( f -> colorspace == 0 )  34
if ( ! f -> transparency && ! f -> chroma_planes )  35
if ( f -> avctx -> bits_per_raw_sample <= 8 )  36
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 37
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 39
if ( f -> avctx -> bits_per_raw_sample <= 8 && ! f -> transparency )  40
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  41
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P; 42
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV440P; 43
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P; 44
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P; 45
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV411P; 46
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV410P; 47
if ( f -> avctx -> bits_per_raw_sample <= 8 && f -> transparency )  52
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  53
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA444P; 54
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA422P; 55
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P; 56
if ( f -> avctx -> bits_per_raw_sample == 9 )  61
f -> packed_at_lsb = 1; 62
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  63
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P9; 64
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P9; 65
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P9; 66
if ( f -> avctx -> bits_per_raw_sample == 10 )  71
f -> packed_at_lsb = 1; 72
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  73
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P10; 74
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P10; 75
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P10; 76
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  82
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P16; 83
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P16; 84
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P16; 85
if ( f -> colorspace == 1 )  91
if ( f -> chroma_h_shift || f -> chroma_v_shift )  92
if ( f -> avctx -> bits_per_raw_sample == 9 )  97
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP9; 98
if ( f -> avctx -> bits_per_raw_sample == 10 )  99
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP10; 100
if ( f -> avctx -> bits_per_raw_sample == 12 )  101
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP12; 102
if ( f -> avctx -> bits_per_raw_sample == 14 )  103
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP14; 104
if ( f -> transparency )  106
f -> avctx -> pix_fmt = AV_PIX_FMT_RGB32; 106
f -> avctx -> pix_fmt = AV_PIX_FMT_0RGB32; 107
if ( f -> version < 2 )  115
context_count = read_quant_tables ( c , f -> quant_table ); 116
if ( context_count < 0 )  117
if ( f -> version < 3 )  121
f -> slice_count = get_symbol ( c , state , 0 ); 122
const uint8_t * p = c -> bytestream_end ; 124
for (f->slice_count = 0;
f->slice_count < MAX_SLICES && 3 < p - c->bytestream_start;
f->slice_count++) 127
int trailer = 3 + 5 * ! ! f -> ec ; 128
int size = AV_RB24 ( p - trailer ) ; 129
if ( size + trailer > p - c -> bytestream_start )  130
p -= size + trailer; 132
if ( f -> slice_count > ( unsigned ) MAX_SLICES || f -> slice_count <= 0 )  135
for (j = 0; j < f->slice_count; j++) 140
FFV1Context * fs = f -> slice_context [ j ] ; 141
fs -> ac = f -> ac; 142
fs -> packed_at_lsb = f -> packed_at_lsb; 143
fs -> slice_damaged = 0; 145
if ( f -> version == 2 )  147
fs -> slice_x = get_symbol ( c , state , 0 ) * f -> width; 148
fs -> slice_y = get_symbol ( c , state , 0 ) * f -> height; 149
fs -> slice_width = ( get_symbol ( c , state , 0 ) + 1 ) * f -> width + fs -> slice_x; 150
fs -> slice_height = ( get_symbol ( c , state , 0 ) + 1 ) * f -> height + fs -> slice_y; 151
fs -> slice_x /= f -> num_h_slices; 153
fs -> slice_y /= f -> num_v_slices; 154
fs -> slice_width = fs -> slice_width / f -> num_h_slices - fs -> slice_x; 155
fs -> slice_height = fs -> slice_height / f -> num_v_slices - fs -> slice_y; 156
if ( ( unsigned ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_height > f -> height )  157
if ( ( unsigned ) fs -> slice_x + ( uint64_t ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_y + ( uint64_t ) fs -> slice_height > f -> height )  160
for (i = 0; i < f->plane_count; i++) 165
if ( f -> version == 2 )  168
int idx = get_symbol ( c , state , 0 ) ; 169
if ( idx > ( unsigned ) f -> quant_table_count )  170
------------------------------
388 /home/speedy/test/source2slice/NVD/CVE_2013_7011_VULN_read_header.c fs -> slice_width = fs -> slice_width / f -> num_h_slices - fs -> slice_x 155
static int CVE_2013_7011_VULN_read_header(FFV1Context *f) 1
uint8_t state [ CONTEXT_SIZE ] ; 3
RangeCoder * const c = & f -> slice_context [ 0 ] -> c 5
memset ( state , 128 , sizeof ( state ) ); 7
if ( f -> version < 2 )  9
unsigned v = get_symbol ( c , state , 0 ) ; 10
if ( v >= 2 )  11
f -> version = v; 15
f -> ac = f -> avctx -> coder_type = get_symbol ( c , state , 0 ); 16
if ( f -> ac > 1 )  17
for (i = 1; i < 256; i++) 18
f -> state_transition [ i ] = get_symbol ( c , state , 1 ) + c -> one_state [ i ]; 19
f -> colorspace = get_symbol ( c , state , 0 ); 22
if ( f -> version > 0 )  24
f -> avctx -> bits_per_raw_sample = get_symbol ( c , state , 0 ); 25
f -> chroma_planes = get_rac ( c , state ); 27
f -> chroma_h_shift = get_symbol ( c , state , 0 ); 28
f -> chroma_v_shift = get_symbol ( c , state , 0 ); 29
f -> transparency = get_rac ( c , state ); 30
f -> plane_count = 2 + f -> transparency; 31
if ( f -> colorspace == 0 )  34
if ( ! f -> transparency && ! f -> chroma_planes )  35
if ( f -> avctx -> bits_per_raw_sample <= 8 )  36
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 37
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 39
if ( f -> avctx -> bits_per_raw_sample <= 8 && ! f -> transparency )  40
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  41
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P; 42
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV440P; 43
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P; 44
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P; 45
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV411P; 46
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV410P; 47
if ( f -> avctx -> bits_per_raw_sample <= 8 && f -> transparency )  52
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  53
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA444P; 54
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA422P; 55
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P; 56
if ( f -> avctx -> bits_per_raw_sample == 9 )  61
f -> packed_at_lsb = 1; 62
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  63
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P9; 64
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P9; 65
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P9; 66
if ( f -> avctx -> bits_per_raw_sample == 10 )  71
f -> packed_at_lsb = 1; 72
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  73
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P10; 74
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P10; 75
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P10; 76
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  82
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P16; 83
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P16; 84
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P16; 85
if ( f -> colorspace == 1 )  91
if ( f -> chroma_h_shift || f -> chroma_v_shift )  92
if ( f -> avctx -> bits_per_raw_sample == 9 )  97
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP9; 98
if ( f -> avctx -> bits_per_raw_sample == 10 )  99
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP10; 100
if ( f -> avctx -> bits_per_raw_sample == 12 )  101
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP12; 102
if ( f -> avctx -> bits_per_raw_sample == 14 )  103
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP14; 104
if ( f -> transparency )  106
f -> avctx -> pix_fmt = AV_PIX_FMT_RGB32; 106
f -> avctx -> pix_fmt = AV_PIX_FMT_0RGB32; 107
if ( f -> version < 2 )  115
context_count = read_quant_tables ( c , f -> quant_table ); 116
if ( context_count < 0 )  117
if ( f -> version < 3 )  121
f -> slice_count = get_symbol ( c , state , 0 ); 122
const uint8_t * p = c -> bytestream_end ; 124
for (f->slice_count = 0;
f->slice_count < MAX_SLICES && 3 < p - c->bytestream_start;
f->slice_count++) 127
int trailer = 3 + 5 * ! ! f -> ec ; 128
int size = AV_RB24 ( p - trailer ) ; 129
if ( size + trailer > p - c -> bytestream_start )  130
p -= size + trailer; 132
if ( f -> slice_count > ( unsigned ) MAX_SLICES || f -> slice_count <= 0 )  135
for (j = 0; j < f->slice_count; j++) 140
FFV1Context * fs = f -> slice_context [ j ] ; 141
fs -> ac = f -> ac; 142
fs -> packed_at_lsb = f -> packed_at_lsb; 143
fs -> slice_damaged = 0; 145
if ( f -> version == 2 )  147
fs -> slice_x = get_symbol ( c , state , 0 ) * f -> width; 148
fs -> slice_y = get_symbol ( c , state , 0 ) * f -> height; 149
fs -> slice_width = ( get_symbol ( c , state , 0 ) + 1 ) * f -> width + fs -> slice_x; 150
fs -> slice_height = ( get_symbol ( c , state , 0 ) + 1 ) * f -> height + fs -> slice_y; 151
fs -> slice_x /= f -> num_h_slices; 153
fs -> slice_y /= f -> num_v_slices; 154
fs -> slice_width = fs -> slice_width / f -> num_h_slices - fs -> slice_x; 155
fs -> slice_height = fs -> slice_height / f -> num_v_slices - fs -> slice_y; 156
if ( ( unsigned ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_height > f -> height )  157
if ( ( unsigned ) fs -> slice_x + ( uint64_t ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_y + ( uint64_t ) fs -> slice_height > f -> height )  160
for (i = 0; i < f->plane_count; i++) 165
if ( f -> version == 2 )  168
int idx = get_symbol ( c , state , 0 ) ; 169
if ( idx > ( unsigned ) f -> quant_table_count )  170
------------------------------
389 /home/speedy/test/source2slice/NVD/CVE_2013_7011_VULN_read_header.c fs -> slice_height = ( get_symbol ( c , state , 0 ) + 1 ) * f -> height + fs -> slice_y 151
static int CVE_2013_7011_VULN_read_header(FFV1Context *f) 1
uint8_t state [ CONTEXT_SIZE ] ; 3
RangeCoder * const c = & f -> slice_context [ 0 ] -> c 5
memset ( state , 128 , sizeof ( state ) ); 7
if ( f -> version < 2 )  9
unsigned v = get_symbol ( c , state , 0 ) ; 10
if ( v >= 2 )  11
f -> version = v; 15
f -> ac = f -> avctx -> coder_type = get_symbol ( c , state , 0 ); 16
if ( f -> ac > 1 )  17
for (i = 1; i < 256; i++) 18
f -> state_transition [ i ] = get_symbol ( c , state , 1 ) + c -> one_state [ i ]; 19
f -> colorspace = get_symbol ( c , state , 0 ); 22
if ( f -> version > 0 )  24
f -> avctx -> bits_per_raw_sample = get_symbol ( c , state , 0 ); 25
f -> chroma_planes = get_rac ( c , state ); 27
f -> chroma_h_shift = get_symbol ( c , state , 0 ); 28
f -> chroma_v_shift = get_symbol ( c , state , 0 ); 29
f -> transparency = get_rac ( c , state ); 30
f -> plane_count = 2 + f -> transparency; 31
if ( f -> colorspace == 0 )  34
if ( ! f -> transparency && ! f -> chroma_planes )  35
if ( f -> avctx -> bits_per_raw_sample <= 8 )  36
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 37
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 39
if ( f -> avctx -> bits_per_raw_sample <= 8 && ! f -> transparency )  40
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  41
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P; 42
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV440P; 43
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P; 44
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P; 45
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV411P; 46
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV410P; 47
if ( f -> avctx -> bits_per_raw_sample <= 8 && f -> transparency )  52
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  53
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA444P; 54
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA422P; 55
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P; 56
if ( f -> avctx -> bits_per_raw_sample == 9 )  61
f -> packed_at_lsb = 1; 62
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  63
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P9; 64
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P9; 65
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P9; 66
if ( f -> avctx -> bits_per_raw_sample == 10 )  71
f -> packed_at_lsb = 1; 72
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  73
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P10; 74
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P10; 75
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P10; 76
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  82
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P16; 83
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P16; 84
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P16; 85
if ( f -> colorspace == 1 )  91
if ( f -> chroma_h_shift || f -> chroma_v_shift )  92
if ( f -> avctx -> bits_per_raw_sample == 9 )  97
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP9; 98
if ( f -> avctx -> bits_per_raw_sample == 10 )  99
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP10; 100
if ( f -> avctx -> bits_per_raw_sample == 12 )  101
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP12; 102
if ( f -> avctx -> bits_per_raw_sample == 14 )  103
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP14; 104
if ( f -> transparency )  106
f -> avctx -> pix_fmt = AV_PIX_FMT_RGB32; 106
f -> avctx -> pix_fmt = AV_PIX_FMT_0RGB32; 107
if ( f -> version < 2 )  115
context_count = read_quant_tables ( c , f -> quant_table ); 116
if ( context_count < 0 )  117
if ( f -> version < 3 )  121
f -> slice_count = get_symbol ( c , state , 0 ); 122
const uint8_t * p = c -> bytestream_end ; 124
for (f->slice_count = 0;
f->slice_count < MAX_SLICES && 3 < p - c->bytestream_start;
f->slice_count++) 127
int trailer = 3 + 5 * ! ! f -> ec ; 128
int size = AV_RB24 ( p - trailer ) ; 129
if ( size + trailer > p - c -> bytestream_start )  130
p -= size + trailer; 132
if ( f -> slice_count > ( unsigned ) MAX_SLICES || f -> slice_count <= 0 )  135
for (j = 0; j < f->slice_count; j++) 140
FFV1Context * fs = f -> slice_context [ j ] ; 141
fs -> ac = f -> ac; 142
fs -> packed_at_lsb = f -> packed_at_lsb; 143
fs -> slice_damaged = 0; 145
if ( f -> version == 2 )  147
fs -> slice_x = get_symbol ( c , state , 0 ) * f -> width; 148
fs -> slice_y = get_symbol ( c , state , 0 ) * f -> height; 149
fs -> slice_width = ( get_symbol ( c , state , 0 ) + 1 ) * f -> width + fs -> slice_x; 150
fs -> slice_height = ( get_symbol ( c , state , 0 ) + 1 ) * f -> height + fs -> slice_y; 151
fs -> slice_x /= f -> num_h_slices; 153
fs -> slice_y /= f -> num_v_slices; 154
fs -> slice_width = fs -> slice_width / f -> num_h_slices - fs -> slice_x; 155
fs -> slice_height = fs -> slice_height / f -> num_v_slices - fs -> slice_y; 156
if ( ( unsigned ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_height > f -> height )  157
if ( ( unsigned ) fs -> slice_x + ( uint64_t ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_y + ( uint64_t ) fs -> slice_height > f -> height )  160
for (i = 0; i < f->plane_count; i++) 165
if ( f -> version == 2 )  168
int idx = get_symbol ( c , state , 0 ) ; 169
if ( idx > ( unsigned ) f -> quant_table_count )  170
------------------------------
390 /home/speedy/test/source2slice/NVD/CVE_2013_7011_VULN_read_header.c fs -> slice_width = ( get_symbol ( c , state , 0 ) + 1 ) * f -> width + fs -> slice_x 150
static int CVE_2013_7011_VULN_read_header(FFV1Context *f) 1
uint8_t state [ CONTEXT_SIZE ] ; 3
RangeCoder * const c = & f -> slice_context [ 0 ] -> c 5
memset ( state , 128 , sizeof ( state ) ); 7
if ( f -> version < 2 )  9
unsigned v = get_symbol ( c , state , 0 ) ; 10
if ( v >= 2 )  11
f -> version = v; 15
f -> ac = f -> avctx -> coder_type = get_symbol ( c , state , 0 ); 16
if ( f -> ac > 1 )  17
for (i = 1; i < 256; i++) 18
f -> state_transition [ i ] = get_symbol ( c , state , 1 ) + c -> one_state [ i ]; 19
f -> colorspace = get_symbol ( c , state , 0 ); 22
if ( f -> version > 0 )  24
f -> avctx -> bits_per_raw_sample = get_symbol ( c , state , 0 ); 25
f -> chroma_planes = get_rac ( c , state ); 27
f -> chroma_h_shift = get_symbol ( c , state , 0 ); 28
f -> chroma_v_shift = get_symbol ( c , state , 0 ); 29
f -> transparency = get_rac ( c , state ); 30
f -> plane_count = 2 + f -> transparency; 31
if ( f -> colorspace == 0 )  34
if ( ! f -> transparency && ! f -> chroma_planes )  35
if ( f -> avctx -> bits_per_raw_sample <= 8 )  36
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 37
f -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 39
if ( f -> avctx -> bits_per_raw_sample <= 8 && ! f -> transparency )  40
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  41
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P; 42
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV440P; 43
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P; 44
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P; 45
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV411P; 46
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV410P; 47
if ( f -> avctx -> bits_per_raw_sample <= 8 && f -> transparency )  52
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  53
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA444P; 54
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA422P; 55
f -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P; 56
if ( f -> avctx -> bits_per_raw_sample == 9 )  61
f -> packed_at_lsb = 1; 62
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  63
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P9; 64
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P9; 65
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P9; 66
if ( f -> avctx -> bits_per_raw_sample == 10 )  71
f -> packed_at_lsb = 1; 72
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  73
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P10; 74
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P10; 75
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P10; 76
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  82
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P16; 83
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P16; 84
f -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P16; 85
if ( f -> colorspace == 1 )  91
if ( f -> chroma_h_shift || f -> chroma_v_shift )  92
if ( f -> avctx -> bits_per_raw_sample == 9 )  97
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP9; 98
if ( f -> avctx -> bits_per_raw_sample == 10 )  99
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP10; 100
if ( f -> avctx -> bits_per_raw_sample == 12 )  101
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP12; 102
if ( f -> avctx -> bits_per_raw_sample == 14 )  103
f -> avctx -> pix_fmt = AV_PIX_FMT_GBRP14; 104
if ( f -> transparency )  106
f -> avctx -> pix_fmt = AV_PIX_FMT_RGB32; 106
f -> avctx -> pix_fmt = AV_PIX_FMT_0RGB32; 107
if ( f -> version < 2 )  115
context_count = read_quant_tables ( c , f -> quant_table ); 116
if ( context_count < 0 )  117
if ( f -> version < 3 )  121
f -> slice_count = get_symbol ( c , state , 0 ); 122
const uint8_t * p = c -> bytestream_end ; 124
for (f->slice_count = 0;
f->slice_count < MAX_SLICES && 3 < p - c->bytestream_start;
f->slice_count++) 127
int trailer = 3 + 5 * ! ! f -> ec ; 128
int size = AV_RB24 ( p - trailer ) ; 129
if ( size + trailer > p - c -> bytestream_start )  130
p -= size + trailer; 132
if ( f -> slice_count > ( unsigned ) MAX_SLICES || f -> slice_count <= 0 )  135
for (j = 0; j < f->slice_count; j++) 140
FFV1Context * fs = f -> slice_context [ j ] ; 141
fs -> ac = f -> ac; 142
fs -> packed_at_lsb = f -> packed_at_lsb; 143
fs -> slice_damaged = 0; 145
if ( f -> version == 2 )  147
fs -> slice_x = get_symbol ( c , state , 0 ) * f -> width; 148
fs -> slice_y = get_symbol ( c , state , 0 ) * f -> height; 149
fs -> slice_width = ( get_symbol ( c , state , 0 ) + 1 ) * f -> width + fs -> slice_x; 150
fs -> slice_height = ( get_symbol ( c , state , 0 ) + 1 ) * f -> height + fs -> slice_y; 151
fs -> slice_x /= f -> num_h_slices; 153
fs -> slice_y /= f -> num_v_slices; 154
fs -> slice_width = fs -> slice_width / f -> num_h_slices - fs -> slice_x; 155
fs -> slice_height = fs -> slice_height / f -> num_v_slices - fs -> slice_y; 156
if ( ( unsigned ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_height > f -> height )  157
if ( ( unsigned ) fs -> slice_x + ( uint64_t ) fs -> slice_width > f -> width || ( unsigned ) fs -> slice_y + ( uint64_t ) fs -> slice_height > f -> height )  160
for (i = 0; i < f->plane_count; i++) 165
if ( f -> version == 2 )  168
int idx = get_symbol ( c , state , 0 ) ; 169
if ( idx > ( unsigned ) f -> quant_table_count )  170
------------------------------
391 /home/speedy/test/source2slice/NVD/CVE_2013_7013_PATCHED_g2m_init_buffers.c c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ) 26
static int CVE_2013_7013_PATCHED_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); 6
aligned_height = FFALIGN ( c -> height , 16 ); 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width , 16 ) * 3; 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
392 /home/speedy/test/source2slice/NVD/CVE_2013_7013_PATCHED_g2m_init_buffers.c c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ) 24
static int CVE_2013_7013_PATCHED_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); 6
aligned_height = FFALIGN ( c -> height , 16 ); 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width , 16 ) * 3; 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
393 /home/speedy/test/source2slice/NVD/CVE_2013_7013_PATCHED_g2m_init_buffers.c c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ) 23
static int CVE_2013_7013_PATCHED_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); 6
aligned_height = FFALIGN ( c -> height , 16 ); 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width , 16 ) * 3; 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
394 /home/speedy/test/source2slice/NVD/CVE_2013_7013_PATCHED_g2m_init_buffers.c c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ) 22
static int CVE_2013_7013_PATCHED_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); 6
aligned_height = FFALIGN ( c -> height , 16 ); 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width , 16 ) * 3; 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
395 /home/speedy/test/source2slice/NVD/CVE_2013_7013_PATCHED_g2m_init_buffers.c c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ) 9
static int CVE_2013_7013_PATCHED_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); 6
aligned_height = FFALIGN ( c -> height , 16 ); 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width , 16 ) * 3; 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
av_free ( c -> synth_tile ); 18
av_free ( c -> jpeg_tile ); 19
av_free ( c -> kempf_buf ); 20
av_free ( c -> kempf_flags ); 21
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
396 /home/speedy/test/source2slice/NVD/CVE_2013_7013_VULN_g2m_init_buffers.c c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ) 26
static int CVE_2013_7013_VULN_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); 6
aligned_height = FFALIGN ( c -> height , 16 ); 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
397 /home/speedy/test/source2slice/NVD/CVE_2013_7013_VULN_g2m_init_buffers.c c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ) 24
static int CVE_2013_7013_VULN_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); 6
aligned_height = FFALIGN ( c -> height , 16 ); 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
398 /home/speedy/test/source2slice/NVD/CVE_2013_7013_VULN_g2m_init_buffers.c c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ) 23
static int CVE_2013_7013_VULN_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); 6
aligned_height = FFALIGN ( c -> height , 16 ); 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
399 /home/speedy/test/source2slice/NVD/CVE_2013_7013_VULN_g2m_init_buffers.c c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ) 22
static int CVE_2013_7013_VULN_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); 6
aligned_height = FFALIGN ( c -> height , 16 ); 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
400 /home/speedy/test/source2slice/NVD/CVE_2013_7013_VULN_g2m_init_buffers.c c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ) 9
static int CVE_2013_7013_VULN_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); 6
aligned_height = FFALIGN ( c -> height , 16 ); 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
av_free ( c -> synth_tile ); 18
av_free ( c -> jpeg_tile ); 19
av_free ( c -> kempf_buf ); 20
av_free ( c -> kempf_flags ); 21
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
401 /home/speedy/test/source2slice/NVD/CVE_2013_7017_PATCHED_ff_jpeg2000_init_component.c Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ) 252
int CVE_2013_7017_PATCHED_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_calloc ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_calloc ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
uint16_t Cx0 , Cy0 ; 242
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
402 /home/speedy/test/source2slice/NVD/CVE_2013_7017_PATCHED_ff_jpeg2000_init_component.c prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ) 199
int CVE_2013_7017_PATCHED_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_calloc ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_calloc ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
403 /home/speedy/test/source2slice/NVD/CVE_2013_7017_PATCHED_ff_jpeg2000_init_component.c nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y 185
int CVE_2013_7017_PATCHED_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_calloc ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_calloc ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
------------------------------
404 /home/speedy/test/source2slice/NVD/CVE_2013_7017_PATCHED_ff_jpeg2000_init_component.c band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ) 118
int CVE_2013_7017_PATCHED_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_calloc ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_calloc ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
405 /home/speedy/test/source2slice/NVD/CVE_2013_7017_PATCHED_ff_jpeg2000_init_component.c band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ) 105
int CVE_2013_7017_PATCHED_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_calloc ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_calloc ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
406 /home/speedy/test/source2slice/NVD/CVE_2013_7017_PATCHED_ff_jpeg2000_init_component.c numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ] 103
int CVE_2013_7017_PATCHED_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_calloc ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_calloc ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
407 /home/speedy/test/source2slice/NVD/CVE_2013_7017_VULN_ff_jpeg2000_init_component.c Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ) 252
int CVE_2013_7017_VULN_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_malloc_array ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_malloc_array ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
uint16_t Cx0 , Cy0 ; 242
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
408 /home/speedy/test/source2slice/NVD/CVE_2013_7017_VULN_ff_jpeg2000_init_component.c prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ) 199
int CVE_2013_7017_VULN_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_malloc_array ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_malloc_array ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
409 /home/speedy/test/source2slice/NVD/CVE_2013_7017_VULN_ff_jpeg2000_init_component.c nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y 185
int CVE_2013_7017_VULN_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_malloc_array ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_malloc_array ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
------------------------------
410 /home/speedy/test/source2slice/NVD/CVE_2013_7017_VULN_ff_jpeg2000_init_component.c band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ) 118
int CVE_2013_7017_VULN_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_malloc_array ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_malloc_array ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
411 /home/speedy/test/source2slice/NVD/CVE_2013_7017_VULN_ff_jpeg2000_init_component.c band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ) 105
int CVE_2013_7017_VULN_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_malloc_array ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_malloc_array ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
412 /home/speedy/test/source2slice/NVD/CVE_2013_7017_VULN_ff_jpeg2000_init_component.c numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ] 103
int CVE_2013_7017_VULN_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_malloc_array ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_malloc_array ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
413 /home/speedy/test/source2slice/NVD/CVE_2013_7019_PATCHED_get_cox.c c -> nreslevels2decode = c -> nreslevels - s -> reduction_factor 27
static int CVE_2013_7019_PATCHED_get_cox(Jpeg2000DecoderContext *s, Jpeg2000CodingStyle *c) 1
if ( bytestream2_get_bytes_left ( & s -> g ) < 5 )  5
c -> nreslevels = bytestream2_get_byteu ( & s -> g ) + 1; 10
if ( c -> nreslevels >= JPEG2000_MAX_RESLEVELS )  11
if ( c -> nreslevels <= s -> reduction_factor )  16
c -> nreslevels2decode = c -> nreslevels - s -> reduction_factor; 27
c -> log2_cblk_width = ( bytestream2_get_byteu ( & s -> g ) & 15 ) + 2; 29
c -> log2_cblk_height = ( bytestream2_get_byteu ( & s -> g ) & 15 ) + 2; 30
if ( c -> log2_cblk_width > 10 || c -> log2_cblk_height > 10 || c -> log2_cblk_width + c -> log2_cblk_height > 12 )  32
if ( c -> log2_cblk_width > 6 || c -> log2_cblk_height > 6 )  38
c -> cblk_style = bytestream2_get_byteu ( & s -> g ); 43
if ( c -> cblk_style != 0 )  44
av_log ( s -> avctx , AV_LOG_WARNING , "extra cblk styles %X\n" , c -> cblk_style ); 45
c -> transform = bytestream2_get_byteu ( & s -> g ); 47
if ( ( s -> avctx -> flags & CODEC_FLAG_BITEXACT ) && ( c -> transform == FF_DWT97 ) )  49
c -> transform = FF_DWT97_INT; 50
if ( c -> csty & JPEG2000_CSTY_PREC )  52
for (i = 0; i < c->nreslevels; i++) 54
c -> log2_prec_widths [ i ] = byte & 0x0F; 56
c -> log2_prec_heights [ i ] = ( byte >> 4 ) & 0x0F; 57
memset ( c -> log2_prec_widths , 15 , sizeof ( c -> log2_prec_widths ) ); 60
memset ( c -> log2_prec_heights , 15 , sizeof ( c -> log2_prec_heights ) ); 61
------------------------------
414 /home/speedy/test/source2slice/NVD/CVE_2013_7019_VULN_get_cox.c c -> nreslevels2decode = c -> nreslevels - s -> reduction_factor 20
static int CVE_2013_7019_VULN_get_cox(Jpeg2000DecoderContext *s, Jpeg2000CodingStyle *c) 1
if ( bytestream2_get_bytes_left ( & s -> g ) < 5 )  5
c -> nreslevels = bytestream2_get_byteu ( & s -> g ) + 1; 10
if ( c -> nreslevels >= JPEG2000_MAX_RESLEVELS )  11
if ( c -> nreslevels < s -> reduction_factor )  17
c -> nreslevels2decode = c -> nreslevels - s -> reduction_factor; 20
c -> log2_cblk_width = ( bytestream2_get_byteu ( & s -> g ) & 15 ) + 2; 22
c -> log2_cblk_height = ( bytestream2_get_byteu ( & s -> g ) & 15 ) + 2; 23
if ( c -> log2_cblk_width > 10 || c -> log2_cblk_height > 10 || c -> log2_cblk_width + c -> log2_cblk_height > 12 )  25
if ( c -> log2_cblk_width > 6 || c -> log2_cblk_height > 6 )  31
c -> cblk_style = bytestream2_get_byteu ( & s -> g ); 36
if ( c -> cblk_style != 0 )  37
av_log ( s -> avctx , AV_LOG_WARNING , "extra cblk styles %X\n" , c -> cblk_style ); 38
c -> transform = bytestream2_get_byteu ( & s -> g ); 40
if ( ( s -> avctx -> flags & CODEC_FLAG_BITEXACT ) && ( c -> transform == FF_DWT97 ) )  42
c -> transform = FF_DWT97_INT; 43
if ( c -> csty & JPEG2000_CSTY_PREC )  45
for (i = 0; i < c->nreslevels; i++) 47
c -> log2_prec_widths [ i ] = byte & 0x0F; 49
c -> log2_prec_heights [ i ] = ( byte >> 4 ) & 0x0F; 50
memset ( c -> log2_prec_widths , 15 , sizeof ( c -> log2_prec_widths ) ); 53
memset ( c -> log2_prec_heights , 15 , sizeof ( c -> log2_prec_heights ) ); 54
------------------------------
415 /home/speedy/test/source2slice/NVD/CVE_2013_7021_PATCHED_filter_frame.c s -> pts = s -> first_pts + av_rescale_q ( s -> frames_out , outlink -> time_base , inlink -> time_base ) 89
static int CVE_2013_7021_PATCHED_filter_frame(AVFilterLink *inlink, AVFrame *buf) 1
AVFilterContext * ctx = inlink -> dst ; 3
FPSContext * s = ctx -> priv ; 4
AVFilterLink * outlink = ctx -> outputs [ 0 ] ; 5
int64_t delta ; 6
int i , ret ; 7
s -> frames_in ++; 9
if ( s -> pts == AV_NOPTS_VALUE )  11
if ( buf -> pts != AV_NOPTS_VALUE )  12
ret = write_to_fifo ( s -> fifo , buf ); 13
if ( ret < 0 )  14
s -> first_pts = s -> pts = buf -> pts; 17
s -> drop ++; 22
if ( buf -> pts == AV_NOPTS_VALUE || av_fifo_size ( s -> fifo ) <= 0 )  28
delta = av_rescale_q_rnd ( buf -> pts - s -> pts , inlink -> time_base , outlink -> time_base , s -> rounding ); 33
if ( delta < 1 )  36
for (i = 0; i < delta; i++) 53
AVFrame * buf_out ; 54
if ( ! av_fifo_size ( s -> fifo ) && i < delta - 1 )  58
AVFrame * dup = av_frame_clone ( buf_out ) ; 59
if ( dup )  62
ret = write_to_fifo ( s -> fifo , dup ); 63
ret = AVERROR ( ENOMEM ); 65
if ( ret < 0 )  67
s -> dup ++; 73
buf_out -> pts = av_rescale_q ( s -> first_pts , inlink -> time_base , outlink -> time_base ) + s -> frames_out; 76
if ( ( ret = ff_filter_frame ( outlink , buf_out ) ) < 0 )  79
s -> frames_out ++; 84
s -> pts = s -> first_pts + av_rescale_q ( s -> frames_out , outlink -> time_base , inlink -> time_base ); 89
------------------------------
416 /home/speedy/test/source2slice/NVD/CVE_2013_7021_PATCHED_filter_frame.c delta = av_rescale_q_rnd ( buf -> pts - s -> pts , inlink -> time_base , outlink -> time_base , s -> rounding ) 33
static int CVE_2013_7021_PATCHED_filter_frame(AVFilterLink *inlink, AVFrame *buf) 1
AVFilterContext * ctx = inlink -> dst ; 3
FPSContext * s = ctx -> priv ; 4
AVFilterLink * outlink = ctx -> outputs [ 0 ] ; 5
int64_t delta ; 6
int i , ret ; 7
s -> frames_in ++; 9
if ( s -> pts == AV_NOPTS_VALUE )  11
if ( buf -> pts != AV_NOPTS_VALUE )  12
ret = write_to_fifo ( s -> fifo , buf ); 13
if ( ret < 0 )  14
s -> first_pts = s -> pts = buf -> pts; 17
s -> drop ++; 22
if ( buf -> pts == AV_NOPTS_VALUE || av_fifo_size ( s -> fifo ) <= 0 )  28
delta = av_rescale_q_rnd ( buf -> pts - s -> pts , inlink -> time_base , outlink -> time_base , s -> rounding ); 33
if ( delta < 1 )  36
for (i = 0; i < delta; i++) 53
if ( ! av_fifo_size ( s -> fifo ) && i < delta - 1 )  58
------------------------------
417 /home/speedy/test/source2slice/NVD/CVE_2013_7021_VULN_filter_frame.c s -> pts = s -> first_pts + av_rescale_q ( s -> frames_out , outlink -> time_base , inlink -> time_base ) 89
static int CVE_2013_7021_VULN_filter_frame(AVFilterLink *inlink, AVFrame *buf) 1
AVFilterContext * ctx = inlink -> dst ; 3
FPSContext * s = ctx -> priv ; 4
AVFilterLink * outlink = ctx -> outputs [ 0 ] ; 5
int64_t delta ; 6
int i , ret ; 7
s -> frames_in ++; 9
if ( s -> pts == AV_NOPTS_VALUE )  11
if ( buf -> pts == AV_NOPTS_VALUE )  28
delta = av_rescale_q_rnd ( buf -> pts - s -> pts , inlink -> time_base , outlink -> time_base , s -> rounding ); 33
if ( delta < 1 )  36
for (i = 0; i < delta; i++) 53
AVFrame * buf_out ; 54
if ( ! av_fifo_size ( s -> fifo ) && i < delta - 1 )  58
AVFrame * dup = av_frame_clone ( buf_out ) ; 59
if ( dup )  62
ret = write_to_fifo ( s -> fifo , dup ); 63
ret = AVERROR ( ENOMEM ); 65
if ( ret < 0 )  67
s -> dup ++; 73
buf_out -> pts = av_rescale_q ( s -> first_pts , inlink -> time_base , outlink -> time_base ) + s -> frames_out; 76
if ( ( ret = ff_filter_frame ( outlink , buf_out ) ) < 0 )  79
s -> frames_out ++; 84
s -> pts = s -> first_pts + av_rescale_q ( s -> frames_out , outlink -> time_base , inlink -> time_base ); 89
------------------------------
418 /home/speedy/test/source2slice/NVD/CVE_2013_7021_VULN_filter_frame.c delta = av_rescale_q_rnd ( buf -> pts - s -> pts , inlink -> time_base , outlink -> time_base , s -> rounding ) 33
static int CVE_2013_7021_VULN_filter_frame(AVFilterLink *inlink, AVFrame *buf) 1
AVFilterContext * ctx = inlink -> dst ; 3
FPSContext * s = ctx -> priv ; 4
AVFilterLink * outlink = ctx -> outputs [ 0 ] ; 5
int64_t delta ; 6
s -> frames_in ++; 9
if ( s -> pts == AV_NOPTS_VALUE )  11
if ( buf -> pts == AV_NOPTS_VALUE )  28
delta = av_rescale_q_rnd ( buf -> pts - s -> pts , inlink -> time_base , outlink -> time_base , s -> rounding ); 33
if ( delta < 1 )  36
for (i = 0; i < delta; i++) 53
if ( ! av_fifo_size ( s -> fifo ) && i < delta - 1 )  58
------------------------------
419 /home/speedy/test/source2slice/NVD/CVE_2013_7022_PATCHED_g2m_init_buffers.c c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ) 26
static int CVE_2013_7022_PATCHED_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width + 15 , 16 ) * 3; 6
aligned_height = c -> height + 15; 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
420 /home/speedy/test/source2slice/NVD/CVE_2013_7022_PATCHED_g2m_init_buffers.c c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ) 24
static int CVE_2013_7022_PATCHED_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width + 15 , 16 ) * 3; 6
aligned_height = c -> height + 15; 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
421 /home/speedy/test/source2slice/NVD/CVE_2013_7022_PATCHED_g2m_init_buffers.c c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ) 23
static int CVE_2013_7022_PATCHED_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width + 15 , 16 ) * 3; 6
aligned_height = c -> height + 15; 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
422 /home/speedy/test/source2slice/NVD/CVE_2013_7022_PATCHED_g2m_init_buffers.c c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ) 22
static int CVE_2013_7022_PATCHED_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width + 15 , 16 ) * 3; 6
aligned_height = c -> height + 15; 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
423 /home/speedy/test/source2slice/NVD/CVE_2013_7022_PATCHED_g2m_init_buffers.c c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ) 9
static int CVE_2013_7022_PATCHED_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width + 15 , 16 ) * 3; 6
aligned_height = c -> height + 15; 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
av_free ( c -> synth_tile ); 18
av_free ( c -> jpeg_tile ); 19
av_free ( c -> kempf_buf ); 20
av_free ( c -> kempf_flags ); 21
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
424 /home/speedy/test/source2slice/NVD/CVE_2013_7022_VULN_g2m_init_buffers.c c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ) 26
static int CVE_2013_7022_VULN_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); 6
aligned_height = FFALIGN ( c -> height , 16 ); 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
425 /home/speedy/test/source2slice/NVD/CVE_2013_7022_VULN_g2m_init_buffers.c c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ) 24
static int CVE_2013_7022_VULN_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); 6
aligned_height = FFALIGN ( c -> height , 16 ); 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
426 /home/speedy/test/source2slice/NVD/CVE_2013_7022_VULN_g2m_init_buffers.c c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ) 23
static int CVE_2013_7022_VULN_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); 6
aligned_height = FFALIGN ( c -> height , 16 ); 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
427 /home/speedy/test/source2slice/NVD/CVE_2013_7022_VULN_g2m_init_buffers.c c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ) 22
static int CVE_2013_7022_VULN_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); 6
aligned_height = FFALIGN ( c -> height , 16 ); 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
428 /home/speedy/test/source2slice/NVD/CVE_2013_7022_VULN_g2m_init_buffers.c c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ) 9
static int CVE_2013_7022_VULN_g2m_init_buffers(G2MContext *c) 1
int aligned_height ; 3
if ( ! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height )  5
c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); 6
aligned_height = FFALIGN ( c -> height , 16 ); 7
c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); 9
if ( ! c -> framebuf )  10
if ( ! c -> synth_tile || ! c -> jpeg_tile || c -> old_tile_w < c -> tile_width || c -> old_tile_h < c -> tile_height )  13
c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); 16
aligned_height = FFALIGN ( c -> tile_height , 16 ); 17
av_free ( c -> synth_tile ); 18
av_free ( c -> jpeg_tile ); 19
av_free ( c -> kempf_buf ); 20
av_free ( c -> kempf_flags ); 21
c -> synth_tile = av_mallocz ( c -> tile_stride * aligned_height ); 22
c -> jpeg_tile = av_mallocz ( c -> tile_stride * aligned_height ); 23
c -> kempf_buf = av_mallocz ( ( c -> tile_width + 1 ) * aligned_height + FF_INPUT_BUFFER_PADDING_SIZE ); 24
c -> kempf_flags = av_mallocz ( c -> tile_width * aligned_height ); 26
if ( ! c -> synth_tile || ! c -> jpeg_tile || ! c -> kempf_buf || ! c -> kempf_flags )  27
------------------------------
429 /home/speedy/test/source2slice/NVD/CVE_2013_7023_PATCHED_ff_combine_frame.c pc -> state64 = ( pc -> state64 << 8 ) | pc -> buffer [ pc -> last_index + next ] 57
int CVE_2013_7023_PATCHED_ff_combine_frame(ParseContext *pc, int next, const uint8_t **buf, int *buf_size) 1
for(; pc->overread>0; pc->overread--) 10
pc -> buffer [ pc -> index ++ ] = pc -> buffer [ pc -> overread_index ++ ]; 11
if ( ! * buf_size && next == END_NOT_FOUND )  15
next = 0; 16
pc -> last_index = pc -> index; 19
if ( next == END_NOT_FOUND )  22
* buf_size = pc -> overread_index = pc -> index + next; 35
if ( pc -> index )  39
void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , next + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ) ; 40
if ( ! new_buffer )  41
pc -> buffer = new_buffer; 46
if ( next > - FF_INPUT_BUFFER_PADDING_SIZE )  47
memcpy ( & pc -> buffer [ pc -> index ] , * buf , next + FF_INPUT_BUFFER_PADDING_SIZE ); 48
pc -> index = 0; 50
for(;next < 0; next++) 55
pc -> state = ( pc -> state << 8 ) | pc -> buffer [ pc -> last_index + next ]; 56
pc -> state64 = ( pc -> state64 << 8 ) | pc -> buffer [ pc -> last_index + next ]; 57
pc -> overread ++; 58
if ( pc -> overread )  61
av_dlog ( NULL , "overread %d, state:%X next:%d index:%d o_index:%d\n" , pc -> overread , pc -> state , next , pc -> index , pc -> overread_index ); 62
------------------------------
430 /home/speedy/test/source2slice/NVD/CVE_2013_7023_PATCHED_ff_combine_frame.c pc -> state = ( pc -> state << 8 ) | pc -> buffer [ pc -> last_index + next ] 56
int CVE_2013_7023_PATCHED_ff_combine_frame(ParseContext *pc, int next, const uint8_t **buf, int *buf_size) 1
for(; pc->overread>0; pc->overread--) 10
pc -> buffer [ pc -> index ++ ] = pc -> buffer [ pc -> overread_index ++ ]; 11
if ( ! * buf_size && next == END_NOT_FOUND )  15
next = 0; 16
pc -> last_index = pc -> index; 19
if ( next == END_NOT_FOUND )  22
* buf_size = pc -> overread_index = pc -> index + next; 35
if ( pc -> index )  39
void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , next + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ) ; 40
if ( ! new_buffer )  41
pc -> buffer = new_buffer; 46
if ( next > - FF_INPUT_BUFFER_PADDING_SIZE )  47
memcpy ( & pc -> buffer [ pc -> index ] , * buf , next + FF_INPUT_BUFFER_PADDING_SIZE ); 48
pc -> index = 0; 50
for(;next < 0; next++) 55
pc -> state = ( pc -> state << 8 ) | pc -> buffer [ pc -> last_index + next ]; 56
pc -> state64 = ( pc -> state64 << 8 ) | pc -> buffer [ pc -> last_index + next ]; 57
pc -> overread ++; 58
if ( pc -> overread )  61
av_dlog ( NULL , "overread %d, state:%X next:%d index:%d o_index:%d\n" , pc -> overread , pc -> state , next , pc -> index , pc -> overread_index ); 62
------------------------------
431 /home/speedy/test/source2slice/NVD/CVE_2013_7023_PATCHED_ff_combine_frame.c * buf_size = pc -> overread_index = pc -> index + next 35
int CVE_2013_7023_PATCHED_ff_combine_frame(ParseContext *pc, int next, const uint8_t **buf, int *buf_size) 1
for(; pc->overread>0; pc->overread--) 10
pc -> buffer [ pc -> index ++ ] = pc -> buffer [ pc -> overread_index ++ ]; 11
if ( ! * buf_size && next == END_NOT_FOUND )  15
next = 0; 16
pc -> last_index = pc -> index; 19
if ( next == END_NOT_FOUND )  22
* buf_size = pc -> overread_index = pc -> index + next; 35
if ( pc -> index )  39
void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , next + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ) ; 40
if ( ! new_buffer )  41
pc -> overread_index = pc -> index = 0; 42
pc -> buffer = new_buffer; 46
memcpy ( & pc -> buffer [ pc -> index ] , * buf , next + FF_INPUT_BUFFER_PADDING_SIZE ); 48
pc -> index = 0; 50
* buf = pc -> buffer; 51
pc -> state = ( pc -> state << 8 ) | pc -> buffer [ pc -> last_index + next ]; 56
pc -> state64 = ( pc -> state64 << 8 ) | pc -> buffer [ pc -> last_index + next ]; 57
pc -> overread ++; 58
if ( pc -> overread )  61
av_dlog ( NULL , "overread %d, state:%X next:%d index:%d o_index:%d\n" , pc -> overread , pc -> state , next , pc -> index , pc -> overread_index ); 62
av_dlog ( NULL , "%X %X %X %X\n" , ( * buf ) [ 0 ] , ( * buf ) [ 1 ] , ( * buf ) [ 2 ] , ( * buf ) [ 3 ] ); 64
------------------------------
432 /home/speedy/test/source2slice/NVD/CVE_2013_7023_VULN_ff_combine_frame.c pc -> state64 = ( pc -> state64 << 8 ) | pc -> buffer [ pc -> last_index + next ] 53
int CVE_2013_7023_VULN_ff_combine_frame(ParseContext *pc, int next, const uint8_t **buf, int *buf_size) 1
for(; pc->overread>0; pc->overread--) 10
pc -> buffer [ pc -> index ++ ] = pc -> buffer [ pc -> overread_index ++ ]; 11
if ( ! * buf_size && next == END_NOT_FOUND )  15
next = 0; 16
pc -> last_index = pc -> index; 19
if ( next == END_NOT_FOUND )  22
* buf_size = pc -> overread_index = pc -> index + next; 33
if ( pc -> index )  37
void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , next + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ) ; 38
if ( ! new_buffer )  40
pc -> buffer = new_buffer; 42
if ( next > - FF_INPUT_BUFFER_PADDING_SIZE )  43
memcpy ( & pc -> buffer [ pc -> index ] , * buf , next + FF_INPUT_BUFFER_PADDING_SIZE ); 44
pc -> index = 0; 46
for(;next < 0; next++) 51
pc -> state = ( pc -> state << 8 ) | pc -> buffer [ pc -> last_index + next ]; 52
pc -> state64 = ( pc -> state64 << 8 ) | pc -> buffer [ pc -> last_index + next ]; 53
pc -> overread ++; 54
if ( pc -> overread )  57
av_dlog ( NULL , "overread %d, state:%X next:%d index:%d o_index:%d\n" , pc -> overread , pc -> state , next , pc -> index , pc -> overread_index ); 58
------------------------------
433 /home/speedy/test/source2slice/NVD/CVE_2013_7023_VULN_ff_combine_frame.c pc -> state = ( pc -> state << 8 ) | pc -> buffer [ pc -> last_index + next ] 52
int CVE_2013_7023_VULN_ff_combine_frame(ParseContext *pc, int next, const uint8_t **buf, int *buf_size) 1
for(; pc->overread>0; pc->overread--) 10
pc -> buffer [ pc -> index ++ ] = pc -> buffer [ pc -> overread_index ++ ]; 11
if ( ! * buf_size && next == END_NOT_FOUND )  15
next = 0; 16
pc -> last_index = pc -> index; 19
if ( next == END_NOT_FOUND )  22
* buf_size = pc -> overread_index = pc -> index + next; 33
if ( pc -> index )  37
void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , next + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ) ; 38
if ( ! new_buffer )  40
pc -> buffer = new_buffer; 42
if ( next > - FF_INPUT_BUFFER_PADDING_SIZE )  43
memcpy ( & pc -> buffer [ pc -> index ] , * buf , next + FF_INPUT_BUFFER_PADDING_SIZE ); 44
pc -> index = 0; 46
for(;next < 0; next++) 51
pc -> state = ( pc -> state << 8 ) | pc -> buffer [ pc -> last_index + next ]; 52
pc -> state64 = ( pc -> state64 << 8 ) | pc -> buffer [ pc -> last_index + next ]; 53
pc -> overread ++; 54
if ( pc -> overread )  57
av_dlog ( NULL , "overread %d, state:%X next:%d index:%d o_index:%d\n" , pc -> overread , pc -> state , next , pc -> index , pc -> overread_index ); 58
------------------------------
434 /home/speedy/test/source2slice/NVD/CVE_2013_7023_VULN_ff_combine_frame.c * buf_size = pc -> overread_index = pc -> index + next 33
int CVE_2013_7023_VULN_ff_combine_frame(ParseContext *pc, int next, const uint8_t **buf, int *buf_size) 1
for(; pc->overread>0; pc->overread--) 10
pc -> buffer [ pc -> index ++ ] = pc -> buffer [ pc -> overread_index ++ ]; 11
if ( ! * buf_size && next == END_NOT_FOUND )  15
next = 0; 16
pc -> last_index = pc -> index; 19
if ( next == END_NOT_FOUND )  22
* buf_size = pc -> overread_index = pc -> index + next; 33
if ( pc -> index )  37
void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , next + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ) ; 38
if ( ! new_buffer )  40
pc -> buffer = new_buffer; 42
memcpy ( & pc -> buffer [ pc -> index ] , * buf , next + FF_INPUT_BUFFER_PADDING_SIZE ); 44
pc -> index = 0; 46
* buf = pc -> buffer; 47
pc -> state = ( pc -> state << 8 ) | pc -> buffer [ pc -> last_index + next ]; 52
pc -> state64 = ( pc -> state64 << 8 ) | pc -> buffer [ pc -> last_index + next ]; 53
pc -> overread ++; 54
if ( pc -> overread )  57
av_dlog ( NULL , "overread %d, state:%X next:%d index:%d o_index:%d\n" , pc -> overread , pc -> state , next , pc -> index , pc -> overread_index ); 58
av_dlog ( NULL , "%X %X %X %X\n" , ( * buf ) [ 0 ] , ( * buf ) [ 1 ] , ( * buf ) [ 2 ] , ( * buf ) [ 3 ] ); 60
------------------------------
435 /home/speedy/test/source2slice/NVD/CVE_2013_7024_PATCHED_jpeg2000_decode_tile.c dst = linel + ( x / s -> cdx [ compno ] * pixelsize + compno * ! planar ) 139
static int CVE_2013_7024_PATCHED_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
int x , y ; 5
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
int x , y ; 37
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
x = cblk -> coord [ 0 ] [ 0 ]; 44
if ( s -> cdef [ 0 ] < 0 )  64
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 118
uint16_t * linel ; 123
int planar = ! ! picture -> data [ 2 ] ; 126
int pixelsize = planar ? 1 : s -> ncomponents ; 127
int plane = 0 ; 128
if ( planar )  130
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 131
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 133
linel = ( uint16_t * ) picture -> data [ plane ] + y / s -> cdy [ compno ] * ( picture -> linesize [ plane ] >> 1 ); 134
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 135
uint16_t * dst ; 136
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 138
dst = linel + ( x / s -> cdx [ compno ] * pixelsize + compno * ! planar ); 139
* dst = val << ( 16 - cbps ); 146
dst += pixelsize; 148
* dst = val << ( 16 - cbps ); 156
dst += pixelsize; 158
linel += picture -> linesize [ plane ] >> 1; 161
------------------------------
436 /home/speedy/test/source2slice/NVD/CVE_2013_7024_PATCHED_jpeg2000_decode_tile.c linel = ( uint16_t * ) picture -> data [ plane ] + y / s -> cdy [ compno ] * ( picture -> linesize [ plane ] >> 1 ) 134
static int CVE_2013_7024_PATCHED_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
int x , y ; 5
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
int x , y ; 37
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
x = cblk -> coord [ 0 ] [ 0 ]; 44
if ( s -> cdef [ 0 ] < 0 )  64
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 118
uint16_t * linel ; 123
int planar = ! ! picture -> data [ 2 ] ; 126
int plane = 0 ; 128
if ( planar )  130
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 131
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 133
linel = ( uint16_t * ) picture -> data [ plane ] + y / s -> cdy [ compno ] * ( picture -> linesize [ plane ] >> 1 ); 134
dst = linel + ( x / s -> cdx [ compno ] * pixelsize + compno * ! planar ); 139
* dst = val << ( 16 - cbps ); 146
dst += pixelsize; 148
* dst = val << ( 16 - cbps ); 156
dst += pixelsize; 158
linel += picture -> linesize [ plane ] >> 1; 161
------------------------------
437 /home/speedy/test/source2slice/NVD/CVE_2013_7024_PATCHED_jpeg2000_decode_tile.c dst = line + x / s -> cdx [ compno ] * pixelsize + compno * ! planar 93
static int CVE_2013_7024_PATCHED_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
int x , y ; 5
uint8_t * line ; 7
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
int x , y ; 37
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
x = cblk -> coord [ 0 ] [ 0 ]; 44
y = cblk -> coord [ 1 ] [ 0 ]; 45
if ( s -> cdef [ 0 ] < 0 )  64
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
int planar = ! ! picture -> data [ 2 ] ; 79
int pixelsize = planar ? 1 : s -> ncomponents ; 80
int plane = 0 ; 81
if ( planar )  83
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 84
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 87
line = picture -> data [ plane ] + y / s -> cdy [ compno ] * picture -> linesize [ plane ]; 88
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 89
uint8_t * dst ; 90
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 92
dst = line + x / s -> cdx [ compno ] * pixelsize + compno * ! planar; 93
* dst = val << ( 8 - cbps ); 100
dst += pixelsize; 102
* dst = val << ( 8 - cbps ); 109
dst += pixelsize; 111
line += picture -> linesize [ plane ]; 114
------------------------------
438 /home/speedy/test/source2slice/NVD/CVE_2013_7024_PATCHED_jpeg2000_decode_tile.c line = picture -> data [ plane ] + y / s -> cdy [ compno ] * picture -> linesize [ plane ] 88
static int CVE_2013_7024_PATCHED_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
int x , y ; 5
uint8_t * line ; 7
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
int x , y ; 37
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
x = cblk -> coord [ 0 ] [ 0 ]; 44
y = cblk -> coord [ 1 ] [ 0 ]; 45
if ( s -> cdef [ 0 ] < 0 )  64
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
int planar = ! ! picture -> data [ 2 ] ; 79
int plane = 0 ; 81
if ( planar )  83
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 84
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 87
line = picture -> data [ plane ] + y / s -> cdy [ compno ] * picture -> linesize [ plane ]; 88
dst = line + x / s -> cdx [ compno ] * pixelsize + compno * ! planar; 93
* dst = val << ( 8 - cbps ); 100
dst += pixelsize; 102
* dst = val << ( 8 - cbps ); 109
dst += pixelsize; 111
line += picture -> linesize [ plane ]; 114
------------------------------
439 /home/speedy/test/source2slice/NVD/CVE_2013_7024_PATCHED_jpeg2000_decode_tile.c nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y 30
static int CVE_2013_7024_PATCHED_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
------------------------------
440 /home/speedy/test/source2slice/NVD/CVE_2013_7024_VULN_jpeg2000_decode_tile.c dst = linel + ( x * pixelsize + compno * ! planar ) 139
static int CVE_2013_7024_VULN_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
int x , y ; 5
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
int x , y ; 37
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
x = cblk -> coord [ 0 ] [ 0 ]; 44
if ( s -> cdef [ 0 ] < 0 )  64
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 118
uint16_t * linel ; 123
int planar = ! ! picture -> data [ 2 ] ; 126
int pixelsize = planar ? 1 : s -> ncomponents ; 127
int plane = 0 ; 128
if ( planar )  130
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 131
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 133
linel = ( uint16_t * ) picture -> data [ plane ] + y * ( picture -> linesize [ plane ] >> 1 ); 134
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 135
uint16_t * dst ; 136
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 138
dst = linel + ( x * pixelsize + compno * ! planar ); 139
* dst = val << ( 16 - cbps ); 146
dst += pixelsize; 148
* dst = val << ( 16 - cbps ); 156
dst += pixelsize; 158
linel += picture -> linesize [ plane ] >> 1; 161
------------------------------
441 /home/speedy/test/source2slice/NVD/CVE_2013_7024_VULN_jpeg2000_decode_tile.c dst = line + x * pixelsize + compno * ! planar 93
static int CVE_2013_7024_VULN_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
int x , y ; 5
uint8_t * line ; 7
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
int x , y ; 37
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
x = cblk -> coord [ 0 ] [ 0 ]; 44
y = cblk -> coord [ 1 ] [ 0 ]; 45
if ( s -> cdef [ 0 ] < 0 )  64
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
int planar = ! ! picture -> data [ 2 ] ; 79
int pixelsize = planar ? 1 : s -> ncomponents ; 80
int plane = 0 ; 81
if ( planar )  83
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 84
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 87
line = picture -> data [ plane ] + y * picture -> linesize [ plane ]; 88
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 89
uint8_t * dst ; 90
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 92
dst = line + x * pixelsize + compno * ! planar; 93
* dst = val << ( 8 - cbps ); 100
dst += pixelsize; 102
* dst = val << ( 8 - cbps ); 109
dst += pixelsize; 111
line += picture -> linesize [ plane ]; 114
------------------------------
442 /home/speedy/test/source2slice/NVD/CVE_2013_7024_VULN_jpeg2000_decode_tile.c line = picture -> data [ plane ] + y * picture -> linesize [ plane ] 88
static int CVE_2013_7024_VULN_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
int x , y ; 5
uint8_t * line ; 7
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
int x , y ; 37
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
x = cblk -> coord [ 0 ] [ 0 ]; 44
y = cblk -> coord [ 1 ] [ 0 ]; 45
if ( s -> cdef [ 0 ] < 0 )  64
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
int planar = ! ! picture -> data [ 2 ] ; 79
int plane = 0 ; 81
if ( planar )  83
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 84
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 87
line = picture -> data [ plane ] + y * picture -> linesize [ plane ]; 88
dst = line + x * pixelsize + compno * ! planar; 93
* dst = val << ( 8 - cbps ); 100
dst += pixelsize; 102
* dst = val << ( 8 - cbps ); 109
dst += pixelsize; 111
line += picture -> linesize [ plane ]; 114
------------------------------
443 /home/speedy/test/source2slice/NVD/CVE_2013_7024_VULN_jpeg2000_decode_tile.c nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y 30
static int CVE_2013_7024_VULN_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
------------------------------
444 /home/speedy/test/source2slice/NVD/CVE_2013_7027_PATCHED_ieee80211_radiotap_iterator_init.c iterator -> _arg = ( uint8_t * ) radiotap_header + sizeof ( * radiotap_header ) 22
int CVE_2013_7027_PATCHED_ieee80211_radiotap_iterator_init(
struct ieee80211_radiotap_iterator *iterator,
struct ieee80211_radiotap_header *radiotap_header,
int max_length, const struct ieee80211_radiotap_vendor_namespaces *vns) 4
if ( max_length < sizeof ( struct ieee80211_radiotap_header ) )  7
if ( radiotap_header -> it_version )  11
if ( max_length < get_unaligned_le16 ( & radiotap_header -> it_len ) )  15
iterator -> _rtheader = radiotap_header; 18
iterator -> _max_length = get_unaligned_le16 ( & radiotap_header -> it_len ); 19
iterator -> _arg_index = 0; 20
iterator -> _bitmap_shifter = get_unaligned_le32 ( & radiotap_header -> it_present ); 21
iterator -> _arg = ( uint8_t * ) radiotap_header + sizeof ( * radiotap_header ); 22
iterator -> _reset_on_ext = 0; 23
iterator -> _next_bitmap = & radiotap_header -> it_present; 24
iterator -> _next_bitmap ++; 25
iterator -> _vns = vns; 26
iterator -> current_namespace = & radiotap_ns; 27
iterator -> is_radiotap_ns = 1; 28
if ( iterator -> _bitmap_shifter & ( 1 << IEEE80211_RADIOTAP_EXT ) )  32
while ( get_unaligned_le32 ( iterator -> _arg ) & ( 1 << IEEE80211_RADIOTAP_EXT ) )  33
iterator -> _arg += sizeof ( uint32_t ); 35
if ( ( unsigned long ) iterator -> _arg - ( unsigned long ) iterator -> _rtheader + sizeof ( uint32_t ) > ( unsigned long ) iterator -> _max_length )  43
iterator -> _arg += sizeof ( uint32_t ); 50
iterator -> this_arg = iterator -> _arg; 59
------------------------------
445 /home/speedy/test/source2slice/NVD/CVE_2013_7027_VULN_ieee80211_radiotap_iterator_init.c iterator -> _arg = ( uint8_t * ) radiotap_header + sizeof ( * radiotap_header ) 18
int CVE_2013_7027_VULN_ieee80211_radiotap_iterator_init(
struct ieee80211_radiotap_iterator *iterator,
struct ieee80211_radiotap_header *radiotap_header,
int max_length, const struct ieee80211_radiotap_vendor_namespaces *vns) 4
if ( radiotap_header -> it_version )  7
if ( max_length < get_unaligned_le16 ( & radiotap_header -> it_len ) )  11
iterator -> _rtheader = radiotap_header; 14
iterator -> _max_length = get_unaligned_le16 ( & radiotap_header -> it_len ); 15
iterator -> _arg_index = 0; 16
iterator -> _bitmap_shifter = get_unaligned_le32 ( & radiotap_header -> it_present ); 17
iterator -> _arg = ( uint8_t * ) radiotap_header + sizeof ( * radiotap_header ); 18
iterator -> _reset_on_ext = 0; 19
iterator -> _next_bitmap = & radiotap_header -> it_present; 20
iterator -> _next_bitmap ++; 21
iterator -> _vns = vns; 22
iterator -> current_namespace = & radiotap_ns; 23
iterator -> is_radiotap_ns = 1; 24
if ( iterator -> _bitmap_shifter & ( 1 << IEEE80211_RADIOTAP_EXT ) )  28
while ( get_unaligned_le32 ( iterator -> _arg ) & ( 1 << IEEE80211_RADIOTAP_EXT ) )  29
iterator -> _arg += sizeof ( uint32_t ); 31
if ( ( unsigned long ) iterator -> _arg - ( unsigned long ) iterator -> _rtheader > ( unsigned long ) iterator -> _max_length )  39
iterator -> _arg += sizeof ( uint32_t ); 45
iterator -> this_arg = iterator -> _arg; 54
------------------------------
446 /home/speedy/test/source2slice/NVD/CVE_2013_7100_PATCHED_unpacksms16.c * udl = ( o - ud ) 26
static void CVE_2013_7100_PATCHED_unpacksms16(unsigned char *i, unsigned char l, unsigned char *udh, int *udhl, unsigned short *ud, int *udl, char udhi) 2
unsigned short * o = ud ; 4
if ( udhi )  6
int n = * i ; 7
if ( n )  9
i ++; 10
l --; 11
while ( l && n )  12
l --; 13
n --; 14
* udh ++ = * i ++; 15
while ( l -- )  19
int v = * i ++ ; 20
if ( l && l -- )  21
v = ( v << 8 ) + * i ++; 22
* o ++ = v; 24
* udl = ( o - ud ); 26
------------------------------
447 /home/speedy/test/source2slice/NVD/CVE_2013_7100_VULN_unpacksms16.c * udl = ( o - ud ) 26
static void CVE_2013_7100_VULN_unpacksms16(unsigned char *i, unsigned char l, unsigned char *udh, int *udhl, unsigned short *ud, int *udl, char udhi) 2
unsigned short * o = ud ; 4
if ( udhi )  6
int n = * i ; 7
if ( n )  9
i ++; 10
l --; 11
while ( l && n )  12
l --; 13
n --; 14
* udh ++ = * i ++; 15
while ( l -- )  19
int v = * i ++ ; 20
if ( l -- )  21
v = ( v << 8 ) + * i ++; 22
* o ++ = v; 24
* udl = ( o - ud ); 26
------------------------------
448 /home/speedy/test/source2slice/NVD/CVE_2013_7266_PATCHED_mISDN_sock_recvmsg.c copied = skb -> len + MISDN_HEADER_LEN 42
static int
CVE_2013_7266_PATCHED_mISDN_sock_recvmsg(struct kiocb *iocb, struct socket *sock,
struct msghdr *msg, size_t len, int flags) 3
struct sk_buff * skb ; 5
struct sock * sk = sock -> sk ; 6
int copied , err ; 8
if ( flags & ( MSG_OOB ) )  14
if ( sk -> sk_state == MISDN_CLOSED )  17
skb = skb_recv_datagram ( sk , flags , flags & MSG_DONTWAIT , & err ); 20
if ( ! skb )  21
copied = skb -> len + MISDN_HEADER_LEN; 42
if ( len < copied )  43
err = skb_copy_datagram_iovec ( skb , 0 , msg -> msg_iov , copied ); 53
return err ? : copied 59
------------------------------
449 /home/speedy/test/source2slice/NVD/CVE_2013_7266_VULN_mISDN_sock_recvmsg.c copied = skb -> len + MISDN_HEADER_LEN 47
static int
CVE_2013_7266_VULN_mISDN_sock_recvmsg(struct kiocb *iocb, struct socket *sock,
struct msghdr *msg, size_t len, int flags) 3
struct sk_buff * skb ; 5
struct sock * sk = sock -> sk ; 6
int copied , err ; 9
if ( flags & ( MSG_OOB ) )  15
if ( sk -> sk_state == MISDN_CLOSED )  18
skb = skb_recv_datagram ( sk , flags , flags & MSG_DONTWAIT , & err ); 21
if ( ! skb )  22
copied = skb -> len + MISDN_HEADER_LEN; 47
if ( len < copied )  48
err = skb_copy_datagram_iovec ( skb , 0 , msg -> msg_iov , copied ); 58
return err ? : copied 64
------------------------------
450 /home/speedy/test/source2slice/NVD/CVE_2014_0069_PATCHED_cifs_iovec_write.c cur_len = save_len - cur_len 76
static ssize_t
CVE_2014_0069_PATCHED_cifs_iovec_write(struct file *file, const struct iovec *iov,
unsigned long nr_segs, loff_t *poffset) 3
unsigned long nr_pages , i ; 5
size_t bytes , copied , len , cur_len ; 6
loff_t offset ; 8
struct cifsFileInfo * open_file ; 10
struct cifs_tcon * tcon ; 11
struct cifs_sb_info * cifs_sb ; 12
struct cifs_writedata * wdata , * tmp ; 13
int rc ; 15
pid_t pid ; 16
len = iov_length ( iov , nr_segs ); 18
if ( ! len )  19
rc = generic_write_checks ( file , poffset , & len , 0 ); 22
if ( rc )  23
cifs_sb = CIFS_SB ( file -> f_path . dentry -> d_sb ); 27
open_file = file -> private_data; 28
tcon = tlink_tcon ( open_file -> tlink ); 29
if ( ! tcon -> ses -> server -> ops -> async_writev )  31
offset = * poffset; 34
if ( cifs_sb -> mnt_cifs_flags & CIFS_MOUNT_RWPIDFORWARD )  36
pid = open_file -> pid; 37
pid = current -> tgid; 39
size_t save_len ; 43
nr_pages = get_numpages ( cifs_sb -> wsize , len , & cur_len ); 45
wdata = cifs_writedata_alloc ( nr_pages , cifs_uncached_writev_complete ); 46
if ( ! wdata )  48
rc = cifs_write_allocate_pages ( wdata -> pages , nr_pages ); 53
if ( rc )  54
kfree ( wdata ); 55
save_len = cur_len; 59
for (i = 0; i < nr_pages; i++) 60
bytes = min_t ( const size_t , cur_len , PAGE_SIZE ) 61
copied = iov_iter_copy_from_user ( wdata -> pages [ i ] , & it , 0 , bytes ); 62
cur_len -= copied; 64
iov_iter_advance ( & it , copied ); 65
if ( copied < bytes )  73
cur_len = save_len - cur_len; 76
if ( ! cur_len )  84
for (i = 0; i < nr_pages; i++) 85
put_page ( wdata -> pages [ i ] ); 86
kfree ( wdata ); 87
for ( ; nr_pages > i + 1; nr_pages--) 97
put_page ( wdata -> pages [ nr_pages - 1 ] ); 98
wdata -> sync_mode = WB_SYNC_ALL; 100
wdata -> nr_pages = nr_pages; 101
wdata -> offset = ( __u64 ) offset; 102
wdata -> cfile = cifsFileInfo_get ( open_file ); 103
wdata -> pid = pid; 104
wdata -> bytes = cur_len; 105
wdata -> pagesz = PAGE_SIZE; 106
wdata -> tailsz = cur_len - ( ( nr_pages - 1 ) * PAGE_SIZE ); 107
rc = cifs_uncached_retry_writev ( wdata ); 108
if ( rc )  109
kref_put ( & wdata -> refcount , cifs_writedata_release ); 110
list_add_tail ( & wdata -> list , & wdata_list ); 114
offset += cur_len; 115
len -= cur_len; 116
while ( len > 0 )  117
list_for_each_entry_safe ( wdata , tmp , & wdata_list , list ) 134
if ( ! rc )  135
rc = wait_for_completion_killable ( & wdata -> done ); 137
if ( rc )  138
if ( wdata -> result )  140
rc = wdata -> result; 141
total_written += wdata -> bytes; 143
if ( rc == - EAGAIN )  146
rc = cifs_uncached_retry_writev ( wdata ); 147
list_del_init ( & wdata -> list ); 151
kref_put ( & wdata -> refcount , cifs_writedata_release ); 152
if ( total_written > 0 )  155
* poffset += total_written; 156
cifs_stats_bytes_written ( tcon , total_written ); 158
return total_written ? total_written : ( ssize_t ) rc ; 159
------------------------------
451 /home/speedy/test/source2slice/NVD/CVE_2014_0069_VULN_cifs_iovec_write.c cur_len = save_len - cur_len 67
static ssize_t
CVE_2014_0069_VULN_cifs_iovec_write(struct file *file, const struct iovec *iov,
unsigned long nr_segs, loff_t *poffset) 3
unsigned long nr_pages , i ; 5
size_t copied , len , cur_len ; 6
loff_t offset ; 8
struct cifsFileInfo * open_file ; 10
struct cifs_tcon * tcon ; 11
struct cifs_sb_info * cifs_sb ; 12
struct cifs_writedata * wdata , * tmp ; 13
int rc ; 15
pid_t pid ; 16
len = iov_length ( iov , nr_segs ); 18
if ( ! len )  19
rc = generic_write_checks ( file , poffset , & len , 0 ); 22
if ( rc )  23
cifs_sb = CIFS_SB ( file -> f_path . dentry -> d_sb ); 27
open_file = file -> private_data; 28
tcon = tlink_tcon ( open_file -> tlink ); 29
if ( ! tcon -> ses -> server -> ops -> async_writev )  31
offset = * poffset; 34
if ( cifs_sb -> mnt_cifs_flags & CIFS_MOUNT_RWPIDFORWARD )  36
pid = open_file -> pid; 37
pid = current -> tgid; 39
size_t save_len ; 43
nr_pages = get_numpages ( cifs_sb -> wsize , len , & cur_len ); 45
wdata = cifs_writedata_alloc ( nr_pages , cifs_uncached_writev_complete ); 46
if ( ! wdata )  48
rc = cifs_write_allocate_pages ( wdata -> pages , nr_pages ); 53
if ( rc )  54
kfree ( wdata ); 55
save_len = cur_len; 59
for (i = 0; i < nr_pages; i++) 60
copied = min_t ( const size_t , cur_len , PAGE_SIZE ) 61
copied = iov_iter_copy_from_user ( wdata -> pages [ i ] , & it , 0 , copied ); 62
cur_len -= copied; 64
iov_iter_advance ( & it , copied ); 65
cur_len = save_len - cur_len; 67
wdata -> sync_mode = WB_SYNC_ALL; 69
wdata -> nr_pages = nr_pages; 70
wdata -> offset = ( __u64 ) offset; 71
wdata -> cfile = cifsFileInfo_get ( open_file ); 72
wdata -> pid = pid; 73
wdata -> bytes = cur_len; 74
wdata -> pagesz = PAGE_SIZE; 75
wdata -> tailsz = cur_len - ( ( nr_pages - 1 ) * PAGE_SIZE ); 76
rc = cifs_uncached_retry_writev ( wdata ); 77
if ( rc )  78
kref_put ( & wdata -> refcount , cifs_writedata_release ); 79
list_add_tail ( & wdata -> list , & wdata_list ); 83
offset += cur_len; 84
len -= cur_len; 85
while ( len > 0 )  86
list_for_each_entry_safe ( wdata , tmp , & wdata_list , list ) 103
if ( ! rc )  104
rc = wait_for_completion_killable ( & wdata -> done ); 106
if ( rc )  107
if ( wdata -> result )  109
rc = wdata -> result; 110
total_written += wdata -> bytes; 112
if ( rc == - EAGAIN )  115
rc = cifs_uncached_retry_writev ( wdata ); 116
list_del_init ( & wdata -> list ); 120
kref_put ( & wdata -> refcount , cifs_writedata_release ); 121
if ( total_written > 0 )  124
* poffset += total_written; 125
cifs_stats_bytes_written ( tcon , total_written ); 127
return total_written ? total_written : ( ssize_t ) rc ; 128
------------------------------
452 /home/speedy/test/source2slice/NVD/CVE_2014_0160_PATCHED_tls1_process_heartbeat.c r = ssl3_write_bytes ( s , TLS1_RT_HEARTBEAT , buffer , 3 + payload + padding ) 43
int
CVE_2014_0160_PATCHED_tls1_process_heartbeat(SSL *s) 2
unsigned char * p = & s -> s3 -> rrec . data [ 0 ] , * pl ; 4
unsigned short hbtype ; 5
unsigned int payload ; 6
unsigned int padding = 16 ; 7
if ( 1 + 2 + 16 > s -> s3 -> rrec . length )  15
hbtype = * p ++; 17
if ( 1 + 2 + payload + 16 > s -> s3 -> rrec . length )  19
if ( hbtype == TLS1_HB_REQUEST )  23
unsigned char * buffer , * bp ; 25
int r ; 26
buffer = OPENSSL_malloc ( 1 + 2 + payload + padding ); 32
r = ssl3_write_bytes ( s , TLS1_RT_HEARTBEAT , buffer , 3 + payload + padding ); 43
if ( r >= 0 && s -> msg_callback )  45
if ( r < 0 )  52
return r ; 53
------------------------------
453 /home/speedy/test/source2slice/NVD/CVE_2014_0160_PATCHED_tls1_process_heartbeat.c buffer = OPENSSL_malloc ( 1 + 2 + payload + padding ) 32
int
CVE_2014_0160_PATCHED_tls1_process_heartbeat(SSL *s) 2
unsigned char * p = & s -> s3 -> rrec . data [ 0 ] , * pl ; 4
unsigned short hbtype ; 5
unsigned int payload ; 6
unsigned int padding = 16 ; 7
if ( 1 + 2 + 16 > s -> s3 -> rrec . length )  15
hbtype = * p ++; 17
if ( 1 + 2 + payload + 16 > s -> s3 -> rrec . length )  19
if ( hbtype == TLS1_HB_REQUEST )  23
unsigned char * buffer , * bp ; 25
buffer = OPENSSL_malloc ( 1 + 2 + payload + padding ); 32
bp = buffer; 33
* bp ++ = TLS1_HB_RESPONSE; 36
s2n ( payload , bp ); 37
memcpy ( bp , pl , payload ); 38
bp += payload; 39
RAND_pseudo_bytes ( bp , padding ); 41
r = ssl3_write_bytes ( s , TLS1_RT_HEARTBEAT , buffer , 3 + payload + padding ); 43
if ( r >= 0 && s -> msg_callback )  45
s -> msg_callback ( 1 , s -> version , TLS1_RT_HEARTBEAT , buffer , 3 + payload + padding , s , s -> msg_callback_arg ); 46
OPENSSL_free ( buffer ); 50
if ( r < 0 )  52
return r ; 53
------------------------------
454 /home/speedy/test/source2slice/NVD/CVE_2014_0160_VULN_dtls1_process_heartbeat.c r = dtls1_write_bytes ( s , TLS1_RT_HEARTBEAT , buffer , 3 + payload + padding ) 39
int
CVE_2014_0160_VULN_dtls1_process_heartbeat(SSL *s) 2
unsigned char * p = & s -> s3 -> rrec . data [ 0 ] , * pl ; 4
unsigned short hbtype ; 5
unsigned int payload ; 6
unsigned int padding = 16 ; 7
hbtype = * p ++; 10
if ( hbtype == TLS1_HB_REQUEST )  19
unsigned char * buffer , * bp ; 21
int r ; 22
buffer = OPENSSL_malloc ( 1 + 2 + payload + padding ); 28
r = dtls1_write_bytes ( s , TLS1_RT_HEARTBEAT , buffer , 3 + payload + padding ); 39
if ( r >= 0 && s -> msg_callback )  41
if ( r < 0 )  48
return r ; 49
------------------------------
455 /home/speedy/test/source2slice/NVD/CVE_2014_0160_VULN_dtls1_process_heartbeat.c buffer = OPENSSL_malloc ( 1 + 2 + payload + padding ) 28
int
CVE_2014_0160_VULN_dtls1_process_heartbeat(SSL *s) 2
unsigned char * p = & s -> s3 -> rrec . data [ 0 ] , * pl ; 4
unsigned short hbtype ; 5
unsigned int payload ; 6
unsigned int padding = 16 ; 7
hbtype = * p ++; 10
if ( hbtype == TLS1_HB_REQUEST )  19
unsigned char * buffer , * bp ; 21
buffer = OPENSSL_malloc ( 1 + 2 + payload + padding ); 28
bp = buffer; 29
* bp ++ = TLS1_HB_RESPONSE; 32
s2n ( payload , bp ); 33
memcpy ( bp , pl , payload ); 34
bp += payload; 35
RAND_pseudo_bytes ( bp , padding ); 37
r = dtls1_write_bytes ( s , TLS1_RT_HEARTBEAT , buffer , 3 + payload + padding ); 39
if ( r >= 0 && s -> msg_callback )  41
s -> msg_callback ( 1 , s -> version , TLS1_RT_HEARTBEAT , buffer , 3 + payload + padding , s , s -> msg_callback_arg ); 42
OPENSSL_free ( buffer ); 46
if ( r < 0 )  48
return r ; 49
------------------------------
456 /home/speedy/test/source2slice/NVD/CVE_2014_0160_VULN_tls1_process_heartbeat.c r = ssl3_write_bytes ( s , TLS1_RT_HEARTBEAT , buffer , 3 + payload + padding ) 39
int
CVE_2014_0160_VULN_tls1_process_heartbeat(SSL *s) 2
unsigned char * p = & s -> s3 -> rrec . data [ 0 ] , * pl ; 4
unsigned short hbtype ; 5
unsigned int payload ; 6
unsigned int padding = 16 ; 7
hbtype = * p ++; 10
if ( hbtype == TLS1_HB_REQUEST )  19
unsigned char * buffer , * bp ; 21
int r ; 22
buffer = OPENSSL_malloc ( 1 + 2 + payload + padding ); 28
r = ssl3_write_bytes ( s , TLS1_RT_HEARTBEAT , buffer , 3 + payload + padding ); 39
if ( r >= 0 && s -> msg_callback )  41
if ( r < 0 )  48
return r ; 49
------------------------------
457 /home/speedy/test/source2slice/NVD/CVE_2014_0160_VULN_tls1_process_heartbeat.c buffer = OPENSSL_malloc ( 1 + 2 + payload + padding ) 28
int
CVE_2014_0160_VULN_tls1_process_heartbeat(SSL *s) 2
unsigned char * p = & s -> s3 -> rrec . data [ 0 ] , * pl ; 4
unsigned short hbtype ; 5
unsigned int payload ; 6
unsigned int padding = 16 ; 7
hbtype = * p ++; 10
if ( hbtype == TLS1_HB_REQUEST )  19
unsigned char * buffer , * bp ; 21
buffer = OPENSSL_malloc ( 1 + 2 + payload + padding ); 28
bp = buffer; 29
* bp ++ = TLS1_HB_RESPONSE; 32
s2n ( payload , bp ); 33
memcpy ( bp , pl , payload ); 34
bp += payload; 35
RAND_pseudo_bytes ( bp , padding ); 37
r = ssl3_write_bytes ( s , TLS1_RT_HEARTBEAT , buffer , 3 + payload + padding ); 39
if ( r >= 0 && s -> msg_callback )  41
s -> msg_callback ( 1 , s -> version , TLS1_RT_HEARTBEAT , buffer , 3 + payload + padding , s , s -> msg_callback_arg ); 42
OPENSSL_free ( buffer ); 46
if ( r < 0 )  48
return r ; 49
------------------------------
458 /home/speedy/test/source2slice/NVD/CVE_2014_1497_PATCHED_WaveReader__LoadFormatChunk.c static_assert ( UINT16_MAX + ( UINT16_MAX % 2 ) < UINT_MAX / sizeof ( char ) , "chunkExtension array too large for iterator." ) 61
bool
CVE_2014_1497_PATCHED_WaveReader::LoadFormatChunk(uint32_t aChunkSize) 2
char waveFormat [ WAVE_FORMAT_CHUNK_SIZE ] ; 5
const char * p = waveFormat ; 6
if ( ! ReadAll ( waveFormat , sizeof ( waveFormat ) ) )  12
if ( ReadUint16LE ( & p ) != WAVE_FORMAT_ENCODING_PCM )  23
p += 4; 32
if ( aChunkSize > WAVE_FORMAT_CHUNK_SIZE )  43
char extLength [ 2 ] ; 44
if ( ! ReadAll ( extLength , sizeof ( extLength ) ) )  47
uint16_t extra = ReadUint16LE ( & p ) ; 53
if ( aChunkSize - ( WAVE_FORMAT_CHUNK_SIZE + 2 ) != extra )  54
extra += extra % 2; 58
if ( extra > 0 )  60
static_assert ( UINT16_MAX + ( UINT16_MAX % 2 ) < UINT_MAX / sizeof ( char ) , "chunkExtension array too large for iterator." ); 61
------------------------------
459 /home/speedy/test/source2slice/NVD/CVE_2014_1497_VULN_WaveReader__LoadFormatChunk.c static_assert ( UINT16_MAX + ( UINT16_MAX % 2 ) < UINT_MAX / sizeof ( char ) , "chunkExtension array too large for iterator." ) 61
bool
CVE_2014_1497_VULN_WaveReader::LoadFormatChunk(uint32_t aChunkSize) 2
char waveFormat [ WAVE_FORMAT_CHUNK_SIZE ] ; 5
const char * p = waveFormat ; 6
if ( ! ReadAll ( waveFormat , sizeof ( waveFormat ) ) )  12
if ( ReadUint16LE ( & p ) != WAVE_FORMAT_ENCODING_PCM )  23
p += 4; 32
if ( aChunkSize > WAVE_FORMAT_CHUNK_SIZE )  43
char extLength [ 2 ] ; 44
if ( ! ReadAll ( extLength , sizeof ( extLength ) ) )  47
uint16_t extra = ReadUint16LE ( & p ) ; 53
if ( aChunkSize - ( WAVE_FORMAT_CHUNK_SIZE + 2 ) != extra )  54
extra += extra % 2; 58
if ( extra > 0 )  60
static_assert ( UINT16_MAX + ( UINT16_MAX % 2 ) < UINT_MAX / sizeof ( char ) , "chunkExtension array too large for iterator." ); 61
------------------------------
460 /home/speedy/test/source2slice/NVD/CVE_2014_1522_PATCHED_ComputeCustom.c aOutput [ i ] = tableInterpolationFactor * lower + ( 1 - tableInterpolationFactor ) * higher 34
void CVE_2014_1522_PATCHED_ComputeCustom(float* aOutput,
TrackTicks ticks,
uint32_t aStart,
uint32_t aEnd) 4
uint32_t periodicWaveSize = mPeriodicWave -> periodicWaveSize ( ) ; 8
float * higherWaveData = nullptr ; 9
float * lowerWaveData = nullptr ; 10
float tableInterpolationFactor ; 11
float rate = 1.0 / mSource -> SampleRate ( ) ; 12
for (uint32_t i = aStart; i < aEnd; ++i) 14
mPhase += periodicWaveSize * mFinalFrequency * rate; 21
mPhase = fmod ( mPhase , periodicWaveSize ); 22
uint32_t j1 = floor ( mPhase ) ; 24
uint32_t j2 = j1 + 1 ; 25
if ( j2 >= periodicWaveSize )  26
j2 -= periodicWaveSize; 27
float sampleInterpolationFactor = mPhase - j1 ; 29
float lower = sampleInterpolationFactor * lowerWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * lowerWaveData [ j2 ] ; 30
float higher = sampleInterpolationFactor * higherWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * higherWaveData [ j2 ] ; 32
aOutput [ i ] = tableInterpolationFactor * lower + ( 1 - tableInterpolationFactor ) * higher; 34
------------------------------
461 /home/speedy/test/source2slice/NVD/CVE_2014_1522_VULN_ComputeCustom.c aOutput [ i ] = tableInterpolationFactor * lower + ( 1 - tableInterpolationFactor ) * higher 36
void CVE_2014_1522_VULN_ComputeCustom(float* aOutput,
TrackTicks ticks,
uint32_t aStart,
uint32_t aEnd) 4
uint32_t periodicWaveSize = mPeriodicWave -> periodicWaveSize ( ) ; 8
float * higherWaveData = nullptr ; 9
float * lowerWaveData = nullptr ; 10
float tableInterpolationFactor ; 11
float rate = 1.0 / mSource -> SampleRate ( ) ; 12
for (uint32_t i = aStart; i < aEnd; ++i) 14
mPhase += periodicWaveSize * mFinalFrequency * rate; 21
if ( mPhase >= periodicWaveSize )  22
mPhase -= periodicWaveSize; 23
uint32_t j1 = floor ( mPhase ) ; 26
uint32_t j2 = j1 + 1 ; 27
if ( j2 >= periodicWaveSize )  28
j2 -= periodicWaveSize; 29
float sampleInterpolationFactor = mPhase - j1 ; 31
float lower = sampleInterpolationFactor * lowerWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * lowerWaveData [ j2 ] ; 32
float higher = sampleInterpolationFactor * higherWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * higherWaveData [ j2 ] ; 34
aOutput [ i ] = tableInterpolationFactor * lower + ( 1 - tableInterpolationFactor ) * higher; 36
------------------------------
462 /home/speedy/test/source2slice/NVD/CVE_2014_1642_PATCHED_pirq_guest_bind.c irq = desc - irq_desc 20
int CVE_2014_1642_PATCHED_pirq_guest_bind(struct vcpu *v, struct pirq *pirq, int will_share) 1
unsigned int irq ; 3
struct irq_desc * desc ; 4
irq_guest_action_t * action , * newaction = NULL ; 5
desc = pirq_spin_lock_irq_desc ( pirq , NULL ); 12
if ( desc == NULL )  13
action = ( irq_guest_action_t * ) desc -> action; 19
irq = desc - irq_desc; 20
if ( ! ( desc -> status & IRQ_GUEST ) )  22
if ( desc -> action != NULL )  24
if ( newaction == NULL )  33
if ( ( newaction = xmalloc ( irq_guest_action_t ) ) != NULL && zalloc_cpumask_var ( & newaction -> cpu_eoi_map ) )  36
if ( ! will_share || ! action -> shareable )  64
if ( action -> nr_guests == 0 )  73
------------------------------
463 /home/speedy/test/source2slice/NVD/CVE_2014_1642_VULN_pirq_guest_bind.c irq = desc - irq_desc 20
int CVE_2014_1642_VULN_pirq_guest_bind(struct vcpu *v, struct pirq *pirq, int will_share) 1
unsigned int irq ; 3
struct irq_desc * desc ; 4
irq_guest_action_t * action , * newaction = NULL ; 5
desc = pirq_spin_lock_irq_desc ( pirq , NULL ); 12
if ( desc == NULL )  13
action = ( irq_guest_action_t * ) desc -> action; 19
irq = desc - irq_desc; 20
if ( ! ( desc -> status & IRQ_GUEST ) )  22
if ( desc -> action != NULL )  24
if ( newaction == NULL )  33
if ( ( newaction = xmalloc ( irq_guest_action_t ) ) != NULL && zalloc_cpumask_var ( & newaction -> cpu_eoi_map ) )  36
if ( ! will_share || ! action -> shareable )  65
if ( action -> nr_guests == 0 )  74
------------------------------
464 /home/speedy/test/source2slice/NVD/CVE_2014_2282_PATCHED_dissect_protocol_data_parameter.c ulp_length = tvb_get_ntohs ( parameter_tvb , PARAMETER_LENGTH_OFFSET ) - PARAMETER_HEADER_LENGTH - DATA_HDR_LENGTH 56
static void
CVE_2014_2282_PATCHED_dissect_protocol_data_parameter(tvbuff_t *parameter_tvb, packet_info *pinfo, proto_tree *tree, proto_tree *parameter_tree, proto_item *parameter_item) 2
guint16 ulp_length ; 4
ulp_length = tvb_get_ntohs ( parameter_tvb , PARAMETER_LENGTH_OFFSET ) - PARAMETER_HEADER_LENGTH - DATA_HDR_LENGTH; 56
proto_item_append_text ( parameter_item , " (SS7 message of %u byte%s)" , ulp_length , plurality ( ulp_length , "" , "s" ) ); 81
payload_tvb = tvb_new_subset ( parameter_tvb , DATA_ULP_OFFSET , ulp_length , ulp_length ); 103
if ( ! dissector_try_uint ( si_dissector_table , tvb_get_guint8 ( parameter_tvb , DATA_SI_OFFSET ) , payload_tvb , pinfo , tree ) )  104
call_dissector ( data_handle , payload_tvb , pinfo , tree ); 105
------------------------------
465 /home/speedy/test/source2slice/NVD/CVE_2014_2282_PATCHED_dissect_protocol_data_parameter.c ulp_length = tvb_get_ntohs ( parameter_tvb , PARAMETER_LENGTH_OFFSET ) - PARAMETER_HEADER_LENGTH - DATA_HDR_LENGTH 16
static void
CVE_2014_2282_PATCHED_dissect_protocol_data_parameter(tvbuff_t *parameter_tvb, packet_info *pinfo, proto_tree *tree, proto_tree *parameter_tree, proto_item *parameter_item) 2
guint16 ulp_length ; 4
ulp_length = tvb_get_ntohs ( parameter_tvb , PARAMETER_LENGTH_OFFSET ) - PARAMETER_HEADER_LENGTH - DATA_HDR_LENGTH; 16
payload_tvb = tvb_new_subset ( parameter_tvb , DATA_ULP_OFFSET , ulp_length , ulp_length ); 17
heuristic_standard = m3ua_heur_mtp3_standard ( payload_tvb , pinfo , opc , dpc , si ); 24
if ( heuristic_standard == HEURISTIC_FAILED_STANDARD )  25
gen_item = proto_tree_add_text ( tree , parameter_tvb , 0 , 0 , "%s" , val_to_str_const ( heuristic_standard , mtp3_standard_vals , "unknown" ) ); 28
mtp3_standard = heuristic_standard; 30
PROTO_ITEM_SET_GENERATED ( gen_item ); 37
mtp3_tap -> addr_dpc . type = ( Standard_Type ) mtp3_standard; 40
mtp3_tap -> addr_dpc . pc = dpc; 41
mtp3_tap -> addr_dpc . ni = tvb_get_guint8 ( parameter_tvb , DATA_NI_OFFSET ); 42
SET_ADDRESS ( & pinfo -> dst , AT_SS7PC , sizeof ( mtp3_addr_pc_t ) , ( guint8 * ) & mtp3_tap -> addr_dpc ); 43
mtp3_tap -> addr_opc . type = ( Standard_Type ) mtp3_standard; 46
mtp3_tap -> addr_opc . pc = opc; 47
mtp3_tap -> addr_opc . ni = tvb_get_guint8 ( parameter_tvb , DATA_NI_OFFSET ); 48
SET_ADDRESS ( & pinfo -> src , AT_SS7PC , sizeof ( mtp3_addr_pc_t ) , ( guint8 * ) & mtp3_tap -> addr_opc ); 49
mtp3_tap -> si_code = tvb_get_guint8 ( parameter_tvb , DATA_SI_OFFSET ); 51
mtp3_tap -> size = 0; 52
tap_queue_packet ( m3ua_tap , pinfo , mtp3_tap ); 54
if ( mtp3_tap -> addr_opc . ni == MTP3_NI_INT0 )  62
if ( mtp3_tap -> addr_dpc . ni == MTP3_NI_INT0 )  71
proto_item_append_text ( parameter_item , " (SS7 message of %u byte%s)" , ulp_length , plurality ( ulp_length , "" , "s" ) ); 81
payload_tvb = tvb_new_subset ( parameter_tvb , DATA_ULP_OFFSET , ulp_length , ulp_length ); 103
if ( ! dissector_try_uint ( si_dissector_table , tvb_get_guint8 ( parameter_tvb , DATA_SI_OFFSET ) , payload_tvb , pinfo , tree ) )  104
call_dissector ( data_handle , payload_tvb , pinfo , tree ); 105
------------------------------
466 /home/speedy/test/source2slice/NVD/CVE_2014_2282_VULN_dissect_protocol_data_parameter.c ulp_length = tvb_get_ntohs ( parameter_tvb , PARAMETER_LENGTH_OFFSET ) - PARAMETER_HEADER_LENGTH - DATA_HDR_LENGTH 54
static void
CVE_2014_2282_VULN_dissect_protocol_data_parameter(tvbuff_t *parameter_tvb, packet_info *pinfo, proto_tree *tree, proto_tree *parameter_tree, proto_item *parameter_item) 2
guint16 ulp_length ; 4
ulp_length = tvb_get_ntohs ( parameter_tvb , PARAMETER_LENGTH_OFFSET ) - PARAMETER_HEADER_LENGTH - DATA_HDR_LENGTH; 54
proto_item_append_text ( parameter_item , " (SS7 message of %u byte%s)" , ulp_length , plurality ( ulp_length , "" , "s" ) ); 79
payload_tvb = tvb_new_subset ( parameter_tvb , DATA_ULP_OFFSET , ulp_length , ulp_length ); 101
if ( ! dissector_try_uint ( si_dissector_table , tvb_get_guint8 ( parameter_tvb , DATA_SI_OFFSET ) , payload_tvb , pinfo , tree ) )  102
call_dissector ( data_handle , payload_tvb , pinfo , tree ); 103
------------------------------
467 /home/speedy/test/source2slice/NVD/CVE_2014_2282_VULN_dissect_protocol_data_parameter.c ulp_length = tvb_get_ntohs ( parameter_tvb , PARAMETER_LENGTH_OFFSET ) - PARAMETER_HEADER_LENGTH - DATA_HDR_LENGTH 14
static void
CVE_2014_2282_VULN_dissect_protocol_data_parameter(tvbuff_t *parameter_tvb, packet_info *pinfo, proto_tree *tree, proto_tree *parameter_tree, proto_item *parameter_item) 2
guint16 ulp_length ; 4
ulp_length = tvb_get_ntohs ( parameter_tvb , PARAMETER_LENGTH_OFFSET ) - PARAMETER_HEADER_LENGTH - DATA_HDR_LENGTH; 14
payload_tvb = tvb_new_subset ( parameter_tvb , DATA_ULP_OFFSET , ulp_length , ulp_length ); 15
heuristic_standard = m3ua_heur_mtp3_standard ( payload_tvb , pinfo , opc , dpc , si ); 22
if ( heuristic_standard == HEURISTIC_FAILED_STANDARD )  23
gen_item = proto_tree_add_text ( tree , parameter_tvb , 0 , 0 , "%s" , val_to_str_const ( heuristic_standard , mtp3_standard_vals , "unknown" ) ); 26
mtp3_standard = heuristic_standard; 28
PROTO_ITEM_SET_GENERATED ( gen_item ); 35
mtp3_tap -> addr_dpc . type = ( Standard_Type ) mtp3_standard; 38
mtp3_tap -> addr_dpc . pc = dpc; 39
mtp3_tap -> addr_dpc . ni = tvb_get_guint8 ( parameter_tvb , DATA_NI_OFFSET ); 40
SET_ADDRESS ( & pinfo -> dst , AT_SS7PC , sizeof ( mtp3_addr_pc_t ) , ( guint8 * ) & mtp3_tap -> addr_dpc ); 41
mtp3_tap -> addr_opc . type = ( Standard_Type ) mtp3_standard; 44
mtp3_tap -> addr_opc . pc = opc; 45
mtp3_tap -> addr_opc . ni = tvb_get_guint8 ( parameter_tvb , DATA_NI_OFFSET ); 46
SET_ADDRESS ( & pinfo -> src , AT_SS7PC , sizeof ( mtp3_addr_pc_t ) , ( guint8 * ) & mtp3_tap -> addr_opc ); 47
mtp3_tap -> si_code = tvb_get_guint8 ( parameter_tvb , DATA_SI_OFFSET ); 49
mtp3_tap -> size = 0; 50
tap_queue_packet ( m3ua_tap , pinfo , mtp3_tap ); 52
if ( mtp3_tap -> addr_opc . ni == MTP3_NI_INT0 )  60
if ( mtp3_tap -> addr_dpc . ni == MTP3_NI_INT0 )  69
proto_item_append_text ( parameter_item , " (SS7 message of %u byte%s)" , ulp_length , plurality ( ulp_length , "" , "s" ) ); 79
payload_tvb = tvb_new_subset ( parameter_tvb , DATA_ULP_OFFSET , ulp_length , ulp_length ); 101
if ( ! dissector_try_uint ( si_dissector_table , tvb_get_guint8 ( parameter_tvb , DATA_SI_OFFSET ) , payload_tvb , pinfo , tree ) )  102
call_dissector ( data_handle , payload_tvb , pinfo , tree ); 103
------------------------------
468 /home/speedy/test/source2slice/NVD/CVE_2014_2289_PATCHED_copy_body_types.c exten_state_sub -> body_types [ i ] = ast_malloc ( hdr -> values [ i ] . slen * sizeof ( char * ) + 1 ) 19
static void CVE_2014_2289_PATCHED_copy_body_types(pjsip_rx_data *rdata,
struct exten_state_subscription *exten_state_sub) 3
int i ; 5
pjsip_accept_hdr * hdr = ( pjsip_accept_hdr * ) pjsip_msg_find_hdr ( rdata -> msg_info . msg , PJSIP_H_ACCEPT , NULL ) ; 6
if ( ! hdr )  9
hdr = & default_presence_accept; 13
exten_state_sub -> body_types_count = hdr -> count; 15
exten_state_sub -> body_types = ast_malloc ( hdr -> count * sizeof ( char * ) ); 16
for (i = 0; i < hdr->count; ++i) 18
exten_state_sub -> body_types [ i ] = ast_malloc ( hdr -> values [ i ] . slen * sizeof ( char * ) + 1 ); 19
ast_copy_string ( exten_state_sub -> body_types [ i ] , pj_strbuf ( & hdr -> values [ i ] ) , hdr -> values [ i ] . slen + 1 ); 22
------------------------------
469 /home/speedy/test/source2slice/NVD/CVE_2014_2289_PATCHED_copy_body_types.c exten_state_sub -> body_types = ast_malloc ( hdr -> count * sizeof ( char * ) ) 16
static void CVE_2014_2289_PATCHED_copy_body_types(pjsip_rx_data *rdata,
struct exten_state_subscription *exten_state_sub) 3
pjsip_accept_hdr * hdr = ( pjsip_accept_hdr * ) pjsip_msg_find_hdr ( rdata -> msg_info . msg , PJSIP_H_ACCEPT , NULL ) ; 6
if ( ! hdr )  9
hdr = & default_presence_accept; 13
exten_state_sub -> body_types_count = hdr -> count; 15
exten_state_sub -> body_types = ast_malloc ( hdr -> count * sizeof ( char * ) ); 16
exten_state_sub -> body_types [ i ] = ast_malloc ( hdr -> values [ i ] . slen * sizeof ( char * ) + 1 ); 19
ast_copy_string ( exten_state_sub -> body_types [ i ] , pj_strbuf ( & hdr -> values [ i ] ) , hdr -> values [ i ] . slen + 1 ); 22
------------------------------
470 /home/speedy/test/source2slice/NVD/CVE_2014_2289_VULN_copy_body_types.c exten_state_sub -> body_types [ i ] = ast_malloc ( hdr -> values [ i ] . slen * sizeof ( char * ) + 1 ) 13
static void CVE_2014_2289_VULN_copy_body_types(pjsip_rx_data *rdata,
struct exten_state_subscription *exten_state_sub) 3
int i ; 5
pjsip_accept_hdr * hdr = ( pjsip_accept_hdr * ) pjsip_msg_find_hdr ( rdata -> msg_info . msg , PJSIP_H_ACCEPT , NULL ) ; 6
exten_state_sub -> body_types_count = hdr -> count; 9
exten_state_sub -> body_types = ast_malloc ( hdr -> count * sizeof ( char * ) ); 10
for (i = 0; i < hdr->count; ++i) 12
exten_state_sub -> body_types [ i ] = ast_malloc ( hdr -> values [ i ] . slen * sizeof ( char * ) + 1 ); 13
ast_copy_string ( exten_state_sub -> body_types [ i ] , pj_strbuf ( & hdr -> values [ i ] ) , hdr -> values [ i ] . slen + 1 ); 16
------------------------------
471 /home/speedy/test/source2slice/NVD/CVE_2014_2289_VULN_copy_body_types.c exten_state_sub -> body_types = ast_malloc ( hdr -> count * sizeof ( char * ) ) 10
static void CVE_2014_2289_VULN_copy_body_types(pjsip_rx_data *rdata,
struct exten_state_subscription *exten_state_sub) 3
pjsip_accept_hdr * hdr = ( pjsip_accept_hdr * ) pjsip_msg_find_hdr ( rdata -> msg_info . msg , PJSIP_H_ACCEPT , NULL ) ; 6
exten_state_sub -> body_types_count = hdr -> count; 9
exten_state_sub -> body_types = ast_malloc ( hdr -> count * sizeof ( char * ) ); 10
exten_state_sub -> body_types [ i ] = ast_malloc ( hdr -> values [ i ] . slen * sizeof ( char * ) + 1 ); 13
ast_copy_string ( exten_state_sub -> body_types [ i ] , pj_strbuf ( & hdr -> values [ i ] ) , hdr -> values [ i ] . slen + 1 ); 16
------------------------------
472 /home/speedy/test/source2slice/NVD/CVE_2014_2739_PATCHED_cma_req_handler.c event . param . ud . private_data_len = IB_CM_SIDR_REQ_PRIVATE_DATA_SIZE - offset 20
static int CVE_2014_2739_PATCHED_cma_req_handler(struct ib_cm_id *cm_id, struct ib_cm_event *ib_event) 1
struct rdma_id_private * listen_id , * conn_id ; 3
struct rdma_cm_event event ; 4
int offset , ret ; 5
listen_id = cm_id -> context; 7
if ( ! cma_check_req_qp_type ( & listen_id -> id , ib_event ) )  8
if ( cma_disable_callback ( listen_id , RDMA_CM_LISTEN ) )  11
memset ( & event , 0 , sizeof event ); 14
offset = cma_user_data_offset ( listen_id ); 15
event . event = RDMA_CM_EVENT_CONNECT_REQUEST; 16
if ( ib_event -> event == IB_CM_SIDR_REQ_RECEIVED )  17
event . param . ud . private_data = ib_event -> private_data + offset; 19
event . param . ud . private_data_len = IB_CM_SIDR_REQ_PRIVATE_DATA_SIZE - offset; 20
ret = conn_id -> id . event_handler ( & conn_id -> id , & event ); 46
if ( ret )  47
return ret ; 74
------------------------------
473 /home/speedy/test/source2slice/NVD/CVE_2014_2739_PATCHED_cma_req_handler.c event . param . ud . private_data = ib_event -> private_data + offset 19
static int CVE_2014_2739_PATCHED_cma_req_handler(struct ib_cm_id *cm_id, struct ib_cm_event *ib_event) 1
struct rdma_id_private * listen_id , * conn_id ; 3
struct rdma_cm_event event ; 4
int offset , ret ; 5
listen_id = cm_id -> context; 7
if ( ! cma_check_req_qp_type ( & listen_id -> id , ib_event ) )  8
if ( cma_disable_callback ( listen_id , RDMA_CM_LISTEN ) )  11
memset ( & event , 0 , sizeof event ); 14
offset = cma_user_data_offset ( listen_id ); 15
event . event = RDMA_CM_EVENT_CONNECT_REQUEST; 16
if ( ib_event -> event == IB_CM_SIDR_REQ_RECEIVED )  17
event . param . ud . private_data = ib_event -> private_data + offset; 19
event . param . ud . private_data_len = IB_CM_SIDR_REQ_PRIVATE_DATA_SIZE - offset; 20
ret = conn_id -> id . event_handler ( & conn_id -> id , & event ); 46
if ( ret )  47
return ret ; 74
------------------------------
474 /home/speedy/test/source2slice/NVD/CVE_2014_2739_VULN_cma_req_handler.c event . param . ud . private_data_len = IB_CM_SIDR_REQ_PRIVATE_DATA_SIZE - offset 29
static int CVE_2014_2739_VULN_cma_req_handler(struct ib_cm_id *cm_id, struct ib_cm_event *ib_event) 1
struct rdma_id_private * listen_id , * conn_id ; 3
struct rdma_cm_event event ; 4
int offset , ret ; 5
listen_id = cm_id -> context; 16
if ( ! cma_check_req_qp_type ( & listen_id -> id , ib_event ) )  17
if ( cma_disable_callback ( listen_id , RDMA_CM_LISTEN ) )  20
memset ( & event , 0 , sizeof event ); 23
offset = cma_user_data_offset ( listen_id ); 24
event . event = RDMA_CM_EVENT_CONNECT_REQUEST; 25
if ( ib_event -> event == IB_CM_SIDR_REQ_RECEIVED )  26
event . param . ud . private_data = ib_event -> private_data + offset; 28
event . param . ud . private_data_len = IB_CM_SIDR_REQ_PRIVATE_DATA_SIZE - offset; 29
ret = conn_id -> id . event_handler ( & conn_id -> id , & event ); 55
if ( ret )  56
return ret ; 100
------------------------------
475 /home/speedy/test/source2slice/NVD/CVE_2014_2739_VULN_cma_req_handler.c event . param . ud . private_data = ib_event -> private_data + offset 28
static int CVE_2014_2739_VULN_cma_req_handler(struct ib_cm_id *cm_id, struct ib_cm_event *ib_event) 1
struct rdma_id_private * listen_id , * conn_id ; 3
struct rdma_cm_event event ; 4
int offset , ret ; 5
listen_id = cm_id -> context; 16
if ( ! cma_check_req_qp_type ( & listen_id -> id , ib_event ) )  17
if ( cma_disable_callback ( listen_id , RDMA_CM_LISTEN ) )  20
memset ( & event , 0 , sizeof event ); 23
offset = cma_user_data_offset ( listen_id ); 24
event . event = RDMA_CM_EVENT_CONNECT_REQUEST; 25
if ( ib_event -> event == IB_CM_SIDR_REQ_RECEIVED )  26
event . param . ud . private_data = ib_event -> private_data + offset; 28
event . param . ud . private_data_len = IB_CM_SIDR_REQ_PRIVATE_DATA_SIZE - offset; 29
ret = conn_id -> id . event_handler ( & conn_id -> id , & event ); 55
if ( ret )  56
return ret ; 100
------------------------------
476 /home/speedy/test/source2slice/NVD/CVE_2014_2889_PATCHED_bpf_jit_compile.c addrs = kmalloc ( flen * sizeof ( * addrs ) , GFP_KERNEL ) 20
void CVE_2014_2889_PATCHED_bpf_jit_compile(struct sk_filter *fp) 1
unsigned int * addrs ; 13
int flen = fp -> len ; 15
if ( ! bpf_jit_enable )  17
addrs = kmalloc ( flen * sizeof ( * addrs ) , GFP_KERNEL ); 20
if ( addrs == NULL )  21
addrs [ i ] = proglen; 29
------------------------------
477 /home/speedy/test/source2slice/NVD/CVE_2014_2889_VULN_bpf_jit_compile.c addrs = kmalloc ( flen * sizeof ( * addrs ) , GFP_KERNEL ) 20
void CVE_2014_2889_VULN_bpf_jit_compile(struct sk_filter *fp) 1
unsigned int * addrs ; 13
int flen = fp -> len ; 15
if ( ! bpf_jit_enable )  17
addrs = kmalloc ( flen * sizeof ( * addrs ) , GFP_KERNEL ); 20
if ( addrs == NULL )  21
addrs [ i ] = proglen; 29
------------------------------
478 /home/speedy/test/source2slice/NVD/CVE_2014_2894_PATCHED_cmd_smart.c s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ] 137
static bool CVE_2014_2894_PATCHED_cmd_smart(IDEState *s, uint8_t cmd) 3
int n ; 5
if ( s -> hcyl != 0xc2 || s -> lcyl != 0x4f )  7
if ( ! s -> smart_enabled && s -> feature != SMART_ENABLE )  11
switch ( s -> feature )  15
switch ( s -> sector )  25
s -> smart_autosave = 0; 27
s -> smart_autosave = 1; 30
if ( ! s -> smart_errors )  38
s -> hcyl = 0x2c; 42
s -> lcyl = 0xf4; 43
memset ( s -> io_buffer , 0 , 0x200 ); 48
s -> io_buffer [ 0 ] = 0x01; 49
for (n = 0; n < ARRAY_SIZE(smart_attributes); n++) 51
s -> io_buffer [ 2 + 0 + ( n * 12 ) ] = smart_attributes [ n ] [ 0 ]; 52
s -> io_buffer [ 2 + 1 + ( n * 12 ) ] = smart_attributes [ n ] [ 11 ]; 53
for (n = 0; n < 511; n++) 57
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 58
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 60
s -> status = READY_STAT | SEEK_STAT; 62
memset ( s -> io_buffer , 0 , 0x200 ); 68
s -> io_buffer [ 0 ] = 0x01; 69
for (n = 0; n < ARRAY_SIZE(smart_attributes); n++) 71
int i ; 72
for (i = 0; i < 11; i++) 73
s -> io_buffer [ 2 + i + ( n * 12 ) ] = smart_attributes [ n ] [ i ]; 74
s -> io_buffer [ 362 ] = 0x02 | ( s -> smart_autosave ? 0x80 : 0x00 ); 78
if ( s -> smart_selftest_count == 0 )  79
s -> io_buffer [ 363 ] = s -> smart_selftest_data [ 3 + ( s -> smart_selftest_count - 1 ) * 24 ]; 82
s -> io_buffer [ 364 ] = 0x20; 87
s -> io_buffer [ 365 ] = 0x01; 88
s -> io_buffer [ 367 ] = ( 1 << 4 | 1 << 3 | 1 ); 90
s -> io_buffer [ 368 ] = 0x03; 91
s -> io_buffer [ 369 ] = 0x00; 92
s -> io_buffer [ 370 ] = 0x01; 93
s -> io_buffer [ 372 ] = 0x02; 94
s -> io_buffer [ 373 ] = 0x36; 95
s -> io_buffer [ 374 ] = 0x01; 96
for (n = 0; n < 511; n++) 98
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 99
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 101
s -> status = READY_STAT | SEEK_STAT; 103
switch ( s -> sector )  109
memset ( s -> io_buffer , 0 , 0x200 ); 111
s -> io_buffer [ 0 ] = 0x01; 112
s -> io_buffer [ 1 ] = 0x00; 113
s -> io_buffer [ 452 ] = s -> smart_errors & 0xff; 114
s -> io_buffer [ 453 ] = ( s -> smart_errors & 0xff00 ) >> 8; 115
for (n = 0; n < 511; n++) 117
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 118
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 120
memset ( s -> io_buffer , 0 , 0x200 ); 123
s -> io_buffer [ 0 ] = 0x01; 124
if ( s -> smart_selftest_count == 0 )  125
s -> io_buffer [ 508 ] = 0; 126
s -> io_buffer [ 508 ] = s -> smart_selftest_count; 128
for (n = 2; n < 506; n++) 129
s -> io_buffer [ n ] = s -> smart_selftest_data [ n ]; 130
for (n = 0; n < 511; n++) 134
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 135
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 137
s -> status = READY_STAT | SEEK_STAT; 142
ide_transfer_start ( s , s -> io_buffer , 0x200 , ide_transfer_stop ); 143
ide_set_irq ( s -> bus ); 144
switch ( s -> sector )  148
s -> smart_selftest_count ++; 152
if ( s -> smart_selftest_count > 21 )  153
s -> smart_selftest_count = 1; 154
n = 2 + ( s -> smart_selftest_count - 1 ) * 24; 156
s -> smart_selftest_data [ n ] = s -> sector; 157
s -> smart_selftest_data [ n + 1 ] = 0x00; 158
s -> smart_selftest_data [ n + 2 ] = 0x34; 159
s -> smart_selftest_data [ n + 3 ] = 0x12; 160
ide_abort_command ( s ); 169
------------------------------
479 /home/speedy/test/source2slice/NVD/CVE_2014_2894_PATCHED_cmd_smart.c s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ] 120
static bool CVE_2014_2894_PATCHED_cmd_smart(IDEState *s, uint8_t cmd) 3
int n ; 5
if ( s -> hcyl != 0xc2 || s -> lcyl != 0x4f )  7
if ( ! s -> smart_enabled && s -> feature != SMART_ENABLE )  11
switch ( s -> feature )  15
switch ( s -> sector )  25
s -> smart_autosave = 0; 27
s -> smart_autosave = 1; 30
if ( ! s -> smart_errors )  38
s -> hcyl = 0x2c; 42
s -> lcyl = 0xf4; 43
memset ( s -> io_buffer , 0 , 0x200 ); 48
s -> io_buffer [ 0 ] = 0x01; 49
for (n = 0; n < ARRAY_SIZE(smart_attributes); n++) 51
s -> io_buffer [ 2 + 0 + ( n * 12 ) ] = smart_attributes [ n ] [ 0 ]; 52
s -> io_buffer [ 2 + 1 + ( n * 12 ) ] = smart_attributes [ n ] [ 11 ]; 53
for (n = 0; n < 511; n++) 57
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 58
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 60
s -> status = READY_STAT | SEEK_STAT; 62
memset ( s -> io_buffer , 0 , 0x200 ); 68
s -> io_buffer [ 0 ] = 0x01; 69
for (n = 0; n < ARRAY_SIZE(smart_attributes); n++) 71
int i ; 72
for (i = 0; i < 11; i++) 73
s -> io_buffer [ 2 + i + ( n * 12 ) ] = smart_attributes [ n ] [ i ]; 74
s -> io_buffer [ 362 ] = 0x02 | ( s -> smart_autosave ? 0x80 : 0x00 ); 78
if ( s -> smart_selftest_count == 0 )  79
s -> io_buffer [ 363 ] = s -> smart_selftest_data [ 3 + ( s -> smart_selftest_count - 1 ) * 24 ]; 82
s -> io_buffer [ 364 ] = 0x20; 87
s -> io_buffer [ 365 ] = 0x01; 88
s -> io_buffer [ 367 ] = ( 1 << 4 | 1 << 3 | 1 ); 90
s -> io_buffer [ 368 ] = 0x03; 91
s -> io_buffer [ 369 ] = 0x00; 92
s -> io_buffer [ 370 ] = 0x01; 93
s -> io_buffer [ 372 ] = 0x02; 94
s -> io_buffer [ 373 ] = 0x36; 95
s -> io_buffer [ 374 ] = 0x01; 96
for (n = 0; n < 511; n++) 98
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 99
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 101
s -> status = READY_STAT | SEEK_STAT; 103
switch ( s -> sector )  109
memset ( s -> io_buffer , 0 , 0x200 ); 111
s -> io_buffer [ 0 ] = 0x01; 112
s -> io_buffer [ 1 ] = 0x00; 113
s -> io_buffer [ 452 ] = s -> smart_errors & 0xff; 114
s -> io_buffer [ 453 ] = ( s -> smart_errors & 0xff00 ) >> 8; 115
for (n = 0; n < 511; n++) 117
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 118
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 120
memset ( s -> io_buffer , 0 , 0x200 ); 123
s -> io_buffer [ 0 ] = 0x01; 124
if ( s -> smart_selftest_count == 0 )  125
s -> io_buffer [ 508 ] = 0; 126
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 135
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 137
s -> status = READY_STAT | SEEK_STAT; 142
ide_transfer_start ( s , s -> io_buffer , 0x200 , ide_transfer_stop ); 143
ide_set_irq ( s -> bus ); 144
switch ( s -> sector )  148
s -> smart_selftest_count ++; 152
if ( s -> smart_selftest_count > 21 )  153
s -> smart_selftest_count = 1; 154
n = 2 + ( s -> smart_selftest_count - 1 ) * 24; 156
s -> smart_selftest_data [ n ] = s -> sector; 157
s -> smart_selftest_data [ n + 1 ] = 0x00; 158
s -> smart_selftest_data [ n + 2 ] = 0x34; 159
s -> smart_selftest_data [ n + 3 ] = 0x12; 160
ide_abort_command ( s ); 169
------------------------------
480 /home/speedy/test/source2slice/NVD/CVE_2014_2894_PATCHED_cmd_smart.c s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ] 101
static bool CVE_2014_2894_PATCHED_cmd_smart(IDEState *s, uint8_t cmd) 3
int n ; 5
if ( s -> hcyl != 0xc2 || s -> lcyl != 0x4f )  7
if ( ! s -> smart_enabled && s -> feature != SMART_ENABLE )  11
switch ( s -> feature )  15
switch ( s -> sector )  25
s -> smart_autosave = 0; 27
s -> smart_autosave = 1; 30
if ( ! s -> smart_errors )  38
s -> hcyl = 0x2c; 42
s -> lcyl = 0xf4; 43
memset ( s -> io_buffer , 0 , 0x200 ); 48
s -> io_buffer [ 0 ] = 0x01; 49
for (n = 0; n < ARRAY_SIZE(smart_attributes); n++) 51
s -> io_buffer [ 2 + 0 + ( n * 12 ) ] = smart_attributes [ n ] [ 0 ]; 52
s -> io_buffer [ 2 + 1 + ( n * 12 ) ] = smart_attributes [ n ] [ 11 ]; 53
for (n = 0; n < 511; n++) 57
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 58
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 60
s -> status = READY_STAT | SEEK_STAT; 62
memset ( s -> io_buffer , 0 , 0x200 ); 68
s -> io_buffer [ 0 ] = 0x01; 69
for (n = 0; n < ARRAY_SIZE(smart_attributes); n++) 71
int i ; 72
for (i = 0; i < 11; i++) 73
s -> io_buffer [ 2 + i + ( n * 12 ) ] = smart_attributes [ n ] [ i ]; 74
s -> io_buffer [ 362 ] = 0x02 | ( s -> smart_autosave ? 0x80 : 0x00 ); 78
if ( s -> smart_selftest_count == 0 )  79
s -> io_buffer [ 363 ] = s -> smart_selftest_data [ 3 + ( s -> smart_selftest_count - 1 ) * 24 ]; 82
s -> io_buffer [ 364 ] = 0x20; 87
s -> io_buffer [ 365 ] = 0x01; 88
s -> io_buffer [ 367 ] = ( 1 << 4 | 1 << 3 | 1 ); 90
s -> io_buffer [ 368 ] = 0x03; 91
s -> io_buffer [ 369 ] = 0x00; 92
s -> io_buffer [ 370 ] = 0x01; 93
s -> io_buffer [ 372 ] = 0x02; 94
s -> io_buffer [ 373 ] = 0x36; 95
s -> io_buffer [ 374 ] = 0x01; 96
for (n = 0; n < 511; n++) 98
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 99
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 101
s -> status = READY_STAT | SEEK_STAT; 103
ide_transfer_start ( s , s -> io_buffer , 0x200 , ide_transfer_stop ); 104
ide_set_irq ( s -> bus ); 105
switch ( s -> sector )  109
memset ( s -> io_buffer , 0 , 0x200 ); 111
s -> io_buffer [ 0 ] = 0x01; 112
s -> io_buffer [ 1 ] = 0x00; 113
s -> io_buffer [ 452 ] = s -> smart_errors & 0xff; 114
s -> io_buffer [ 453 ] = ( s -> smart_errors & 0xff00 ) >> 8; 115
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 118
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 120
memset ( s -> io_buffer , 0 , 0x200 ); 123
s -> io_buffer [ 0 ] = 0x01; 124
if ( s -> smart_selftest_count == 0 )  125
s -> io_buffer [ 508 ] = 0; 126
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 135
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 137
s -> status = READY_STAT | SEEK_STAT; 142
ide_transfer_start ( s , s -> io_buffer , 0x200 , ide_transfer_stop ); 143
ide_set_irq ( s -> bus ); 144
switch ( s -> sector )  148
s -> smart_selftest_count ++; 152
if ( s -> smart_selftest_count > 21 )  153
s -> smart_selftest_count = 1; 154
n = 2 + ( s -> smart_selftest_count - 1 ) * 24; 156
s -> smart_selftest_data [ n ] = s -> sector; 157
s -> smart_selftest_data [ n + 1 ] = 0x00; 158
s -> smart_selftest_data [ n + 2 ] = 0x34; 159
s -> smart_selftest_data [ n + 3 ] = 0x12; 160
ide_abort_command ( s ); 169
------------------------------
481 /home/speedy/test/source2slice/NVD/CVE_2014_2894_PATCHED_cmd_smart.c s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ] 60
static bool CVE_2014_2894_PATCHED_cmd_smart(IDEState *s, uint8_t cmd) 3
int n ; 5
if ( s -> hcyl != 0xc2 || s -> lcyl != 0x4f )  7
if ( ! s -> smart_enabled && s -> feature != SMART_ENABLE )  11
switch ( s -> feature )  15
switch ( s -> sector )  25
s -> smart_autosave = 0; 27
s -> smart_autosave = 1; 30
if ( ! s -> smart_errors )  38
s -> hcyl = 0x2c; 42
s -> lcyl = 0xf4; 43
memset ( s -> io_buffer , 0 , 0x200 ); 48
s -> io_buffer [ 0 ] = 0x01; 49
for (n = 0; n < ARRAY_SIZE(smart_attributes); n++) 51
s -> io_buffer [ 2 + 0 + ( n * 12 ) ] = smart_attributes [ n ] [ 0 ]; 52
s -> io_buffer [ 2 + 1 + ( n * 12 ) ] = smart_attributes [ n ] [ 11 ]; 53
for (n = 0; n < 511; n++) 57
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 58
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 60
s -> status = READY_STAT | SEEK_STAT; 62
ide_transfer_start ( s , s -> io_buffer , 0x200 , ide_transfer_stop ); 63
ide_set_irq ( s -> bus ); 64
memset ( s -> io_buffer , 0 , 0x200 ); 68
s -> io_buffer [ 0 ] = 0x01; 69
s -> io_buffer [ 2 + i + ( n * 12 ) ] = smart_attributes [ n ] [ i ]; 74
s -> io_buffer [ 362 ] = 0x02 | ( s -> smart_autosave ? 0x80 : 0x00 ); 78
if ( s -> smart_selftest_count == 0 )  79
s -> io_buffer [ 363 ] = 0; 80
s -> io_buffer [ 363 ] = s -> smart_selftest_data [ 3 + ( s -> smart_selftest_count - 1 ) * 24 ]; 82
s -> io_buffer [ 364 ] = 0x20; 87
s -> io_buffer [ 365 ] = 0x01; 88
s -> io_buffer [ 367 ] = ( 1 << 4 | 1 << 3 | 1 ); 90
s -> io_buffer [ 368 ] = 0x03; 91
s -> io_buffer [ 369 ] = 0x00; 92
s -> io_buffer [ 370 ] = 0x01; 93
s -> io_buffer [ 372 ] = 0x02; 94
s -> io_buffer [ 373 ] = 0x36; 95
s -> io_buffer [ 374 ] = 0x01; 96
for (n = 0; n < 511; n++) 98
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 99
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 101
s -> status = READY_STAT | SEEK_STAT; 103
ide_transfer_start ( s , s -> io_buffer , 0x200 , ide_transfer_stop ); 104
ide_set_irq ( s -> bus ); 105
switch ( s -> sector )  109
memset ( s -> io_buffer , 0 , 0x200 ); 111
s -> io_buffer [ 0 ] = 0x01; 112
s -> io_buffer [ 1 ] = 0x00; 113
s -> io_buffer [ 452 ] = s -> smart_errors & 0xff; 114
s -> io_buffer [ 453 ] = ( s -> smart_errors & 0xff00 ) >> 8; 115
for (n = 0; n < 511; n++) 117
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 118
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 120
memset ( s -> io_buffer , 0 , 0x200 ); 123
s -> io_buffer [ 0 ] = 0x01; 124
if ( s -> smart_selftest_count == 0 )  125
s -> io_buffer [ 508 ] = 0; 126
for (n = 2; n < 506; n++) 129
s -> io_buffer [ n ] = s -> smart_selftest_data [ n ]; 130
for (n = 0; n < 511; n++) 134
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 135
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 137
s -> status = READY_STAT | SEEK_STAT; 142
ide_transfer_start ( s , s -> io_buffer , 0x200 , ide_transfer_stop ); 143
ide_set_irq ( s -> bus ); 144
switch ( s -> sector )  148
s -> smart_selftest_count ++; 152
if ( s -> smart_selftest_count > 21 )  153
s -> smart_selftest_count = 1; 154
n = 2 + ( s -> smart_selftest_count - 1 ) * 24; 156
s -> smart_selftest_data [ n ] = s -> sector; 157
s -> smart_selftest_data [ n + 1 ] = 0x00; 158
s -> smart_selftest_data [ n + 2 ] = 0x34; 159
s -> smart_selftest_data [ n + 3 ] = 0x12; 160
ide_abort_command ( s ); 169
------------------------------
482 /home/speedy/test/source2slice/NVD/CVE_2014_2894_VULN_cmd_smart.c s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ] 137
static bool CVE_2014_2894_VULN_cmd_smart(IDEState *s, uint8_t cmd) 3
int n ; 5
if ( s -> hcyl != 0xc2 || s -> lcyl != 0x4f )  7
if ( ! s -> smart_enabled && s -> feature != SMART_ENABLE )  11
switch ( s -> feature )  15
s -> smart_enabled = 0; 17
s -> smart_enabled = 1; 21
switch ( s -> sector )  25
s -> smart_autosave = 0; 27
s -> smart_autosave = 1; 30
if ( ! s -> smart_errors )  38
s -> hcyl = 0x2c; 42
s -> lcyl = 0xf4; 43
memset ( s -> io_buffer , 0 , 0x200 ); 48
s -> io_buffer [ 0 ] = 0x01; 49
for (n = 0; n < ARRAY_SIZE(smart_attributes); n++) 51
s -> io_buffer [ 2 + 0 + ( n * 12 ) ] = smart_attributes [ n ] [ 0 ]; 52
s -> io_buffer [ 2 + 1 + ( n * 12 ) ] = smart_attributes [ n ] [ 11 ]; 53
for (n = 0; n < 511; n++) 57
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 58
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 60
s -> status = READY_STAT | SEEK_STAT; 62
memset ( s -> io_buffer , 0 , 0x200 ); 68
s -> io_buffer [ 0 ] = 0x01; 69
for (n = 0; n < ARRAY_SIZE(smart_attributes); n++) 71
int i ; 72
for (i = 0; i < 11; i++) 73
s -> io_buffer [ 2 + i + ( n * 12 ) ] = smart_attributes [ n ] [ i ]; 74
s -> io_buffer [ 362 ] = 0x02 | ( s -> smart_autosave ? 0x80 : 0x00 ); 78
if ( s -> smart_selftest_count == 0 )  79
s -> io_buffer [ 363 ] = s -> smart_selftest_data [ 3 + ( s -> smart_selftest_count - 1 ) * 24 ]; 82
s -> io_buffer [ 364 ] = 0x20; 87
s -> io_buffer [ 365 ] = 0x01; 88
s -> io_buffer [ 367 ] = ( 1 << 4 | 1 << 3 | 1 ); 90
s -> io_buffer [ 368 ] = 0x03; 91
s -> io_buffer [ 369 ] = 0x00; 92
s -> io_buffer [ 370 ] = 0x01; 93
s -> io_buffer [ 372 ] = 0x02; 94
s -> io_buffer [ 373 ] = 0x36; 95
s -> io_buffer [ 374 ] = 0x01; 96
for (n = 0; n < 511; n++) 98
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 99
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 101
s -> status = READY_STAT | SEEK_STAT; 103
switch ( s -> sector )  109
memset ( s -> io_buffer , 0 , 0x200 ); 111
s -> io_buffer [ 0 ] = 0x01; 112
s -> io_buffer [ 1 ] = 0x00; 113
s -> io_buffer [ 452 ] = s -> smart_errors & 0xff; 114
s -> io_buffer [ 453 ] = ( s -> smart_errors & 0xff00 ) >> 8; 115
for (n = 0; n < 511; n++) 117
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 118
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 120
memset ( s -> io_buffer , 0 , 0x200 ); 123
s -> io_buffer [ 0 ] = 0x01; 124
if ( s -> smart_selftest_count == 0 )  125
s -> io_buffer [ 508 ] = 0; 126
s -> io_buffer [ 508 ] = s -> smart_selftest_count; 128
for (n = 2; n < 506; n++) 129
s -> io_buffer [ n ] = s -> smart_selftest_data [ n ]; 130
for (n = 0; n < 511; n++) 134
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 135
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 137
------------------------------
483 /home/speedy/test/source2slice/NVD/CVE_2014_2894_VULN_cmd_smart.c s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ] 120
static bool CVE_2014_2894_VULN_cmd_smart(IDEState *s, uint8_t cmd) 3
int n ; 5
if ( s -> hcyl != 0xc2 || s -> lcyl != 0x4f )  7
if ( ! s -> smart_enabled && s -> feature != SMART_ENABLE )  11
switch ( s -> feature )  15
s -> smart_enabled = 0; 17
s -> smart_enabled = 1; 21
switch ( s -> sector )  25
s -> smart_autosave = 0; 27
s -> smart_autosave = 1; 30
if ( ! s -> smart_errors )  38
s -> hcyl = 0x2c; 42
s -> lcyl = 0xf4; 43
memset ( s -> io_buffer , 0 , 0x200 ); 48
s -> io_buffer [ 0 ] = 0x01; 49
for (n = 0; n < ARRAY_SIZE(smart_attributes); n++) 51
s -> io_buffer [ 2 + 0 + ( n * 12 ) ] = smart_attributes [ n ] [ 0 ]; 52
s -> io_buffer [ 2 + 1 + ( n * 12 ) ] = smart_attributes [ n ] [ 11 ]; 53
for (n = 0; n < 511; n++) 57
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 58
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 60
s -> status = READY_STAT | SEEK_STAT; 62
memset ( s -> io_buffer , 0 , 0x200 ); 68
s -> io_buffer [ 0 ] = 0x01; 69
for (n = 0; n < ARRAY_SIZE(smart_attributes); n++) 71
int i ; 72
for (i = 0; i < 11; i++) 73
s -> io_buffer [ 2 + i + ( n * 12 ) ] = smart_attributes [ n ] [ i ]; 74
s -> io_buffer [ 362 ] = 0x02 | ( s -> smart_autosave ? 0x80 : 0x00 ); 78
if ( s -> smart_selftest_count == 0 )  79
s -> io_buffer [ 363 ] = s -> smart_selftest_data [ 3 + ( s -> smart_selftest_count - 1 ) * 24 ]; 82
s -> io_buffer [ 364 ] = 0x20; 87
s -> io_buffer [ 365 ] = 0x01; 88
s -> io_buffer [ 367 ] = ( 1 << 4 | 1 << 3 | 1 ); 90
s -> io_buffer [ 368 ] = 0x03; 91
s -> io_buffer [ 369 ] = 0x00; 92
s -> io_buffer [ 370 ] = 0x01; 93
s -> io_buffer [ 372 ] = 0x02; 94
s -> io_buffer [ 373 ] = 0x36; 95
s -> io_buffer [ 374 ] = 0x01; 96
for (n = 0; n < 511; n++) 98
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 99
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 101
s -> status = READY_STAT | SEEK_STAT; 103
switch ( s -> sector )  109
memset ( s -> io_buffer , 0 , 0x200 ); 111
s -> io_buffer [ 0 ] = 0x01; 112
s -> io_buffer [ 1 ] = 0x00; 113
s -> io_buffer [ 452 ] = s -> smart_errors & 0xff; 114
s -> io_buffer [ 453 ] = ( s -> smart_errors & 0xff00 ) >> 8; 115
for (n = 0; n < 511; n++) 117
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 118
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 120
memset ( s -> io_buffer , 0 , 0x200 ); 123
s -> io_buffer [ 0 ] = 0x01; 124
if ( s -> smart_selftest_count == 0 )  125
s -> io_buffer [ 508 ] = 0; 126
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 135
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 137
------------------------------
484 /home/speedy/test/source2slice/NVD/CVE_2014_2894_VULN_cmd_smart.c s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ] 101
static bool CVE_2014_2894_VULN_cmd_smart(IDEState *s, uint8_t cmd) 3
int n ; 5
if ( s -> hcyl != 0xc2 || s -> lcyl != 0x4f )  7
if ( ! s -> smart_enabled && s -> feature != SMART_ENABLE )  11
switch ( s -> feature )  15
s -> smart_enabled = 0; 17
s -> smart_enabled = 1; 21
switch ( s -> sector )  25
s -> smart_autosave = 0; 27
s -> smart_autosave = 1; 30
if ( ! s -> smart_errors )  38
s -> hcyl = 0x2c; 42
s -> lcyl = 0xf4; 43
memset ( s -> io_buffer , 0 , 0x200 ); 48
s -> io_buffer [ 0 ] = 0x01; 49
for (n = 0; n < ARRAY_SIZE(smart_attributes); n++) 51
s -> io_buffer [ 2 + 0 + ( n * 12 ) ] = smart_attributes [ n ] [ 0 ]; 52
s -> io_buffer [ 2 + 1 + ( n * 12 ) ] = smart_attributes [ n ] [ 11 ]; 53
for (n = 0; n < 511; n++) 57
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 58
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 60
s -> status = READY_STAT | SEEK_STAT; 62
memset ( s -> io_buffer , 0 , 0x200 ); 68
s -> io_buffer [ 0 ] = 0x01; 69
for (n = 0; n < ARRAY_SIZE(smart_attributes); n++) 71
int i ; 72
for (i = 0; i < 11; i++) 73
s -> io_buffer [ 2 + i + ( n * 12 ) ] = smart_attributes [ n ] [ i ]; 74
s -> io_buffer [ 362 ] = 0x02 | ( s -> smart_autosave ? 0x80 : 0x00 ); 78
if ( s -> smart_selftest_count == 0 )  79
s -> io_buffer [ 363 ] = s -> smart_selftest_data [ 3 + ( s -> smart_selftest_count - 1 ) * 24 ]; 82
s -> io_buffer [ 364 ] = 0x20; 87
s -> io_buffer [ 365 ] = 0x01; 88
s -> io_buffer [ 367 ] = ( 1 << 4 | 1 << 3 | 1 ); 90
s -> io_buffer [ 368 ] = 0x03; 91
s -> io_buffer [ 369 ] = 0x00; 92
s -> io_buffer [ 370 ] = 0x01; 93
s -> io_buffer [ 372 ] = 0x02; 94
s -> io_buffer [ 373 ] = 0x36; 95
s -> io_buffer [ 374 ] = 0x01; 96
for (n = 0; n < 511; n++) 98
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 99
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 101
s -> status = READY_STAT | SEEK_STAT; 103
ide_transfer_start ( s , s -> io_buffer , 0x200 , ide_transfer_stop ); 104
ide_set_irq ( s -> bus ); 105
switch ( s -> sector )  109
memset ( s -> io_buffer , 0 , 0x200 ); 111
s -> io_buffer [ 0 ] = 0x01; 112
s -> io_buffer [ 1 ] = 0x00; 113
s -> io_buffer [ 452 ] = s -> smart_errors & 0xff; 114
s -> io_buffer [ 453 ] = ( s -> smart_errors & 0xff00 ) >> 8; 115
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 118
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 120
memset ( s -> io_buffer , 0 , 0x200 ); 123
s -> io_buffer [ 0 ] = 0x01; 124
if ( s -> smart_selftest_count == 0 )  125
s -> io_buffer [ 508 ] = 0; 126
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 135
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 137
------------------------------
485 /home/speedy/test/source2slice/NVD/CVE_2014_2894_VULN_cmd_smart.c s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ] 60
static bool CVE_2014_2894_VULN_cmd_smart(IDEState *s, uint8_t cmd) 3
int n ; 5
if ( s -> hcyl != 0xc2 || s -> lcyl != 0x4f )  7
if ( ! s -> smart_enabled && s -> feature != SMART_ENABLE )  11
switch ( s -> feature )  15
s -> smart_enabled = 0; 17
s -> smart_enabled = 1; 21
switch ( s -> sector )  25
s -> smart_autosave = 0; 27
s -> smart_autosave = 1; 30
if ( ! s -> smart_errors )  38
s -> hcyl = 0x2c; 42
s -> lcyl = 0xf4; 43
memset ( s -> io_buffer , 0 , 0x200 ); 48
s -> io_buffer [ 0 ] = 0x01; 49
for (n = 0; n < ARRAY_SIZE(smart_attributes); n++) 51
s -> io_buffer [ 2 + 0 + ( n * 12 ) ] = smart_attributes [ n ] [ 0 ]; 52
s -> io_buffer [ 2 + 1 + ( n * 12 ) ] = smart_attributes [ n ] [ 11 ]; 53
for (n = 0; n < 511; n++) 57
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 58
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 60
s -> status = READY_STAT | SEEK_STAT; 62
ide_transfer_start ( s , s -> io_buffer , 0x200 , ide_transfer_stop ); 63
ide_set_irq ( s -> bus ); 64
memset ( s -> io_buffer , 0 , 0x200 ); 68
s -> io_buffer [ 0 ] = 0x01; 69
s -> io_buffer [ 2 + i + ( n * 12 ) ] = smart_attributes [ n ] [ i ]; 74
s -> io_buffer [ 362 ] = 0x02 | ( s -> smart_autosave ? 0x80 : 0x00 ); 78
if ( s -> smart_selftest_count == 0 )  79
s -> io_buffer [ 363 ] = 0; 80
s -> io_buffer [ 363 ] = s -> smart_selftest_data [ 3 + ( s -> smart_selftest_count - 1 ) * 24 ]; 82
s -> io_buffer [ 364 ] = 0x20; 87
s -> io_buffer [ 365 ] = 0x01; 88
s -> io_buffer [ 367 ] = ( 1 << 4 | 1 << 3 | 1 ); 90
s -> io_buffer [ 368 ] = 0x03; 91
s -> io_buffer [ 369 ] = 0x00; 92
s -> io_buffer [ 370 ] = 0x01; 93
s -> io_buffer [ 372 ] = 0x02; 94
s -> io_buffer [ 373 ] = 0x36; 95
s -> io_buffer [ 374 ] = 0x01; 96
for (n = 0; n < 511; n++) 98
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 99
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 101
s -> status = READY_STAT | SEEK_STAT; 103
ide_transfer_start ( s , s -> io_buffer , 0x200 , ide_transfer_stop ); 104
ide_set_irq ( s -> bus ); 105
switch ( s -> sector )  109
memset ( s -> io_buffer , 0 , 0x200 ); 111
s -> io_buffer [ 0 ] = 0x01; 112
s -> io_buffer [ 1 ] = 0x00; 113
s -> io_buffer [ 452 ] = s -> smart_errors & 0xff; 114
s -> io_buffer [ 453 ] = ( s -> smart_errors & 0xff00 ) >> 8; 115
for (n = 0; n < 511; n++) 117
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 118
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 120
memset ( s -> io_buffer , 0 , 0x200 ); 123
s -> io_buffer [ 0 ] = 0x01; 124
if ( s -> smart_selftest_count == 0 )  125
s -> io_buffer [ 508 ] = 0; 126
for (n = 2; n < 506; n++) 129
s -> io_buffer [ n ] = s -> smart_selftest_data [ n ]; 130
for (n = 0; n < 511; n++) 134
s -> io_buffer [ 511 ] += s -> io_buffer [ n ]; 135
s -> io_buffer [ 511 ] = 0x100 - s -> io_buffer [ 511 ]; 137
------------------------------
486 /home/speedy/test/source2slice/NVD/CVE_2014_3122_PATCHED_try_to_unmap_cluster.c end = address + CLUSTER_SIZE 20
static int CVE_2014_3122_PATCHED_try_to_unmap_cluster(unsigned long cursor, unsigned int *mapcount,
struct vm_area_struct *vma, struct page *check_page) 2
unsigned long address ; 12
unsigned long end ; 15
address = ( vma -> vm_start + cursor ) & CLUSTER_MASK; 19
end = address + CLUSTER_SIZE; 20
if ( end > vma -> vm_end )  23
mmun_end = end; 39
mmu_notifier_invalidate_range_start ( mm , mmun_start , mmun_end ); 40
for (; address < end; pte++, address += PAGE_SIZE) 57
mmu_notifier_invalidate_range_end ( mm , mmun_start , mmun_end ); 101
------------------------------
487 /home/speedy/test/source2slice/NVD/CVE_2014_3122_PATCHED_try_to_unmap_cluster.c address = ( vma -> vm_start + cursor ) & CLUSTER_MASK 19
static int CVE_2014_3122_PATCHED_try_to_unmap_cluster(unsigned long cursor, unsigned int *mapcount,
struct vm_area_struct *vma, struct page *check_page) 2
unsigned long address ; 12
address = ( vma -> vm_start + cursor ) & CLUSTER_MASK; 19
end = address + CLUSTER_SIZE; 20
if ( address < vma -> vm_start )  21
if ( end > vma -> vm_end )  23
pgd = pgd_offset ( mm , address ); 26
if ( ! pgd_present ( * pgd ) )  27
pud = pud_offset ( pgd , address ); 30
if ( ! pud_present ( * pud ) )  31
pmd = pmd_offset ( pud , address ); 34
if ( ! pmd_present ( * pmd ) )  35
mmun_start = address; 38
mmun_end = end; 39
mmu_notifier_invalidate_range_start ( mm , mmun_start , mmun_end ); 40
pte = pte_offset_map_lock ( mm , pmd , address , & ptl ); 52
for (; address < end; pte++, address += PAGE_SIZE) 57
if ( ! pte_present ( * pte ) )  58
page = vm_normal_page ( vma , address , * pte ); 60
BUG_ON ( ! page || PageAnon ( page ) ); 61
if ( page == check_page )  64
mlock_vma_page ( page ); 66
if ( trylock_page ( page ) )  68
mlock_vma_page ( page ); 74
unlock_page ( page ); 75
if ( ptep_clear_flush_young_notify ( vma , address , pte ) )  80
flush_cache_page ( vma , address , pte_pfn ( * pte ) ); 84
pteval = ptep_clear_flush ( vma , address , pte ); 85
if ( page -> index != linear_page_index ( vma , address ) )  88
set_pte_at ( mm , address , pte , pgoff_to_pte ( page -> index ) ); 89
if ( pte_dirty ( pteval ) )  92
set_page_dirty ( page ); 93
page_remove_rmap ( page ); 95
page_cache_release ( page ); 96
pte_unmap_unlock ( pte - 1 , ptl ); 100
mmu_notifier_invalidate_range_end ( mm , mmun_start , mmun_end ); 101
------------------------------
488 /home/speedy/test/source2slice/NVD/CVE_2014_3122_VULN_try_to_unmap_cluster.c end = address + CLUSTER_SIZE 20
static int CVE_2014_3122_VULN_try_to_unmap_cluster(unsigned long cursor, unsigned int *mapcount,
struct vm_area_struct *vma, struct page *check_page) 2
unsigned long address ; 12
unsigned long end ; 15
address = ( vma -> vm_start + cursor ) & CLUSTER_MASK; 19
end = address + CLUSTER_SIZE; 20
if ( end > vma -> vm_end )  23
mmun_end = end; 39
mmu_notifier_invalidate_range_start ( mm , mmun_start , mmun_end ); 40
for (; address < end; pte++, address += PAGE_SIZE) 57
mmu_notifier_invalidate_range_end ( mm , mmun_start , mmun_end ); 91
------------------------------
489 /home/speedy/test/source2slice/NVD/CVE_2014_3122_VULN_try_to_unmap_cluster.c address = ( vma -> vm_start + cursor ) & CLUSTER_MASK 19
static int CVE_2014_3122_VULN_try_to_unmap_cluster(unsigned long cursor, unsigned int *mapcount,
struct vm_area_struct *vma, struct page *check_page) 2
unsigned long address ; 12
address = ( vma -> vm_start + cursor ) & CLUSTER_MASK; 19
end = address + CLUSTER_SIZE; 20
if ( address < vma -> vm_start )  21
if ( end > vma -> vm_end )  23
pgd = pgd_offset ( mm , address ); 26
if ( ! pgd_present ( * pgd ) )  27
pud = pud_offset ( pgd , address ); 30
if ( ! pud_present ( * pud ) )  31
pmd = pmd_offset ( pud , address ); 34
if ( ! pmd_present ( * pmd ) )  35
mmun_start = address; 38
mmun_end = end; 39
mmu_notifier_invalidate_range_start ( mm , mmun_start , mmun_end ); 40
pte = pte_offset_map_lock ( mm , pmd , address , & ptl ); 52
for (; address < end; pte++, address += PAGE_SIZE) 57
if ( ! pte_present ( * pte ) )  58
page = vm_normal_page ( vma , address , * pte ); 60
BUG_ON ( ! page || PageAnon ( page ) ); 61
mlock_vma_page ( page ); 64
if ( page == check_page )  65
if ( ptep_clear_flush_young_notify ( vma , address , pte ) )  70
flush_cache_page ( vma , address , pte_pfn ( * pte ) ); 74
pteval = ptep_clear_flush ( vma , address , pte ); 75
if ( page -> index != linear_page_index ( vma , address ) )  78
set_pte_at ( mm , address , pte , pgoff_to_pte ( page -> index ) ); 79
if ( pte_dirty ( pteval ) )  82
set_page_dirty ( page ); 83
page_remove_rmap ( page ); 85
page_cache_release ( page ); 86
pte_unmap_unlock ( pte - 1 , ptl ); 90
mmu_notifier_invalidate_range_end ( mm , mmun_start , mmun_end ); 91
------------------------------
490 /home/speedy/test/source2slice/NVD/CVE_2014_3182_PATCHED_logi_dj_recv_add_djhid_device.c dj_dev -> reports_supported = get_unaligned_le32 ( dj_report -> report_params + DEVICE_PAIRED_RF_REPORT_TYPE ) 60
static void CVE_2014_3182_PATCHED_logi_dj_recv_add_djhid_device(struct dj_receiver_dev *djrcv_dev,
struct dj_report *dj_report) 2
struct hid_device * dj_hiddev ; 8
struct dj_device * dj_dev ; 9
if ( dj_report -> report_params [ DEVICE_PAIRED_PARAM_SPFUNCTION ] & SPFUNCTION_DEVICE_LIST_EMPTY )  16
if ( djrcv_dev -> paired_dj_devices [ dj_report -> device_index ] )  23
dj_hiddev = hid_allocate_device ( ); 29
if ( IS_ERR ( dj_hiddev ) )  30
dj_dev = kzalloc ( sizeof ( struct dj_device ) , GFP_KERNEL ); 52
if ( ! dj_dev )  54
dj_dev -> reports_supported = get_unaligned_le32 ( dj_report -> report_params + DEVICE_PAIRED_RF_REPORT_TYPE ); 60
dj_dev -> hdev = dj_hiddev; 62
dj_dev -> dj_receiver_dev = djrcv_dev; 63
dj_dev -> device_index = dj_report -> device_index; 64
dj_hiddev -> driver_data = dj_dev; 65
djrcv_dev -> paired_dj_devices [ dj_report -> device_index ] = dj_dev; 67
if ( hid_add_device ( dj_hiddev ) )  69
------------------------------
491 /home/speedy/test/source2slice/NVD/CVE_2014_3182_VULN_logi_dj_recv_add_djhid_device.c dj_dev -> reports_supported = get_unaligned_le32 ( dj_report -> report_params + DEVICE_PAIRED_RF_REPORT_TYPE ) 67
static void CVE_2014_3182_VULN_logi_dj_recv_add_djhid_device(struct dj_receiver_dev *djrcv_dev,
struct dj_report *dj_report) 2
struct hid_device * dj_hiddev ; 8
struct dj_device * dj_dev ; 9
if ( dj_report -> report_params [ DEVICE_PAIRED_PARAM_SPFUNCTION ] & SPFUNCTION_DEVICE_LIST_EMPTY )  16
if ( ( dj_report -> device_index < DJ_DEVICE_INDEX_MIN ) || ( dj_report -> device_index > DJ_DEVICE_INDEX_MAX ) )  23
if ( djrcv_dev -> paired_dj_devices [ dj_report -> device_index ] )  30
dj_hiddev = hid_allocate_device ( ); 36
if ( IS_ERR ( dj_hiddev ) )  37
dj_dev = kzalloc ( sizeof ( struct dj_device ) , GFP_KERNEL ); 59
if ( ! dj_dev )  61
dj_dev -> reports_supported = get_unaligned_le32 ( dj_report -> report_params + DEVICE_PAIRED_RF_REPORT_TYPE ); 67
dj_dev -> hdev = dj_hiddev; 69
dj_dev -> dj_receiver_dev = djrcv_dev; 70
dj_dev -> device_index = dj_report -> device_index; 71
dj_hiddev -> driver_data = dj_dev; 72
djrcv_dev -> paired_dj_devices [ dj_report -> device_index ] = dj_dev; 74
if ( hid_add_device ( dj_hiddev ) )  76
------------------------------
492 /home/speedy/test/source2slice/NVD/CVE_2014_3511_PATCHED_ssl23_get_client_hello.c p = p + csl + sil + cl 293
int CVE_2014_3511_PATCHED_ssl23_get_client_hello(SSL *s) 1
char buf_space [ 11 ] ; 3
unsigned char * p , * d , * d_len , * dd ; 17
unsigned int csl , sil , cl ; 19
int v [ 2 ] ; 22
if ( s -> state == SSL23_ST_SR_CLNT_HELLO_A )  24
if ( ! ssl3_setup_buffers ( s ) )  29
n = ssl23_read_bytes ( s , sizeof buf_space ); 31
if ( n != sizeof buf_space )  32
p = s -> packet; 34
if ( ( p [ 0 ] & 0x80 ) && ( p [ 2 ] == SSL2_MT_CLIENT_HELLO ) )  38
if ( ( p [ 3 ] == 0x00 ) && ( p [ 4 ] == 0x02 ) )  43
if ( p [ 3 ] == SSL3_VERSION_MAJOR )  50
if ( p [ 4 ] >= TLS1_VERSION_MINOR )  54
if ( p [ 4 ] >= TLS1_2_VERSION_MINOR && ! ( s -> options & SSL_OP_NO_TLSv1_2 ) )  56
s -> version = TLS1_2_VERSION; 59
s -> state = SSL23_ST_SR_CLNT_HELLO_B; 60
if ( p [ 4 ] >= TLS1_1_VERSION_MINOR && ! ( s -> options & SSL_OP_NO_TLSv1_1 ) )  62
s -> version = TLS1_1_VERSION; 65
s -> state = SSL23_ST_SR_CLNT_HELLO_B; 67
if ( ! ( s -> options & SSL_OP_NO_TLSv1 ) )  69
s -> version = TLS1_VERSION; 71
s -> state = SSL23_ST_SR_CLNT_HELLO_B; 73
if ( ! ( s -> options & SSL_OP_NO_SSLv3 ) )  75
s -> version = SSL3_VERSION; 77
s -> state = SSL23_ST_SR_CLNT_HELLO_B; 79
if ( ! ( s -> options & SSL_OP_NO_SSLv3 ) )  86
s -> version = SSL3_VERSION; 88
s -> state = SSL23_ST_SR_CLNT_HELLO_B; 90
if ( ( p [ 0 ] == SSL3_RT_HANDSHAKE ) && ( p [ 1 ] == SSL3_VERSION_MAJOR ) && ( p [ 5 ] == SSL3_MT_CLIENT_HELLO ) && ( ( p [ 3 ] == 0 && p [ 4 ] < 5 ) || ( p [ 9 ] >= p [ 1 ] ) ) )  97
if ( p [ 3 ] == 0 && p [ 4 ] < 6 )  116
if ( p [ 9 ] > SSL3_VERSION_MAJOR )  126
v [ 1 ] = 0xff; 127
v [ 1 ] = p [ 10 ]; 129
if ( v [ 1 ] >= TLS1_VERSION_MINOR )  130
if ( v [ 1 ] >= TLS1_2_VERSION_MINOR && ! ( s -> options & SSL_OP_NO_TLSv1_2 ) )  132
s -> version = TLS1_2_VERSION; 135
if ( v [ 1 ] >= TLS1_1_VERSION_MINOR && ! ( s -> options & SSL_OP_NO_TLSv1_1 ) )  138
s -> version = TLS1_1_VERSION; 141
if ( ! ( s -> options & SSL_OP_NO_TLSv1 ) )  144
s -> version = TLS1_VERSION; 146
if ( ! ( s -> options & SSL_OP_NO_SSLv3 ) )  149
s -> version = SSL3_VERSION; 151
if ( ! ( s -> options & SSL_OP_NO_SSLv3 ) )  158
s -> version = SSL3_VERSION; 160
if ( ! ( s -> options & SSL_OP_NO_TLSv1 ) )  163
s -> version = TLS1_VERSION; 167
if ( ( strncmp ( "GET " , ( char * ) p , 4 ) == 0 ) || ( strncmp ( "POST " , ( char * ) p , 5 ) == 0 ) || ( strncmp ( "HEAD " , ( char * ) p , 5 ) == 0 ) || ( strncmp ( "PUT " , ( char * ) p , 4 ) == 0 ) )  172
if ( strncmp ( "CONNECT" , ( char * ) p , 7 ) == 0 )  180
if ( FIPS_mode ( ) && ( s -> version < TLS1_VERSION ) )  188
if ( s -> state == SSL23_ST_SR_CLNT_HELLO_B )  196
p = s -> packet; 202
n = ( ( p [ 0 ] & 0x7f ) << 8 ) | p [ 1 ]; 218
if ( n > ( 1024 * 4 ) )  219
if ( n < 9 )  224
j = ssl23_read_bytes ( s , n + 2 ); 230
if ( j <= 0 )  234
p = s -> packet; 240
p += 5; 241
if ( ( csl + sil + cl + 11 ) != s -> packet_length )  246
p = p + csl + sil + cl; 293
while ( p < s -> packet + s -> packet_length )  294
* ( d ++ ) = * ( p ++ ); 296
i = ( d - ( unsigned char * ) s -> init_buf -> data ) - 4; 300
l2n3 ( ( long ) i , d_len ); 301
s -> s3 -> tmp . message_size = i; 306
if ( ! ssl_init_wbio_buffer ( s , 1 ) )  364
s -> state = SSL3_ST_SR_CLNT_HELLO_A; 367
s -> rstate = SSL_ST_READ_HEADER; 373
s -> packet_length = n; 374
if ( s -> s3 -> rbuf . buf == NULL )  375
if ( ! ssl3_setup_read_buffer ( s ) )  376
s -> packet = & ( s -> s3 -> rbuf . buf [ 0 ] ); 379
memcpy ( s -> packet , buf , n ); 380
s -> s3 -> rbuf . left = n; 381
s -> s3 -> rbuf . offset = 0; 382
s -> s3 -> rbuf . left = 0; 387
s -> s3 -> rbuf . offset = 0; 388
if ( s -> version == TLS1_2_VERSION )  390
s -> method = TLSv1_2_server_method ( ); 391
if ( s -> version == TLS1_1_VERSION )  392
if ( s -> version == TLS1_VERSION )  394
s -> handshake_func = s -> method -> ssl_accept; 401
s -> init_num = 0; 410
return ( SSL_accept ( s ) ) ; 413
------------------------------
493 /home/speedy/test/source2slice/NVD/CVE_2014_3511_VULN_ssl23_get_client_hello.c p = p + csl + sil + cl 277
int CVE_2014_3511_VULN_ssl23_get_client_hello(SSL *s) 1
char buf_space [ 11 ] ; 3
unsigned char * p , * d , * d_len , * dd ; 17
unsigned int csl , sil , cl ; 19
int v [ 2 ] ; 22
if ( s -> state == SSL23_ST_SR_CLNT_HELLO_A )  24
if ( ! ssl3_setup_buffers ( s ) )  29
n = ssl23_read_bytes ( s , sizeof buf_space ); 31
if ( n != sizeof buf_space )  32
p = s -> packet; 34
if ( ( p [ 0 ] & 0x80 ) && ( p [ 2 ] == SSL2_MT_CLIENT_HELLO ) )  38
if ( ( p [ 3 ] == 0x00 ) && ( p [ 4 ] == 0x02 ) )  43
if ( p [ 3 ] == SSL3_VERSION_MAJOR )  50
if ( p [ 4 ] >= TLS1_VERSION_MINOR )  54
if ( p [ 4 ] >= TLS1_2_VERSION_MINOR && ! ( s -> options & SSL_OP_NO_TLSv1_2 ) )  56
s -> version = TLS1_2_VERSION; 59
s -> state = SSL23_ST_SR_CLNT_HELLO_B; 60
if ( p [ 4 ] >= TLS1_1_VERSION_MINOR && ! ( s -> options & SSL_OP_NO_TLSv1_1 ) )  62
s -> version = TLS1_1_VERSION; 65
s -> state = SSL23_ST_SR_CLNT_HELLO_B; 67
if ( ! ( s -> options & SSL_OP_NO_TLSv1 ) )  69
s -> version = TLS1_VERSION; 71
s -> state = SSL23_ST_SR_CLNT_HELLO_B; 73
if ( ! ( s -> options & SSL_OP_NO_SSLv3 ) )  75
s -> version = SSL3_VERSION; 77
s -> state = SSL23_ST_SR_CLNT_HELLO_B; 79
if ( ! ( s -> options & SSL_OP_NO_SSLv3 ) )  86
s -> version = SSL3_VERSION; 88
s -> state = SSL23_ST_SR_CLNT_HELLO_B; 90
if ( ( p [ 0 ] == SSL3_RT_HANDSHAKE ) && ( p [ 1 ] == SSL3_VERSION_MAJOR ) && ( p [ 5 ] == SSL3_MT_CLIENT_HELLO ) && ( ( p [ 3 ] == 0 && p [ 4 ] < 5 ) || ( p [ 9 ] >= p [ 1 ] ) ) )  97
v [ 0 ] = p [ 1 ]; 107
if ( p [ 3 ] == 0 && p [ 4 ] < 6 )  116
if ( p [ 9 ] > SSL3_VERSION_MAJOR )  130
v [ 1 ] = 0xff; 131
v [ 1 ] = p [ 10 ]; 133
if ( v [ 1 ] >= TLS1_VERSION_MINOR )  134
if ( v [ 1 ] >= TLS1_2_VERSION_MINOR && ! ( s -> options & SSL_OP_NO_TLSv1_2 ) )  136
s -> version = TLS1_2_VERSION; 139
if ( v [ 1 ] >= TLS1_1_VERSION_MINOR && ! ( s -> options & SSL_OP_NO_TLSv1_1 ) )  142
s -> version = TLS1_1_VERSION; 145
if ( ! ( s -> options & SSL_OP_NO_TLSv1 ) )  148
s -> version = TLS1_VERSION; 150
if ( ! ( s -> options & SSL_OP_NO_SSLv3 ) )  153
s -> version = SSL3_VERSION; 155
if ( ! ( s -> options & SSL_OP_NO_SSLv3 ) )  162
s -> version = SSL3_VERSION; 164
if ( ! ( s -> options & SSL_OP_NO_TLSv1 ) )  167
s -> version = TLS1_VERSION; 171
if ( ( strncmp ( "GET " , ( char * ) p , 4 ) == 0 ) || ( strncmp ( "POST " , ( char * ) p , 5 ) == 0 ) || ( strncmp ( "HEAD " , ( char * ) p , 5 ) == 0 ) || ( strncmp ( "PUT " , ( char * ) p , 4 ) == 0 ) )  176
if ( strncmp ( "CONNECT" , ( char * ) p , 7 ) == 0 )  184
if ( FIPS_mode ( ) && ( s -> version < TLS1_VERSION ) )  192
if ( s -> state == SSL23_ST_SR_CLNT_HELLO_B )  200
p = s -> packet; 206
n = ( ( p [ 0 ] & 0x7f ) << 8 ) | p [ 1 ]; 210
if ( n > ( 1024 * 4 ) )  211
j = ssl23_read_bytes ( s , n + 2 ); 217
if ( j <= 0 )  218
p = s -> packet; 224
p += 5; 225
if ( ( csl + sil + cl + 11 ) != s -> packet_length )  230
p = p + csl + sil + cl; 277
while ( p < s -> packet + s -> packet_length )  278
* ( d ++ ) = * ( p ++ ); 280
i = ( d - ( unsigned char * ) s -> init_buf -> data ) - 4; 284
l2n3 ( ( long ) i , d_len ); 285
s -> s3 -> tmp . message_size = i; 290
if ( ! ssl_init_wbio_buffer ( s , 1 ) )  348
s -> state = SSL3_ST_SR_CLNT_HELLO_A; 351
s -> rstate = SSL_ST_READ_HEADER; 357
s -> packet_length = n; 358
if ( s -> s3 -> rbuf . buf == NULL )  359
if ( ! ssl3_setup_read_buffer ( s ) )  360
s -> packet = & ( s -> s3 -> rbuf . buf [ 0 ] ); 363
memcpy ( s -> packet , buf , n ); 364
s -> s3 -> rbuf . left = n; 365
s -> s3 -> rbuf . offset = 0; 366
s -> s3 -> rbuf . left = 0; 371
s -> s3 -> rbuf . offset = 0; 372
if ( s -> version == TLS1_2_VERSION )  374
s -> method = TLSv1_2_server_method ( ); 375
if ( s -> version == TLS1_1_VERSION )  376
if ( s -> version == TLS1_VERSION )  378
s -> handshake_func = s -> method -> ssl_accept; 385
s -> init_num = 0; 394
return ( SSL_accept ( s ) ) ; 397
------------------------------
494 /home/speedy/test/source2slice/NVD/CVE_2014_3523_PATCHED_winnt_accept.c context -> sa_client = ( void * ) ( context -> buff + context -> sa_server_len ) 359
static unsigned int __stdcall CVE_2014_3523_PATCHED_winnt_accept(void *lr_) 12
ap_listen_rec * lr = ( ap_listen_rec * ) lr_ ; 14
winnt_conn_ctx_t * context = NULL ; 16
DWORD BytesRead ; 17
SOCKET nlsd ; 18
LPFN_ACCEPTEX lpfnAcceptEx = NULL ; 19
LPFN_GETACCEPTEXSOCKADDRS lpfnGetAcceptExSockaddrs = NULL ; 20
GUID GuidAcceptEx = WSAID_ACCEPTEX ; 21
GUID GuidGetAcceptExSockaddrs = WSAID_GETACCEPTEXSOCKADDRS ; 22
core_server_config * core_sconf ; 23
const char * accf_name ; 24
int rv ; 25
int accf ; 26
int err_count = 0 ; 27
HANDLE events [ 3 ] ; 28
SOCKADDR_STORAGE ss_listen ; 30
core_sconf = ap_get_core_module_config ( ap_server_conf -> module_config ); 35
accf_name = apr_table_get ( core_sconf -> accf_map , lr -> protocol ); 36
if ( ! accf_name )  38
accf = 0; 39
accf_name = "none"; 40
if ( strcmp ( accf_name , "data" ) == 0 )  46
accf = 2; 47
if ( strcmp ( accf_name , "connect" ) == 0 )  48
accf = 1; 49
if ( strcmp ( accf_name , "none" ) == 0 )  50
accf = 0; 51
accf = 0; 53
if ( getsockname ( nlsd , ( struct sockaddr * ) & ss_listen , & namelen ) == SOCKET_ERROR )  64
if ( accf > 0 )  73
if ( WSAIoctl ( nlsd , SIO_GET_EXTENSION_FUNCTION_POINTER , & GuidAcceptEx , sizeof GuidAcceptEx , & lpfnAcceptEx , sizeof lpfnAcceptEx , & BytesRead , NULL , NULL ) == SOCKET_ERROR )  75
if ( WSAIoctl ( nlsd , SIO_GET_EXTENSION_FUNCTION_POINTER , & GuidGetAcceptExSockaddrs , sizeof GuidGetAcceptExSockaddrs , & lpfnGetAcceptExSockaddrs , sizeof lpfnGetAcceptExSockaddrs , & BytesRead , NULL , NULL ) == SOCKET_ERROR )  84
events [ 1 ] = exit_event; 94
events [ 2 ] = max_requests_per_child_event; 95
events [ 0 ] = exit_event; 102
events [ 1 ] = max_requests_per_child_event; 103
events [ 2 ] = CreateEvent ( NULL , FALSE , FALSE , NULL ); 104
rv = WSAEventSelect ( nlsd , events [ 2 ] , FD_ACCEPT ); 109
if ( rv )  110
while ( ! shutdown_in_progress )  123
if ( ! context )  124
int timeout ; 125
context = mpm_get_completion_context ( & timeout ); 127
if ( ! context )  128
if ( ! timeout )  129
if ( err_count > MAX_ACCEPTEX_ERR_COUNT )  132
if ( accf > 0 )  144
DWORD len ; 146
char * buf ; 147
if ( context -> accept_socket == INVALID_SOCKET )  151
context -> accept_socket = socket ( ss_listen . ss_family , SOCK_STREAM , IPPROTO_TCP ); 152
context -> socket_family = ss_listen . ss_family; 154
if ( context -> socket_family != ss_listen . ss_family )  156
closesocket ( context -> accept_socket ); 157
context -> accept_socket = socket ( ss_listen . ss_family , SOCK_STREAM , IPPROTO_TCP ); 158
context -> socket_family = ss_listen . ss_family; 160
if ( context -> accept_socket == INVALID_SOCKET )  167
if ( accf == 2 )  176
len = APR_BUCKET_BUFF_SIZE; 177
buf = apr_bucket_alloc ( len , context -> ba ); 178
len -= PADDED_ADDR_SIZE * 2; 179
len = 0; 182
buf = context -> buff; 183
if ( ! lpfnAcceptEx ( nlsd , context -> accept_socket , buf , len , PADDED_ADDR_SIZE , PADDED_ADDR_SIZE , & BytesRead , & context -> overlapped ) )  189
rv = apr_get_netos_error ( ); 192
if ( ( rv == APR_FROM_OS_ERROR ( WSAECONNRESET ) ) || ( rv == APR_FROM_OS_ERROR ( WSAEACCES ) ) )  193
apr_bucket_free ( buf ); 200
closesocket ( context -> accept_socket ); 201
context -> accept_socket = INVALID_SOCKET; 202
if ( ( rv == APR_FROM_OS_ERROR ( WSAEINVAL ) ) || ( rv == APR_FROM_OS_ERROR ( WSAENOTSOCK ) ) )  205
apr_bucket_free ( buf ); 216
closesocket ( context -> accept_socket ); 217
context -> accept_socket = INVALID_SOCKET; 218
if ( err_count > MAX_ACCEPTEX_ERR_COUNT )  220
err_count = 0; 229
accf = 0; 230
if ( ( rv != APR_FROM_OS_ERROR ( ERROR_IO_PENDING ) ) && ( rv != APR_FROM_OS_ERROR ( WSA_IO_PENDING ) ) )  234
apr_bucket_free ( buf ); 237
closesocket ( context -> accept_socket ); 238
context -> accept_socket = INVALID_SOCKET; 239
if ( err_count > MAX_ACCEPTEX_ERR_COUNT )  241
err_count = 0; 248
accf = 0; 249
err_count = 0; 255
events [ 0 ] = context -> overlapped . hEvent; 256
rv = WaitForMultipleObjectsEx ( 3 , events , FALSE , INFINITE , TRUE ); 259
while ( rv == WAIT_IO_COMPLETION )  260
if ( rv == WAIT_OBJECT_0 )  262
if ( ( context -> accept_socket != INVALID_SOCKET ) && ! GetOverlappedResult ( ( HANDLE ) context -> accept_socket , & context -> overlapped , & BytesRead , FALSE ) )  263
closesocket ( context -> accept_socket ); 270
context -> accept_socket = INVALID_SOCKET; 271
closesocket ( context -> accept_socket ); 276
apr_bucket_free ( buf ); 279
if ( context -> accept_socket == INVALID_SOCKET )  283
apr_bucket_free ( buf ); 285
err_count = 0; 289
if ( setsockopt ( context -> accept_socket , SOL_SOCKET , SO_UPDATE_ACCEPT_CONTEXT , ( char * ) & nlsd , sizeof ( nlsd ) ) )  296
lpfnGetAcceptExSockaddrs ( buf , len , PADDED_ADDR_SIZE , PADDED_ADDR_SIZE , & context -> sa_server , & context -> sa_server_len , & context -> sa_client , & context -> sa_client_len ); 308
if ( accf == 2 && BytesRead )  315
apr_bucket * b ; 317
b = apr_bucket_heap_create ( buf , APR_BUCKET_BUFF_SIZE , apr_bucket_free , context -> ba ); 318
b -> length = BytesRead; 321
context -> overlapped . Pointer = b; 322
apr_bucket_free ( buf ); 326
context -> overlapped . Pointer = NULL; 328
if ( context -> accept_socket != INVALID_SOCKET )  334
closesocket ( context -> accept_socket ); 335
rv = WaitForMultipleObjectsEx ( 3 , events , FALSE , INFINITE , TRUE ); 345
while ( rv == WAIT_IO_COMPLETION )  346
if ( rv != WAIT_OBJECT_0 + 2 )  349
context -> sa_server = ( void * ) context -> buff; 356
context -> sa_server_len = sizeof ( context -> buff ) / 2; 357
context -> sa_client_len = context -> sa_server_len; 358
context -> sa_client = ( void * ) ( context -> buff + context -> sa_server_len ); 359
context -> accept_socket = accept ( nlsd , context -> sa_server , & context -> sa_server_len ); 362
if ( context -> accept_socket == INVALID_SOCKET )  365
rv = apr_get_netos_error ( ); 367
if ( rv == APR_FROM_OS_ERROR ( WSAECONNRESET ) || rv == APR_FROM_OS_ERROR ( WSAEINPROGRESS ) || rv == APR_FROM_OS_ERROR ( WSAEWOULDBLOCK ) )  368
if ( rv == APR_FROM_OS_ERROR ( WSAEMFILE ) || rv == APR_FROM_OS_ERROR ( WSAENOBUFS ) )  382
if ( err_count > MAX_ACCEPTEX_ERR_COUNT )  387
WSAEventSelect ( context -> accept_socket , 0 , 0 ); 402
context -> overlapped . Pointer = NULL; 403
err_count = 0; 404
context -> sa_server_len = sizeof ( context -> buff ) / 2; 406
if ( getsockname ( context -> accept_socket , context -> sa_server , & context -> sa_server_len ) == SOCKET_ERROR )  407
if ( ( getpeername ( context -> accept_socket , context -> sa_client , & context -> sa_client_len ) ) == SOCKET_ERROR )  413
memset ( & context -> sa_client , '\0' , sizeof ( context -> sa_client ) ); 417
sockinfo . os_sock = & context -> accept_socket; 421
sockinfo . local = context -> sa_server; 422
sockinfo . remote = context -> sa_client; 423
sockinfo . family = context -> sa_server -> sa_family; 424
sockinfo . type = SOCK_STREAM; 425
sockinfo . protocol = IPPROTO_TCP; 426
ioctlsocket ( context -> accept_socket , FIONBIO , & zero ); 432
setsockopt ( context -> accept_socket , SOL_SOCKET , SO_RCVTIMEO , ( char * ) & zero , sizeof ( zero ) ); 433
setsockopt ( context -> accept_socket , SOL_SOCKET , SO_SNDTIMEO , ( char * ) & zero , sizeof ( zero ) ); 435
apr_os_sock_make ( & context -> sock , & sockinfo , context -> ptrans ); 437
PostQueuedCompletionStatus ( ThreadDispatchIOCP , BytesRead , IOCP_CONNECTION_ACCEPTED , & context -> overlapped ); 442
context = NULL; 445
CloseHandle ( events [ 2 ] ); 448
------------------------------
495 /home/speedy/test/source2slice/NVD/CVE_2014_3523_VULN_winnt_accept.c context -> sa_client = ( void * ) ( context -> buff + context -> sa_server_len ) 355
static unsigned int __stdcall CVE_2014_3523_VULN_winnt_accept(void *lr_) 12
ap_listen_rec * lr = ( ap_listen_rec * ) lr_ ; 14
winnt_conn_ctx_t * context = NULL ; 16
DWORD BytesRead ; 17
SOCKET nlsd ; 18
LPFN_ACCEPTEX lpfnAcceptEx = NULL ; 19
LPFN_GETACCEPTEXSOCKADDRS lpfnGetAcceptExSockaddrs = NULL ; 20
GUID GuidAcceptEx = WSAID_ACCEPTEX ; 21
GUID GuidGetAcceptExSockaddrs = WSAID_GETACCEPTEXSOCKADDRS ; 22
core_server_config * core_sconf ; 23
const char * accf_name ; 24
int rv ; 25
int accf ; 26
int err_count = 0 ; 27
HANDLE events [ 3 ] ; 28
SOCKADDR_STORAGE ss_listen ; 30
core_sconf = ap_get_core_module_config ( ap_server_conf -> module_config ); 35
accf_name = apr_table_get ( core_sconf -> accf_map , lr -> protocol ); 36
if ( ! accf_name )  38
accf = 0; 39
accf_name = "none"; 40
if ( strcmp ( accf_name , "data" ) == 0 )  46
accf = 2; 47
if ( strcmp ( accf_name , "connect" ) == 0 )  48
accf = 1; 49
if ( strcmp ( accf_name , "none" ) == 0 )  50
accf = 0; 51
accf = 0; 53
if ( getsockname ( nlsd , ( struct sockaddr * ) & ss_listen , & namelen ) == SOCKET_ERROR )  64
if ( accf > 0 )  73
if ( WSAIoctl ( nlsd , SIO_GET_EXTENSION_FUNCTION_POINTER , & GuidAcceptEx , sizeof GuidAcceptEx , & lpfnAcceptEx , sizeof lpfnAcceptEx , & BytesRead , NULL , NULL ) == SOCKET_ERROR )  75
if ( WSAIoctl ( nlsd , SIO_GET_EXTENSION_FUNCTION_POINTER , & GuidGetAcceptExSockaddrs , sizeof GuidGetAcceptExSockaddrs , & lpfnGetAcceptExSockaddrs , sizeof lpfnGetAcceptExSockaddrs , & BytesRead , NULL , NULL ) == SOCKET_ERROR )  84
events [ 1 ] = exit_event; 94
events [ 2 ] = max_requests_per_child_event; 95
events [ 0 ] = exit_event; 102
events [ 1 ] = max_requests_per_child_event; 103
events [ 2 ] = CreateEvent ( NULL , FALSE , FALSE , NULL ); 104
rv = WSAEventSelect ( nlsd , events [ 2 ] , FD_ACCEPT ); 109
if ( rv )  110
while ( ! shutdown_in_progress )  123
if ( ! context )  124
int timeout ; 125
context = mpm_get_completion_context ( & timeout ); 127
if ( ! context )  128
if ( ! timeout )  129
if ( err_count > MAX_ACCEPTEX_ERR_COUNT )  132
if ( accf > 0 )  144
DWORD len ; 146
char * buf ; 147
if ( context -> accept_socket == INVALID_SOCKET )  151
context -> accept_socket = socket ( ss_listen . ss_family , SOCK_STREAM , IPPROTO_TCP ); 152
context -> socket_family = ss_listen . ss_family; 154
if ( context -> socket_family != ss_listen . ss_family )  156
closesocket ( context -> accept_socket ); 157
context -> accept_socket = socket ( ss_listen . ss_family , SOCK_STREAM , IPPROTO_TCP ); 158
context -> socket_family = ss_listen . ss_family; 160
if ( context -> accept_socket == INVALID_SOCKET )  167
if ( accf == 2 )  176
len = APR_BUCKET_BUFF_SIZE; 177
buf = apr_bucket_alloc ( len , context -> ba ); 178
len -= PADDED_ADDR_SIZE * 2; 179
len = 0; 182
buf = context -> buff; 183
if ( ! lpfnAcceptEx ( nlsd , context -> accept_socket , buf , len , PADDED_ADDR_SIZE , PADDED_ADDR_SIZE , & BytesRead , & context -> overlapped ) )  189
rv = apr_get_netos_error ( ); 192
if ( ( rv == APR_FROM_OS_ERROR ( WSAECONNRESET ) ) || ( rv == APR_FROM_OS_ERROR ( WSAEACCES ) ) )  193
apr_bucket_free ( buf ); 200
closesocket ( context -> accept_socket ); 201
context -> accept_socket = INVALID_SOCKET; 202
if ( ( rv == APR_FROM_OS_ERROR ( WSAEINVAL ) ) || ( rv == APR_FROM_OS_ERROR ( WSAENOTSOCK ) ) )  205
apr_bucket_free ( buf ); 216
closesocket ( context -> accept_socket ); 217
context -> accept_socket = INVALID_SOCKET; 218
if ( err_count > MAX_ACCEPTEX_ERR_COUNT )  220
err_count = 0; 229
accf = 0; 230
if ( ( rv != APR_FROM_OS_ERROR ( ERROR_IO_PENDING ) ) && ( rv != APR_FROM_OS_ERROR ( WSA_IO_PENDING ) ) )  234
apr_bucket_free ( buf ); 237
closesocket ( context -> accept_socket ); 238
context -> accept_socket = INVALID_SOCKET; 239
if ( err_count > MAX_ACCEPTEX_ERR_COUNT )  241
err_count = 0; 248
accf = 0; 249
err_count = 0; 255
events [ 0 ] = context -> overlapped . hEvent; 256
rv = WaitForMultipleObjectsEx ( 3 , events , FALSE , INFINITE , TRUE ); 259
while ( rv == WAIT_IO_COMPLETION )  260
if ( rv == WAIT_OBJECT_0 )  262
if ( ( context -> accept_socket != INVALID_SOCKET ) && ! GetOverlappedResult ( ( HANDLE ) context -> accept_socket , & context -> overlapped , & BytesRead , FALSE ) )  263
closesocket ( context -> accept_socket ); 270
context -> accept_socket = INVALID_SOCKET; 271
closesocket ( context -> accept_socket ); 276
apr_bucket_free ( buf ); 279
if ( context -> accept_socket == INVALID_SOCKET )  283
apr_bucket_free ( buf ); 285
err_count = 0; 289
if ( setsockopt ( context -> accept_socket , SOL_SOCKET , SO_UPDATE_ACCEPT_CONTEXT , ( char * ) & nlsd , sizeof ( nlsd ) ) )  296
lpfnGetAcceptExSockaddrs ( buf , len , PADDED_ADDR_SIZE , PADDED_ADDR_SIZE , & context -> sa_server , & context -> sa_server_len , & context -> sa_client , & context -> sa_client_len ); 308
if ( accf == 2 && BytesRead )  315
apr_bucket * b ; 317
b = apr_bucket_heap_create ( buf , APR_BUCKET_BUFF_SIZE , apr_bucket_free , context -> ba ); 318
b -> length = BytesRead; 321
context -> overlapped . Pointer = b; 322
context -> overlapped . Pointer = NULL; 325
if ( context -> accept_socket != INVALID_SOCKET )  330
closesocket ( context -> accept_socket ); 331
rv = WaitForMultipleObjectsEx ( 3 , events , FALSE , INFINITE , TRUE ); 341
while ( rv == WAIT_IO_COMPLETION )  342
if ( rv != WAIT_OBJECT_0 + 2 )  345
context -> sa_server = ( void * ) context -> buff; 352
context -> sa_server_len = sizeof ( context -> buff ) / 2; 353
context -> sa_client_len = context -> sa_server_len; 354
context -> sa_client = ( void * ) ( context -> buff + context -> sa_server_len ); 355
context -> accept_socket = accept ( nlsd , context -> sa_server , & context -> sa_server_len ); 358
if ( context -> accept_socket == INVALID_SOCKET )  361
rv = apr_get_netos_error ( ); 363
if ( rv == APR_FROM_OS_ERROR ( WSAECONNRESET ) || rv == APR_FROM_OS_ERROR ( WSAEINPROGRESS ) || rv == APR_FROM_OS_ERROR ( WSAEWOULDBLOCK ) )  364
if ( rv == APR_FROM_OS_ERROR ( WSAEMFILE ) || rv == APR_FROM_OS_ERROR ( WSAENOBUFS ) )  378
if ( err_count > MAX_ACCEPTEX_ERR_COUNT )  383
WSAEventSelect ( context -> accept_socket , 0 , 0 ); 398
context -> overlapped . Pointer = NULL; 399
err_count = 0; 400
context -> sa_server_len = sizeof ( context -> buff ) / 2; 402
if ( getsockname ( context -> accept_socket , context -> sa_server , & context -> sa_server_len ) == SOCKET_ERROR )  403
if ( ( getpeername ( context -> accept_socket , context -> sa_client , & context -> sa_client_len ) ) == SOCKET_ERROR )  409
memset ( & context -> sa_client , '\0' , sizeof ( context -> sa_client ) ); 413
sockinfo . os_sock = & context -> accept_socket; 417
sockinfo . local = context -> sa_server; 418
sockinfo . remote = context -> sa_client; 419
sockinfo . family = context -> sa_server -> sa_family; 420
sockinfo . type = SOCK_STREAM; 421
sockinfo . protocol = IPPROTO_TCP; 422
ioctlsocket ( context -> accept_socket , FIONBIO , & zero ); 428
setsockopt ( context -> accept_socket , SOL_SOCKET , SO_RCVTIMEO , ( char * ) & zero , sizeof ( zero ) ); 429
setsockopt ( context -> accept_socket , SOL_SOCKET , SO_SNDTIMEO , ( char * ) & zero , sizeof ( zero ) ); 431
apr_os_sock_make ( & context -> sock , & sockinfo , context -> ptrans ); 433
PostQueuedCompletionStatus ( ThreadDispatchIOCP , BytesRead , IOCP_CONNECTION_ACCEPTED , & context -> overlapped ); 438
context = NULL; 441
CloseHandle ( events [ 2 ] ); 444
------------------------------
496 /home/speedy/test/source2slice/NVD/CVE_2014_3537_PATCHED_get_file.c plen = len - ( ptr - filename ) 147
static char *				/* O  - Real filename */
CVE_2014_3537_PATCHED_get_file(cupsd_client_t *con,		/* I  - Client connection */
struct stat    *filestats,	/* O  - File information */
char           *filename,	/* IO - Filename buffer */
int            len)		/* I  - Buffer length */ 8
int status ; 9
char * ptr ; 10
int plen ; 11
char language [ 7 ] ; 12
language [ 0 ] = '\0'; 19
if ( ! strncmp ( con -> uri , "/ppd/" , 5 ) )  21
if ( ! strncmp ( con -> uri , "/rss/" , 5 ) && ! strchr ( con -> uri + 5 , '/' ) )  23
if ( ! strncmp ( con -> uri , "/admin/conf/" , 12 ) )  25
if ( ! strncmp ( con -> uri , "/admin/log/" , 11 ) )  27
if ( ! strncmp ( con -> uri + 11 , "access_log" , 10 ) && AccessLog [ 0 ] == '/' )  29
if ( ! strncmp ( con -> uri + 11 , "error_log" , 9 ) && ErrorLog [ 0 ] == '/' )  31
if ( ! strncmp ( con -> uri + 11 , "page_log" , 8 ) && PageLog [ 0 ] == '/' )  33
if ( con -> language )  38
snprintf ( language , sizeof ( language ) , "/%s" , con -> language -> language ); 40
snprintf ( filename , len , "%s%s" , DocumentRoot , con -> uri ); 44
if ( ( ptr = strchr ( filename , '?' ) ) != NULL )  46
* ptr = '\0'; 47
if ( ( status = stat ( filename , filestats ) ) != 0 && language [ 0 ] && strncmp ( con -> uri , "/ppd/" , 5 ) && strncmp ( con -> uri , "/admin/conf/" , 12 ) && strncmp ( con -> uri , "/admin/log/" , 11 ) )  54
language [ 3 ] = '\0'; 63
snprintf ( filename , len , "%s%s%s" , DocumentRoot , language , con -> uri ); 64
if ( ( ptr = strchr ( filename , '?' ) ) != NULL )  66
* ptr = '\0'; 67
if ( ( status = lstat ( filename , filestats ) ) != 0 )  69
language [ 0 ] = '\0'; 75
snprintf ( filename , len , "%s%s" , DocumentRoot , con -> uri ); 76
if ( ( ptr = strchr ( filename , '?' ) ) != NULL )  78
* ptr = '\0'; 79
status = lstat ( filename , filestats ); 81
if ( ! status && S_ISLNK ( filestats -> st_mode ) )  89
if ( ! status && ! ( filestats -> st_mode & S_IROTH ) )  100
if ( ! status && S_ISDIR ( filestats -> st_mode ) )  110
if ( status && language [ 0 ] )  125
if ( language [ 3 ] )  131
language [ 0 ] = '\0'; 132
language [ 0 ] = '\0'; 134
snprintf ( filename , len , "%s%s%s" , DocumentRoot , language , con -> uri ); 141
if ( ( ptr = strchr ( filename , '?' ) ) != NULL )  143
* ptr = '\0'; 144
ptr = filename + strlen ( filename ); 146
plen = len - ( ptr - filename ); 147
strlcpy ( ptr , "index.html" , plen ); 149
status = stat ( filename , filestats ); 150
if ( status )  153
strlcpy ( ptr , "index.class" , plen ); 155
status = stat ( filename , filestats ); 156
if ( status )  161
strlcpy ( ptr , "index.pl" , plen ); 163
status = stat ( filename , filestats ); 164
if ( status )  169
strlcpy ( ptr , "index.php" , plen ); 171
status = stat ( filename , filestats ); 172
if ( status )  177
strlcpy ( ptr , "index.pyc" , plen ); 179
status = stat ( filename , filestats ); 180
if ( status )  183
strlcpy ( ptr , "index.py" , plen ); 185
status = stat ( filename , filestats ); 186
while ( status && language [ 0 ] )  191
------------------------------
497 /home/speedy/test/source2slice/NVD/CVE_2014_3537_PATCHED_get_file.c ptr = filename + strlen ( filename ) 146
static char *				/* O  - Real filename */
CVE_2014_3537_PATCHED_get_file(cupsd_client_t *con,		/* I  - Client connection */
struct stat    *filestats,	/* O  - File information */
char           *filename,	/* IO - Filename buffer */
int            len)		/* I  - Buffer length */ 8
int status ; 9
char * ptr ; 10
char language [ 7 ] ; 12
language [ 0 ] = '\0'; 19
if ( ! strncmp ( con -> uri , "/ppd/" , 5 ) )  21
if ( ! strncmp ( con -> uri , "/rss/" , 5 ) && ! strchr ( con -> uri + 5 , '/' ) )  23
if ( ! strncmp ( con -> uri , "/admin/conf/" , 12 ) )  25
if ( ! strncmp ( con -> uri , "/admin/log/" , 11 ) )  27
if ( ! strncmp ( con -> uri + 11 , "access_log" , 10 ) && AccessLog [ 0 ] == '/' )  29
if ( ! strncmp ( con -> uri + 11 , "error_log" , 9 ) && ErrorLog [ 0 ] == '/' )  31
if ( ! strncmp ( con -> uri + 11 , "page_log" , 8 ) && PageLog [ 0 ] == '/' )  33
if ( con -> language )  38
snprintf ( language , sizeof ( language ) , "/%s" , con -> language -> language ); 40
snprintf ( filename , len , "%s%s" , DocumentRoot , con -> uri ); 44
if ( ( status = stat ( filename , filestats ) ) != 0 && language [ 0 ] && strncmp ( con -> uri , "/ppd/" , 5 ) && strncmp ( con -> uri , "/admin/conf/" , 12 ) && strncmp ( con -> uri , "/admin/log/" , 11 ) )  54
language [ 3 ] = '\0'; 63
snprintf ( filename , len , "%s%s%s" , DocumentRoot , language , con -> uri ); 64
if ( ( status = lstat ( filename , filestats ) ) != 0 )  69
language [ 0 ] = '\0'; 75
snprintf ( filename , len , "%s%s" , DocumentRoot , con -> uri ); 76
status = lstat ( filename , filestats ); 81
if ( ! status && S_ISLNK ( filestats -> st_mode ) )  89
if ( ! status && ! ( filestats -> st_mode & S_IROTH ) )  100
if ( ! status && S_ISDIR ( filestats -> st_mode ) )  110
if ( status && language [ 0 ] )  125
if ( language [ 3 ] )  131
language [ 0 ] = '\0'; 132
language [ 0 ] = '\0'; 134
snprintf ( filename , len , "%s%s%s" , DocumentRoot , language , con -> uri ); 141
ptr = filename + strlen ( filename ); 146
plen = len - ( ptr - filename ); 147
strlcpy ( ptr , "index.html" , plen ); 149
status = stat ( filename , filestats ); 150
if ( status )  153
strlcpy ( ptr , "index.class" , plen ); 155
status = stat ( filename , filestats ); 156
if ( status )  161
strlcpy ( ptr , "index.pl" , plen ); 163
status = stat ( filename , filestats ); 164
if ( status )  169
strlcpy ( ptr , "index.php" , plen ); 171
status = stat ( filename , filestats ); 172
if ( status )  177
strlcpy ( ptr , "index.pyc" , plen ); 179
status = stat ( filename , filestats ); 180
if ( status )  183
strlcpy ( ptr , "index.py" , plen ); 185
status = stat ( filename , filestats ); 186
while ( status && language [ 0 ] )  191
------------------------------
498 /home/speedy/test/source2slice/NVD/CVE_2014_3537_VULN_get_file.c plen = len - ( ptr - filename ) 126
static char *				/* O  - Real filename */
CVE_2014_3537_VULN_get_file(cupsd_client_t *con,		/* I  - Client connection */
struct stat    *filestats,	/* O  - File information */
char           *filename,	/* IO - Filename buffer */
int            len)		/* I  - Buffer length */ 8
int status ; 9
char * ptr ; 10
int plen ; 11
char language [ 7 ] ; 12
language [ 0 ] = '\0'; 19
if ( ! strncmp ( con -> uri , "/ppd/" , 5 ) )  21
if ( ! strncmp ( con -> uri , "/rss/" , 5 ) && ! strchr ( con -> uri + 5 , '/' ) )  23
if ( ! strncmp ( con -> uri , "/admin/conf/" , 12 ) )  25
if ( ! strncmp ( con -> uri , "/admin/log/" , 11 ) )  27
if ( ! strncmp ( con -> uri + 11 , "access_log" , 10 ) && AccessLog [ 0 ] == '/' )  29
if ( ! strncmp ( con -> uri + 11 , "error_log" , 9 ) && ErrorLog [ 0 ] == '/' )  31
if ( ! strncmp ( con -> uri + 11 , "page_log" , 8 ) && PageLog [ 0 ] == '/' )  33
if ( con -> language )  38
snprintf ( language , sizeof ( language ) , "/%s" , con -> language -> language ); 40
snprintf ( filename , len , "%s%s" , DocumentRoot , con -> uri ); 44
if ( ( ptr = strchr ( filename , '?' ) ) != NULL )  46
* ptr = '\0'; 47
if ( ( status = stat ( filename , filestats ) ) != 0 && language [ 0 ] && strncmp ( con -> uri , "/ppd/" , 5 ) && strncmp ( con -> uri , "/admin/conf/" , 12 ) && strncmp ( con -> uri , "/admin/log/" , 11 ) )  54
language [ 3 ] = '\0'; 63
snprintf ( filename , len , "%s%s%s" , DocumentRoot , language , con -> uri ); 64
if ( ( ptr = strchr ( filename , '?' ) ) != NULL )  66
* ptr = '\0'; 67
if ( ( status = stat ( filename , filestats ) ) != 0 )  69
language [ 0 ] = '\0'; 75
snprintf ( filename , len , "%s%s" , DocumentRoot , con -> uri ); 76
if ( ( ptr = strchr ( filename , '?' ) ) != NULL )  78
* ptr = '\0'; 79
status = stat ( filename , filestats ); 81
if ( ! status && S_ISDIR ( filestats -> st_mode ) )  89
if ( status && language [ 0 ] )  104
if ( language [ 3 ] )  110
language [ 0 ] = '\0'; 111
language [ 0 ] = '\0'; 113
snprintf ( filename , len , "%s%s%s" , DocumentRoot , language , con -> uri ); 120
if ( ( ptr = strchr ( filename , '?' ) ) != NULL )  122
* ptr = '\0'; 123
ptr = filename + strlen ( filename ); 125
plen = len - ( ptr - filename ); 126
strlcpy ( ptr , "index.html" , plen ); 128
status = stat ( filename , filestats ); 129
if ( status )  132
strlcpy ( ptr , "index.class" , plen ); 134
status = stat ( filename , filestats ); 135
if ( status )  140
strlcpy ( ptr , "index.pl" , plen ); 142
status = stat ( filename , filestats ); 143
if ( status )  148
strlcpy ( ptr , "index.php" , plen ); 150
status = stat ( filename , filestats ); 151
if ( status )  156
strlcpy ( ptr , "index.pyc" , plen ); 158
status = stat ( filename , filestats ); 159
if ( status )  162
strlcpy ( ptr , "index.py" , plen ); 164
status = stat ( filename , filestats ); 165
while ( status && language [ 0 ] )  170
------------------------------
499 /home/speedy/test/source2slice/NVD/CVE_2014_3537_VULN_get_file.c ptr = filename + strlen ( filename ) 125
static char *				/* O  - Real filename */
CVE_2014_3537_VULN_get_file(cupsd_client_t *con,		/* I  - Client connection */
struct stat    *filestats,	/* O  - File information */
char           *filename,	/* IO - Filename buffer */
int            len)		/* I  - Buffer length */ 8
int status ; 9
char * ptr ; 10
char language [ 7 ] ; 12
language [ 0 ] = '\0'; 19
if ( ! strncmp ( con -> uri , "/ppd/" , 5 ) )  21
if ( ! strncmp ( con -> uri , "/rss/" , 5 ) && ! strchr ( con -> uri + 5 , '/' ) )  23
if ( ! strncmp ( con -> uri , "/admin/conf/" , 12 ) )  25
if ( ! strncmp ( con -> uri , "/admin/log/" , 11 ) )  27
if ( ! strncmp ( con -> uri + 11 , "access_log" , 10 ) && AccessLog [ 0 ] == '/' )  29
if ( ! strncmp ( con -> uri + 11 , "error_log" , 9 ) && ErrorLog [ 0 ] == '/' )  31
if ( ! strncmp ( con -> uri + 11 , "page_log" , 8 ) && PageLog [ 0 ] == '/' )  33
if ( con -> language )  38
snprintf ( language , sizeof ( language ) , "/%s" , con -> language -> language ); 40
snprintf ( filename , len , "%s%s" , DocumentRoot , con -> uri ); 44
if ( ( status = stat ( filename , filestats ) ) != 0 && language [ 0 ] && strncmp ( con -> uri , "/ppd/" , 5 ) && strncmp ( con -> uri , "/admin/conf/" , 12 ) && strncmp ( con -> uri , "/admin/log/" , 11 ) )  54
language [ 3 ] = '\0'; 63
snprintf ( filename , len , "%s%s%s" , DocumentRoot , language , con -> uri ); 64
if ( ( status = stat ( filename , filestats ) ) != 0 )  69
language [ 0 ] = '\0'; 75
snprintf ( filename , len , "%s%s" , DocumentRoot , con -> uri ); 76
status = stat ( filename , filestats ); 81
if ( ! status && S_ISDIR ( filestats -> st_mode ) )  89
if ( status && language [ 0 ] )  104
if ( language [ 3 ] )  110
language [ 0 ] = '\0'; 111
language [ 0 ] = '\0'; 113
snprintf ( filename , len , "%s%s%s" , DocumentRoot , language , con -> uri ); 120
ptr = filename + strlen ( filename ); 125
plen = len - ( ptr - filename ); 126
strlcpy ( ptr , "index.html" , plen ); 128
status = stat ( filename , filestats ); 129
if ( status )  132
strlcpy ( ptr , "index.class" , plen ); 134
status = stat ( filename , filestats ); 135
if ( status )  140
strlcpy ( ptr , "index.pl" , plen ); 142
status = stat ( filename , filestats ); 143
if ( status )  148
strlcpy ( ptr , "index.php" , plen ); 150
status = stat ( filename , filestats ); 151
if ( status )  156
strlcpy ( ptr , "index.pyc" , plen ); 158
status = stat ( filename , filestats ); 159
if ( status )  162
strlcpy ( ptr , "index.py" , plen ); 164
status = stat ( filename , filestats ); 165
while ( status && language [ 0 ] )  170
------------------------------
500 /home/speedy/test/source2slice/NVD/CVE_2014_3601_PATCHED_kvm_iommu_map_pages.c end_gfn = gfn + slot -> npages 14
int CVE_2014_3601_PATCHED_kvm_iommu_map_pages(struct kvm *kvm, struct kvm_memory_slot *slot) 1
gfn_t gfn , end_gfn ; 3
struct iommu_domain * domain = kvm -> arch . iommu_domain ; 6
if ( ! domain )  10
gfn = slot -> base_gfn; 13
end_gfn = gfn + slot -> npages; 14
while ( gfn < end_gfn )  21
while ( ( gfn + ( page_size >> PAGE_SHIFT ) ) > end_gfn )  34
------------------------------
501 /home/speedy/test/source2slice/NVD/CVE_2014_3601_VULN_kvm_iommu_map_pages.c end_gfn = gfn + slot -> npages 14
int CVE_2014_3601_VULN_kvm_iommu_map_pages(struct kvm *kvm, struct kvm_memory_slot *slot) 1
gfn_t gfn , end_gfn ; 3
struct iommu_domain * domain = kvm -> arch . iommu_domain ; 6
if ( ! domain )  10
gfn = slot -> base_gfn; 13
end_gfn = gfn + slot -> npages; 14
while ( gfn < end_gfn )  21
while ( ( gfn + ( page_size >> PAGE_SHIFT ) ) > end_gfn )  34
------------------------------
502 /home/speedy/test/source2slice/NVD/CVE_2014_3631_PATCHED_assoc_array_gc.c new_s = kmalloc ( sizeof ( struct assoc_array_shortcut ) + keylen * sizeof ( unsigned long ) , GFP_KERNEL ) 40
int CVE_2014_3631_PATCHED_assoc_array_gc(struct assoc_array *array,
const struct assoc_array_ops *ops,
bool (*iterator)(void *object, void *iterator_data),
void *iterator_data) 4
struct assoc_array_shortcut * shortcut , * new_s ; 6
struct assoc_array_node * node , * new_n ; 7
struct assoc_array_edit * edit ; 8
struct assoc_array_ptr * cursor , * ptr ; 9
struct assoc_array_ptr * new_root , * new_parent , * * new_ptr_pp ; 10
int keylen , slot , nr_free , next_slot , i ; 12
if ( ! array -> root )  16
edit = kzalloc ( sizeof ( struct assoc_array_edit ) , GFP_KERNEL ); 19
if ( ! edit )  20
new_root = new_parent = NULL; 28
new_ptr_pp = & new_root; 29
cursor = array -> root; 30
if ( assoc_array_ptr_is_shortcut ( cursor ) )  36
shortcut = assoc_array_ptr_to_shortcut ( cursor ); 37
keylen = round_up ( shortcut -> skip_to_level , ASSOC_ARRAY_KEY_CHUNK_SIZE ); 38
keylen >>= ASSOC_ARRAY_KEY_CHUNK_SHIFT; 39
new_s = kmalloc ( sizeof ( struct assoc_array_shortcut ) + keylen * sizeof ( unsigned long ) , GFP_KERNEL ); 40
if ( ! new_s )  42
pr_devel ( "dup shortcut %p -> %p\n" , shortcut , new_s ); 44
memcpy ( new_s , shortcut , ( sizeof ( struct assoc_array_shortcut ) + keylen * sizeof ( unsigned long ) ) ); 45
new_s -> back_pointer = new_parent; 47
new_s -> parent_slot = shortcut -> parent_slot; 48
* new_ptr_pp = new_parent = assoc_array_shortcut_to_ptr ( new_s ); 49
new_ptr_pp = & new_s -> next_node; 50
cursor = shortcut -> next_node; 51
node = assoc_array_ptr_to_node ( cursor ); 55
new_n = kzalloc ( sizeof ( struct assoc_array_node ) , GFP_KERNEL ); 56
if ( ! new_n )  57
pr_devel ( "dup node %p -> %p\n" , node , new_n ); 59
new_n -> back_pointer = new_parent; 60
new_n -> parent_slot = node -> parent_slot; 61
* new_ptr_pp = new_parent = assoc_array_node_to_ptr ( new_n ); 62
slot = 0; 64
for (; slot < ASSOC_ARRAY_FAN_OUT; slot++) 68
ptr = node -> slots [ slot ]; 69
if ( ! ptr )  70
if ( assoc_array_ptr_is_leaf ( ptr ) )  73
if ( iterator ( assoc_array_ptr_to_leaf ( ptr ) , iterator_data ) )  74
new_n -> slots [ slot ] = ptr; 79
new_ptr_pp = & new_n -> slots [ slot ]; 83
cursor = ptr; 84
pr_devel ( "-- compress node %p --\n" , new_n ); 88
new_n -> nr_leaves_on_branch = 0; 93
nr_free = 0; 94
for (slot = 0; slot < ASSOC_ARRAY_FAN_OUT; slot++) 95
ptr = new_n -> slots [ slot ]; 96
if ( ! ptr )  97
nr_free ++; 98
if ( assoc_array_ptr_is_leaf ( ptr ) )  99
new_n -> nr_leaves_on_branch ++; 100
pr_devel ( "free=%d, leaves=%lu\n" , nr_free , new_n -> nr_leaves_on_branch ); 102
next_slot = 0; 105
for (slot = 0; slot < ASSOC_ARRAY_FAN_OUT; slot++) 106
struct assoc_array_shortcut * s ; 107
struct assoc_array_node * child ; 108
ptr = new_n -> slots [ slot ]; 110
if ( ! ptr || assoc_array_ptr_is_leaf ( ptr ) )  111
s = NULL; 114
if ( assoc_array_ptr_is_shortcut ( ptr ) )  115
s = assoc_array_ptr_to_shortcut ( ptr ); 116
ptr = s -> next_node; 117
child = assoc_array_ptr_to_node ( ptr ); 120
new_n -> nr_leaves_on_branch += child -> nr_leaves_on_branch; 121
if ( child -> nr_leaves_on_branch <= nr_free + 1 )  123
pr_devel ( "[%d] fold node %lu/%d [nx %d]\n" , slot , child -> nr_leaves_on_branch , nr_free + 1 , next_slot ); 125
BUG_ON ( s ); 132
new_n -> slots [ slot ] = NULL; 134
nr_free ++; 135
if ( slot < next_slot )  136
next_slot = slot; 137
for (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) 138
struct assoc_array_ptr * p = child -> slots [ i ] ; 139
if ( ! p )  140
BUG_ON ( assoc_array_ptr_is_meta ( p ) ); 142
while ( new_n -> slots [ next_slot ] )  143
next_slot ++; 144
BUG_ON ( next_slot >= ASSOC_ARRAY_FAN_OUT ); 145
new_n -> slots [ next_slot ++ ] = p; 146
nr_free --; 147
kfree ( child ); 149
pr_devel ( "[%d] retain node %lu/%d [nx %d]\n" , slot , child -> nr_leaves_on_branch , nr_free + 1 , next_slot ); 151
pr_devel ( "after: %lu\n" , new_n -> nr_leaves_on_branch ); 157
nr_leaves_on_tree = new_n -> nr_leaves_on_branch; 159
if ( nr_free == ASSOC_ARRAY_FAN_OUT - 1 )  162
for (slot = 0; slot < ASSOC_ARRAY_FAN_OUT; slot++) 163
if ( ptr = new_n -> slots [ slot ] )  164
if ( assoc_array_ptr_is_meta ( ptr ) && assoc_array_ptr_is_shortcut ( ptr ) )  167
pr_devel ( "excise node %p with 1 shortcut\n" , new_n ); 169
new_s = assoc_array_ptr_to_shortcut ( ptr ); 170
new_parent = new_n -> back_pointer; 171
slot = new_n -> parent_slot; 172
kfree ( new_n ); 173
if ( ! new_parent )  174
new_s -> back_pointer = NULL; 175
new_s -> parent_slot = 0; 176
new_root = ptr; 177
if ( assoc_array_ptr_is_shortcut ( new_parent ) )  181
struct assoc_array_shortcut * s = assoc_array_ptr_to_shortcut ( new_parent ) ; 183
new_parent = new_s -> back_pointer = s -> back_pointer; 188
slot = new_s -> parent_slot = s -> parent_slot; 189
kfree ( s ); 190
if ( ! new_parent )  191
new_s -> back_pointer = NULL; 192
new_s -> parent_slot = 0; 193
new_root = ptr; 194
new_s -> back_pointer = new_parent; 199
new_s -> parent_slot = slot; 200
new_n = assoc_array_ptr_to_node ( new_parent ); 201
new_n -> slots [ slot ] = ptr; 202
ptr = new_n -> back_pointer; 210
if ( ! ptr )  211
if ( assoc_array_ptr_is_shortcut ( ptr ) )  214
new_s = assoc_array_ptr_to_shortcut ( ptr ); 215
new_parent = new_s -> back_pointer; 216
slot = new_s -> parent_slot; 217
if ( new_n -> nr_leaves_on_branch <= ASSOC_ARRAY_FAN_OUT )  219
struct assoc_array_node * n ; 220
new_n -> back_pointer = new_parent; 223
new_n -> parent_slot = slot; 224
kfree ( new_s ); 225
if ( ! new_parent )  226
new_root = assoc_array_node_to_ptr ( new_n ); 227
n = assoc_array_ptr_to_node ( new_parent ); 231
n -> slots [ slot ] = assoc_array_node_to_ptr ( new_n ); 232
new_parent = ptr; 235
new_n = assoc_array_ptr_to_node ( new_parent ); 237
ptr = node -> back_pointer; 240
if ( assoc_array_ptr_is_shortcut ( ptr ) )  241
shortcut = assoc_array_ptr_to_shortcut ( ptr ); 242
slot = shortcut -> parent_slot; 243
cursor = shortcut -> back_pointer; 244
if ( ! cursor )  245
slot = node -> parent_slot; 248
cursor = ptr; 249
BUG_ON ( ! cursor ); 251
node = assoc_array_ptr_to_node ( cursor ); 252
slot ++; 253
edit -> set [ 0 ] . to = new_root; 257
assoc_array_apply_edit ( edit ); 258
edit -> array -> nr_leaves_on_tree = nr_leaves_on_tree; 259
------------------------------
503 /home/speedy/test/source2slice/NVD/CVE_2014_3631_VULN_assoc_array_gc.c new_s = kmalloc ( sizeof ( struct assoc_array_shortcut ) + keylen * sizeof ( unsigned long ) , GFP_KERNEL ) 40
int CVE_2014_3631_VULN_assoc_array_gc(struct assoc_array *array,
const struct assoc_array_ops *ops,
bool (*iterator)(void *object, void *iterator_data),
void *iterator_data) 4
struct assoc_array_shortcut * shortcut , * new_s ; 6
struct assoc_array_node * node , * new_n ; 7
struct assoc_array_edit * edit ; 8
struct assoc_array_ptr * cursor , * ptr ; 9
struct assoc_array_ptr * new_root , * new_parent , * * new_ptr_pp ; 10
int keylen , slot , nr_free , next_slot , i ; 12
if ( ! array -> root )  16
edit = kzalloc ( sizeof ( struct assoc_array_edit ) , GFP_KERNEL ); 19
if ( ! edit )  20
new_root = new_parent = NULL; 28
new_ptr_pp = & new_root; 29
cursor = array -> root; 30
if ( assoc_array_ptr_is_shortcut ( cursor ) )  36
shortcut = assoc_array_ptr_to_shortcut ( cursor ); 37
keylen = round_up ( shortcut -> skip_to_level , ASSOC_ARRAY_KEY_CHUNK_SIZE ); 38
keylen >>= ASSOC_ARRAY_KEY_CHUNK_SHIFT; 39
new_s = kmalloc ( sizeof ( struct assoc_array_shortcut ) + keylen * sizeof ( unsigned long ) , GFP_KERNEL ); 40
if ( ! new_s )  42
pr_devel ( "dup shortcut %p -> %p\n" , shortcut , new_s ); 44
memcpy ( new_s , shortcut , ( sizeof ( struct assoc_array_shortcut ) + keylen * sizeof ( unsigned long ) ) ); 45
new_s -> back_pointer = new_parent; 47
new_s -> parent_slot = shortcut -> parent_slot; 48
* new_ptr_pp = new_parent = assoc_array_shortcut_to_ptr ( new_s ); 49
new_ptr_pp = & new_s -> next_node; 50
cursor = shortcut -> next_node; 51
node = assoc_array_ptr_to_node ( cursor ); 55
new_n = kzalloc ( sizeof ( struct assoc_array_node ) , GFP_KERNEL ); 56
if ( ! new_n )  57
pr_devel ( "dup node %p -> %p\n" , node , new_n ); 59
new_n -> back_pointer = new_parent; 60
new_n -> parent_slot = node -> parent_slot; 61
* new_ptr_pp = new_parent = assoc_array_node_to_ptr ( new_n ); 62
slot = 0; 64
for (; slot < ASSOC_ARRAY_FAN_OUT; slot++) 68
ptr = node -> slots [ slot ]; 69
if ( ! ptr )  70
if ( assoc_array_ptr_is_leaf ( ptr ) )  73
if ( iterator ( assoc_array_ptr_to_leaf ( ptr ) , iterator_data ) )  74
new_n -> slots [ slot ] = ptr; 79
new_ptr_pp = & new_n -> slots [ slot ]; 83
cursor = ptr; 84
pr_devel ( "-- compress node %p --\n" , new_n ); 88
new_n -> nr_leaves_on_branch = 0; 93
nr_free = 0; 94
for (slot = 0; slot < ASSOC_ARRAY_FAN_OUT; slot++) 95
ptr = new_n -> slots [ slot ]; 96
if ( ! ptr )  97
nr_free ++; 98
if ( assoc_array_ptr_is_leaf ( ptr ) )  99
new_n -> nr_leaves_on_branch ++; 100
pr_devel ( "free=%d, leaves=%lu\n" , nr_free , new_n -> nr_leaves_on_branch ); 102
next_slot = 0; 105
for (slot = 0; slot < ASSOC_ARRAY_FAN_OUT; slot++) 106
struct assoc_array_shortcut * s ; 107
struct assoc_array_node * child ; 108
ptr = new_n -> slots [ slot ]; 110
if ( ! ptr || assoc_array_ptr_is_leaf ( ptr ) )  111
s = NULL; 114
if ( assoc_array_ptr_is_shortcut ( ptr ) )  115
s = assoc_array_ptr_to_shortcut ( ptr ); 116
ptr = s -> next_node; 117
child = assoc_array_ptr_to_node ( ptr ); 120
new_n -> nr_leaves_on_branch += child -> nr_leaves_on_branch; 121
if ( child -> nr_leaves_on_branch <= nr_free + 1 )  123
pr_devel ( "[%d] fold node %lu/%d [nx %d]\n" , slot , child -> nr_leaves_on_branch , nr_free + 1 , next_slot ); 125
BUG_ON ( s ); 132
new_n -> slots [ slot ] = NULL; 134
nr_free ++; 135
if ( slot < next_slot )  136
next_slot = slot; 137
for (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) 138
struct assoc_array_ptr * p = child -> slots [ i ] ; 139
if ( ! p )  140
BUG_ON ( assoc_array_ptr_is_meta ( p ) ); 142
while ( new_n -> slots [ next_slot ] )  143
next_slot ++; 144
BUG_ON ( next_slot >= ASSOC_ARRAY_FAN_OUT ); 145
new_n -> slots [ next_slot ++ ] = p; 146
nr_free --; 147
kfree ( child ); 149
pr_devel ( "[%d] retain node %lu/%d [nx %d]\n" , slot , child -> nr_leaves_on_branch , nr_free + 1 , next_slot ); 151
pr_devel ( "after: %lu\n" , new_n -> nr_leaves_on_branch ); 157
nr_leaves_on_tree = new_n -> nr_leaves_on_branch; 159
if ( nr_free == ASSOC_ARRAY_FAN_OUT - 1 )  162
for (slot = 0; slot < ASSOC_ARRAY_FAN_OUT; slot++) 163
if ( ptr = new_n -> slots [ slot ] )  164
if ( assoc_array_ptr_is_meta ( ptr ) && assoc_array_ptr_is_shortcut ( ptr ) )  167
pr_devel ( "excise node %p with 1 shortcut\n" , new_n ); 169
new_s = assoc_array_ptr_to_shortcut ( ptr ); 170
new_parent = new_n -> back_pointer; 171
slot = new_n -> parent_slot; 172
kfree ( new_n ); 173
if ( ! new_parent )  174
new_s -> back_pointer = NULL; 175
new_s -> parent_slot = 0; 176
new_root = ptr; 177
if ( assoc_array_ptr_is_shortcut ( new_parent ) )  181
struct assoc_array_shortcut * s = assoc_array_ptr_to_shortcut ( new_parent ) ; 183
new_parent = new_s -> back_pointer = s -> back_pointer; 188
slot = new_s -> parent_slot = s -> parent_slot; 189
kfree ( s ); 190
if ( ! new_parent )  191
new_s -> back_pointer = NULL; 192
new_s -> parent_slot = 0; 193
new_root = ptr; 194
new_s -> back_pointer = new_parent; 199
new_s -> parent_slot = slot; 200
new_n = assoc_array_ptr_to_node ( new_parent ); 201
new_n -> slots [ slot ] = ptr; 202
ptr = new_n -> back_pointer; 210
if ( ! ptr )  211
if ( assoc_array_ptr_is_shortcut ( ptr ) )  214
new_s = assoc_array_ptr_to_shortcut ( ptr ); 215
new_parent = new_s -> back_pointer; 216
slot = new_s -> parent_slot; 217
if ( new_n -> nr_leaves_on_branch <= ASSOC_ARRAY_FAN_OUT )  219
struct assoc_array_node * n ; 220
new_n -> back_pointer = new_parent; 223
new_n -> parent_slot = slot; 224
kfree ( new_s ); 225
if ( ! new_parent )  226
new_root = assoc_array_node_to_ptr ( new_n ); 227
n = assoc_array_ptr_to_node ( new_parent ); 231
n -> slots [ slot ] = assoc_array_node_to_ptr ( new_n ); 232
new_parent = ptr; 235
new_n = assoc_array_ptr_to_node ( new_parent ); 237
ptr = node -> back_pointer; 240
if ( assoc_array_ptr_is_shortcut ( ptr ) )  241
shortcut = assoc_array_ptr_to_shortcut ( ptr ); 242
slot = shortcut -> parent_slot; 243
cursor = shortcut -> back_pointer; 244
slot = node -> parent_slot; 246
cursor = ptr; 247
BUG_ON ( ! ptr ); 249
node = assoc_array_ptr_to_node ( cursor ); 250
slot ++; 251
edit -> set [ 0 ] . to = new_root; 255
assoc_array_apply_edit ( edit ); 256
edit -> array -> nr_leaves_on_tree = nr_leaves_on_tree; 257
assoc_array_destroy_subtree ( new_root , edit -> ops ); 262
kfree ( edit ); 263
------------------------------
504 /home/speedy/test/source2slice/NVD/CVE_2014_3640_PATCHED_udp_input.c uh = ( struct udphdr * ) ( ( caddr_t ) ip + iphlen ) 31
void
CVE_2014_3640_PATCHED_udp_input(register struct mbuf *m, int iphlen) 3
register struct ip * ip ;
register struct udphdr * uh ; 7
if ( iphlen > sizeof ( struct ip ) )  22
iphlen = sizeof ( struct ip ); 24
ip = mtod ( m , struct ip * ) 30
uh = ( struct udphdr * ) ( ( caddr_t ) ip + iphlen ); 31
len = ntohs ( ( u_int16_t ) uh -> uh_ulen ); 37
if ( ip -> ip_len != len )  39
if ( len > ip -> ip_len )  40
m_adj ( m , len - ip -> ip_len ); 43
ip -> ip_len = len; 44
save_ip = * ip; 51
save_ip . ip_len += iphlen; 52
if ( uh -> uh_sum )  57
memset ( & ( ( struct ipovly * ) ip ) -> ih_mbuf , 0 , sizeof ( struct mbuf_ptr ) ); 58
( ( struct ipovly * ) ip ) -> ih_x1 = 0; 59
( ( struct ipovly * ) ip ) -> ih_len = uh -> uh_ulen; 60
if ( cksum ( m , len + sizeof ( struct ip ) ) )  61
if ( ntohs ( uh -> uh_dport ) == BOOTP_SERVER )  69
if ( ntohs ( uh -> uh_dport ) == TFTP_SERVER )  81
if ( so == & slirp -> udb || so -> so_lport != uh -> uh_sport || so -> so_laddr . s_addr != ip -> ip_src . s_addr )  90
if ( tmp -> so_lport == uh -> uh_sport && tmp -> so_laddr . s_addr == ip -> ip_src . s_addr )  96
so -> so_laddr = ip -> ip_src; 128
so -> so_lport = uh -> uh_sport; 129
if ( ( so -> so_iptos = udp_tos ( so ) ) == 0 )  131
so -> so_iptos = ip -> ip_tos; 132
so -> so_faddr = ip -> ip_dst; 140
so -> so_fport = uh -> uh_dport; 141
if ( so -> so_emu )  150
udp_emu ( so , m ); 151
if ( sosendto ( so , m ) == - 1 )  153
* ip = save_ip; 156
m_free ( so -> so_m ); 161
* ip = save_ip; 166
so -> so_m = m; 167
------------------------------
505 /home/speedy/test/source2slice/NVD/CVE_2014_3640_VULN_udp_input.c uh = ( struct udphdr * ) ( ( caddr_t ) ip + iphlen ) 31
void
CVE_2014_3640_VULN_udp_input(register struct mbuf *m, int iphlen) 3
register struct ip * ip ;
register struct udphdr * uh ; 7
if ( iphlen > sizeof ( struct ip ) )  22
iphlen = sizeof ( struct ip ); 24
ip = mtod ( m , struct ip * ) 30
uh = ( struct udphdr * ) ( ( caddr_t ) ip + iphlen ); 31
len = ntohs ( ( u_int16_t ) uh -> uh_ulen ); 37
if ( ip -> ip_len != len )  39
if ( len > ip -> ip_len )  40
m_adj ( m , len - ip -> ip_len ); 43
ip -> ip_len = len; 44
save_ip = * ip; 51
save_ip . ip_len += iphlen; 52
if ( uh -> uh_sum )  57
memset ( & ( ( struct ipovly * ) ip ) -> ih_mbuf , 0 , sizeof ( struct mbuf_ptr ) ); 58
( ( struct ipovly * ) ip ) -> ih_x1 = 0; 59
( ( struct ipovly * ) ip ) -> ih_len = uh -> uh_ulen; 60
if ( cksum ( m , len + sizeof ( struct ip ) ) )  61
if ( ntohs ( uh -> uh_dport ) == BOOTP_SERVER )  69
if ( ntohs ( uh -> uh_dport ) == TFTP_SERVER )  81
if ( so -> so_lport != uh -> uh_sport || so -> so_laddr . s_addr != ip -> ip_src . s_addr )  90
if ( tmp -> so_lport == uh -> uh_sport && tmp -> so_laddr . s_addr == ip -> ip_src . s_addr )  96
so -> so_laddr = ip -> ip_src; 128
so -> so_lport = uh -> uh_sport; 129
if ( ( so -> so_iptos = udp_tos ( so ) ) == 0 )  131
so -> so_iptos = ip -> ip_tos; 132
so -> so_faddr = ip -> ip_dst; 140
so -> so_fport = uh -> uh_dport; 141
if ( so -> so_emu )  150
udp_emu ( so , m ); 151
if ( sosendto ( so , m ) == - 1 )  153
* ip = save_ip; 156
m_free ( so -> so_m ); 161
* ip = save_ip; 166
so -> so_m = m; 167
------------------------------
506 /home/speedy/test/source2slice/NVD/CVE_2014_4027_PATCHED_rd_build_device_space.c sg_table = kzalloc ( sg_tables * sizeof ( struct rd_dev_sg_table ) , GFP_KERNEL ) 23
static int CVE_2014_4027_PATCHED_rd_build_device_space(struct rd_dev *rd_dev) 1
struct rd_dev_sg_table * sg_table ; 3
u32 sg_tables , total_sg_needed ; 4
u32 max_sg_per_table = ( RD_MAX_ALLOCATION_SIZE / sizeof ( struct scatterlist ) ) ; 5
if ( rd_dev -> rd_page_count <= 0 )  9
if ( rd_dev -> rd_flags & RDF_NULLIO )  16
total_sg_needed = rd_dev -> rd_page_count; 19
sg_tables = ( total_sg_needed / max_sg_per_table ) + 1; 21
sg_table = kzalloc ( sg_tables * sizeof ( struct rd_dev_sg_table ) , GFP_KERNEL ); 23
if ( ! sg_table )  24
rd_dev -> sg_table_array = sg_table; 30
rd_dev -> sg_table_count = sg_tables; 31
rc = rd_allocate_sgl_table ( rd_dev , sg_table , total_sg_needed , 0x00 ); 33
if ( rc )  34
return rc ; 35
pr_debug ( "CORE_RD[%u] - Built Ramdisk Device ID: %u space of"
" %u pages in %u tables\n" , rd_dev -> rd_host -> rd_host_id ,
rd_dev -> rd_dev_id , rd_dev -> rd_page_count ,
rd_dev -> sg_table_count ) 40
------------------------------
507 /home/speedy/test/source2slice/NVD/CVE_2014_4027_PATCHED_rd_build_device_space.c sg_tables = ( total_sg_needed / max_sg_per_table ) + 1 21
static int CVE_2014_4027_PATCHED_rd_build_device_space(struct rd_dev *rd_dev) 1
u32 sg_tables , total_sg_needed ; 4
u32 max_sg_per_table = ( RD_MAX_ALLOCATION_SIZE / sizeof ( struct scatterlist ) ) ; 5
if ( rd_dev -> rd_page_count <= 0 )  9
if ( rd_dev -> rd_flags & RDF_NULLIO )  16
total_sg_needed = rd_dev -> rd_page_count; 19
sg_tables = ( total_sg_needed / max_sg_per_table ) + 1; 21
sg_table = kzalloc ( sg_tables * sizeof ( struct rd_dev_sg_table ) , GFP_KERNEL ); 23
if ( ! sg_table )  24
rd_dev -> sg_table_array = sg_table; 30
rd_dev -> sg_table_count = sg_tables; 31
rc = rd_allocate_sgl_table ( rd_dev , sg_table , total_sg_needed , 0x00 ); 33
if ( rc )  34
return rc ; 35
pr_debug ( "CORE_RD[%u] - Built Ramdisk Device ID: %u space of"
" %u pages in %u tables\n" , rd_dev -> rd_host -> rd_host_id ,
rd_dev -> rd_dev_id , rd_dev -> rd_page_count ,
rd_dev -> sg_table_count ) 40
------------------------------
508 /home/speedy/test/source2slice/NVD/CVE_2014_4027_VULN_rd_build_device_space.c sg_table [ i ++ ] . page_end_offset = ( page_offset + sg_per_table ) - 1 51
static int CVE_2014_4027_VULN_rd_build_device_space(struct rd_dev *rd_dev) 1
u32 i = 0 , j , page_offset = 0 , sg_per_table , sg_tables , total_sg_needed ; 3
u32 max_sg_per_table = ( RD_MAX_ALLOCATION_SIZE / sizeof ( struct scatterlist ) ) ; 4
struct rd_dev_sg_table * sg_table ; 6
struct page * pg ; 7
struct scatterlist * sg ; 8
if ( rd_dev -> rd_page_count <= 0 )  10
if ( rd_dev -> rd_flags & RDF_NULLIO )  17
total_sg_needed = rd_dev -> rd_page_count; 20
sg_tables = ( total_sg_needed / max_sg_per_table ) + 1; 22
sg_table = kzalloc ( sg_tables * sizeof ( struct rd_dev_sg_table ) , GFP_KERNEL ); 24
if ( ! sg_table )  25
while ( total_sg_needed )  34
sg_per_table = ( total_sg_needed > max_sg_per_table ) ? max_sg_per_table : total_sg_needed; 35
sg = kzalloc ( sg_per_table * sizeof ( struct scatterlist ) , GFP_KERNEL ); 38
if ( ! sg )  40
sg_table [ i ] . sg_table = sg; 48
sg_table [ i ] . rd_sg_count = sg_per_table; 49
sg_table [ i ] . page_start_offset = page_offset; 50
sg_table [ i ++ ] . page_end_offset = ( page_offset + sg_per_table ) - 1; 51
for (j = 0; j < sg_per_table; j++) 54
pg = alloc_pages ( GFP_KERNEL , 0 ); 55
if ( ! pg )  56
page_offset += sg_per_table; 65
total_sg_needed -= sg_per_table; 66
------------------------------
509 /home/speedy/test/source2slice/NVD/CVE_2014_4027_VULN_rd_build_device_space.c sg = kzalloc ( sg_per_table * sizeof ( struct scatterlist ) , GFP_KERNEL ) 38
static int CVE_2014_4027_VULN_rd_build_device_space(struct rd_dev *rd_dev) 1
u32 max_sg_per_table = ( RD_MAX_ALLOCATION_SIZE / sizeof ( struct scatterlist ) ) ; 4
struct rd_dev_sg_table * sg_table ; 6
struct page * pg ; 7
struct scatterlist * sg ; 8
if ( rd_dev -> rd_page_count <= 0 )  10
if ( rd_dev -> rd_flags & RDF_NULLIO )  17
total_sg_needed = rd_dev -> rd_page_count; 20
sg_tables = ( total_sg_needed / max_sg_per_table ) + 1; 22
sg_table = kzalloc ( sg_tables * sizeof ( struct rd_dev_sg_table ) , GFP_KERNEL ); 24
if ( ! sg_table )  25
while ( total_sg_needed )  34
sg_per_table = ( total_sg_needed > max_sg_per_table ) ? max_sg_per_table : total_sg_needed; 35
sg = kzalloc ( sg_per_table * sizeof ( struct scatterlist ) , GFP_KERNEL ); 38
if ( ! sg )  40
sg_init_table ( sg , sg_per_table ); 46
sg_table [ i ] . sg_table = sg; 48
sg_table [ i ] . rd_sg_count = sg_per_table; 49
sg_table [ i ] . page_start_offset = page_offset; 50
sg_table [ i ++ ] . page_end_offset = ( page_offset + sg_per_table ) - 1; 51
for (j = 0; j < sg_per_table; j++) 54
pg = alloc_pages ( GFP_KERNEL , 0 ); 55
if ( ! pg )  56
sg_assign_page ( & sg [ j ] , pg ); 61
sg [ j ] . length = PAGE_SIZE; 62
total_sg_needed -= sg_per_table; 66
------------------------------
510 /home/speedy/test/source2slice/NVD/CVE_2014_4027_VULN_rd_build_device_space.c sg_table = kzalloc ( sg_tables * sizeof ( struct rd_dev_sg_table ) , GFP_KERNEL ) 24
static int CVE_2014_4027_VULN_rd_build_device_space(struct rd_dev *rd_dev) 1
u32 max_sg_per_table = ( RD_MAX_ALLOCATION_SIZE / sizeof ( struct scatterlist ) ) ; 4
struct rd_dev_sg_table * sg_table ; 6
if ( rd_dev -> rd_page_count <= 0 )  10
if ( rd_dev -> rd_flags & RDF_NULLIO )  17
total_sg_needed = rd_dev -> rd_page_count; 20
sg_tables = ( total_sg_needed / max_sg_per_table ) + 1; 22
sg_table = kzalloc ( sg_tables * sizeof ( struct rd_dev_sg_table ) , GFP_KERNEL ); 24
if ( ! sg_table )  25
rd_dev -> sg_table_array = sg_table; 31
rd_dev -> sg_table_count = sg_tables; 32
sg_table [ i ] . sg_table = sg; 48
sg_table [ i ] . rd_sg_count = sg_per_table; 49
sg_table [ i ] . page_start_offset = page_offset; 50
sg_table [ i ++ ] . page_end_offset = ( page_offset + sg_per_table ) - 1; 51
pr_debug ( "CORE_RD[%u] - Built Ramdisk Device ID: %u space of"
" %u pages in %u tables\n" , rd_dev -> rd_host -> rd_host_id ,
rd_dev -> rd_dev_id , rd_dev -> rd_page_count ,
rd_dev -> sg_table_count ) 72
------------------------------
511 /home/speedy/test/source2slice/NVD/CVE_2014_4027_VULN_rd_build_device_space.c sg_tables = ( total_sg_needed / max_sg_per_table ) + 1 22
static int CVE_2014_4027_VULN_rd_build_device_space(struct rd_dev *rd_dev) 1
u32 max_sg_per_table = ( RD_MAX_ALLOCATION_SIZE / sizeof ( struct scatterlist ) ) ; 4
if ( rd_dev -> rd_page_count <= 0 )  10
if ( rd_dev -> rd_flags & RDF_NULLIO )  17
total_sg_needed = rd_dev -> rd_page_count; 20
sg_tables = ( total_sg_needed / max_sg_per_table ) + 1; 22
sg_table = kzalloc ( sg_tables * sizeof ( struct rd_dev_sg_table ) , GFP_KERNEL ); 24
if ( ! sg_table )  25
rd_dev -> sg_table_array = sg_table; 31
rd_dev -> sg_table_count = sg_tables; 32
sg_table [ i ] . sg_table = sg; 48
sg_table [ i ] . rd_sg_count = sg_per_table; 49
sg_table [ i ] . page_start_offset = page_offset; 50
sg_table [ i ++ ] . page_end_offset = ( page_offset + sg_per_table ) - 1; 51
pr_debug ( "CORE_RD[%u] - Built Ramdisk Device ID: %u space of"
" %u pages in %u tables\n" , rd_dev -> rd_host -> rd_host_id ,
rd_dev -> rd_dev_id , rd_dev -> rd_page_count ,
rd_dev -> sg_table_count ) 72
------------------------------
512 /home/speedy/test/source2slice/NVD/CVE_2014_4174_PATCHED_libpcap_dump.c rec_hdr . hdr . orig_len = phdr -> len + phdrsize 19
static gboolean CVE_2014_4174_PATCHED_libpcap_dump(wtap_dumper *wdh,
const struct wtap_pkthdr *phdr,
const guint8 *pd, int *err) 3
const union wtap_pseudo_header * pseudo_header = & phdr -> pseudo_header ; 5
struct pcaprec_ss990915_hdr rec_hdr ; 6
int phdrsize ; 8
phdrsize = pcap_get_phdr_size ( wdh -> encap , pseudo_header ); 10
rec_hdr . hdr . ts_sec = ( guint32 ) phdr -> ts . secs; 12
if ( wdh -> tsprecision == WTAP_FILE_TSPREC_NSEC )  13
rec_hdr . hdr . ts_usec = phdr -> ts . nsecs; 14
rec_hdr . hdr . ts_usec = phdr -> ts . nsecs / 1000; 16
rec_hdr . hdr . incl_len = phdr -> caplen + phdrsize; 18
rec_hdr . hdr . orig_len = phdr -> len + phdrsize; 19
if ( rec_hdr . hdr . incl_len > WTAP_MAX_PACKET_SIZE )  21
rec_hdr . ifindex = 0; 54
rec_hdr . protocol = 0; 55
rec_hdr . pkt_type = 0; 56
rec_hdr . ifindex = 0; 61
rec_hdr . protocol = 0; 62
rec_hdr . pkt_type = 0; 63
rec_hdr . cpu1 = 0; 64
rec_hdr . cpu2 = 0; 65
memcpy ( & rec_hdr . ifindex , pseudo_header -> nokia . stuff , 4 ); 71
rec_hdr . protocol = 0; 73
rec_hdr . pkt_type = 0; 74
rec_hdr . cpu1 = 0; 75
rec_hdr . cpu2 = 0; 76
if ( ! wtap_dump_file_write ( wdh , & rec_hdr , hdr_size , err ) )  88
------------------------------
513 /home/speedy/test/source2slice/NVD/CVE_2014_4174_PATCHED_libpcap_dump.c rec_hdr . hdr . incl_len = phdr -> caplen + phdrsize 18
static gboolean CVE_2014_4174_PATCHED_libpcap_dump(wtap_dumper *wdh,
const struct wtap_pkthdr *phdr,
const guint8 *pd, int *err) 3
const union wtap_pseudo_header * pseudo_header = & phdr -> pseudo_header ; 5
struct pcaprec_ss990915_hdr rec_hdr ; 6
int phdrsize ; 8
phdrsize = pcap_get_phdr_size ( wdh -> encap , pseudo_header ); 10
rec_hdr . hdr . ts_sec = ( guint32 ) phdr -> ts . secs; 12
if ( wdh -> tsprecision == WTAP_FILE_TSPREC_NSEC )  13
rec_hdr . hdr . ts_usec = phdr -> ts . nsecs; 14
rec_hdr . hdr . ts_usec = phdr -> ts . nsecs / 1000; 16
rec_hdr . hdr . incl_len = phdr -> caplen + phdrsize; 18
rec_hdr . hdr . orig_len = phdr -> len + phdrsize; 19
if ( rec_hdr . hdr . incl_len > WTAP_MAX_PACKET_SIZE )  21
rec_hdr . ifindex = 0; 54
rec_hdr . protocol = 0; 55
rec_hdr . pkt_type = 0; 56
rec_hdr . ifindex = 0; 61
rec_hdr . protocol = 0; 62
rec_hdr . pkt_type = 0; 63
rec_hdr . cpu1 = 0; 64
rec_hdr . cpu2 = 0; 65
memcpy ( & rec_hdr . ifindex , pseudo_header -> nokia . stuff , 4 ); 71
rec_hdr . protocol = 0; 73
rec_hdr . pkt_type = 0; 74
rec_hdr . cpu1 = 0; 75
rec_hdr . cpu2 = 0; 76
if ( ! wtap_dump_file_write ( wdh , & rec_hdr , hdr_size , err ) )  88
------------------------------
514 /home/speedy/test/source2slice/NVD/CVE_2014_4174_VULN_libpcap_dump.c rec_hdr . hdr . orig_len = phdr -> len + phdrsize 19
static gboolean CVE_2014_4174_VULN_libpcap_dump(wtap_dumper *wdh,
const struct wtap_pkthdr *phdr,
const guint8 *pd, int *err) 3
const union wtap_pseudo_header * pseudo_header = & phdr -> pseudo_header ; 5
struct pcaprec_ss990915_hdr rec_hdr ; 6
int phdrsize ; 8
phdrsize = pcap_get_phdr_size ( wdh -> encap , pseudo_header ); 10
rec_hdr . hdr . ts_sec = ( guint32 ) phdr -> ts . secs; 12
if ( wdh -> tsprecision == WTAP_FILE_TSPREC_NSEC )  13
rec_hdr . hdr . ts_usec = phdr -> ts . nsecs; 14
rec_hdr . hdr . ts_usec = phdr -> ts . nsecs / 1000; 16
rec_hdr . hdr . incl_len = phdr -> caplen + phdrsize; 18
rec_hdr . hdr . orig_len = phdr -> len + phdrsize; 19
if ( rec_hdr . hdr . incl_len > WTAP_MAX_PACKET_SIZE || rec_hdr . hdr . orig_len > WTAP_MAX_PACKET_SIZE )  21
rec_hdr . ifindex = 0; 54
rec_hdr . protocol = 0; 55
rec_hdr . pkt_type = 0; 56
rec_hdr . ifindex = 0; 61
rec_hdr . protocol = 0; 62
rec_hdr . pkt_type = 0; 63
rec_hdr . cpu1 = 0; 64
rec_hdr . cpu2 = 0; 65
memcpy ( & rec_hdr . ifindex , pseudo_header -> nokia . stuff , 4 ); 71
rec_hdr . protocol = 0; 73
rec_hdr . pkt_type = 0; 74
rec_hdr . cpu1 = 0; 75
rec_hdr . cpu2 = 0; 76
if ( ! wtap_dump_file_write ( wdh , & rec_hdr , hdr_size , err ) )  88
------------------------------
515 /home/speedy/test/source2slice/NVD/CVE_2014_4174_VULN_libpcap_dump.c rec_hdr . hdr . incl_len = phdr -> caplen + phdrsize 18
static gboolean CVE_2014_4174_VULN_libpcap_dump(wtap_dumper *wdh,
const struct wtap_pkthdr *phdr,
const guint8 *pd, int *err) 3
const union wtap_pseudo_header * pseudo_header = & phdr -> pseudo_header ; 5
struct pcaprec_ss990915_hdr rec_hdr ; 6
int phdrsize ; 8
phdrsize = pcap_get_phdr_size ( wdh -> encap , pseudo_header ); 10
rec_hdr . hdr . ts_sec = ( guint32 ) phdr -> ts . secs; 12
if ( wdh -> tsprecision == WTAP_FILE_TSPREC_NSEC )  13
rec_hdr . hdr . ts_usec = phdr -> ts . nsecs; 14
rec_hdr . hdr . ts_usec = phdr -> ts . nsecs / 1000; 16
rec_hdr . hdr . incl_len = phdr -> caplen + phdrsize; 18
rec_hdr . hdr . orig_len = phdr -> len + phdrsize; 19
if ( rec_hdr . hdr . incl_len > WTAP_MAX_PACKET_SIZE || rec_hdr . hdr . orig_len > WTAP_MAX_PACKET_SIZE )  21
rec_hdr . ifindex = 0; 54
rec_hdr . protocol = 0; 55
rec_hdr . pkt_type = 0; 56
rec_hdr . ifindex = 0; 61
rec_hdr . protocol = 0; 62
rec_hdr . pkt_type = 0; 63
rec_hdr . cpu1 = 0; 64
rec_hdr . cpu2 = 0; 65
memcpy ( & rec_hdr . ifindex , pseudo_header -> nokia . stuff , 4 ); 71
rec_hdr . protocol = 0; 73
rec_hdr . pkt_type = 0; 74
rec_hdr . cpu1 = 0; 75
rec_hdr . cpu2 = 0; 76
if ( ! wtap_dump_file_write ( wdh , & rec_hdr , hdr_size , err ) )  88
------------------------------
516 /home/speedy/test/source2slice/NVD/CVE_2014_4608_PATCHED_lzo1x_decompress_safe.c * out_len = op - out 201
int CVE_2014_4608_PATCHED_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t , 15 ) && HAVE_OP ( t , 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
ip = ie; 52
op = oe; 53
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t , 15 ) ) )  130
op += 8; 133
op += 8; 136
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 , 0 ) )  140
state = next; 141
op += next; 143
ip += next; 144
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 , 0 ) && HAVE_OP ( 4 , 0 ) ) )  170
op += t; 172
ip += t; 173
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
* out_len = op - out; 187
* out_len = op - out; 193
* out_len = op - out; 197
* out_len = op - out; 201
------------------------------
517 /home/speedy/test/source2slice/NVD/CVE_2014_4608_PATCHED_lzo1x_decompress_safe.c * out_len = op - out 197
int CVE_2014_4608_PATCHED_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t , 15 ) && HAVE_OP ( t , 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
ip = ie; 52
op = oe; 53
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t , 15 ) ) )  130
op += 8; 133
op += 8; 136
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 , 0 ) )  140
state = next; 141
op += next; 143
ip += next; 144
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 , 0 ) && HAVE_OP ( 4 , 0 ) ) )  170
op += t; 172
ip += t; 173
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
* out_len = op - out; 187
* out_len = op - out; 193
* out_len = op - out; 197
* out_len = op - out; 201
------------------------------
518 /home/speedy/test/source2slice/NVD/CVE_2014_4608_PATCHED_lzo1x_decompress_safe.c * out_len = op - out 193
int CVE_2014_4608_PATCHED_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t , 15 ) && HAVE_OP ( t , 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
ip = ie; 52
op = oe; 53
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t , 15 ) ) )  130
op += 8; 133
op += 8; 136
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 , 0 ) )  140
state = next; 141
op += next; 143
ip += next; 144
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 , 0 ) && HAVE_OP ( 4 , 0 ) ) )  170
op += t; 172
ip += t; 173
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
* out_len = op - out; 187
* out_len = op - out; 193
* out_len = op - out; 197
* out_len = op - out; 201
------------------------------
519 /home/speedy/test/source2slice/NVD/CVE_2014_4608_PATCHED_lzo1x_decompress_safe.c * out_len = op - out 187
int CVE_2014_4608_PATCHED_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t , 15 ) && HAVE_OP ( t , 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
ip = ie; 52
op = oe; 53
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t , 15 ) ) )  130
op += 8; 133
op += 8; 136
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 , 0 ) )  140
state = next; 141
op += next; 143
ip += next; 144
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 , 0 ) && HAVE_OP ( 4 , 0 ) ) )  170
op += t; 172
ip += t; 173
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
* out_len = op - out; 187
* out_len = op - out; 193
* out_len = op - out; 197
* out_len = op - out; 201
------------------------------
520 /home/speedy/test/source2slice/NVD/CVE_2014_4608_VULN_lzo1x_decompress_safe.c * out_len = op - out 201
int CVE_2014_4608_VULN_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t + 15 ) && HAVE_OP ( t + 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
ip = ie; 52
op = oe; 53
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t + 15 ) ) )  130
op += 8; 133
op += 8; 136
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 ) )  140
state = next; 141
op += next; 143
ip += next; 144
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 ) && HAVE_OP ( 4 ) ) )  170
op += t; 172
ip += t; 173
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
* out_len = op - out; 187
* out_len = op - out; 193
* out_len = op - out; 197
* out_len = op - out; 201
------------------------------
521 /home/speedy/test/source2slice/NVD/CVE_2014_4608_VULN_lzo1x_decompress_safe.c * out_len = op - out 197
int CVE_2014_4608_VULN_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t + 15 ) && HAVE_OP ( t + 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
ip = ie; 52
op = oe; 53
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t + 15 ) ) )  130
op += 8; 133
op += 8; 136
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 ) )  140
state = next; 141
op += next; 143
ip += next; 144
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 ) && HAVE_OP ( 4 ) ) )  170
op += t; 172
ip += t; 173
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
* out_len = op - out; 187
* out_len = op - out; 193
* out_len = op - out; 197
* out_len = op - out; 201
------------------------------
522 /home/speedy/test/source2slice/NVD/CVE_2014_4608_VULN_lzo1x_decompress_safe.c * out_len = op - out 193
int CVE_2014_4608_VULN_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t + 15 ) && HAVE_OP ( t + 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
ip = ie; 52
op = oe; 53
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t + 15 ) ) )  130
op += 8; 133
op += 8; 136
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 ) )  140
state = next; 141
op += next; 143
ip += next; 144
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 ) && HAVE_OP ( 4 ) ) )  170
op += t; 172
ip += t; 173
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
* out_len = op - out; 187
* out_len = op - out; 193
* out_len = op - out; 197
* out_len = op - out; 201
------------------------------
523 /home/speedy/test/source2slice/NVD/CVE_2014_4608_VULN_lzo1x_decompress_safe.c * out_len = op - out 187
int CVE_2014_4608_VULN_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t + 15 ) && HAVE_OP ( t + 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
ip = ie; 52
op = oe; 53
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t + 15 ) ) )  130
op += 8; 133
op += 8; 136
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 ) )  140
state = next; 141
op += next; 143
ip += next; 144
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 ) && HAVE_OP ( 4 ) ) )  170
op += t; 172
ip += t; 173
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
* out_len = op - out; 187
* out_len = op - out; 193
* out_len = op - out; 197
* out_len = op - out; 201
------------------------------
524 /home/speedy/test/source2slice/NVD/CVE_2014_4654_PATCHED_snd_ctl_elem_add.c ue -> elem_data = ( char * ) ue + sizeof ( * ue ) 80
static int CVE_2014_4654_PATCHED_snd_ctl_elem_add(struct snd_ctl_file *file,
struct snd_ctl_elem_info *info, int replace) 2
struct snd_card * card = file -> card ; 4
long private_size ; 7
struct user_element * ue ; 8
int idx , err ; 9
if ( info -> count < 1 )  11
info -> id . numid = 0; 17
if ( replace )  20
err = snd_ctl_remove_user_ctl ( file , & info -> id ); 21
if ( err )  22
if ( card -> user_ctl_count >= MAX_USER_CONTROLS )  26
switch ( info -> type )  44
private_size = sizeof ( long ); 47
if ( info -> count > 128 )  48
private_size = sizeof ( long long ); 52
if ( info -> count > 64 )  53
private_size = sizeof ( unsigned int ); 57
if ( info -> count > 128 || info -> value . enumerated . items == 0 )  58
private_size = sizeof ( unsigned char ); 62
if ( info -> count > 512 )  63
private_size = sizeof ( struct snd_aes_iec958 ); 67
if ( info -> count != 1 )  68
private_size *= info -> count; 74
ue = kzalloc ( sizeof ( struct user_element ) + private_size , GFP_KERNEL ); 75
if ( ue == NULL )  76
ue -> info = * info; 78
ue -> info . access = 0; 79
ue -> elem_data = ( char * ) ue + sizeof ( * ue ); 80
ue -> elem_data_size = private_size; 81
if ( ue -> info . type == SNDRV_CTL_ELEM_TYPE_ENUMERATED )  82
err = snd_ctl_elem_init_enum_names ( ue ); 83
if ( err < 0 )  84
kfree ( ue ); 85
return err ; 86
kfree ( ue -> priv_data ); 92
kfree ( ue ); 93
_kctl -> private_data = ue; 96
for (idx = 0; idx < _kctl->count; idx++) 97
_kctl -> vd [ idx ] . owner = file; 98
err = snd_ctl_add ( card , _kctl ); 99
if ( err < 0 )  100
return err ; 101
------------------------------
525 /home/speedy/test/source2slice/NVD/CVE_2014_4654_VULN_snd_ctl_elem_add.c ue -> elem_data = ( char * ) ue + sizeof ( * ue ) 87
static int CVE_2014_4654_VULN_snd_ctl_elem_add(struct snd_ctl_file *file,
struct snd_ctl_elem_info *info, int replace) 2
struct snd_card * card = file -> card ; 4
struct snd_kcontrol kctl , * _kctl ; 5
long private_size ; 7
struct user_element * ue ; 8
int idx , err ; 9
if ( ! replace && card -> user_ctl_count >= MAX_USER_CONTROLS )  11
if ( info -> count < 1 )  13
info -> id . numid = 0; 19
_kctl = snd_ctl_find_id ( card , & info -> id ); 22
err = 0; 23
if ( _kctl )  24
if ( replace )  25
err = snd_ctl_remove ( card , _kctl ); 26
err = - EBUSY; 28
if ( replace )  30
err = - ENOENT; 31
if ( err < 0 )  34
switch ( info -> type )  51
private_size = sizeof ( long ); 54
if ( info -> count > 128 )  55
private_size = sizeof ( long long ); 59
if ( info -> count > 64 )  60
private_size = sizeof ( unsigned int ); 64
if ( info -> count > 128 || info -> value . enumerated . items == 0 )  65
private_size = sizeof ( unsigned char ); 69
if ( info -> count > 512 )  70
private_size = sizeof ( struct snd_aes_iec958 ); 74
if ( info -> count != 1 )  75
private_size *= info -> count; 81
ue = kzalloc ( sizeof ( struct user_element ) + private_size , GFP_KERNEL ); 82
if ( ue == NULL )  83
ue -> info = * info; 85
ue -> info . access = 0; 86
ue -> elem_data = ( char * ) ue + sizeof ( * ue ); 87
ue -> elem_data_size = private_size; 88
if ( ue -> info . type == SNDRV_CTL_ELEM_TYPE_ENUMERATED )  89
err = snd_ctl_elem_init_enum_names ( ue ); 90
if ( err < 0 )  91
kfree ( ue ); 92
return err ; 93
kfree ( ue -> priv_data ); 99
kfree ( ue ); 100
_kctl -> private_data = ue; 103
for (idx = 0; idx < _kctl->count; idx++) 104
_kctl -> vd [ idx ] . owner = file; 105
err = snd_ctl_add ( card , _kctl ); 106
if ( err < 0 )  107
return err ; 108
------------------------------
526 /home/speedy/test/source2slice/NVD/CVE_2014_4655_PATCHED_snd_ctl_elem_add.c ue -> elem_data = ( char * ) ue + sizeof ( * ue ) 80
static int CVE_2014_4655_PATCHED_snd_ctl_elem_add(struct snd_ctl_file *file,
struct snd_ctl_elem_info *info, int replace) 2
struct snd_card * card = file -> card ; 4
long private_size ; 7
struct user_element * ue ; 8
int idx , err ; 9
if ( info -> count < 1 )  11
info -> id . numid = 0; 17
if ( replace )  20
err = snd_ctl_remove_user_ctl ( file , & info -> id ); 21
if ( err )  22
if ( card -> user_ctl_count >= MAX_USER_CONTROLS )  26
switch ( info -> type )  44
private_size = sizeof ( long ); 47
if ( info -> count > 128 )  48
private_size = sizeof ( long long ); 52
if ( info -> count > 64 )  53
private_size = sizeof ( unsigned int ); 57
if ( info -> count > 128 || info -> value . enumerated . items == 0 )  58
private_size = sizeof ( unsigned char ); 62
if ( info -> count > 512 )  63
private_size = sizeof ( struct snd_aes_iec958 ); 67
if ( info -> count != 1 )  68
private_size *= info -> count; 74
ue = kzalloc ( sizeof ( struct user_element ) + private_size , GFP_KERNEL ); 75
if ( ue == NULL )  76
ue -> info = * info; 78
ue -> info . access = 0; 79
ue -> elem_data = ( char * ) ue + sizeof ( * ue ); 80
ue -> elem_data_size = private_size; 81
if ( ue -> info . type == SNDRV_CTL_ELEM_TYPE_ENUMERATED )  82
err = snd_ctl_elem_init_enum_names ( ue ); 83
if ( err < 0 )  84
kfree ( ue ); 85
return err ; 86
kfree ( ue -> priv_data ); 92
kfree ( ue ); 93
_kctl -> private_data = ue; 96
for (idx = 0; idx < _kctl->count; idx++) 97
_kctl -> vd [ idx ] . owner = file; 98
err = snd_ctl_add ( card , _kctl ); 99
if ( err < 0 )  100
return err ; 101
------------------------------
527 /home/speedy/test/source2slice/NVD/CVE_2014_4655_VULN_snd_ctl_elem_add.c ue -> elem_data = ( char * ) ue + sizeof ( * ue ) 87
static int CVE_2014_4655_VULN_snd_ctl_elem_add(struct snd_ctl_file *file,
struct snd_ctl_elem_info *info, int replace) 2
struct snd_card * card = file -> card ; 4
struct snd_kcontrol kctl , * _kctl ; 5
long private_size ; 7
struct user_element * ue ; 8
int idx , err ; 9
if ( ! replace && card -> user_ctl_count >= MAX_USER_CONTROLS )  11
if ( info -> count < 1 )  13
info -> id . numid = 0; 19
_kctl = snd_ctl_find_id ( card , & info -> id ); 22
err = 0; 23
if ( _kctl )  24
if ( replace )  25
err = snd_ctl_remove ( card , _kctl ); 26
err = - EBUSY; 28
if ( replace )  30
err = - ENOENT; 31
if ( err < 0 )  34
switch ( info -> type )  51
private_size = sizeof ( long ); 54
if ( info -> count > 128 )  55
private_size = sizeof ( long long ); 59
if ( info -> count > 64 )  60
private_size = sizeof ( unsigned int ); 64
if ( info -> count > 128 || info -> value . enumerated . items == 0 )  65
private_size = sizeof ( unsigned char ); 69
if ( info -> count > 512 )  70
private_size = sizeof ( struct snd_aes_iec958 ); 74
if ( info -> count != 1 )  75
private_size *= info -> count; 81
ue = kzalloc ( sizeof ( struct user_element ) + private_size , GFP_KERNEL ); 82
if ( ue == NULL )  83
ue -> info = * info; 85
ue -> info . access = 0; 86
ue -> elem_data = ( char * ) ue + sizeof ( * ue ); 87
ue -> elem_data_size = private_size; 88
if ( ue -> info . type == SNDRV_CTL_ELEM_TYPE_ENUMERATED )  89
err = snd_ctl_elem_init_enum_names ( ue ); 90
if ( err < 0 )  91
kfree ( ue ); 92
return err ; 93
kfree ( ue -> priv_data ); 99
kfree ( ue ); 100
_kctl -> private_data = ue; 103
for (idx = 0; idx < _kctl->count; idx++) 104
_kctl -> vd [ idx ] . owner = file; 105
err = snd_ctl_add ( card , _kctl ); 106
if ( err < 0 )  107
return err ; 108
------------------------------
528 /home/speedy/test/source2slice/NVD/CVE_2014_5271_PATCHED_encode_frame.c frame_size = buf - orig_buf 118
static int CVE_2014_5271_PATCHED_encode_frame(AVCodecContext *avctx, AVPacket *pkt,
const AVFrame *pic, int *got_packet) 2
ProresContext * ctx = avctx -> priv_data ; 4
uint8_t * orig_buf , * buf , * slice_hdr , * slice_sizes , * tmp ; 5
int sizes [ 4 ] = { 0 } ; 9
int slice_hdr_size = 2 + 2 * ( ctx -> num_planes - 1 ) ; 10
int frame_size , picture_size , slice_size ; 11
int pkt_size , ret ; 12
* avctx -> coded_frame = * pic; 15
avctx -> coded_frame -> pict_type = AV_PICTURE_TYPE_I; 16
avctx -> coded_frame -> key_frame = 1; 17
pkt_size = ctx -> frame_size_upper_bound; 19
if ( ( ret = ff_alloc_packet2 ( avctx , pkt , pkt_size + FF_MIN_BUFFER_SIZE ) ) < 0 )  21
orig_buf = pkt -> data; 24
orig_buf += 4; 27
buf = orig_buf; 29
buf += 2; 33
if ( ctx -> quant_sel != QUANT_MAT_DEFAULT )  50
for (i = 0; i < 64; i++) 53
for (i = 0; i < 64; i++) 56
for (ctx->cur_picture_idx = 0;
ctx->cur_picture_idx < ctx->pictures_per_frame;
ctx->cur_picture_idx++) 65
buf += 4; 69
buf += ctx -> slices_per_picture * 2; 75
if ( ! ctx -> force_quant )  78
ret = avctx -> execute2 ( avctx , find_quant_thread , NULL , NULL , ctx -> mb_height ); 79
if ( ret )  81
for (y = 0; y < ctx->mb_height; y++) 85
int mbs_per_slice = ctx -> mbs_per_slice ; 86
for (x = mb = 0; x < ctx->mb_width; x += mbs_per_slice, mb++) 87
q = ctx -> force_quant ? ctx -> force_quant : ctx -> slice_q [ mb + y * ctx -> slices_width ]; 88
while ( ctx -> mb_width - x < mbs_per_slice )  91
mbs_per_slice >>= 1; 92
buf += slice_hdr_size - 1; 96
ret = encode_slice ( avctx , pic , & pb , sizes , x , y , q , mbs_per_slice ); 98
if ( ret < 0 )  99
slice_size = slice_hdr_size + sizes [ ctx -> num_planes - 1 ]; 103
for (i = 0; i < ctx->num_planes - 1; i++) 104
slice_size += sizes [ i ]; 106
buf += slice_size - slice_hdr_size; 109
orig_buf -= 8; 117
frame_size = buf - orig_buf; 118
bytestream_put_be32 ( & orig_buf , frame_size ); 119
pkt -> size = frame_size; 121
pkt -> flags |= AV_PKT_FLAG_KEY; 122
------------------------------
529 /home/speedy/test/source2slice/NVD/CVE_2014_5271_PATCHED_encode_frame.c slice_size = slice_hdr_size + sizes [ ctx -> num_planes - 1 ] 103
static int CVE_2014_5271_PATCHED_encode_frame(AVCodecContext *avctx, AVPacket *pkt,
const AVFrame *pic, int *got_packet) 2
ProresContext * ctx = avctx -> priv_data ; 4
int sizes [ 4 ] = { 0 } ; 9
int slice_hdr_size = 2 + 2 * ( ctx -> num_planes - 1 ) ; 10
int frame_size , picture_size , slice_size ; 11
int pkt_size , ret ; 12
* avctx -> coded_frame = * pic; 15
avctx -> coded_frame -> pict_type = AV_PICTURE_TYPE_I; 16
avctx -> coded_frame -> key_frame = 1; 17
pkt_size = ctx -> frame_size_upper_bound; 19
if ( ( ret = ff_alloc_packet2 ( avctx , pkt , pkt_size + FF_MIN_BUFFER_SIZE ) ) < 0 )  21
for (ctx->cur_picture_idx = 0;
ctx->cur_picture_idx < ctx->pictures_per_frame;
ctx->cur_picture_idx++) 65
picture_size_pos = buf + 1; 67
buf += 4; 69
bytestream_put_be16 ( & buf , ctx -> slices_per_picture ); 70
bytestream_put_byte ( & buf , av_log2 ( ctx -> mbs_per_slice ) << 4 ); 71
slice_sizes = buf; 74
buf += ctx -> slices_per_picture * 2; 75
if ( ! ctx -> force_quant )  78
ret = avctx -> execute2 ( avctx , find_quant_thread , NULL , NULL , ctx -> mb_height ); 79
if ( ret )  81
for (y = 0; y < ctx->mb_height; y++) 85
int mbs_per_slice = ctx -> mbs_per_slice ; 86
for (x = mb = 0; x < ctx->mb_width; x += mbs_per_slice, mb++) 87
q = ctx -> force_quant ? ctx -> force_quant : ctx -> slice_q [ mb + y * ctx -> slices_width ]; 88
while ( ctx -> mb_width - x < mbs_per_slice )  91
mbs_per_slice >>= 1; 92
bytestream_put_byte ( & buf , slice_hdr_size << 3 ); 94
slice_hdr = buf; 95
buf += slice_hdr_size - 1; 96
init_put_bits ( & pb , buf , ( pkt_size - ( buf - orig_buf ) ) * 8 ); 97
ret = encode_slice ( avctx , pic , & pb , sizes , x , y , q , mbs_per_slice ); 98
if ( ret < 0 )  99
bytestream_put_byte ( & slice_hdr , q ); 102
slice_size = slice_hdr_size + sizes [ ctx -> num_planes - 1 ]; 103
bytestream_put_be16 ( & slice_hdr , sizes [ i ] ); 105
slice_size += sizes [ i ]; 106
bytestream_put_be16 ( & slice_sizes , slice_size ); 108
buf += slice_size - slice_hdr_size; 109
picture_size = buf - ( picture_size_pos - 1 ); 113
bytestream_put_be32 ( & picture_size_pos , picture_size ); 114
frame_size = buf - orig_buf; 118
bytestream_put_be32 ( & orig_buf , frame_size ); 119
pkt -> size = frame_size; 121
pkt -> flags |= AV_PKT_FLAG_KEY; 122
------------------------------
530 /home/speedy/test/source2slice/NVD/CVE_2014_5271_PATCHED_encode_frame.c q = ctx -> force_quant ? ctx -> force_quant : ctx -> slice_q [ mb + y * ctx -> slices_width ] 88
static int CVE_2014_5271_PATCHED_encode_frame(AVCodecContext *avctx, AVPacket *pkt,
const AVFrame *pic, int *got_packet) 2
ProresContext * ctx = avctx -> priv_data ; 4
int sizes [ 4 ] = { 0 } ; 9
int pkt_size , ret ; 12
* avctx -> coded_frame = * pic; 15
avctx -> coded_frame -> pict_type = AV_PICTURE_TYPE_I; 16
avctx -> coded_frame -> key_frame = 1; 17
pkt_size = ctx -> frame_size_upper_bound; 19
if ( ( ret = ff_alloc_packet2 ( avctx , pkt , pkt_size + FF_MIN_BUFFER_SIZE ) ) < 0 )  21
for (ctx->cur_picture_idx = 0;
ctx->cur_picture_idx < ctx->pictures_per_frame;
ctx->cur_picture_idx++) 65
if ( ! ctx -> force_quant )  78
ret = avctx -> execute2 ( avctx , find_quant_thread , NULL , NULL , ctx -> mb_height ); 79
if ( ret )  81
for (y = 0; y < ctx->mb_height; y++) 85
int mbs_per_slice = ctx -> mbs_per_slice ; 86
for (x = mb = 0; x < ctx->mb_width; x += mbs_per_slice, mb++) 87
q = ctx -> force_quant ? ctx -> force_quant : ctx -> slice_q [ mb + y * ctx -> slices_width ]; 88
while ( ctx -> mb_width - x < mbs_per_slice )  91
mbs_per_slice >>= 1; 92
ret = encode_slice ( avctx , pic , & pb , sizes , x , y , q , mbs_per_slice ); 98
if ( ret < 0 )  99
return ret ; 100
bytestream_put_byte ( & slice_hdr , q ); 102
------------------------------
531 /home/speedy/test/source2slice/NVD/CVE_2014_5271_PATCHED_encode_slice.c get_alpha_data ( ctx , src , linesize , xp , yp , pwidth , avctx -> height / ctx -> pictures_per_frame , ctx -> blocks [ 0 ] , mbs_per_slice , ctx -> alpha_bits ) 61
static int CVE_2014_5271_PATCHED_encode_slice(AVCodecContext *avctx, const AVFrame *pic,
PutBitContext *pb,
int sizes[4], int x, int y, int quant,
int mbs_per_slice) 4
ProresContext * ctx = avctx -> priv_data ; 6
int i , xp , yp ; 7
const uint16_t * src ; 9
int slice_width_factor = av_log2 ( mbs_per_slice ) ; 10
int num_cblocks , pwidth , linesize , line_add ; 11
int plane_factor , is_chroma ; 12
uint16_t * qmat ; 13
if ( ctx -> pictures_per_frame == 1 )  15
line_add = 0; 16
line_add = ctx -> cur_picture_idx ^ ! pic -> top_field_first; 18
if ( ctx -> force_quant )  20
qmat = ctx -> quants [ 0 ]; 21
if ( quant < MAX_STORED_Q )  22
qmat = ctx -> quants [ quant ]; 23
qmat = ctx -> custom_q; 25
for (i = 0; i < 64; i++) 26
qmat [ i ] = ctx -> quant_mat [ i ] * quant; 27
for (i = 0; i < ctx->num_planes; i++) 30
is_chroma = ( i == 1 || i == 2 ); 31
plane_factor = slice_width_factor + 2; 32
if ( is_chroma )  33
plane_factor += ctx -> chroma_factor - 3; 34
if ( ! is_chroma || ctx -> chroma_factor == CFACTOR_Y444 )  35
xp = x << 4; 36
yp = y << 4; 37
num_cblocks = 4; 38
pwidth = avctx -> width; 39
xp = x << 3; 41
yp = y << 4; 42
num_cblocks = 2; 43
pwidth = avctx -> width >> 1; 44
linesize = pic -> linesize [ i ] * ctx -> pictures_per_frame; 47
src = ( const uint16_t * ) ( pic -> data [ i ] + yp * linesize + line_add * pic -> linesize [ i ] ) + xp; 48
if ( i < 3 )  51
sizes [ i ] = encode_slice_plane ( ctx , pb , src , linesize , mbs_per_slice , ctx -> blocks [ 0 ] , num_cblocks , plane_factor , qmat ); 56
get_alpha_data ( ctx , src , linesize , xp , yp , pwidth , avctx -> height / ctx -> pictures_per_frame , ctx -> blocks [ 0 ] , mbs_per_slice , ctx -> alpha_bits ); 61
sizes [ i ] = encode_alpha_plane ( ctx , pb , src , linesize , mbs_per_slice , ctx -> blocks [ 0 ] , quant ); 64
if ( put_bits_left ( pb ) < 0 )  69
------------------------------
532 /home/speedy/test/source2slice/NVD/CVE_2014_5271_PATCHED_encode_slice.c get_slice_data ( ctx , src , linesize , xp , yp , pwidth , avctx -> height / ctx -> pictures_per_frame , ctx -> blocks [ 0 ] , ctx -> emu_buf , mbs_per_slice , num_cblocks , is_chroma ) 52
static int CVE_2014_5271_PATCHED_encode_slice(AVCodecContext *avctx, const AVFrame *pic,
PutBitContext *pb,
int sizes[4], int x, int y, int quant,
int mbs_per_slice) 4
ProresContext * ctx = avctx -> priv_data ; 6
int i , xp , yp ; 7
const uint16_t * src ; 9
int slice_width_factor = av_log2 ( mbs_per_slice ) ; 10
int num_cblocks , pwidth , linesize , line_add ; 11
int plane_factor , is_chroma ; 12
uint16_t * qmat ; 13
if ( ctx -> pictures_per_frame == 1 )  15
line_add = 0; 16
line_add = ctx -> cur_picture_idx ^ ! pic -> top_field_first; 18
if ( ctx -> force_quant )  20
qmat = ctx -> quants [ 0 ]; 21
if ( quant < MAX_STORED_Q )  22
qmat = ctx -> quants [ quant ]; 23
qmat = ctx -> custom_q; 25
for (i = 0; i < 64; i++) 26
qmat [ i ] = ctx -> quant_mat [ i ] * quant; 27
for (i = 0; i < ctx->num_planes; i++) 30
is_chroma = ( i == 1 || i == 2 ); 31
plane_factor = slice_width_factor + 2; 32
if ( is_chroma )  33
plane_factor += ctx -> chroma_factor - 3; 34
if ( ! is_chroma || ctx -> chroma_factor == CFACTOR_Y444 )  35
xp = x << 4; 36
yp = y << 4; 37
num_cblocks = 4; 38
pwidth = avctx -> width; 39
xp = x << 3; 41
yp = y << 4; 42
num_cblocks = 2; 43
pwidth = avctx -> width >> 1; 44
linesize = pic -> linesize [ i ] * ctx -> pictures_per_frame; 47
src = ( const uint16_t * ) ( pic -> data [ i ] + yp * linesize + line_add * pic -> linesize [ i ] ) + xp; 48
if ( i < 3 )  51
get_slice_data ( ctx , src , linesize , xp , yp , pwidth , avctx -> height / ctx -> pictures_per_frame , ctx -> blocks [ 0 ] , ctx -> emu_buf , mbs_per_slice , num_cblocks , is_chroma ); 52
sizes [ i ] = encode_slice_plane ( ctx , pb , src , linesize , mbs_per_slice , ctx -> blocks [ 0 ] , num_cblocks , plane_factor , qmat ); 56
sizes [ i ] = encode_alpha_plane ( ctx , pb , src , linesize , mbs_per_slice , ctx -> blocks [ 0 ] , quant ); 64
if ( put_bits_left ( pb ) < 0 )  69
------------------------------
533 /home/speedy/test/source2slice/NVD/CVE_2014_5271_PATCHED_encode_slice.c src = ( const uint16_t * ) ( pic -> data [ i ] + yp * linesize + line_add * pic -> linesize [ i ] ) + xp 48
static int CVE_2014_5271_PATCHED_encode_slice(AVCodecContext *avctx, const AVFrame *pic,
PutBitContext *pb,
int sizes[4], int x, int y, int quant,
int mbs_per_slice) 4
ProresContext * ctx = avctx -> priv_data ; 6
int i , xp , yp ; 7
const uint16_t * src ; 9
int slice_width_factor = av_log2 ( mbs_per_slice ) ; 10
int num_cblocks , pwidth , linesize , line_add ; 11
int plane_factor , is_chroma ; 12
uint16_t * qmat ; 13
if ( ctx -> pictures_per_frame == 1 )  15
line_add = 0; 16
line_add = ctx -> cur_picture_idx ^ ! pic -> top_field_first; 18
if ( ctx -> force_quant )  20
qmat = ctx -> quants [ 0 ]; 21
if ( quant < MAX_STORED_Q )  22
qmat = ctx -> quants [ quant ]; 23
qmat = ctx -> custom_q; 25
for (i = 0; i < 64; i++) 26
qmat [ i ] = ctx -> quant_mat [ i ] * quant; 27
for (i = 0; i < ctx->num_planes; i++) 30
is_chroma = ( i == 1 || i == 2 ); 31
plane_factor = slice_width_factor + 2; 32
if ( is_chroma )  33
plane_factor += ctx -> chroma_factor - 3; 34
if ( ! is_chroma || ctx -> chroma_factor == CFACTOR_Y444 )  35
xp = x << 4; 36
yp = y << 4; 37
num_cblocks = 4; 38
xp = x << 3; 41
yp = y << 4; 42
num_cblocks = 2; 43
linesize = pic -> linesize [ i ] * ctx -> pictures_per_frame; 47
src = ( const uint16_t * ) ( pic -> data [ i ] + yp * linesize + line_add * pic -> linesize [ i ] ) + xp; 48
if ( i < 3 )  51
get_slice_data ( ctx , src , linesize , xp , yp , pwidth , avctx -> height / ctx -> pictures_per_frame , ctx -> blocks [ 0 ] , ctx -> emu_buf , mbs_per_slice , num_cblocks , is_chroma ); 52
sizes [ i ] = encode_slice_plane ( ctx , pb , src , linesize , mbs_per_slice , ctx -> blocks [ 0 ] , num_cblocks , plane_factor , qmat ); 56
get_alpha_data ( ctx , src , linesize , xp , yp , pwidth , avctx -> height / ctx -> pictures_per_frame , ctx -> blocks [ 0 ] , mbs_per_slice , ctx -> alpha_bits ); 61
sizes [ i ] = encode_alpha_plane ( ctx , pb , src , linesize , mbs_per_slice , ctx -> blocks [ 0 ] , quant ); 64
total_size += sizes [ i ]; 68
if ( put_bits_left ( pb ) < 0 )  69
return total_size ; 75
------------------------------
534 /home/speedy/test/source2slice/NVD/CVE_2014_5271_VULN_encode_frame.c frame_size = buf - orig_buf 116
static int CVE_2014_5271_VULN_encode_frame(AVCodecContext *avctx, AVPacket *pkt,
const AVFrame *pic, int *got_packet) 2
ProresContext * ctx = avctx -> priv_data ; 4
uint8_t * orig_buf , * buf , * slice_hdr , * slice_sizes , * tmp ; 5
int sizes [ 4 ] = { 0 } ; 9
int slice_hdr_size = 2 + 2 * ( ctx -> num_planes - 1 ) ; 10
int frame_size , picture_size , slice_size ; 11
int pkt_size , ret ; 12
* avctx -> coded_frame = * pic; 15
avctx -> coded_frame -> pict_type = AV_PICTURE_TYPE_I; 16
avctx -> coded_frame -> key_frame = 1; 17
pkt_size = ctx -> frame_size_upper_bound + FF_MIN_BUFFER_SIZE; 19
if ( ( ret = ff_alloc_packet2 ( avctx , pkt , pkt_size ) ) < 0 )  21
orig_buf = pkt -> data; 24
orig_buf += 4; 27
buf = orig_buf; 29
buf += 2; 33
if ( ctx -> quant_sel != QUANT_MAT_DEFAULT )  50
for (i = 0; i < 64; i++) 53
for (i = 0; i < 64; i++) 56
for (ctx->cur_picture_idx = 0;
ctx->cur_picture_idx < ctx->pictures_per_frame;
ctx->cur_picture_idx++) 65
buf += 4; 69
buf += ctx -> slices_per_picture * 2; 75
if ( ! ctx -> force_quant )  78
ret = avctx -> execute2 ( avctx , find_quant_thread , NULL , NULL , ctx -> mb_height ); 79
if ( ret )  81
for (y = 0; y < ctx->mb_height; y++) 85
int mbs_per_slice = ctx -> mbs_per_slice ; 86
for (x = mb = 0; x < ctx->mb_width; x += mbs_per_slice, mb++) 87
while ( ctx -> mb_width - x < mbs_per_slice )  91
mbs_per_slice >>= 1; 92
buf += slice_hdr_size - 1; 96
slice_size = slice_hdr_size + sizes [ ctx -> num_planes - 1 ]; 101
for (i = 0; i < ctx->num_planes - 1; i++) 102
slice_size += sizes [ i ]; 104
buf += slice_size - slice_hdr_size; 107
orig_buf -= 8; 115
frame_size = buf - orig_buf; 116
bytestream_put_be32 ( & orig_buf , frame_size ); 117
pkt -> size = frame_size; 119
pkt -> flags |= AV_PKT_FLAG_KEY; 120
------------------------------
535 /home/speedy/test/source2slice/NVD/CVE_2014_5271_VULN_encode_frame.c slice_size = slice_hdr_size + sizes [ ctx -> num_planes - 1 ] 101
static int CVE_2014_5271_VULN_encode_frame(AVCodecContext *avctx, AVPacket *pkt,
const AVFrame *pic, int *got_packet) 2
ProresContext * ctx = avctx -> priv_data ; 4
int sizes [ 4 ] = { 0 } ; 9
int slice_hdr_size = 2 + 2 * ( ctx -> num_planes - 1 ) ; 10
int frame_size , picture_size , slice_size ; 11
int pkt_size , ret ; 12
* avctx -> coded_frame = * pic; 15
avctx -> coded_frame -> pict_type = AV_PICTURE_TYPE_I; 16
avctx -> coded_frame -> key_frame = 1; 17
pkt_size = ctx -> frame_size_upper_bound + FF_MIN_BUFFER_SIZE; 19
if ( ( ret = ff_alloc_packet2 ( avctx , pkt , pkt_size ) ) < 0 )  21
for (ctx->cur_picture_idx = 0;
ctx->cur_picture_idx < ctx->pictures_per_frame;
ctx->cur_picture_idx++) 65
picture_size_pos = buf + 1; 67
buf += 4; 69
bytestream_put_be16 ( & buf , ctx -> slices_per_picture ); 70
bytestream_put_byte ( & buf , av_log2 ( ctx -> mbs_per_slice ) << 4 ); 71
slice_sizes = buf; 74
buf += ctx -> slices_per_picture * 2; 75
if ( ! ctx -> force_quant )  78
ret = avctx -> execute2 ( avctx , find_quant_thread , NULL , NULL , ctx -> mb_height ); 79
if ( ret )  81
for (y = 0; y < ctx->mb_height; y++) 85
int mbs_per_slice = ctx -> mbs_per_slice ; 86
for (x = mb = 0; x < ctx->mb_width; x += mbs_per_slice, mb++) 87
while ( ctx -> mb_width - x < mbs_per_slice )  91
mbs_per_slice >>= 1; 92
bytestream_put_byte ( & buf , slice_hdr_size << 3 ); 94
slice_hdr = buf; 95
buf += slice_hdr_size - 1; 96
init_put_bits ( & pb , buf , ( pkt_size - ( buf - orig_buf ) ) * 8 ); 97
bytestream_put_byte ( & slice_hdr , q ); 100
slice_size = slice_hdr_size + sizes [ ctx -> num_planes - 1 ]; 101
bytestream_put_be16 ( & slice_hdr , sizes [ i ] ); 103
slice_size += sizes [ i ]; 104
bytestream_put_be16 ( & slice_sizes , slice_size ); 106
buf += slice_size - slice_hdr_size; 107
picture_size = buf - ( picture_size_pos - 1 ); 111
bytestream_put_be32 ( & picture_size_pos , picture_size ); 112
frame_size = buf - orig_buf; 116
bytestream_put_be32 ( & orig_buf , frame_size ); 117
pkt -> size = frame_size; 119
pkt -> flags |= AV_PKT_FLAG_KEY; 120
------------------------------
536 /home/speedy/test/source2slice/NVD/CVE_2014_5271_VULN_encode_frame.c q = ctx -> force_quant ? ctx -> force_quant : ctx -> slice_q [ mb + y * ctx -> slices_width ] 88
static int CVE_2014_5271_VULN_encode_frame(AVCodecContext *avctx, AVPacket *pkt,
const AVFrame *pic, int *got_packet) 2
ProresContext * ctx = avctx -> priv_data ; 4
int pkt_size , ret ; 12
* avctx -> coded_frame = * pic; 15
avctx -> coded_frame -> pict_type = AV_PICTURE_TYPE_I; 16
avctx -> coded_frame -> key_frame = 1; 17
pkt_size = ctx -> frame_size_upper_bound + FF_MIN_BUFFER_SIZE; 19
if ( ( ret = ff_alloc_packet2 ( avctx , pkt , pkt_size ) ) < 0 )  21
for (ctx->cur_picture_idx = 0;
ctx->cur_picture_idx < ctx->pictures_per_frame;
ctx->cur_picture_idx++) 65
if ( ! ctx -> force_quant )  78
ret = avctx -> execute2 ( avctx , find_quant_thread , NULL , NULL , ctx -> mb_height ); 79
if ( ret )  81
for (y = 0; y < ctx->mb_height; y++) 85
int mbs_per_slice = ctx -> mbs_per_slice ; 86
for (x = mb = 0; x < ctx->mb_width; x += mbs_per_slice, mb++) 87
q = ctx -> force_quant ? ctx -> force_quant : ctx -> slice_q [ mb + y * ctx -> slices_width ]; 88
while ( ctx -> mb_width - x < mbs_per_slice )  91
mbs_per_slice >>= 1; 92
encode_slice ( avctx , pic , & pb , sizes , x , y , q , mbs_per_slice ); 98
bytestream_put_byte ( & slice_hdr , q ); 100
------------------------------
537 /home/speedy/test/source2slice/NVD/CVE_2014_5271_VULN_encode_frame.c pkt_size = ctx -> frame_size_upper_bound + FF_MIN_BUFFER_SIZE 19
static int CVE_2014_5271_VULN_encode_frame(AVCodecContext *avctx, AVPacket *pkt,
const AVFrame *pic, int *got_packet) 2
ProresContext * ctx = avctx -> priv_data ; 4
int pkt_size , ret ; 12
pkt_size = ctx -> frame_size_upper_bound + FF_MIN_BUFFER_SIZE; 19
if ( ( ret = ff_alloc_packet2 ( avctx , pkt , pkt_size ) ) < 0 )  21
return ret ; 22
if ( ret )  81
return ret ; 82
init_put_bits ( & pb , buf , ( pkt_size - ( buf - orig_buf ) ) * 8 ); 97
------------------------------
538 /home/speedy/test/source2slice/NVD/CVE_2014_5271_VULN_encode_slice.c get_alpha_data ( ctx , src , linesize , xp , yp , pwidth , avctx -> height / ctx -> pictures_per_frame , ctx -> blocks [ 0 ] , mbs_per_slice , ctx -> alpha_bits ) 61
static int CVE_2014_5271_VULN_encode_slice(AVCodecContext *avctx, const AVFrame *pic,
PutBitContext *pb,
int sizes[4], int x, int y, int quant,
int mbs_per_slice) 4
ProresContext * ctx = avctx -> priv_data ; 6
int i , xp , yp ; 7
const uint16_t * src ; 9
int slice_width_factor = av_log2 ( mbs_per_slice ) ; 10
int num_cblocks , pwidth , linesize , line_add ; 11
int plane_factor , is_chroma ; 12
uint16_t * qmat ; 13
if ( ctx -> pictures_per_frame == 1 )  15
line_add = 0; 16
line_add = ctx -> cur_picture_idx ^ ! pic -> top_field_first; 18
if ( ctx -> force_quant )  20
qmat = ctx -> quants [ 0 ]; 21
if ( quant < MAX_STORED_Q )  22
qmat = ctx -> quants [ quant ]; 23
qmat = ctx -> custom_q; 25
for (i = 0; i < 64; i++) 26
qmat [ i ] = ctx -> quant_mat [ i ] * quant; 27
for (i = 0; i < ctx->num_planes; i++) 30
is_chroma = ( i == 1 || i == 2 ); 31
plane_factor = slice_width_factor + 2; 32
if ( is_chroma )  33
plane_factor += ctx -> chroma_factor - 3; 34
if ( ! is_chroma || ctx -> chroma_factor == CFACTOR_Y444 )  35
xp = x << 4; 36
yp = y << 4; 37
num_cblocks = 4; 38
pwidth = avctx -> width; 39
xp = x << 3; 41
yp = y << 4; 42
num_cblocks = 2; 43
pwidth = avctx -> width >> 1; 44
linesize = pic -> linesize [ i ] * ctx -> pictures_per_frame; 47
src = ( const uint16_t * ) ( pic -> data [ i ] + yp * linesize + line_add * pic -> linesize [ i ] ) + xp; 48
if ( i < 3 )  51
sizes [ i ] = encode_slice_plane ( ctx , pb , src , linesize , mbs_per_slice , ctx -> blocks [ 0 ] , num_cblocks , plane_factor , qmat ); 56
get_alpha_data ( ctx , src , linesize , xp , yp , pwidth , avctx -> height / ctx -> pictures_per_frame , ctx -> blocks [ 0 ] , mbs_per_slice , ctx -> alpha_bits ); 61
sizes [ i ] = encode_alpha_plane ( ctx , pb , src , linesize , mbs_per_slice , ctx -> blocks [ 0 ] , quant ); 64
------------------------------
539 /home/speedy/test/source2slice/NVD/CVE_2014_5271_VULN_encode_slice.c get_slice_data ( ctx , src , linesize , xp , yp , pwidth , avctx -> height / ctx -> pictures_per_frame , ctx -> blocks [ 0 ] , ctx -> emu_buf , mbs_per_slice , num_cblocks , is_chroma ) 52
static int CVE_2014_5271_VULN_encode_slice(AVCodecContext *avctx, const AVFrame *pic,
PutBitContext *pb,
int sizes[4], int x, int y, int quant,
int mbs_per_slice) 4
ProresContext * ctx = avctx -> priv_data ; 6
int i , xp , yp ; 7
const uint16_t * src ; 9
int slice_width_factor = av_log2 ( mbs_per_slice ) ; 10
int num_cblocks , pwidth , linesize , line_add ; 11
int plane_factor , is_chroma ; 12
uint16_t * qmat ; 13
if ( ctx -> pictures_per_frame == 1 )  15
line_add = 0; 16
line_add = ctx -> cur_picture_idx ^ ! pic -> top_field_first; 18
if ( ctx -> force_quant )  20
qmat = ctx -> quants [ 0 ]; 21
if ( quant < MAX_STORED_Q )  22
qmat = ctx -> quants [ quant ]; 23
qmat = ctx -> custom_q; 25
for (i = 0; i < 64; i++) 26
qmat [ i ] = ctx -> quant_mat [ i ] * quant; 27
for (i = 0; i < ctx->num_planes; i++) 30
is_chroma = ( i == 1 || i == 2 ); 31
plane_factor = slice_width_factor + 2; 32
if ( is_chroma )  33
plane_factor += ctx -> chroma_factor - 3; 34
if ( ! is_chroma || ctx -> chroma_factor == CFACTOR_Y444 )  35
xp = x << 4; 36
yp = y << 4; 37
num_cblocks = 4; 38
pwidth = avctx -> width; 39
xp = x << 3; 41
yp = y << 4; 42
num_cblocks = 2; 43
pwidth = avctx -> width >> 1; 44
linesize = pic -> linesize [ i ] * ctx -> pictures_per_frame; 47
src = ( const uint16_t * ) ( pic -> data [ i ] + yp * linesize + line_add * pic -> linesize [ i ] ) + xp; 48
if ( i < 3 )  51
get_slice_data ( ctx , src , linesize , xp , yp , pwidth , avctx -> height / ctx -> pictures_per_frame , ctx -> blocks [ 0 ] , ctx -> emu_buf , mbs_per_slice , num_cblocks , is_chroma ); 52
sizes [ i ] = encode_slice_plane ( ctx , pb , src , linesize , mbs_per_slice , ctx -> blocks [ 0 ] , num_cblocks , plane_factor , qmat ); 56
sizes [ i ] = encode_alpha_plane ( ctx , pb , src , linesize , mbs_per_slice , ctx -> blocks [ 0 ] , quant ); 64
------------------------------
540 /home/speedy/test/source2slice/NVD/CVE_2014_5271_VULN_encode_slice.c src = ( const uint16_t * ) ( pic -> data [ i ] + yp * linesize + line_add * pic -> linesize [ i ] ) + xp 48
static int CVE_2014_5271_VULN_encode_slice(AVCodecContext *avctx, const AVFrame *pic,
PutBitContext *pb,
int sizes[4], int x, int y, int quant,
int mbs_per_slice) 4
ProresContext * ctx = avctx -> priv_data ; 6
int i , xp , yp ; 7
const uint16_t * src ; 9
int slice_width_factor = av_log2 ( mbs_per_slice ) ; 10
int num_cblocks , pwidth , linesize , line_add ; 11
int plane_factor , is_chroma ; 12
uint16_t * qmat ; 13
if ( ctx -> pictures_per_frame == 1 )  15
line_add = 0; 16
line_add = ctx -> cur_picture_idx ^ ! pic -> top_field_first; 18
if ( ctx -> force_quant )  20
qmat = ctx -> quants [ 0 ]; 21
if ( quant < MAX_STORED_Q )  22
qmat = ctx -> quants [ quant ]; 23
qmat = ctx -> custom_q; 25
for (i = 0; i < 64; i++) 26
qmat [ i ] = ctx -> quant_mat [ i ] * quant; 27
for (i = 0; i < ctx->num_planes; i++) 30
is_chroma = ( i == 1 || i == 2 ); 31
plane_factor = slice_width_factor + 2; 32
if ( is_chroma )  33
plane_factor += ctx -> chroma_factor - 3; 34
if ( ! is_chroma || ctx -> chroma_factor == CFACTOR_Y444 )  35
xp = x << 4; 36
yp = y << 4; 37
num_cblocks = 4; 38
xp = x << 3; 41
yp = y << 4; 42
num_cblocks = 2; 43
linesize = pic -> linesize [ i ] * ctx -> pictures_per_frame; 47
src = ( const uint16_t * ) ( pic -> data [ i ] + yp * linesize + line_add * pic -> linesize [ i ] ) + xp; 48
if ( i < 3 )  51
get_slice_data ( ctx , src , linesize , xp , yp , pwidth , avctx -> height / ctx -> pictures_per_frame , ctx -> blocks [ 0 ] , ctx -> emu_buf , mbs_per_slice , num_cblocks , is_chroma ); 52
sizes [ i ] = encode_slice_plane ( ctx , pb , src , linesize , mbs_per_slice , ctx -> blocks [ 0 ] , num_cblocks , plane_factor , qmat ); 56
get_alpha_data ( ctx , src , linesize , xp , yp , pwidth , avctx -> height / ctx -> pictures_per_frame , ctx -> blocks [ 0 ] , mbs_per_slice , ctx -> alpha_bits ); 61
sizes [ i ] = encode_alpha_plane ( ctx , pb , src , linesize , mbs_per_slice , ctx -> blocks [ 0 ] , quant ); 64
total_size += sizes [ i ]; 68
return total_size ; 70
------------------------------
541 /home/speedy/test/source2slice/NVD/CVE_2014_5471_PATCHED_isofs_read_inode.c de = ( struct iso_directory_record * ) ( bh -> b_data + offset ) 23
static int CVE_2014_5471_PATCHED_isofs_read_inode(struct inode *inode, int relocated) 1
unsigned long block ; 6
struct iso_directory_record * de ; 9
unsigned long offset ; 12
struct iso_inode_info * ei = ISOFS_I ( inode ) ; 13
block = ei -> i_iget5_block; 16
bh = sb_bread ( inode -> i_sb , block ); 17
if ( ! bh )  18
offset = ei -> i_iget5_offset; 21
de = ( struct iso_directory_record * ) ( bh -> b_data + offset ); 23
de_len = * ( unsigned char * ) de; 24
if ( offset + de_len > bufsize )  26
tmpde = kmalloc ( de_len , GFP_KERNEL ); 29
if ( tmpde == NULL )  30
memcpy ( tmpde , bh -> b_data + offset , frag1 ); 35
memcpy ( ( char * ) tmpde + frag1 , bh -> b_data , de_len - frag1 ); 40
de = tmpde; 41
if ( de -> flags [ - high_sierra ] & 2 )  51
ei -> i_section_size = isonum_733 ( de -> size ); 84
if ( de -> flags [ - high_sierra ] & 0x80 )  85
ei -> i_next_section_block = 0; 91
ei -> i_next_section_offset = 0; 92
inode -> i_size = isonum_733 ( de -> size ); 93
inode -> i_size &= 0x00ffffff; 103
if ( de -> interleave [ 0 ] )  105
inode -> i_size = 0; 107
if ( de -> file_unit_size [ 0 ] != 0 )  112
printk ( KERN_DEBUG "ISOFS: File unit size != 0 for ISO file (%ld).\n" ,
inode -> i_ino ) 114
if ( ( de -> flags [ - high_sierra ] & ~2 ) != 0 )  120
printk ( KERN_DEBUG "ISOFS: Unusual flag settings for ISO file "
"(%ld %x).\n" ,
inode -> i_ino , de -> flags [ - high_sierra ] ) 123
inode -> i_mtime . tv_sec = inode -> i_atime . tv_sec = inode -> i_ctime . tv_sec = iso_date ( de -> date , high_sierra ); 127
inode -> i_mtime . tv_nsec = inode -> i_atime . tv_nsec = inode -> i_ctime . tv_nsec = 0; 130
ei -> i_first_extent = ( isonum_733 ( de -> extent ) + isonum_711 ( de -> ext_attr_length ) ); 134
inode -> i_blocks = ( inode -> i_size + 511 ) >> 9; 138
parse_rock_ridge_inode ( de , inode , relocated ); 146
inode -> i_uid = sbi -> s_uid; 149
inode -> i_gid = sbi -> s_gid; 151
if ( S_ISDIR ( inode -> i_mode ) && sbi -> s_overriderockperm && sbi -> s_dmode != ISOFS_INVALID_MODE )  154
inode -> i_mode = S_IFDIR | sbi -> s_dmode; 156
if ( S_ISREG ( inode -> i_mode ) && sbi -> s_overriderockperm && sbi -> s_fmode != ISOFS_INVALID_MODE )  157
inode -> i_mode = S_IFREG | sbi -> s_fmode; 159
if ( S_ISREG ( inode -> i_mode ) )  162
inode -> i_fop = & generic_ro_fops; 163
switch ( ei -> i_file_format )  164
inode -> i_data . a_ops = & zisofs_aops; 167
inode -> i_data . a_ops = & isofs_aops; 171
if ( S_ISDIR ( inode -> i_mode ) )  174
if ( S_ISLNK ( inode -> i_mode ) )  177
init_special_inode ( inode , inode -> i_mode , inode -> i_rdev ); 182
kfree ( tmpde ); 186
------------------------------
542 /home/speedy/test/source2slice/NVD/CVE_2014_5471_VULN_isofs_read_inode.c de = ( struct iso_directory_record * ) ( bh -> b_data + offset ) 23
static int CVE_2014_5471_VULN_isofs_read_inode(struct inode *inode) 1
unsigned long block ; 6
struct iso_directory_record * de ; 9
unsigned long offset ; 12
struct iso_inode_info * ei = ISOFS_I ( inode ) ; 13
block = ei -> i_iget5_block; 16
bh = sb_bread ( inode -> i_sb , block ); 17
if ( ! bh )  18
offset = ei -> i_iget5_offset; 21
de = ( struct iso_directory_record * ) ( bh -> b_data + offset ); 23
de_len = * ( unsigned char * ) de; 24
if ( offset + de_len > bufsize )  26
tmpde = kmalloc ( de_len , GFP_KERNEL ); 29
if ( tmpde == NULL )  30
memcpy ( tmpde , bh -> b_data + offset , frag1 ); 35
memcpy ( ( char * ) tmpde + frag1 , bh -> b_data , de_len - frag1 ); 40
de = tmpde; 41
if ( de -> flags [ - high_sierra ] & 2 )  51
ei -> i_section_size = isonum_733 ( de -> size ); 84
if ( de -> flags [ - high_sierra ] & 0x80 )  85
ei -> i_next_section_block = 0; 91
ei -> i_next_section_offset = 0; 92
inode -> i_size = isonum_733 ( de -> size ); 93
inode -> i_size &= 0x00ffffff; 103
if ( de -> interleave [ 0 ] )  105
inode -> i_size = 0; 107
if ( de -> file_unit_size [ 0 ] != 0 )  112
printk ( KERN_DEBUG "ISOFS: File unit size != 0 for ISO file (%ld).\n" ,
inode -> i_ino ) 114
if ( ( de -> flags [ - high_sierra ] & ~2 ) != 0 )  120
printk ( KERN_DEBUG "ISOFS: Unusual flag settings for ISO file "
"(%ld %x).\n" ,
inode -> i_ino , de -> flags [ - high_sierra ] ) 123
inode -> i_mtime . tv_sec = inode -> i_atime . tv_sec = inode -> i_ctime . tv_sec = iso_date ( de -> date , high_sierra ); 127
inode -> i_mtime . tv_nsec = inode -> i_atime . tv_nsec = inode -> i_ctime . tv_nsec = 0; 130
ei -> i_first_extent = ( isonum_733 ( de -> extent ) + isonum_711 ( de -> ext_attr_length ) ); 134
inode -> i_blocks = ( inode -> i_size + 511 ) >> 9; 138
parse_rock_ridge_inode ( de , inode ); 146
inode -> i_uid = sbi -> s_uid; 149
inode -> i_gid = sbi -> s_gid; 151
if ( S_ISDIR ( inode -> i_mode ) && sbi -> s_overriderockperm && sbi -> s_dmode != ISOFS_INVALID_MODE )  154
inode -> i_mode = S_IFDIR | sbi -> s_dmode; 156
if ( S_ISREG ( inode -> i_mode ) && sbi -> s_overriderockperm && sbi -> s_fmode != ISOFS_INVALID_MODE )  157
inode -> i_mode = S_IFREG | sbi -> s_fmode; 159
if ( S_ISREG ( inode -> i_mode ) )  162
inode -> i_fop = & generic_ro_fops; 163
switch ( ei -> i_file_format )  164
inode -> i_data . a_ops = & zisofs_aops; 167
inode -> i_data . a_ops = & isofs_aops; 171
if ( S_ISDIR ( inode -> i_mode ) )  174
if ( S_ISLNK ( inode -> i_mode ) )  177
init_special_inode ( inode , inode -> i_mode , inode -> i_rdev ); 182
kfree ( tmpde ); 186
------------------------------
543 /home/speedy/test/source2slice/NVD/CVE_2014_5472_PATCHED_isofs_read_inode.c de = ( struct iso_directory_record * ) ( bh -> b_data + offset ) 23
static int CVE_2014_5472_PATCHED_isofs_read_inode(struct inode *inode, int relocated) 1
unsigned long block ; 6
struct iso_directory_record * de ; 9
unsigned long offset ; 12
struct iso_inode_info * ei = ISOFS_I ( inode ) ; 13
block = ei -> i_iget5_block; 16
bh = sb_bread ( inode -> i_sb , block ); 17
if ( ! bh )  18
offset = ei -> i_iget5_offset; 21
de = ( struct iso_directory_record * ) ( bh -> b_data + offset ); 23
de_len = * ( unsigned char * ) de; 24
if ( offset + de_len > bufsize )  26
tmpde = kmalloc ( de_len , GFP_KERNEL ); 29
if ( tmpde == NULL )  30
memcpy ( tmpde , bh -> b_data + offset , frag1 ); 35
memcpy ( ( char * ) tmpde + frag1 , bh -> b_data , de_len - frag1 ); 40
de = tmpde; 41
if ( de -> flags [ - high_sierra ] & 2 )  51
ei -> i_section_size = isonum_733 ( de -> size ); 84
if ( de -> flags [ - high_sierra ] & 0x80 )  85
ei -> i_next_section_block = 0; 91
ei -> i_next_section_offset = 0; 92
inode -> i_size = isonum_733 ( de -> size ); 93
inode -> i_size &= 0x00ffffff; 103
if ( de -> interleave [ 0 ] )  105
inode -> i_size = 0; 107
if ( de -> file_unit_size [ 0 ] != 0 )  112
printk ( KERN_DEBUG "ISOFS: File unit size != 0 for ISO file (%ld).\n" ,
inode -> i_ino ) 114
if ( ( de -> flags [ - high_sierra ] & ~2 ) != 0 )  120
printk ( KERN_DEBUG "ISOFS: Unusual flag settings for ISO file "
"(%ld %x).\n" ,
inode -> i_ino , de -> flags [ - high_sierra ] ) 123
inode -> i_mtime . tv_sec = inode -> i_atime . tv_sec = inode -> i_ctime . tv_sec = iso_date ( de -> date , high_sierra ); 127
inode -> i_mtime . tv_nsec = inode -> i_atime . tv_nsec = inode -> i_ctime . tv_nsec = 0; 130
ei -> i_first_extent = ( isonum_733 ( de -> extent ) + isonum_711 ( de -> ext_attr_length ) ); 134
inode -> i_blocks = ( inode -> i_size + 511 ) >> 9; 138
parse_rock_ridge_inode ( de , inode , relocated ); 146
inode -> i_uid = sbi -> s_uid; 149
inode -> i_gid = sbi -> s_gid; 151
if ( S_ISDIR ( inode -> i_mode ) && sbi -> s_overriderockperm && sbi -> s_dmode != ISOFS_INVALID_MODE )  154
inode -> i_mode = S_IFDIR | sbi -> s_dmode; 156
if ( S_ISREG ( inode -> i_mode ) && sbi -> s_overriderockperm && sbi -> s_fmode != ISOFS_INVALID_MODE )  157
inode -> i_mode = S_IFREG | sbi -> s_fmode; 159
if ( S_ISREG ( inode -> i_mode ) )  162
inode -> i_fop = & generic_ro_fops; 163
switch ( ei -> i_file_format )  164
inode -> i_data . a_ops = & zisofs_aops; 167
inode -> i_data . a_ops = & isofs_aops; 171
if ( S_ISDIR ( inode -> i_mode ) )  174
if ( S_ISLNK ( inode -> i_mode ) )  177
init_special_inode ( inode , inode -> i_mode , inode -> i_rdev ); 182
kfree ( tmpde ); 186
------------------------------
544 /home/speedy/test/source2slice/NVD/CVE_2014_5472_VULN_isofs_read_inode.c de = ( struct iso_directory_record * ) ( bh -> b_data + offset ) 23
static int CVE_2014_5472_VULN_isofs_read_inode(struct inode *inode) 1
unsigned long block ; 6
struct iso_directory_record * de ; 9
unsigned long offset ; 12
struct iso_inode_info * ei = ISOFS_I ( inode ) ; 13
block = ei -> i_iget5_block; 16
bh = sb_bread ( inode -> i_sb , block ); 17
if ( ! bh )  18
offset = ei -> i_iget5_offset; 21
de = ( struct iso_directory_record * ) ( bh -> b_data + offset ); 23
de_len = * ( unsigned char * ) de; 24
if ( offset + de_len > bufsize )  26
tmpde = kmalloc ( de_len , GFP_KERNEL ); 29
if ( tmpde == NULL )  30
memcpy ( tmpde , bh -> b_data + offset , frag1 ); 35
memcpy ( ( char * ) tmpde + frag1 , bh -> b_data , de_len - frag1 ); 40
de = tmpde; 41
if ( de -> flags [ - high_sierra ] & 2 )  51
ei -> i_section_size = isonum_733 ( de -> size ); 84
if ( de -> flags [ - high_sierra ] & 0x80 )  85
ei -> i_next_section_block = 0; 91
ei -> i_next_section_offset = 0; 92
inode -> i_size = isonum_733 ( de -> size ); 93
inode -> i_size &= 0x00ffffff; 103
if ( de -> interleave [ 0 ] )  105
inode -> i_size = 0; 107
if ( de -> file_unit_size [ 0 ] != 0 )  112
printk ( KERN_DEBUG "ISOFS: File unit size != 0 for ISO file (%ld).\n" ,
inode -> i_ino ) 114
if ( ( de -> flags [ - high_sierra ] & ~2 ) != 0 )  120
printk ( KERN_DEBUG "ISOFS: Unusual flag settings for ISO file "
"(%ld %x).\n" ,
inode -> i_ino , de -> flags [ - high_sierra ] ) 123
inode -> i_mtime . tv_sec = inode -> i_atime . tv_sec = inode -> i_ctime . tv_sec = iso_date ( de -> date , high_sierra ); 127
inode -> i_mtime . tv_nsec = inode -> i_atime . tv_nsec = inode -> i_ctime . tv_nsec = 0; 130
ei -> i_first_extent = ( isonum_733 ( de -> extent ) + isonum_711 ( de -> ext_attr_length ) ); 134
inode -> i_blocks = ( inode -> i_size + 511 ) >> 9; 138
parse_rock_ridge_inode ( de , inode ); 146
inode -> i_uid = sbi -> s_uid; 149
inode -> i_gid = sbi -> s_gid; 151
if ( S_ISDIR ( inode -> i_mode ) && sbi -> s_overriderockperm && sbi -> s_dmode != ISOFS_INVALID_MODE )  154
inode -> i_mode = S_IFDIR | sbi -> s_dmode; 156
if ( S_ISREG ( inode -> i_mode ) && sbi -> s_overriderockperm && sbi -> s_fmode != ISOFS_INVALID_MODE )  157
inode -> i_mode = S_IFREG | sbi -> s_fmode; 159
if ( S_ISREG ( inode -> i_mode ) )  162
inode -> i_fop = & generic_ro_fops; 163
switch ( ei -> i_file_format )  164
inode -> i_data . a_ops = & zisofs_aops; 167
inode -> i_data . a_ops = & isofs_aops; 171
if ( S_ISDIR ( inode -> i_mode ) )  174
if ( S_ISLNK ( inode -> i_mode ) )  177
init_special_inode ( inode , inode -> i_mode , inode -> i_rdev ); 182
kfree ( tmpde ); 186
------------------------------
545 /home/speedy/test/source2slice/NVD/CVE_2015_0228_PATCHED_lua_websocket_read.c rv = apr_socket_recv ( sock , buffer + at , & received ) 114
static int CVE_2015_0228_PATCHED_lua_websocket_read(lua_State *L) 1
apr_socket_t * sock ; 3
apr_status_t rv ; 4
int do_read = 1 ; 5
unsigned short payload_short = 0 ; 9
unsigned char * mask_bytes ; 11
char byte ; 12
int plaintext ; 13
request_rec * r = ap_lua_check_request_rec ( L , 1 ) ; 16
plaintext = ap_lua_ssl_is_https ( r -> connection ) ? 0 : 1; 17
mask_bytes = apr_pcalloc ( r -> pool , 4 ); 20
sock = ap_get_conn_socket ( r -> connection ); 21
while ( do_read )  23
do_read = 0; 24
if ( plaintext )  26
rv = apr_socket_recv ( sock , & byte , & len ); 27
rv = lua_websocket_readbytes ( r -> connection , & byte , 1 ); 30
if ( rv == APR_SUCCESS )  32
unsigned char fin , opcode , mask , payload ; 33
opcode = ( byte << 4 ) >> 4; 35
if ( plaintext )  38
rv = apr_socket_recv ( sock , & byte , & len ); 39
rv = lua_websocket_readbytes ( r -> connection , & byte , 1 ); 42
if ( rv == APR_SUCCESS )  44
mask = byte >> 7; 45
payload = byte - 128; 46
plen = payload; 47
if ( payload == 126 )  50
len = 2; 51
if ( plaintext )  52
rv = apr_socket_recv ( sock , ( char * ) & payload_short , & len ); 53
rv = lua_websocket_readbytes ( r -> connection , ( char * ) & payload_short , 2 ); 56
payload_short = ntohs ( payload_short ); 59
if ( rv == APR_SUCCESS )  61
plen = payload_short; 62
if ( payload == 127 )  69
len = 8; 70
if ( plaintext )  71
rv = apr_socket_recv ( sock , ( char * ) & payload_long , & len ); 72
rv = lua_websocket_readbytes ( r -> connection , ( char * ) & payload_long , 8 ); 75
if ( rv == APR_SUCCESS )  78
plen = ap_ntoh64 ( & payload_long ); 79
if ( mask )  91
len = 4; 92
if ( plaintext )  93
rv = apr_socket_recv ( sock , ( char * ) mask_bytes , & len ); 94
rv = lua_websocket_readbytes ( r -> connection , ( char * ) mask_bytes , 4 ); 97
if ( rv != APR_SUCCESS )  100
if ( plen < ( HUGE_STRING_LEN * 1024 ) && plen > 0 )  104
apr_size_t remaining = plen ; 105
apr_size_t received ; 106
apr_off_t at = 0 ; 107
char * buffer = apr_palloc ( r -> pool , plen + 1 ) ; 108
buffer [ plen ] = 0; 109
if ( plaintext )  111
while ( remaining > 0 )  112
received = remaining; 113
rv = apr_socket_recv ( sock , buffer + at , & received ); 114
if ( received > 0 )  115
remaining -= received; 116
at += received; 117
if ( opcode == 0x09 )  145
do_read = 1; 151
------------------------------
546 /home/speedy/test/source2slice/NVD/CVE_2015_0228_VULN_lua_websocket_read.c rv = apr_socket_recv ( sock , buffer + at , & received ) 111
static int CVE_2015_0228_VULN_lua_websocket_read(lua_State *L) 1
apr_socket_t * sock ; 3
apr_status_t rv ; 4
unsigned short payload_short = 0 ; 8
unsigned char * mask_bytes ; 10
char byte ; 11
int plaintext ; 12
request_rec * r = ap_lua_check_request_rec ( L , 1 ) ; 15
plaintext = ap_lua_ssl_is_https ( r -> connection ) ? 0 : 1; 16
mask_bytes = apr_pcalloc ( r -> pool , 4 ); 19
sock = ap_get_conn_socket ( r -> connection ); 20
if ( plaintext )  23
rv = apr_socket_recv ( sock , & byte , & len ); 24
rv = lua_websocket_readbytes ( r -> connection , & byte , 1 ); 27
if ( rv == APR_SUCCESS )  29
unsigned char fin , opcode , mask , payload ; 30
opcode = ( byte << 4 ) >> 4; 32
if ( plaintext )  35
rv = apr_socket_recv ( sock , & byte , & len ); 36
rv = lua_websocket_readbytes ( r -> connection , & byte , 1 ); 39
if ( rv == APR_SUCCESS )  41
mask = byte >> 7; 42
payload = byte - 128; 43
plen = payload; 44
if ( payload == 126 )  47
len = 2; 48
if ( plaintext )  49
rv = apr_socket_recv ( sock , ( char * ) & payload_short , & len ); 50
rv = lua_websocket_readbytes ( r -> connection , ( char * ) & payload_short , 2 ); 53
payload_short = ntohs ( payload_short ); 56
if ( rv == APR_SUCCESS )  58
plen = payload_short; 59
if ( payload == 127 )  66
len = 8; 67
if ( plaintext )  68
rv = apr_socket_recv ( sock , ( char * ) & payload_long , & len ); 69
rv = lua_websocket_readbytes ( r -> connection , ( char * ) & payload_long , 8 ); 72
if ( rv == APR_SUCCESS )  75
plen = ap_ntoh64 ( & payload_long ); 76
if ( mask )  88
len = 4; 89
if ( plaintext )  90
rv = apr_socket_recv ( sock , ( char * ) mask_bytes , & len ); 91
rv = lua_websocket_readbytes ( r -> connection , ( char * ) mask_bytes , 4 ); 94
if ( rv != APR_SUCCESS )  97
if ( plen < ( HUGE_STRING_LEN * 1024 ) && plen > 0 )  101
if ( opcode == 0x09 )  142
CVE_2015_0228_VULN_lua_websocket_read ( L ); 148
static int CVE_2015_0228_VULN_lua_websocket_read(lua_State *L) 1
apr_socket_t * sock ; 3
apr_status_t rv ; 4
unsigned short payload_short = 0 ; 8
unsigned char * mask_bytes ; 10
char byte ; 11
int plaintext ; 12
request_rec * r = ap_lua_check_request_rec ( L , 1 ) ; 15
plaintext = ap_lua_ssl_is_https ( r -> connection ) ? 0 : 1; 16
mask_bytes = apr_pcalloc ( r -> pool , 4 ); 19
sock = ap_get_conn_socket ( r -> connection ); 20
if ( plaintext )  23
rv = apr_socket_recv ( sock , & byte , & len ); 24
rv = lua_websocket_readbytes ( r -> connection , & byte , 1 ); 27
if ( rv == APR_SUCCESS )  29
unsigned char fin , opcode , mask , payload ; 30
opcode = ( byte << 4 ) >> 4; 32
if ( plaintext )  35
rv = apr_socket_recv ( sock , & byte , & len ); 36
rv = lua_websocket_readbytes ( r -> connection , & byte , 1 ); 39
if ( rv == APR_SUCCESS )  41
mask = byte >> 7; 42
payload = byte - 128; 43
plen = payload; 44
if ( payload == 126 )  47
len = 2; 48
if ( plaintext )  49
rv = apr_socket_recv ( sock , ( char * ) & payload_short , & len ); 50
rv = lua_websocket_readbytes ( r -> connection , ( char * ) & payload_short , 2 ); 53
payload_short = ntohs ( payload_short ); 56
if ( rv == APR_SUCCESS )  58
plen = payload_short; 59
if ( payload == 127 )  66
len = 8; 67
if ( plaintext )  68
rv = apr_socket_recv ( sock , ( char * ) & payload_long , & len ); 69
rv = lua_websocket_readbytes ( r -> connection , ( char * ) & payload_long , 8 ); 72
if ( rv == APR_SUCCESS )  75
plen = ap_ntoh64 ( & payload_long ); 76
if ( mask )  88
len = 4; 89
if ( plaintext )  90
rv = apr_socket_recv ( sock , ( char * ) mask_bytes , & len ); 91
rv = lua_websocket_readbytes ( r -> connection , ( char * ) mask_bytes , 4 ); 94
if ( rv != APR_SUCCESS )  97
if ( plen < ( HUGE_STRING_LEN * 1024 ) && plen > 0 )  101
if ( opcode == 0x09 )  142
CVE_2015_0228_VULN_lua_websocket_read ( L ); 148
static int CVE_2015_0228_VULN_lua_websocket_read(lua_State *L) 1
apr_socket_t * sock ; 3
apr_status_t rv ; 4
unsigned short payload_short = 0 ; 8
unsigned char * mask_bytes ; 10
char byte ; 11
int plaintext ; 12
request_rec * r = ap_lua_check_request_rec ( L , 1 ) ; 15
plaintext = ap_lua_ssl_is_https ( r -> connection ) ? 0 : 1; 16
mask_bytes = apr_pcalloc ( r -> pool , 4 ); 19
sock = ap_get_conn_socket ( r -> connection ); 20
if ( plaintext )  23
rv = apr_socket_recv ( sock , & byte , & len ); 24
rv = lua_websocket_readbytes ( r -> connection , & byte , 1 ); 27
if ( rv == APR_SUCCESS )  29
unsigned char fin , opcode , mask , payload ; 30
opcode = ( byte << 4 ) >> 4; 32
if ( plaintext )  35
rv = apr_socket_recv ( sock , & byte , & len ); 36
rv = lua_websocket_readbytes ( r -> connection , & byte , 1 ); 39
if ( rv == APR_SUCCESS )  41
mask = byte >> 7; 42
payload = byte - 128; 43
plen = payload; 44
if ( payload == 126 )  47
len = 2; 48
if ( plaintext )  49
rv = apr_socket_recv ( sock , ( char * ) & payload_short , & len ); 50
rv = lua_websocket_readbytes ( r -> connection , ( char * ) & payload_short , 2 ); 53
payload_short = ntohs ( payload_short ); 56
if ( rv == APR_SUCCESS )  58
plen = payload_short; 59
if ( payload == 127 )  66
len = 8; 67
if ( plaintext )  68
rv = apr_socket_recv ( sock , ( char * ) & payload_long , & len ); 69
rv = lua_websocket_readbytes ( r -> connection , ( char * ) & payload_long , 8 ); 72
if ( rv == APR_SUCCESS )  75
plen = ap_ntoh64 ( & payload_long ); 76
if ( mask )  88
len = 4; 89
if ( plaintext )  90
rv = apr_socket_recv ( sock , ( char * ) mask_bytes , & len ); 91
rv = lua_websocket_readbytes ( r -> connection , ( char * ) mask_bytes , 4 ); 94
if ( rv != APR_SUCCESS )  97
if ( plen < ( HUGE_STRING_LEN * 1024 ) && plen > 0 )  101
if ( opcode == 0x09 )  142
CVE_2015_0228_VULN_lua_websocket_read ( L ); 148
static int CVE_2015_0228_VULN_lua_websocket_read(lua_State *L) 1
apr_socket_t * sock ; 3
apr_status_t rv ; 4
unsigned short payload_short = 0 ; 8
unsigned char * mask_bytes ; 10
char byte ; 11
int plaintext ; 12
request_rec * r = ap_lua_check_request_rec ( L , 1 ) ; 15
plaintext = ap_lua_ssl_is_https ( r -> connection ) ? 0 : 1; 16
mask_bytes = apr_pcalloc ( r -> pool , 4 ); 19
sock = ap_get_conn_socket ( r -> connection ); 20
if ( plaintext )  23
rv = apr_socket_recv ( sock , & byte , & len ); 24
rv = lua_websocket_readbytes ( r -> connection , & byte , 1 ); 27
if ( rv == APR_SUCCESS )  29
unsigned char fin , opcode , mask , payload ; 30
if ( plaintext )  35
rv = apr_socket_recv ( sock , & byte , & len ); 36
rv = lua_websocket_readbytes ( r -> connection , & byte , 1 ); 39
if ( rv == APR_SUCCESS )  41
mask = byte >> 7; 42
payload = byte - 128; 43
plen = payload; 44
if ( payload == 126 )  47
len = 2; 48
if ( plaintext )  49
rv = apr_socket_recv ( sock , ( char * ) & payload_short , & len ); 50
rv = lua_websocket_readbytes ( r -> connection , ( char * ) & payload_short , 2 ); 53
payload_short = ntohs ( payload_short ); 56
if ( rv == APR_SUCCESS )  58
plen = payload_short; 59
if ( payload == 127 )  66
len = 8; 67
if ( plaintext )  68
rv = apr_socket_recv ( sock , ( char * ) & payload_long , & len ); 69
rv = lua_websocket_readbytes ( r -> connection , ( char * ) & payload_long , 8 ); 72
if ( rv == APR_SUCCESS )  75
plen = ap_ntoh64 ( & payload_long ); 76
if ( mask )  88
len = 4; 89
if ( plaintext )  90
rv = apr_socket_recv ( sock , ( char * ) mask_bytes , & len ); 91
rv = lua_websocket_readbytes ( r -> connection , ( char * ) mask_bytes , 4 ); 94
if ( rv != APR_SUCCESS )  97
if ( plen < ( HUGE_STRING_LEN * 1024 ) && plen > 0 )  101
apr_size_t remaining = plen ; 102
apr_size_t received ; 103
apr_off_t at = 0 ; 104
char * buffer = apr_palloc ( r -> pool , plen + 1 ) ; 105
buffer [ plen ] = 0; 106
if ( plaintext )  108
while ( remaining > 0 )  109
received = remaining; 110
rv = apr_socket_recv ( sock , buffer + at , & received ); 111
if ( received > 0 )  112
remaining -= received; 113
at += received; 114
------------------------------
547 /home/speedy/test/source2slice/NVD/CVE_2015_0833_PATCHED_NS_main.c NS_tsnprintf ( newDistDir , sizeof ( newDistDir ) / sizeof ( newDistDir [ 0 ] ) , NS_T ( "%s/Contents/Resources/distribution" ) , gInstallDirPath ) 826
int CVE_2015_0833_PATCHED_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
gInstallDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 48
bool noServiceFallback = getenv ( "MOZ_NO_SERVICE_FALLBACK" ) != nullptr ; 57
useService = IsUpdateStatusPendingService ( ); 63
testOnlyFallbackKeyExists = DoesFallbackKeyExist ( ); 67
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
gWorkingDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 117
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( ! _waccess ( updateLockFilePath , F_OK ) && NS_tremove ( updateLockFilePath ) != 0 )  277
updateLockFileHandle = CreateFileW ( updateLockFilePath , GENERIC_READ | GENERIC_WRITE , 0 , nullptr , OPEN_ALWAYS , FILE_FLAG_DELETE_ON_CLOSE , nullptr ); 290
if ( updateLockFileHandle == INVALID_HANDLE_VALUE || ( useService && testOnlyFallbackKeyExists && noServiceFallback ) )  318
GonkAutoMounter mounter ; 544
if ( mounter . GetAccess ( ) != MountAccess :: ReadWrite )  545
if ( ! sReplaceRequest )  556
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  558
int rv = NS_tmkdir ( gWorkingDirPath , 0755 ) ; 560
if ( rv == OK && errno != EEXIST )  561
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  563
if ( ! sReplaceRequest )  577
NS_tchar * destpath = ( NS_tchar * ) malloc ( ( NS_tstrlen ( gWorkingDirPath ) + 2 ) * sizeof ( NS_tchar ) ) ; 580
if ( ! destpath )  581
NS_tchar applyDirLongPath [ MAXPATHLEN ] ; 598
if ( ! GetLongPathNameW ( gWorkingDirPath , applyDirLongPath , sizeof ( applyDirLongPath ) / sizeof ( applyDirLongPath [ 0 ] ) ) )  599
if ( argc > callbackIndex )  613
NS_tchar callbackLongPath [ MAXPATHLEN ] ; 619
NS_tchar * targetPath = argv [ callbackIndex ] ; 621
NS_tchar buffer [ MAXPATHLEN * 2 ] = { NS_T ( '\0' ) } ; 622
if ( sReplaceRequest )  624
targetPath = buffer; 649
if ( ! GetLongPathNameW ( targetPath , callbackLongPath , sizeof ( callbackLongPath ) / sizeof ( callbackLongPath [ 0 ] ) ) )  651
if ( ! sReplaceRequest )  667
const int max_retries = 10 ; 701
int retries = 1 ; 702
DWORD lastWriteError = 0 ; 703
callbackFile = CreateFileW ( targetPath , DELETE | GENERIC_WRITE , FILE_SHARE_DELETE | FILE_SHARE_WRITE , nullptr , OPEN_EXISTING , 0 , nullptr ); 708
if ( callbackFile != INVALID_HANDLE_VALUE )  713
lastWriteError = GetLastError ( ); 716
while ( ++ retries <= max_retries )  722
if ( callbackFile == INVALID_HANDLE_VALUE )  725
if ( lastWriteError != ERROR_SHARING_VIOLATION )  727
if ( gSucceeded && ! sStagedUpdate )  814
NS_tchar oldDistDir [ MAXPATHLEN ] ; 820
int rv = NS_taccess ( oldDistDir , F_OK ) ; 823
if ( ! rv )  824
NS_tchar newDistDir [ MAXPATHLEN ] ; 825
NS_tsnprintf ( newDistDir , sizeof ( newDistDir ) / sizeof ( newDistDir [ 0 ] ) , NS_T ( "%s/Contents/Resources/distribution" ) , gInstallDirPath ); 826
------------------------------
548 /home/speedy/test/source2slice/NVD/CVE_2015_0833_PATCHED_NS_main.c NS_tsnprintf ( oldDistDir , sizeof ( oldDistDir ) / sizeof ( oldDistDir [ 0 ] ) , NS_T ( "%s/Contents/MacOS/distribution" ) , gInstallDirPath ) 821
int CVE_2015_0833_PATCHED_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
gInstallDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 48
bool noServiceFallback = getenv ( "MOZ_NO_SERVICE_FALLBACK" ) != nullptr ; 57
useService = IsUpdateStatusPendingService ( ); 63
testOnlyFallbackKeyExists = DoesFallbackKeyExist ( ); 67
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
gWorkingDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 117
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( ! _waccess ( updateLockFilePath , F_OK ) && NS_tremove ( updateLockFilePath ) != 0 )  277
updateLockFileHandle = CreateFileW ( updateLockFilePath , GENERIC_READ | GENERIC_WRITE , 0 , nullptr , OPEN_ALWAYS , FILE_FLAG_DELETE_ON_CLOSE , nullptr ); 290
if ( updateLockFileHandle == INVALID_HANDLE_VALUE || ( useService && testOnlyFallbackKeyExists && noServiceFallback ) )  318
GonkAutoMounter mounter ; 544
if ( mounter . GetAccess ( ) != MountAccess :: ReadWrite )  545
if ( ! sReplaceRequest )  556
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  558
int rv = NS_tmkdir ( gWorkingDirPath , 0755 ) ; 560
if ( rv == OK && errno != EEXIST )  561
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  563
if ( ! sReplaceRequest )  577
NS_tchar * destpath = ( NS_tchar * ) malloc ( ( NS_tstrlen ( gWorkingDirPath ) + 2 ) * sizeof ( NS_tchar ) ) ; 580
if ( ! destpath )  581
NS_tchar applyDirLongPath [ MAXPATHLEN ] ; 598
if ( ! GetLongPathNameW ( gWorkingDirPath , applyDirLongPath , sizeof ( applyDirLongPath ) / sizeof ( applyDirLongPath [ 0 ] ) ) )  599
if ( argc > callbackIndex )  613
NS_tchar callbackLongPath [ MAXPATHLEN ] ; 619
NS_tchar * targetPath = argv [ callbackIndex ] ; 621
NS_tchar buffer [ MAXPATHLEN * 2 ] = { NS_T ( '\0' ) } ; 622
if ( sReplaceRequest )  624
targetPath = buffer; 649
if ( ! GetLongPathNameW ( targetPath , callbackLongPath , sizeof ( callbackLongPath ) / sizeof ( callbackLongPath [ 0 ] ) ) )  651
if ( ! sReplaceRequest )  667
const int max_retries = 10 ; 701
int retries = 1 ; 702
DWORD lastWriteError = 0 ; 703
callbackFile = CreateFileW ( targetPath , DELETE | GENERIC_WRITE , FILE_SHARE_DELETE | FILE_SHARE_WRITE , nullptr , OPEN_EXISTING , 0 , nullptr ); 708
if ( callbackFile != INVALID_HANDLE_VALUE )  713
lastWriteError = GetLastError ( ); 716
while ( ++ retries <= max_retries )  722
if ( callbackFile == INVALID_HANDLE_VALUE )  725
if ( lastWriteError != ERROR_SHARING_VIOLATION )  727
if ( gSucceeded && ! sStagedUpdate )  814
NS_tchar oldDistDir [ MAXPATHLEN ] ; 820
NS_tsnprintf ( oldDistDir , sizeof ( oldDistDir ) / sizeof ( oldDistDir [ 0 ] ) , NS_T ( "%s/Contents/MacOS/distribution" ) , gInstallDirPath ); 821
------------------------------
549 /home/speedy/test/source2slice/NVD/CVE_2015_0833_PATCHED_NS_main.c NS_tsnprintf ( oldPrecomplete , sizeof ( oldPrecomplete ) / sizeof ( oldPrecomplete [ 0 ] ) , NS_T ( "%s/precomplete" ) , gInstallDirPath ) 816
int CVE_2015_0833_PATCHED_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
gInstallDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 48
bool noServiceFallback = getenv ( "MOZ_NO_SERVICE_FALLBACK" ) != nullptr ; 57
useService = IsUpdateStatusPendingService ( ); 63
testOnlyFallbackKeyExists = DoesFallbackKeyExist ( ); 67
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
gWorkingDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 117
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( ! _waccess ( updateLockFilePath , F_OK ) && NS_tremove ( updateLockFilePath ) != 0 )  277
updateLockFileHandle = CreateFileW ( updateLockFilePath , GENERIC_READ | GENERIC_WRITE , 0 , nullptr , OPEN_ALWAYS , FILE_FLAG_DELETE_ON_CLOSE , nullptr ); 290
if ( updateLockFileHandle == INVALID_HANDLE_VALUE || ( useService && testOnlyFallbackKeyExists && noServiceFallback ) )  318
GonkAutoMounter mounter ; 544
if ( mounter . GetAccess ( ) != MountAccess :: ReadWrite )  545
if ( ! sReplaceRequest )  556
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  558
int rv = NS_tmkdir ( gWorkingDirPath , 0755 ) ; 560
if ( rv == OK && errno != EEXIST )  561
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  563
if ( ! sReplaceRequest )  577
NS_tchar * destpath = ( NS_tchar * ) malloc ( ( NS_tstrlen ( gWorkingDirPath ) + 2 ) * sizeof ( NS_tchar ) ) ; 580
if ( ! destpath )  581
NS_tchar applyDirLongPath [ MAXPATHLEN ] ; 598
if ( ! GetLongPathNameW ( gWorkingDirPath , applyDirLongPath , sizeof ( applyDirLongPath ) / sizeof ( applyDirLongPath [ 0 ] ) ) )  599
if ( argc > callbackIndex )  613
NS_tchar callbackLongPath [ MAXPATHLEN ] ; 619
NS_tchar * targetPath = argv [ callbackIndex ] ; 621
NS_tchar buffer [ MAXPATHLEN * 2 ] = { NS_T ( '\0' ) } ; 622
if ( sReplaceRequest )  624
targetPath = buffer; 649
if ( ! GetLongPathNameW ( targetPath , callbackLongPath , sizeof ( callbackLongPath ) / sizeof ( callbackLongPath [ 0 ] ) ) )  651
if ( ! sReplaceRequest )  667
const int max_retries = 10 ; 701
int retries = 1 ; 702
DWORD lastWriteError = 0 ; 703
callbackFile = CreateFileW ( targetPath , DELETE | GENERIC_WRITE , FILE_SHARE_DELETE | FILE_SHARE_WRITE , nullptr , OPEN_EXISTING , 0 , nullptr ); 708
if ( callbackFile != INVALID_HANDLE_VALUE )  713
lastWriteError = GetLastError ( ); 716
while ( ++ retries <= max_retries )  722
if ( callbackFile == INVALID_HANDLE_VALUE )  725
if ( lastWriteError != ERROR_SHARING_VIOLATION )  727
if ( gSucceeded && ! sStagedUpdate )  814
NS_tchar oldPrecomplete [ MAXPATHLEN ] ; 815
NS_tsnprintf ( oldPrecomplete , sizeof ( oldPrecomplete ) / sizeof ( oldPrecomplete [ 0 ] ) , NS_T ( "%s/precomplete" ) , gInstallDirPath ); 816
------------------------------
550 /home/speedy/test/source2slice/NVD/CVE_2015_0833_PATCHED_NS_main.c NS_tsnprintf ( elevatedLockFilePath , sizeof ( elevatedLockFilePath ) / sizeof ( elevatedLockFilePath [ 0 ] ) , NS_T ( "%s/update_elevated.lock" ) , gPatchDirPath ) 298
int CVE_2015_0833_PATCHED_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
gPatchDirPath = argv [ 1 ]; 42
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
NS_tchar elevatedLockFilePath [ MAXPATHLEN ] = { NS_T ( '\0' ) } ; 246
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( ! _waccess ( updateLockFilePath , F_OK ) && NS_tremove ( updateLockFilePath ) != 0 )  277
NS_tsnprintf ( elevatedLockFilePath , sizeof ( elevatedLockFilePath ) / sizeof ( elevatedLockFilePath [ 0 ] ) , NS_T ( "%s/update_elevated.lock" ) , gPatchDirPath ); 298
------------------------------
551 /home/speedy/test/source2slice/NVD/CVE_2015_0833_PATCHED_NS_main.c NS_tsnprintf ( updateLockFilePath , sizeof ( updateLockFilePath ) / sizeof ( updateLockFilePath [ 0 ] ) , NS_T ( "%s.update_in_progress.lock" ) , argv [ callbackIndex ] ) 269
int CVE_2015_0833_PATCHED_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( sStagedUpdate )  250
if ( sReplaceRequest )  256
NS_tsnprintf ( updateLockFilePath , sizeof ( updateLockFilePath ) / sizeof ( updateLockFilePath [ 0 ] ) , NS_T ( "%s.update_in_progress.lock" ) , argv [ callbackIndex ] ); 269
------------------------------
552 /home/speedy/test/source2slice/NVD/CVE_2015_0833_PATCHED_NS_main.c NS_tsnprintf ( updateLockFilePath , sizeof ( updateLockFilePath ) / sizeof ( updateLockFilePath [ 0 ] ) , NS_T ( "%s\\moz_update_in_progress.lock" ) , installDir ) 263
int CVE_2015_0833_PATCHED_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( sStagedUpdate )  250
if ( sReplaceRequest )  256
NS_tchar installDir [ MAXPATHLEN ] ; 259
NS_tsnprintf ( updateLockFilePath , sizeof ( updateLockFilePath ) / sizeof ( updateLockFilePath [ 0 ] ) , NS_T ( "%s\\moz_update_in_progress.lock" ) , installDir ); 263
------------------------------
553 /home/speedy/test/source2slice/NVD/CVE_2015_0833_PATCHED_NS_main.c NS_tsnprintf ( updateLockFilePath , sizeof ( updateLockFilePath ) / sizeof ( updateLockFilePath [ 0 ] ) , NS_T ( "%s/updated.update_in_progress.lock" ) , gInstallDirPath ) 253
int CVE_2015_0833_PATCHED_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
gInstallDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 48
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( sStagedUpdate )  250
NS_tsnprintf ( updateLockFilePath , sizeof ( updateLockFilePath ) / sizeof ( updateLockFilePath [ 0 ] ) , NS_T ( "%s/updated.update_in_progress.lock" ) , gInstallDirPath ); 253
------------------------------
554 /home/speedy/test/source2slice/NVD/CVE_2015_0833_PATCHED_UpdateThreadFunc.c NS_tsnprintf ( updatingDir , sizeof ( updatingDir ) / sizeof ( updatingDir [ 0 ] ) , NS_T ( "%s/updating" ) , gWorkingDirPath ) 82
static void
CVE_2015_0833_PATCHED_UpdateThreadFunc(void *param) 2
int rv ; 5
if ( sReplaceRequest )  6
NS_tchar dataFile [ MAXPATHLEN ] ; 9
rv = GetUpdateFileName ( dataFile , sizeof ( dataFile ) / sizeof ( dataFile [ 0 ] ) ); 10
if ( rv == OK )  11
rv = gArchiveReader . Open ( dataFile ); 12
if ( rv == OK )  16
rv = gArchiveReader . VerifySignature ( ); 42
if ( rv == OK )  55
if ( rv == OK )  56
NS_tchar updateSettingsPath [ MAX_TEXT_LEN ] ; 57
MARChannelStringTable MARStrings ; 61
if ( ReadMARChannelIDs ( updateSettingsPath , & MARStrings ) != OK )  62
MARStrings . MARChannelID [ 0 ] = '\0'; 65
rv = gArchiveReader . VerifyProductInformation ( MARStrings . MARChannelID , MOZ_APP_VERSION ); 68
if ( rv == OK && sStagedUpdate && ! sIsOSUpdate )  74
rv = CopyInstallDirToDestDir ( ); 75
if ( rv == OK )  78
NS_tchar updatingDir [ MAXPATHLEN ] ; 81
NS_tsnprintf ( updatingDir , sizeof ( updatingDir ) / sizeof ( updatingDir [ 0 ] ) , NS_T ( "%s/updating" ) , gWorkingDirPath ); 82
------------------------------
555 /home/speedy/test/source2slice/NVD/CVE_2015_0833_PATCHED_UpdateThreadFunc.c NS_tsnprintf ( updateSettingsPath , sizeof ( updateSettingsPath ) / sizeof ( updateSettingsPath [ 0 ] ) , NS_T ( "%s/update-settings.ini" ) , gWorkingDirPath ) 58
static void
CVE_2015_0833_PATCHED_UpdateThreadFunc(void *param) 2
int rv ; 5
if ( sReplaceRequest )  6
NS_tchar dataFile [ MAXPATHLEN ] ; 9
rv = GetUpdateFileName ( dataFile , sizeof ( dataFile ) / sizeof ( dataFile [ 0 ] ) ); 10
if ( rv == OK )  11
rv = gArchiveReader . Open ( dataFile ); 12
if ( rv == OK )  16
rv = gArchiveReader . VerifySignature ( ); 42
if ( rv == OK )  55
if ( rv == OK )  56
NS_tchar updateSettingsPath [ MAX_TEXT_LEN ] ; 57
NS_tsnprintf ( updateSettingsPath , sizeof ( updateSettingsPath ) / sizeof ( updateSettingsPath [ 0 ] ) , NS_T ( "%s/update-settings.ini" ) , gWorkingDirPath ); 58
------------------------------
556 /home/speedy/test/source2slice/NVD/CVE_2015_0833_VULN_NS_main.c NS_tsnprintf ( newDistDir , sizeof ( newDistDir ) / sizeof ( newDistDir [ 0 ] ) , NS_T ( "%s/Contents/Resources/distribution" ) , gInstallDirPath ) 826
int CVE_2015_0833_VULN_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
gInstallDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 48
bool noServiceFallback = getenv ( "MOZ_NO_SERVICE_FALLBACK" ) != nullptr ; 57
useService = IsUpdateStatusPendingService ( ); 63
testOnlyFallbackKeyExists = DoesFallbackKeyExist ( ); 67
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
gWorkingDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 117
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( ! _waccess ( updateLockFilePath , F_OK ) && NS_tremove ( updateLockFilePath ) != 0 )  277
updateLockFileHandle = CreateFileW ( updateLockFilePath , GENERIC_READ | GENERIC_WRITE , 0 , nullptr , OPEN_ALWAYS , FILE_FLAG_DELETE_ON_CLOSE , nullptr ); 290
if ( updateLockFileHandle == INVALID_HANDLE_VALUE || ( useService && testOnlyFallbackKeyExists && noServiceFallback ) )  318
GonkAutoMounter mounter ; 544
if ( mounter . GetAccess ( ) != MountAccess :: ReadWrite )  545
if ( ! sReplaceRequest )  556
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  558
int rv = NS_tmkdir ( gWorkingDirPath , 0755 ) ; 560
if ( rv == OK && errno != EEXIST )  561
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  563
if ( ! sReplaceRequest )  577
NS_tchar * destpath = ( NS_tchar * ) malloc ( ( NS_tstrlen ( gWorkingDirPath ) + 2 ) * sizeof ( NS_tchar ) ) ; 580
if ( ! destpath )  581
NS_tchar applyDirLongPath [ MAXPATHLEN ] ; 598
if ( ! GetLongPathNameW ( gWorkingDirPath , applyDirLongPath , sizeof ( applyDirLongPath ) / sizeof ( applyDirLongPath [ 0 ] ) ) )  599
if ( argc > callbackIndex )  613
NS_tchar callbackLongPath [ MAXPATHLEN ] ; 619
NS_tchar * targetPath = argv [ callbackIndex ] ; 621
NS_tchar buffer [ MAXPATHLEN * 2 ] = { NS_T ( '\0' ) } ; 622
if ( sReplaceRequest )  624
targetPath = buffer; 649
if ( ! GetLongPathNameW ( targetPath , callbackLongPath , sizeof ( callbackLongPath ) / sizeof ( callbackLongPath [ 0 ] ) ) )  651
if ( ! sReplaceRequest )  667
const int max_retries = 10 ; 701
int retries = 1 ; 702
DWORD lastWriteError = 0 ; 703
callbackFile = CreateFileW ( targetPath , DELETE | GENERIC_WRITE , FILE_SHARE_DELETE | FILE_SHARE_WRITE , nullptr , OPEN_EXISTING , 0 , nullptr ); 708
if ( callbackFile != INVALID_HANDLE_VALUE )  713
lastWriteError = GetLastError ( ); 716
while ( ++ retries <= max_retries )  722
if ( callbackFile == INVALID_HANDLE_VALUE )  725
if ( lastWriteError != ERROR_SHARING_VIOLATION )  727
if ( gSucceeded && ! sStagedUpdate )  814
NS_tchar oldDistDir [ MAXPATHLEN ] ; 820
int rv = NS_taccess ( oldDistDir , F_OK ) ; 823
if ( ! rv )  824
NS_tchar newDistDir [ MAXPATHLEN ] ; 825
NS_tsnprintf ( newDistDir , sizeof ( newDistDir ) / sizeof ( newDistDir [ 0 ] ) , NS_T ( "%s/Contents/Resources/distribution" ) , gInstallDirPath ); 826
------------------------------
557 /home/speedy/test/source2slice/NVD/CVE_2015_0833_VULN_NS_main.c NS_tsnprintf ( oldDistDir , sizeof ( oldDistDir ) / sizeof ( oldDistDir [ 0 ] ) , NS_T ( "%s/Contents/MacOS/distribution" ) , gInstallDirPath ) 821
int CVE_2015_0833_VULN_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
gInstallDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 48
bool noServiceFallback = getenv ( "MOZ_NO_SERVICE_FALLBACK" ) != nullptr ; 57
useService = IsUpdateStatusPendingService ( ); 63
testOnlyFallbackKeyExists = DoesFallbackKeyExist ( ); 67
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
gWorkingDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 117
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( ! _waccess ( updateLockFilePath , F_OK ) && NS_tremove ( updateLockFilePath ) != 0 )  277
updateLockFileHandle = CreateFileW ( updateLockFilePath , GENERIC_READ | GENERIC_WRITE , 0 , nullptr , OPEN_ALWAYS , FILE_FLAG_DELETE_ON_CLOSE , nullptr ); 290
if ( updateLockFileHandle == INVALID_HANDLE_VALUE || ( useService && testOnlyFallbackKeyExists && noServiceFallback ) )  318
GonkAutoMounter mounter ; 544
if ( mounter . GetAccess ( ) != MountAccess :: ReadWrite )  545
if ( ! sReplaceRequest )  556
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  558
int rv = NS_tmkdir ( gWorkingDirPath , 0755 ) ; 560
if ( rv == OK && errno != EEXIST )  561
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  563
if ( ! sReplaceRequest )  577
NS_tchar * destpath = ( NS_tchar * ) malloc ( ( NS_tstrlen ( gWorkingDirPath ) + 2 ) * sizeof ( NS_tchar ) ) ; 580
if ( ! destpath )  581
NS_tchar applyDirLongPath [ MAXPATHLEN ] ; 598
if ( ! GetLongPathNameW ( gWorkingDirPath , applyDirLongPath , sizeof ( applyDirLongPath ) / sizeof ( applyDirLongPath [ 0 ] ) ) )  599
if ( argc > callbackIndex )  613
NS_tchar callbackLongPath [ MAXPATHLEN ] ; 619
NS_tchar * targetPath = argv [ callbackIndex ] ; 621
NS_tchar buffer [ MAXPATHLEN * 2 ] = { NS_T ( '\0' ) } ; 622
if ( sReplaceRequest )  624
targetPath = buffer; 649
if ( ! GetLongPathNameW ( targetPath , callbackLongPath , sizeof ( callbackLongPath ) / sizeof ( callbackLongPath [ 0 ] ) ) )  651
if ( ! sReplaceRequest )  667
const int max_retries = 10 ; 701
int retries = 1 ; 702
DWORD lastWriteError = 0 ; 703
callbackFile = CreateFileW ( targetPath , DELETE | GENERIC_WRITE , FILE_SHARE_DELETE | FILE_SHARE_WRITE , nullptr , OPEN_EXISTING , 0 , nullptr ); 708
if ( callbackFile != INVALID_HANDLE_VALUE )  713
lastWriteError = GetLastError ( ); 716
while ( ++ retries <= max_retries )  722
if ( callbackFile == INVALID_HANDLE_VALUE )  725
if ( lastWriteError != ERROR_SHARING_VIOLATION )  727
if ( gSucceeded && ! sStagedUpdate )  814
NS_tchar oldDistDir [ MAXPATHLEN ] ; 820
NS_tsnprintf ( oldDistDir , sizeof ( oldDistDir ) / sizeof ( oldDistDir [ 0 ] ) , NS_T ( "%s/Contents/MacOS/distribution" ) , gInstallDirPath ); 821
------------------------------
558 /home/speedy/test/source2slice/NVD/CVE_2015_0833_VULN_NS_main.c NS_tsnprintf ( oldPrecomplete , sizeof ( oldPrecomplete ) / sizeof ( oldPrecomplete [ 0 ] ) , NS_T ( "%s/precomplete" ) , gInstallDirPath ) 816
int CVE_2015_0833_VULN_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
gInstallDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 48
bool noServiceFallback = getenv ( "MOZ_NO_SERVICE_FALLBACK" ) != nullptr ; 57
useService = IsUpdateStatusPendingService ( ); 63
testOnlyFallbackKeyExists = DoesFallbackKeyExist ( ); 67
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
gWorkingDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 117
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( ! _waccess ( updateLockFilePath , F_OK ) && NS_tremove ( updateLockFilePath ) != 0 )  277
updateLockFileHandle = CreateFileW ( updateLockFilePath , GENERIC_READ | GENERIC_WRITE , 0 , nullptr , OPEN_ALWAYS , FILE_FLAG_DELETE_ON_CLOSE , nullptr ); 290
if ( updateLockFileHandle == INVALID_HANDLE_VALUE || ( useService && testOnlyFallbackKeyExists && noServiceFallback ) )  318
GonkAutoMounter mounter ; 544
if ( mounter . GetAccess ( ) != MountAccess :: ReadWrite )  545
if ( ! sReplaceRequest )  556
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  558
int rv = NS_tmkdir ( gWorkingDirPath , 0755 ) ; 560
if ( rv == OK && errno != EEXIST )  561
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  563
if ( ! sReplaceRequest )  577
NS_tchar * destpath = ( NS_tchar * ) malloc ( ( NS_tstrlen ( gWorkingDirPath ) + 2 ) * sizeof ( NS_tchar ) ) ; 580
if ( ! destpath )  581
NS_tchar applyDirLongPath [ MAXPATHLEN ] ; 598
if ( ! GetLongPathNameW ( gWorkingDirPath , applyDirLongPath , sizeof ( applyDirLongPath ) / sizeof ( applyDirLongPath [ 0 ] ) ) )  599
if ( argc > callbackIndex )  613
NS_tchar callbackLongPath [ MAXPATHLEN ] ; 619
NS_tchar * targetPath = argv [ callbackIndex ] ; 621
NS_tchar buffer [ MAXPATHLEN * 2 ] = { NS_T ( '\0' ) } ; 622
if ( sReplaceRequest )  624
targetPath = buffer; 649
if ( ! GetLongPathNameW ( targetPath , callbackLongPath , sizeof ( callbackLongPath ) / sizeof ( callbackLongPath [ 0 ] ) ) )  651
if ( ! sReplaceRequest )  667
const int max_retries = 10 ; 701
int retries = 1 ; 702
DWORD lastWriteError = 0 ; 703
callbackFile = CreateFileW ( targetPath , DELETE | GENERIC_WRITE , FILE_SHARE_DELETE | FILE_SHARE_WRITE , nullptr , OPEN_EXISTING , 0 , nullptr ); 708
if ( callbackFile != INVALID_HANDLE_VALUE )  713
lastWriteError = GetLastError ( ); 716
while ( ++ retries <= max_retries )  722
if ( callbackFile == INVALID_HANDLE_VALUE )  725
if ( lastWriteError != ERROR_SHARING_VIOLATION )  727
if ( gSucceeded && ! sStagedUpdate )  814
NS_tchar oldPrecomplete [ MAXPATHLEN ] ; 815
NS_tsnprintf ( oldPrecomplete , sizeof ( oldPrecomplete ) / sizeof ( oldPrecomplete [ 0 ] ) , NS_T ( "%s/precomplete" ) , gInstallDirPath ); 816
------------------------------
559 /home/speedy/test/source2slice/NVD/CVE_2015_0833_VULN_NS_main.c NS_tsnprintf ( elevatedLockFilePath , sizeof ( elevatedLockFilePath ) / sizeof ( elevatedLockFilePath [ 0 ] ) , NS_T ( "%s/update_elevated.lock" ) , gPatchDirPath ) 298
int CVE_2015_0833_VULN_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
gPatchDirPath = argv [ 1 ]; 42
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
NS_tchar elevatedLockFilePath [ MAXPATHLEN ] = { NS_T ( '\0' ) } ; 246
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( ! _waccess ( updateLockFilePath , F_OK ) && NS_tremove ( updateLockFilePath ) != 0 )  277
NS_tsnprintf ( elevatedLockFilePath , sizeof ( elevatedLockFilePath ) / sizeof ( elevatedLockFilePath [ 0 ] ) , NS_T ( "%s/update_elevated.lock" ) , gPatchDirPath ); 298
------------------------------
560 /home/speedy/test/source2slice/NVD/CVE_2015_0833_VULN_NS_main.c NS_tsnprintf ( updateLockFilePath , sizeof ( updateLockFilePath ) / sizeof ( updateLockFilePath [ 0 ] ) , NS_T ( "%s.update_in_progress.lock" ) , argv [ callbackIndex ] ) 269
int CVE_2015_0833_VULN_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( sStagedUpdate )  250
if ( sReplaceRequest )  256
NS_tsnprintf ( updateLockFilePath , sizeof ( updateLockFilePath ) / sizeof ( updateLockFilePath [ 0 ] ) , NS_T ( "%s.update_in_progress.lock" ) , argv [ callbackIndex ] ); 269
------------------------------
561 /home/speedy/test/source2slice/NVD/CVE_2015_0833_VULN_NS_main.c NS_tsnprintf ( updateLockFilePath , sizeof ( updateLockFilePath ) / sizeof ( updateLockFilePath [ 0 ] ) , NS_T ( "%s\\moz_update_in_progress.lock" ) , installDir ) 263
int CVE_2015_0833_VULN_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( sStagedUpdate )  250
if ( sReplaceRequest )  256
NS_tchar installDir [ MAXPATHLEN ] ; 259
NS_tsnprintf ( updateLockFilePath , sizeof ( updateLockFilePath ) / sizeof ( updateLockFilePath [ 0 ] ) , NS_T ( "%s\\moz_update_in_progress.lock" ) , installDir ); 263
------------------------------
562 /home/speedy/test/source2slice/NVD/CVE_2015_0833_VULN_NS_main.c NS_tsnprintf ( updateLockFilePath , sizeof ( updateLockFilePath ) / sizeof ( updateLockFilePath [ 0 ] ) , NS_T ( "%s/updated.update_in_progress.lock" ) , gInstallDirPath ) 253
int CVE_2015_0833_VULN_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
gInstallDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 48
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( sStagedUpdate )  250
NS_tsnprintf ( updateLockFilePath , sizeof ( updateLockFilePath ) / sizeof ( updateLockFilePath [ 0 ] ) , NS_T ( "%s/updated.update_in_progress.lock" ) , gInstallDirPath ); 253
------------------------------
563 /home/speedy/test/source2slice/NVD/CVE_2015_0833_VULN_UpdateThreadFunc.c NS_tsnprintf ( updatingDir , sizeof ( updatingDir ) / sizeof ( updatingDir [ 0 ] ) , NS_T ( "%s/updating" ) , gWorkingDirPath ) 47
static void
CVE_2015_0833_VULN_UpdateThreadFunc(void *param) 2
int rv ; 5
if ( sReplaceRequest )  6
NS_tchar dataFile [ MAXPATHLEN ] ; 9
rv = GetUpdateFileName ( dataFile , sizeof ( dataFile ) / sizeof ( dataFile [ 0 ] ) ); 10
if ( rv == OK )  11
rv = gArchiveReader . Open ( dataFile ); 12
if ( rv == OK )  16
rv = gArchiveReader . VerifySignature ( ); 17
if ( rv == OK )  20
if ( rv == OK )  21
NS_tchar updateSettingsPath [ MAX_TEXT_LEN ] ; 22
MARChannelStringTable MARStrings ; 26
if ( ReadMARChannelIDs ( updateSettingsPath , & MARStrings ) != OK )  27
MARStrings . MARChannelID [ 0 ] = '\0'; 30
rv = gArchiveReader . VerifyProductInformation ( MARStrings . MARChannelID , MOZ_APP_VERSION ); 33
if ( rv == OK && sStagedUpdate && ! sIsOSUpdate )  39
rv = CopyInstallDirToDestDir ( ); 40
if ( rv == OK )  43
NS_tchar updatingDir [ MAXPATHLEN ] ; 46
NS_tsnprintf ( updatingDir , sizeof ( updatingDir ) / sizeof ( updatingDir [ 0 ] ) , NS_T ( "%s/updating" ) , gWorkingDirPath ); 47
------------------------------
564 /home/speedy/test/source2slice/NVD/CVE_2015_0833_VULN_UpdateThreadFunc.c NS_tsnprintf ( updateSettingsPath , sizeof ( updateSettingsPath ) / sizeof ( updateSettingsPath [ 0 ] ) , NS_T ( "%s/update-settings.ini" ) , gWorkingDirPath ) 23
static void
CVE_2015_0833_VULN_UpdateThreadFunc(void *param) 2
int rv ; 5
if ( sReplaceRequest )  6
NS_tchar dataFile [ MAXPATHLEN ] ; 9
rv = GetUpdateFileName ( dataFile , sizeof ( dataFile ) / sizeof ( dataFile [ 0 ] ) ); 10
if ( rv == OK )  11
rv = gArchiveReader . Open ( dataFile ); 12
if ( rv == OK )  16
rv = gArchiveReader . VerifySignature ( ); 17
if ( rv == OK )  20
if ( rv == OK )  21
NS_tchar updateSettingsPath [ MAX_TEXT_LEN ] ; 22
NS_tsnprintf ( updateSettingsPath , sizeof ( updateSettingsPath ) / sizeof ( updateSettingsPath [ 0 ] ) , NS_T ( "%s/update-settings.ini" ) , gWorkingDirPath ); 23
------------------------------
565 /home/speedy/test/source2slice/NVD/CVE_2015_2922_PATCHED_ndisc_router_discovery.c rtime = ( rtime * HZ ) / 1000 169
static void CVE_2015_2922_PATCHED_ndisc_router_discovery(struct sk_buff *skb) 1
struct ra_msg * ra_msg = ( struct ra_msg * ) skb_transport_header ( skb ) ; 3
struct inet6_dev * in6_dev ; 5
int lifetime ; 7
struct ndisc_options ndopts ; 8
int optlen ; 9
__u8 * opt = ( __u8 * ) ( ra_msg + 1 ) ; 12
optlen = ( skb -> tail - skb -> transport_header ) - sizeof ( struct ra_msg ); 14
if ( ! ( ipv6_addr_type ( & ipv6_hdr ( skb ) -> saddr ) & IPV6_ADDR_LINKLOCAL ) )  16
if ( optlen < 0 )  20
if ( skb -> ndisc_nodetype == NDISC_NODETYPE_HOST )  26
in6_dev = __in6_dev_get ( skb -> dev ); 36
if ( in6_dev == NULL )  37
if ( ! ndisc_parse_options ( opt , optlen , & ndopts ) )  43
if ( ! accept_ra ( in6_dev ) )  48
if ( skb -> ndisc_nodetype == NDISC_NODETYPE_NODEFAULT )  53
if ( in6_dev -> if_flags & IF_RS_SENT )  57
in6_dev -> if_flags |= IF_RA_RCVD; 62
in6_dev -> if_flags = ( in6_dev -> if_flags & ~ ( IF_RA_MANAGED | IF_RA_OTHERCONF ) ) | ( ra_msg -> icmph . icmp6_addrconf_managed ? IF_RA_MANAGED : 0 ) | ( ra_msg -> icmph . icmp6_addrconf_other ? IF_RA_OTHERCONF : 0 ); 69
if ( ! in6_dev -> cnf . accept_ra_defrtr )  76
if ( ipv6_chk_addr ( dev_net ( in6_dev -> dev ) , & ipv6_hdr ( skb ) -> saddr , NULL , 0 ) )  79
lifetime = ntohs ( ra_msg -> icmph . icmp6_rt_lifetime ); 82
pref = ra_msg -> icmph . icmp6_router_pref; 85
if ( pref == ICMPV6_ROUTER_PREF_INVALID || ! in6_dev -> cnf . accept_ra_rtr_pref )  87
pref = ICMPV6_ROUTER_PREF_MEDIUM; 89
rt = rt6_get_dflt_router ( & ipv6_hdr ( skb ) -> saddr , skb -> dev ); 92
if ( rt )  94
neigh = dst_neigh_lookup ( & rt -> dst , & ipv6_hdr ( skb ) -> saddr ); 95
if ( ! neigh )  96
if ( rt && lifetime == 0 )  104
rt = NULL; 106
if ( rt == NULL && lifetime )  109
rt = rt6_add_dflt_router ( & ipv6_hdr ( skb ) -> saddr , skb -> dev , pref ); 112
if ( rt == NULL )  113
neigh = dst_neigh_lookup ( & rt -> dst , & ipv6_hdr ( skb ) -> saddr ); 120
if ( neigh == NULL )  121
if ( ra_msg -> icmph . icmp6_hop_limit )  135
if ( in6_dev -> cnf . hop_limit < ra_msg -> icmph . icmp6_hop_limit )  139
in6_dev -> cnf . hop_limit = ra_msg -> icmph . icmp6_hop_limit; 140
if ( in6_dev -> nd_parms )  155
unsigned long rtime = ntohl ( ra_msg -> retrans_timer ) ; 156
if ( rtime && rtime / 1000 < MAX_SCHEDULE_TIMEOUT / HZ )  158
rtime = ( rtime * HZ ) / 1000; 159
if ( rtime < HZ / 10 )  160
rtime = HZ / 10; 161
rtime = ntohl ( ra_msg -> reachable_time ); 167
if ( rtime && rtime / 1000 < MAX_SCHEDULE_TIMEOUT / ( 3 * HZ ) )  168
rtime = ( rtime * HZ ) / 1000; 169
if ( rtime < HZ / 10 )  171
if ( rtime != in6_dev -> nd_parms -> base_reachable_time )  174
in6_dev -> nd_parms -> base_reachable_time = rtime; 175
in6_dev -> nd_parms -> gc_staletime = 3 * rtime; 176
in6_dev -> nd_parms -> reachable_time = neigh_rand_reach_time ( rtime ); 177
in6_dev -> tstamp = jiffies; 178
inet6_ifinfo_notify ( RTM_NEWLINK , in6_dev ); 179
if ( ! accept_ra ( in6_dev ) )  211
if ( ipv6_chk_addr ( dev_net ( in6_dev -> dev ) , & ipv6_hdr ( skb ) -> saddr , NULL , 0 ) )  215
if ( in6_dev -> cnf . accept_ra_rtr_pref && ndopts . nd_opts_ri )  218
if ( ri -> prefix_len > in6_dev -> cnf . accept_ra_rt_info_max_plen )  229
if ( in6_dev -> cnf . accept_ra_pinfo && ndopts . nd_opts_pi )  245
if ( in6_dev -> cnf . mtu6 != mtu )  265
in6_dev -> cnf . mtu6 = mtu; 266
------------------------------
566 /home/speedy/test/source2slice/NVD/CVE_2015_2922_PATCHED_ndisc_router_discovery.c rtime = ( rtime * HZ ) / 1000 159
static void CVE_2015_2922_PATCHED_ndisc_router_discovery(struct sk_buff *skb) 1
struct ra_msg * ra_msg = ( struct ra_msg * ) skb_transport_header ( skb ) ; 3
struct inet6_dev * in6_dev ; 5
int lifetime ; 7
struct ndisc_options ndopts ; 8
int optlen ; 9
__u8 * opt = ( __u8 * ) ( ra_msg + 1 ) ; 12
optlen = ( skb -> tail - skb -> transport_header ) - sizeof ( struct ra_msg ); 14
if ( ! ( ipv6_addr_type ( & ipv6_hdr ( skb ) -> saddr ) & IPV6_ADDR_LINKLOCAL ) )  16
if ( optlen < 0 )  20
if ( skb -> ndisc_nodetype == NDISC_NODETYPE_HOST )  26
in6_dev = __in6_dev_get ( skb -> dev ); 36
if ( in6_dev == NULL )  37
if ( ! ndisc_parse_options ( opt , optlen , & ndopts ) )  43
if ( ! accept_ra ( in6_dev ) )  48
if ( skb -> ndisc_nodetype == NDISC_NODETYPE_NODEFAULT )  53
if ( in6_dev -> if_flags & IF_RS_SENT )  57
in6_dev -> if_flags |= IF_RA_RCVD; 62
in6_dev -> if_flags = ( in6_dev -> if_flags & ~ ( IF_RA_MANAGED | IF_RA_OTHERCONF ) ) | ( ra_msg -> icmph . icmp6_addrconf_managed ? IF_RA_MANAGED : 0 ) | ( ra_msg -> icmph . icmp6_addrconf_other ? IF_RA_OTHERCONF : 0 ); 69
if ( ! in6_dev -> cnf . accept_ra_defrtr )  76
if ( ipv6_chk_addr ( dev_net ( in6_dev -> dev ) , & ipv6_hdr ( skb ) -> saddr , NULL , 0 ) )  79
lifetime = ntohs ( ra_msg -> icmph . icmp6_rt_lifetime ); 82
pref = ra_msg -> icmph . icmp6_router_pref; 85
if ( pref == ICMPV6_ROUTER_PREF_INVALID || ! in6_dev -> cnf . accept_ra_rtr_pref )  87
pref = ICMPV6_ROUTER_PREF_MEDIUM; 89
rt = rt6_get_dflt_router ( & ipv6_hdr ( skb ) -> saddr , skb -> dev ); 92
if ( rt )  94
neigh = dst_neigh_lookup ( & rt -> dst , & ipv6_hdr ( skb ) -> saddr ); 95
if ( ! neigh )  96
if ( rt && lifetime == 0 )  104
rt = NULL; 106
if ( rt == NULL && lifetime )  109
rt = rt6_add_dflt_router ( & ipv6_hdr ( skb ) -> saddr , skb -> dev , pref ); 112
if ( rt == NULL )  113
neigh = dst_neigh_lookup ( & rt -> dst , & ipv6_hdr ( skb ) -> saddr ); 120
if ( neigh == NULL )  121
if ( ra_msg -> icmph . icmp6_hop_limit )  135
if ( in6_dev -> cnf . hop_limit < ra_msg -> icmph . icmp6_hop_limit )  139
in6_dev -> cnf . hop_limit = ra_msg -> icmph . icmp6_hop_limit; 140
if ( in6_dev -> nd_parms )  155
unsigned long rtime = ntohl ( ra_msg -> retrans_timer ) ; 156
if ( rtime && rtime / 1000 < MAX_SCHEDULE_TIMEOUT / HZ )  158
rtime = ( rtime * HZ ) / 1000; 159
if ( rtime < HZ / 10 )  160
in6_dev -> nd_parms -> retrans_time = rtime; 162
in6_dev -> tstamp = jiffies; 163
inet6_ifinfo_notify ( RTM_NEWLINK , in6_dev ); 164
if ( rtime && rtime / 1000 < MAX_SCHEDULE_TIMEOUT / ( 3 * HZ ) )  168
rtime = ( rtime * HZ ) / 1000; 169
if ( rtime < HZ / 10 )  171
if ( rtime != in6_dev -> nd_parms -> base_reachable_time )  174
in6_dev -> nd_parms -> base_reachable_time = rtime; 175
in6_dev -> nd_parms -> gc_staletime = 3 * rtime; 176
in6_dev -> nd_parms -> reachable_time = neigh_rand_reach_time ( rtime ); 177
in6_dev -> tstamp = jiffies; 178
inet6_ifinfo_notify ( RTM_NEWLINK , in6_dev ); 179
if ( ! accept_ra ( in6_dev ) )  211
if ( ipv6_chk_addr ( dev_net ( in6_dev -> dev ) , & ipv6_hdr ( skb ) -> saddr , NULL , 0 ) )  215
if ( in6_dev -> cnf . accept_ra_rtr_pref && ndopts . nd_opts_ri )  218
if ( ri -> prefix_len > in6_dev -> cnf . accept_ra_rt_info_max_plen )  229
if ( in6_dev -> cnf . accept_ra_pinfo && ndopts . nd_opts_pi )  245
if ( in6_dev -> cnf . mtu6 != mtu )  265
in6_dev -> cnf . mtu6 = mtu; 266
------------------------------
567 /home/speedy/test/source2slice/NVD/CVE_2015_2922_PATCHED_ndisc_router_discovery.c optlen = ( skb -> tail - skb -> transport_header ) - sizeof ( struct ra_msg ) 14
static void CVE_2015_2922_PATCHED_ndisc_router_discovery(struct sk_buff *skb) 1
int optlen ; 9
optlen = ( skb -> tail - skb -> transport_header ) - sizeof ( struct ra_msg ); 14
if ( optlen < 0 )  20
if ( ! ndisc_parse_options ( opt , optlen , & ndopts ) )  43
------------------------------
568 /home/speedy/test/source2slice/NVD/CVE_2015_2922_VULN_ndisc_router_discovery.c rtime = ( rtime * HZ ) / 1000 162
static void CVE_2015_2922_VULN_ndisc_router_discovery(struct sk_buff *skb) 1
struct ra_msg * ra_msg = ( struct ra_msg * ) skb_transport_header ( skb ) ; 3
struct inet6_dev * in6_dev ; 5
int lifetime ; 7
struct ndisc_options ndopts ; 8
int optlen ; 9
__u8 * opt = ( __u8 * ) ( ra_msg + 1 ) ; 12
optlen = ( skb -> tail - skb -> transport_header ) - sizeof ( struct ra_msg ); 14
if ( ! ( ipv6_addr_type ( & ipv6_hdr ( skb ) -> saddr ) & IPV6_ADDR_LINKLOCAL ) )  16
if ( optlen < 0 )  20
if ( skb -> ndisc_nodetype == NDISC_NODETYPE_HOST )  26
in6_dev = __in6_dev_get ( skb -> dev ); 36
if ( in6_dev == NULL )  37
if ( ! ndisc_parse_options ( opt , optlen , & ndopts ) )  43
if ( ! accept_ra ( in6_dev ) )  48
if ( skb -> ndisc_nodetype == NDISC_NODETYPE_NODEFAULT )  53
if ( in6_dev -> if_flags & IF_RS_SENT )  57
in6_dev -> if_flags |= IF_RA_RCVD; 62
in6_dev -> if_flags = ( in6_dev -> if_flags & ~ ( IF_RA_MANAGED | IF_RA_OTHERCONF ) ) | ( ra_msg -> icmph . icmp6_addrconf_managed ? IF_RA_MANAGED : 0 ) | ( ra_msg -> icmph . icmp6_addrconf_other ? IF_RA_OTHERCONF : 0 ); 69
if ( ! in6_dev -> cnf . accept_ra_defrtr )  76
if ( ipv6_chk_addr ( dev_net ( in6_dev -> dev ) , & ipv6_hdr ( skb ) -> saddr , NULL , 0 ) )  79
lifetime = ntohs ( ra_msg -> icmph . icmp6_rt_lifetime ); 82
pref = ra_msg -> icmph . icmp6_router_pref; 85
if ( pref == ICMPV6_ROUTER_PREF_INVALID || ! in6_dev -> cnf . accept_ra_rtr_pref )  87
pref = ICMPV6_ROUTER_PREF_MEDIUM; 89
rt = rt6_get_dflt_router ( & ipv6_hdr ( skb ) -> saddr , skb -> dev ); 92
if ( rt )  94
neigh = dst_neigh_lookup ( & rt -> dst , & ipv6_hdr ( skb ) -> saddr ); 95
if ( ! neigh )  96
if ( rt && lifetime == 0 )  104
rt = NULL; 106
if ( rt == NULL && lifetime )  109
rt = rt6_add_dflt_router ( & ipv6_hdr ( skb ) -> saddr , skb -> dev , pref ); 112
if ( rt == NULL )  113
neigh = dst_neigh_lookup ( & rt -> dst , & ipv6_hdr ( skb ) -> saddr ); 120
if ( neigh == NULL )  121
if ( ra_msg -> icmph . icmp6_hop_limit )  135
in6_dev -> cnf . hop_limit = ra_msg -> icmph . icmp6_hop_limit; 136
if ( in6_dev -> nd_parms )  148
unsigned long rtime = ntohl ( ra_msg -> retrans_timer ) ; 149
if ( rtime && rtime / 1000 < MAX_SCHEDULE_TIMEOUT / HZ )  151
rtime = ( rtime * HZ ) / 1000; 152
if ( rtime < HZ / 10 )  153
rtime = HZ / 10; 154
rtime = ntohl ( ra_msg -> reachable_time ); 160
if ( rtime && rtime / 1000 < MAX_SCHEDULE_TIMEOUT / ( 3 * HZ ) )  161
rtime = ( rtime * HZ ) / 1000; 162
if ( rtime < HZ / 10 )  164
if ( rtime != in6_dev -> nd_parms -> base_reachable_time )  167
in6_dev -> nd_parms -> base_reachable_time = rtime; 168
in6_dev -> nd_parms -> gc_staletime = 3 * rtime; 169
in6_dev -> nd_parms -> reachable_time = neigh_rand_reach_time ( rtime ); 170
in6_dev -> tstamp = jiffies; 171
inet6_ifinfo_notify ( RTM_NEWLINK , in6_dev ); 172
if ( ! accept_ra ( in6_dev ) )  204
if ( ipv6_chk_addr ( dev_net ( in6_dev -> dev ) , & ipv6_hdr ( skb ) -> saddr , NULL , 0 ) )  208
if ( in6_dev -> cnf . accept_ra_rtr_pref && ndopts . nd_opts_ri )  211
if ( ri -> prefix_len > in6_dev -> cnf . accept_ra_rt_info_max_plen )  222
if ( in6_dev -> cnf . accept_ra_pinfo && ndopts . nd_opts_pi )  238
if ( in6_dev -> cnf . mtu6 != mtu )  258
in6_dev -> cnf . mtu6 = mtu; 259
------------------------------
569 /home/speedy/test/source2slice/NVD/CVE_2015_2922_VULN_ndisc_router_discovery.c rtime = ( rtime * HZ ) / 1000 152
static void CVE_2015_2922_VULN_ndisc_router_discovery(struct sk_buff *skb) 1
struct ra_msg * ra_msg = ( struct ra_msg * ) skb_transport_header ( skb ) ; 3
struct inet6_dev * in6_dev ; 5
int lifetime ; 7
struct ndisc_options ndopts ; 8
int optlen ; 9
__u8 * opt = ( __u8 * ) ( ra_msg + 1 ) ; 12
optlen = ( skb -> tail - skb -> transport_header ) - sizeof ( struct ra_msg ); 14
if ( ! ( ipv6_addr_type ( & ipv6_hdr ( skb ) -> saddr ) & IPV6_ADDR_LINKLOCAL ) )  16
if ( optlen < 0 )  20
if ( skb -> ndisc_nodetype == NDISC_NODETYPE_HOST )  26
in6_dev = __in6_dev_get ( skb -> dev ); 36
if ( in6_dev == NULL )  37
if ( ! ndisc_parse_options ( opt , optlen , & ndopts ) )  43
if ( ! accept_ra ( in6_dev ) )  48
if ( skb -> ndisc_nodetype == NDISC_NODETYPE_NODEFAULT )  53
if ( in6_dev -> if_flags & IF_RS_SENT )  57
in6_dev -> if_flags |= IF_RA_RCVD; 62
in6_dev -> if_flags = ( in6_dev -> if_flags & ~ ( IF_RA_MANAGED | IF_RA_OTHERCONF ) ) | ( ra_msg -> icmph . icmp6_addrconf_managed ? IF_RA_MANAGED : 0 ) | ( ra_msg -> icmph . icmp6_addrconf_other ? IF_RA_OTHERCONF : 0 ); 69
if ( ! in6_dev -> cnf . accept_ra_defrtr )  76
if ( ipv6_chk_addr ( dev_net ( in6_dev -> dev ) , & ipv6_hdr ( skb ) -> saddr , NULL , 0 ) )  79
lifetime = ntohs ( ra_msg -> icmph . icmp6_rt_lifetime ); 82
pref = ra_msg -> icmph . icmp6_router_pref; 85
if ( pref == ICMPV6_ROUTER_PREF_INVALID || ! in6_dev -> cnf . accept_ra_rtr_pref )  87
pref = ICMPV6_ROUTER_PREF_MEDIUM; 89
rt = rt6_get_dflt_router ( & ipv6_hdr ( skb ) -> saddr , skb -> dev ); 92
if ( rt )  94
neigh = dst_neigh_lookup ( & rt -> dst , & ipv6_hdr ( skb ) -> saddr ); 95
if ( ! neigh )  96
if ( rt && lifetime == 0 )  104
rt = NULL; 106
if ( rt == NULL && lifetime )  109
rt = rt6_add_dflt_router ( & ipv6_hdr ( skb ) -> saddr , skb -> dev , pref ); 112
if ( rt == NULL )  113
neigh = dst_neigh_lookup ( & rt -> dst , & ipv6_hdr ( skb ) -> saddr ); 120
if ( neigh == NULL )  121
if ( ra_msg -> icmph . icmp6_hop_limit )  135
in6_dev -> cnf . hop_limit = ra_msg -> icmph . icmp6_hop_limit; 136
if ( in6_dev -> nd_parms )  148
unsigned long rtime = ntohl ( ra_msg -> retrans_timer ) ; 149
if ( rtime && rtime / 1000 < MAX_SCHEDULE_TIMEOUT / HZ )  151
rtime = ( rtime * HZ ) / 1000; 152
if ( rtime < HZ / 10 )  153
in6_dev -> nd_parms -> retrans_time = rtime; 155
in6_dev -> tstamp = jiffies; 156
inet6_ifinfo_notify ( RTM_NEWLINK , in6_dev ); 157
if ( rtime && rtime / 1000 < MAX_SCHEDULE_TIMEOUT / ( 3 * HZ ) )  161
rtime = ( rtime * HZ ) / 1000; 162
if ( rtime < HZ / 10 )  164
if ( rtime != in6_dev -> nd_parms -> base_reachable_time )  167
in6_dev -> nd_parms -> base_reachable_time = rtime; 168
in6_dev -> nd_parms -> gc_staletime = 3 * rtime; 169
in6_dev -> nd_parms -> reachable_time = neigh_rand_reach_time ( rtime ); 170
in6_dev -> tstamp = jiffies; 171
inet6_ifinfo_notify ( RTM_NEWLINK , in6_dev ); 172
if ( ! accept_ra ( in6_dev ) )  204
if ( ipv6_chk_addr ( dev_net ( in6_dev -> dev ) , & ipv6_hdr ( skb ) -> saddr , NULL , 0 ) )  208
if ( in6_dev -> cnf . accept_ra_rtr_pref && ndopts . nd_opts_ri )  211
if ( ri -> prefix_len > in6_dev -> cnf . accept_ra_rt_info_max_plen )  222
if ( in6_dev -> cnf . accept_ra_pinfo && ndopts . nd_opts_pi )  238
if ( in6_dev -> cnf . mtu6 != mtu )  258
in6_dev -> cnf . mtu6 = mtu; 259
------------------------------
570 /home/speedy/test/source2slice/NVD/CVE_2015_2922_VULN_ndisc_router_discovery.c optlen = ( skb -> tail - skb -> transport_header ) - sizeof ( struct ra_msg ) 14
static void CVE_2015_2922_VULN_ndisc_router_discovery(struct sk_buff *skb) 1
int optlen ; 9
optlen = ( skb -> tail - skb -> transport_header ) - sizeof ( struct ra_msg ); 14
if ( optlen < 0 )  20
if ( ! ndisc_parse_options ( opt , optlen , & ndopts ) )  43
------------------------------
571 /home/speedy/test/source2slice/NVD/CVE_2015_3331_PATCHED___driver_rfc4106_decrypt.c retval = memcmp ( src + tempCipherLen , authTag , auth_tag_len ) ? - EBADMSG : 0 64
static int CVE_2015_3331_PATCHED___driver_rfc4106_decrypt(struct aead_request *req) 1
u8 * src , * dst , * assoc ; 4
struct crypto_aead * tfm = crypto_aead_reqtfm ( req ) ; 8
unsigned long auth_tag_len = crypto_aead_authsize ( tfm ) ; 11
u8 iv_and_authTag [ 32 + AESNI_ALIGN ] ; 12
u8 * iv = ( u8 * ) PTR_ALIGN ( ( u8 * ) iv_and_authTag , AESNI_ALIGN ) ; 13
u8 * authTag = iv + 16 ; 14
if ( unlikely ( ( req -> cryptlen < auth_tag_len ) || ( req -> assoclen != 8 && req -> assoclen != 12 ) ) )  20
tempCipherLen = ( unsigned long ) ( req -> cryptlen - auth_tag_len ); 27
if ( ( sg_is_last ( req -> src ) ) && ( sg_is_last ( req -> assoc ) ) )  35
src = scatterwalk_map ( & src_sg_walk ); 39
src = kmalloc ( req -> cryptlen + req -> assoclen , GFP_ATOMIC ); 49
if ( ! src )  50
retval = memcmp ( src + tempCipherLen , authTag , auth_tag_len ) ? - EBADMSG : 0; 64
return retval ; 80
------------------------------
572 /home/speedy/test/source2slice/NVD/CVE_2015_3331_PATCHED___driver_rfc4106_decrypt.c assoc = ( src + req -> cryptlen ) 52
static int CVE_2015_3331_PATCHED___driver_rfc4106_decrypt(struct aead_request *req) 1
u8 * src , * dst , * assoc ; 4
struct crypto_aead * tfm = crypto_aead_reqtfm ( req ) ; 8
unsigned long auth_tag_len = crypto_aead_authsize ( tfm ) ; 11
if ( unlikely ( ( req -> cryptlen < auth_tag_len ) || ( req -> assoclen != 8 && req -> assoclen != 12 ) ) )  20
if ( ( sg_is_last ( req -> src ) ) && ( sg_is_last ( req -> assoc ) ) )  35
src = kmalloc ( req -> cryptlen + req -> assoclen , GFP_ATOMIC ); 49
if ( ! src )  50
assoc = ( src + req -> cryptlen ); 52
scatterwalk_map_and_copy ( assoc , req -> assoc , 0 , req -> assoclen , 0 ); 54
aesni_gcm_dec ( aes_ctx , dst , src , tempCipherLen , iv , ctx -> hash_subkey , assoc , ( unsigned long ) req -> assoclen , authTag , auth_tag_len ); 59
scatterwalk_unmap ( assoc ); 73
------------------------------
573 /home/speedy/test/source2slice/NVD/CVE_2015_3331_PATCHED___driver_rfc4106_decrypt.c src = kmalloc ( req -> cryptlen + req -> assoclen , GFP_ATOMIC ) 49
static int CVE_2015_3331_PATCHED___driver_rfc4106_decrypt(struct aead_request *req) 1
u8 * src , * dst , * assoc ; 4
struct crypto_aead * tfm = crypto_aead_reqtfm ( req ) ; 8
unsigned long auth_tag_len = crypto_aead_authsize ( tfm ) ; 11
if ( unlikely ( ( req -> cryptlen < auth_tag_len ) || ( req -> assoclen != 8 && req -> assoclen != 12 ) ) )  20
if ( ( sg_is_last ( req -> src ) ) && ( sg_is_last ( req -> assoc ) ) )  35
src = kmalloc ( req -> cryptlen + req -> assoclen , GFP_ATOMIC ); 49
if ( ! src )  50
assoc = ( src + req -> cryptlen ); 52
scatterwalk_map_and_copy ( src , req -> src , 0 , req -> cryptlen , 0 ); 53
scatterwalk_map_and_copy ( assoc , req -> assoc , 0 , req -> assoclen , 0 ); 54
dst = src; 56
aesni_gcm_dec ( aes_ctx , dst , src , tempCipherLen , iv , ctx -> hash_subkey , assoc , ( unsigned long ) req -> assoclen , authTag , auth_tag_len ); 59
retval = memcmp ( src + tempCipherLen , authTag , auth_tag_len ) ? - EBADMSG : 0; 64
scatterwalk_unmap ( dst ); 69
scatterwalk_unmap ( src ); 72
scatterwalk_unmap ( assoc ); 73
scatterwalk_map_and_copy ( dst , req -> dst , 0 , tempCipherLen , 1 ); 77
kfree ( src ); 78
return retval ; 80
------------------------------
574 /home/speedy/test/source2slice/NVD/CVE_2015_3331_PATCHED___driver_rfc4106_decrypt.c tempCipherLen = ( unsigned long ) ( req -> cryptlen - auth_tag_len ) 27
static int CVE_2015_3331_PATCHED___driver_rfc4106_decrypt(struct aead_request *req) 1
struct crypto_aead * tfm = crypto_aead_reqtfm ( req ) ; 8
unsigned long auth_tag_len = crypto_aead_authsize ( tfm ) ; 11
if ( unlikely ( ( req -> cryptlen < auth_tag_len ) || ( req -> assoclen != 8 && req -> assoclen != 12 ) ) )  20
tempCipherLen = ( unsigned long ) ( req -> cryptlen - auth_tag_len ); 27
aesni_gcm_dec ( aes_ctx , dst , src , tempCipherLen , iv , ctx -> hash_subkey , assoc , ( unsigned long ) req -> assoclen , authTag , auth_tag_len ); 59
retval = memcmp ( src + tempCipherLen , authTag , auth_tag_len ) ? - EBADMSG : 0; 64
scatterwalk_map_and_copy ( dst , req -> dst , 0 , tempCipherLen , 1 ); 77
return retval ; 80
------------------------------
575 /home/speedy/test/source2slice/NVD/CVE_2015_3331_VULN___driver_rfc4106_decrypt.c retval = memcmp ( src + tempCipherLen , authTag , auth_tag_len ) ? - EBADMSG : 0 64
static int CVE_2015_3331_VULN___driver_rfc4106_decrypt(struct aead_request *req) 1
u8 * src , * dst , * assoc ; 4
struct crypto_aead * tfm = crypto_aead_reqtfm ( req ) ; 8
unsigned long auth_tag_len = crypto_aead_authsize ( tfm ) ; 11
u8 iv_and_authTag [ 32 + AESNI_ALIGN ] ; 12
u8 * iv = ( u8 * ) PTR_ALIGN ( ( u8 * ) iv_and_authTag , AESNI_ALIGN ) ; 13
u8 * authTag = iv + 16 ; 14
if ( unlikely ( ( req -> cryptlen < auth_tag_len ) || ( req -> assoclen != 8 && req -> assoclen != 12 ) ) )  20
tempCipherLen = ( unsigned long ) ( req -> cryptlen - auth_tag_len ); 27
if ( ( sg_is_last ( req -> src ) ) && ( sg_is_last ( req -> assoc ) ) )  35
src = scatterwalk_map ( & src_sg_walk ); 39
src = kmalloc ( req -> cryptlen + req -> assoclen , GFP_ATOMIC ); 49
if ( ! src )  50
retval = memcmp ( src + tempCipherLen , authTag , auth_tag_len ) ? - EBADMSG : 0; 64
return retval ; 80
------------------------------
576 /home/speedy/test/source2slice/NVD/CVE_2015_3331_VULN___driver_rfc4106_decrypt.c assoc = ( src + req -> cryptlen + auth_tag_len ) 52
static int CVE_2015_3331_VULN___driver_rfc4106_decrypt(struct aead_request *req) 1
u8 * src , * dst , * assoc ; 4
struct crypto_aead * tfm = crypto_aead_reqtfm ( req ) ; 8
unsigned long auth_tag_len = crypto_aead_authsize ( tfm ) ; 11
if ( unlikely ( ( req -> cryptlen < auth_tag_len ) || ( req -> assoclen != 8 && req -> assoclen != 12 ) ) )  20
if ( ( sg_is_last ( req -> src ) ) && ( sg_is_last ( req -> assoc ) ) )  35
src = kmalloc ( req -> cryptlen + req -> assoclen , GFP_ATOMIC ); 49
if ( ! src )  50
assoc = ( src + req -> cryptlen + auth_tag_len ); 52
scatterwalk_map_and_copy ( assoc , req -> assoc , 0 , req -> assoclen , 0 ); 54
aesni_gcm_dec ( aes_ctx , dst , src , tempCipherLen , iv , ctx -> hash_subkey , assoc , ( unsigned long ) req -> assoclen , authTag , auth_tag_len ); 59
scatterwalk_unmap ( assoc ); 73
------------------------------
577 /home/speedy/test/source2slice/NVD/CVE_2015_3331_VULN___driver_rfc4106_decrypt.c src = kmalloc ( req -> cryptlen + req -> assoclen , GFP_ATOMIC ) 49
static int CVE_2015_3331_VULN___driver_rfc4106_decrypt(struct aead_request *req) 1
u8 * src , * dst , * assoc ; 4
struct crypto_aead * tfm = crypto_aead_reqtfm ( req ) ; 8
unsigned long auth_tag_len = crypto_aead_authsize ( tfm ) ; 11
if ( unlikely ( ( req -> cryptlen < auth_tag_len ) || ( req -> assoclen != 8 && req -> assoclen != 12 ) ) )  20
if ( ( sg_is_last ( req -> src ) ) && ( sg_is_last ( req -> assoc ) ) )  35
src = kmalloc ( req -> cryptlen + req -> assoclen , GFP_ATOMIC ); 49
if ( ! src )  50
assoc = ( src + req -> cryptlen + auth_tag_len ); 52
scatterwalk_map_and_copy ( src , req -> src , 0 , req -> cryptlen , 0 ); 53
scatterwalk_map_and_copy ( assoc , req -> assoc , 0 , req -> assoclen , 0 ); 54
dst = src; 56
aesni_gcm_dec ( aes_ctx , dst , src , tempCipherLen , iv , ctx -> hash_subkey , assoc , ( unsigned long ) req -> assoclen , authTag , auth_tag_len ); 59
retval = memcmp ( src + tempCipherLen , authTag , auth_tag_len ) ? - EBADMSG : 0; 64
scatterwalk_unmap ( dst ); 69
scatterwalk_unmap ( src ); 72
scatterwalk_unmap ( assoc ); 73
scatterwalk_map_and_copy ( dst , req -> dst , 0 , req -> cryptlen , 1 ); 77
kfree ( src ); 78
return retval ; 80
------------------------------
578 /home/speedy/test/source2slice/NVD/CVE_2015_3331_VULN___driver_rfc4106_decrypt.c tempCipherLen = ( unsigned long ) ( req -> cryptlen - auth_tag_len ) 27
static int CVE_2015_3331_VULN___driver_rfc4106_decrypt(struct aead_request *req) 1
struct crypto_aead * tfm = crypto_aead_reqtfm ( req ) ; 8
unsigned long auth_tag_len = crypto_aead_authsize ( tfm ) ; 11
if ( unlikely ( ( req -> cryptlen < auth_tag_len ) || ( req -> assoclen != 8 && req -> assoclen != 12 ) ) )  20
tempCipherLen = ( unsigned long ) ( req -> cryptlen - auth_tag_len ); 27
aesni_gcm_dec ( aes_ctx , dst , src , tempCipherLen , iv , ctx -> hash_subkey , assoc , ( unsigned long ) req -> assoclen , authTag , auth_tag_len ); 59
retval = memcmp ( src + tempCipherLen , authTag , auth_tag_len ) ? - EBADMSG : 0; 64
return retval ; 80
------------------------------
579 /home/speedy/test/source2slice/NVD/CVE_2015_3808_PATCHED_dissect_lbmr_pser.c opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ) 36
static int CVE_2015_3808_PATCHED_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
curr_offset += hdr_len; 26
if ( ( flags & LBMR_PSER_OPT_FLAG ) != 0 )  28
opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ); 36
proto_item_set_len ( opts_item , opt_len ); 43
opt_len -= L_LBMR_PSER_OPTLEN_T; 46
while ( opt_len > 0 )  47
opt_len -= L_LBMR_PSER_OPT_CTXINST_T; 65
opt_len -= option_len; 70
------------------------------
580 /home/speedy/test/source2slice/NVD/CVE_2015_3808_PATCHED_dissect_lbmr_pser.c flags_item = proto_tree_add_none_format ( tree , hf_lbmr_pser_flags , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , "Flags (0x%04x)" , flags ) 16
static int CVE_2015_3808_PATCHED_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
flags_item = proto_tree_add_none_format ( tree , hf_lbmr_pser_flags , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , "Flags (0x%04x)" , flags ); 16
flags_tree = proto_item_add_subtree ( flags_item , ett_lbmr_pser_flags ); 17
proto_tree_add_item ( flags_tree , hf_lbmr_pser_flags_option , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , ENC_BIG_ENDIAN ); 18
------------------------------
581 /home/speedy/test/source2slice/NVD/CVE_2015_3808_PATCHED_dissect_lbmr_pser.c topic_len = hdr_len - L_LBMR_PSER_T 13
static int CVE_2015_3808_PATCHED_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
topic_len = hdr_len - L_LBMR_PSER_T; 13
proto_tree_add_item ( tree , hf_lbmr_pser_topic , tvb , offset + O_LBMR_PSER_T_TOPIC , topic_len , ENC_ASCII | ENC_NA ); 25
------------------------------
582 /home/speedy/test/source2slice/NVD/CVE_2015_3808_PATCHED_dissect_lbmr_pser.c flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ) 12
static int CVE_2015_3808_PATCHED_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
flags_item = proto_tree_add_none_format ( tree , hf_lbmr_pser_flags , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , "Flags (0x%04x)" , flags ); 16
flags_tree = proto_item_add_subtree ( flags_item , ett_lbmr_pser_flags ); 17
proto_tree_add_item ( flags_tree , hf_lbmr_pser_flags_option , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , ENC_BIG_ENDIAN ); 18
if ( ( flags & LBMR_PSER_OPT_FLAG ) != 0 )  28
------------------------------
583 /home/speedy/test/source2slice/NVD/CVE_2015_3808_PATCHED_dissect_lbmr_pser.c hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ) 11
static int CVE_2015_3808_PATCHED_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
topic_len = hdr_len - L_LBMR_PSER_T; 13
proto_tree_add_item ( tree , hf_lbmr_pser_topic , tvb , offset + O_LBMR_PSER_T_TOPIC , topic_len , ENC_ASCII | ENC_NA ); 25
curr_offset += hdr_len; 26
len = hdr_len; 27
opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ); 36
opts_item = proto_tree_add_item ( tree , hf_lbmr_pser_opts , tvb , curr_offset , - 1 , ENC_NA ); 37
opts_tree = proto_item_add_subtree ( opts_item , ett_lbmr_pser_opts ); 38
optlen_item = proto_tree_add_item ( opts_tree , hf_lbmr_pser_optlen , tvb , curr_offset , L_LBMR_PSER_OPTLEN_T , ENC_NA ); 39
optlen_tree = proto_item_add_subtree ( optlen_item , ett_lbmr_pser_opt_len ); 40
proto_tree_add_item ( optlen_tree , hf_lbmr_pser_optlen_type , tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_TYPE , L_LBMR_PSER_OPTLEN_T_TYPE , ENC_BIG_ENDIAN ); 41
proto_tree_add_item ( optlen_tree , hf_lbmr_pser_optlen_optlen , tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN , L_LBMR_PSER_OPTLEN_T_OPTLEN , ENC_BIG_ENDIAN ); 42
proto_item_set_len ( opts_item , opt_len ); 43
len += L_LBMR_PSER_OPTLEN_T; 44
curr_offset += L_LBMR_PSER_OPTLEN_T; 45
opt_len -= L_LBMR_PSER_OPTLEN_T; 46
while ( opt_len > 0 )  47
guint8 opt_type = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_TYPE ) ; 51
guint8 option_len = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_LEN ) ; 52
switch ( opt_type )  54
ctxinst_item = proto_tree_add_item ( opts_tree , hf_lbmr_pser_opt_ctxinst , tvb , curr_offset , L_LBMR_PSER_OPT_CTXINST_T , ENC_NA ); 58
ctxinst_tree = proto_item_add_subtree ( ctxinst_item , ett_lbmr_pser_opt_ctxinst ); 59
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_len , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_LEN , L_LBMR_PSER_OPT_CTXINST_T_LEN , ENC_BIG_ENDIAN ); 60
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_type , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_TYPE , L_LBMR_PSER_OPT_CTXINST_T_TYPE , ENC_BIG_ENDIAN ); 61
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_ctxinst , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_CTXINST , L_LBMR_PSER_OPT_CTXINST_T_CTXINST , ENC_NA ); 62
len += L_LBMR_PSER_OPT_CTXINST_T; 63
curr_offset += L_LBMR_PSER_OPT_CTXINST_T; 64
opt_len -= L_LBMR_PSER_OPT_CTXINST_T; 65
len += option_len; 68
curr_offset += option_len; 69
opt_len -= option_len; 70
expert_add_info_format ( pinfo , NULL , & ei_lbmr_analysis_invalid_value , "Unknown LBMR PSER option 0x%02x" , opt_type ); 71
if ( option_len == 0 )  72
return ( len ) ; 73
return ( len ) ; 79
------------------------------
584 /home/speedy/test/source2slice/NVD/CVE_2015_3808_VULN_dissect_lbmr_pser.c opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ) 36
static int CVE_2015_3808_VULN_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
curr_offset += hdr_len; 26
if ( ( flags & LBMR_PSER_OPT_FLAG ) != 0 )  28
opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ); 36
proto_item_set_len ( opts_item , opt_len ); 43
opt_len -= L_LBMR_PSER_OPTLEN_T; 46
while ( opt_len > 0 )  47
opt_len -= L_LBMR_PSER_OPT_CTXINST_T; 65
opt_len -= option_len; 70
------------------------------
585 /home/speedy/test/source2slice/NVD/CVE_2015_3808_VULN_dissect_lbmr_pser.c flags_item = proto_tree_add_none_format ( tree , hf_lbmr_pser_flags , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , "Flags (0x%04x)" , flags ) 16
static int CVE_2015_3808_VULN_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
flags_item = proto_tree_add_none_format ( tree , hf_lbmr_pser_flags , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , "Flags (0x%04x)" , flags ); 16
flags_tree = proto_item_add_subtree ( flags_item , ett_lbmr_pser_flags ); 17
proto_tree_add_item ( flags_tree , hf_lbmr_pser_flags_option , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , ENC_BIG_ENDIAN ); 18
------------------------------
586 /home/speedy/test/source2slice/NVD/CVE_2015_3808_VULN_dissect_lbmr_pser.c topic_len = hdr_len - L_LBMR_PSER_T 13
static int CVE_2015_3808_VULN_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
topic_len = hdr_len - L_LBMR_PSER_T; 13
proto_tree_add_item ( tree , hf_lbmr_pser_topic , tvb , offset + O_LBMR_PSER_T_TOPIC , topic_len , ENC_ASCII | ENC_NA ); 25
------------------------------
587 /home/speedy/test/source2slice/NVD/CVE_2015_3808_VULN_dissect_lbmr_pser.c flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ) 12
static int CVE_2015_3808_VULN_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
flags_item = proto_tree_add_none_format ( tree , hf_lbmr_pser_flags , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , "Flags (0x%04x)" , flags ); 16
flags_tree = proto_item_add_subtree ( flags_item , ett_lbmr_pser_flags ); 17
proto_tree_add_item ( flags_tree , hf_lbmr_pser_flags_option , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , ENC_BIG_ENDIAN ); 18
if ( ( flags & LBMR_PSER_OPT_FLAG ) != 0 )  28
------------------------------
588 /home/speedy/test/source2slice/NVD/CVE_2015_3808_VULN_dissect_lbmr_pser.c hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ) 11
static int CVE_2015_3808_VULN_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
topic_len = hdr_len - L_LBMR_PSER_T; 13
proto_tree_add_item ( tree , hf_lbmr_pser_topic , tvb , offset + O_LBMR_PSER_T_TOPIC , topic_len , ENC_ASCII | ENC_NA ); 25
curr_offset += hdr_len; 26
len = hdr_len; 27
opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ); 36
opts_item = proto_tree_add_item ( tree , hf_lbmr_pser_opts , tvb , curr_offset , - 1 , ENC_NA ); 37
opts_tree = proto_item_add_subtree ( opts_item , ett_lbmr_pser_opts ); 38
optlen_item = proto_tree_add_item ( opts_tree , hf_lbmr_pser_optlen , tvb , curr_offset , L_LBMR_PSER_OPTLEN_T , ENC_NA ); 39
optlen_tree = proto_item_add_subtree ( optlen_item , ett_lbmr_pser_opt_len ); 40
proto_tree_add_item ( optlen_tree , hf_lbmr_pser_optlen_type , tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_TYPE , L_LBMR_PSER_OPTLEN_T_TYPE , ENC_BIG_ENDIAN ); 41
proto_tree_add_item ( optlen_tree , hf_lbmr_pser_optlen_optlen , tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN , L_LBMR_PSER_OPTLEN_T_OPTLEN , ENC_BIG_ENDIAN ); 42
proto_item_set_len ( opts_item , opt_len ); 43
len += L_LBMR_PSER_OPTLEN_T; 44
curr_offset += L_LBMR_PSER_OPTLEN_T; 45
opt_len -= L_LBMR_PSER_OPTLEN_T; 46
while ( opt_len > 0 )  47
guint8 opt_type = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_TYPE ) ; 51
switch ( opt_type )  54
ctxinst_item = proto_tree_add_item ( opts_tree , hf_lbmr_pser_opt_ctxinst , tvb , offset , L_LBMR_PSER_OPT_CTXINST_T , ENC_NA ); 58
ctxinst_tree = proto_item_add_subtree ( ctxinst_item , ett_lbmr_pser_opt_ctxinst ); 59
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_len , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_LEN , L_LBMR_PSER_OPT_CTXINST_T_LEN , ENC_BIG_ENDIAN ); 60
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_type , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_TYPE , L_LBMR_PSER_OPT_CTXINST_T_TYPE , ENC_BIG_ENDIAN ); 61
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_ctxinst , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_CTXINST , L_LBMR_PSER_OPT_CTXINST_T_CTXINST , ENC_NA ); 62
len += L_LBMR_PSER_OPT_CTXINST_T; 63
curr_offset += L_LBMR_PSER_OPT_CTXINST_T; 64
opt_len -= L_LBMR_PSER_OPT_CTXINST_T; 65
len += option_len; 68
curr_offset += option_len; 69
opt_len -= option_len; 70
expert_add_info_format ( pinfo , NULL , & ei_lbmr_analysis_invalid_value , "Unknown LBMR PSER option 0x%02x" , opt_type ); 71
return ( len ) ; 76
------------------------------
589 /home/speedy/test/source2slice/NVD/CVE_2015_3809_PATCHED_dissect_lbmr_pser.c opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ) 36
static int CVE_2015_3809_PATCHED_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
curr_offset += hdr_len; 26
if ( ( flags & LBMR_PSER_OPT_FLAG ) != 0 )  28
opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ); 36
proto_item_set_len ( opts_item , opt_len ); 43
opt_len -= L_LBMR_PSER_OPTLEN_T; 46
while ( opt_len > 0 )  47
opt_len -= L_LBMR_PSER_OPT_CTXINST_T; 65
opt_len -= option_len; 70
------------------------------
590 /home/speedy/test/source2slice/NVD/CVE_2015_3809_PATCHED_dissect_lbmr_pser.c flags_item = proto_tree_add_none_format ( tree , hf_lbmr_pser_flags , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , "Flags (0x%04x)" , flags ) 16
static int CVE_2015_3809_PATCHED_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
flags_item = proto_tree_add_none_format ( tree , hf_lbmr_pser_flags , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , "Flags (0x%04x)" , flags ); 16
flags_tree = proto_item_add_subtree ( flags_item , ett_lbmr_pser_flags ); 17
proto_tree_add_item ( flags_tree , hf_lbmr_pser_flags_option , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , ENC_BIG_ENDIAN ); 18
------------------------------
591 /home/speedy/test/source2slice/NVD/CVE_2015_3809_PATCHED_dissect_lbmr_pser.c topic_len = hdr_len - L_LBMR_PSER_T 13
static int CVE_2015_3809_PATCHED_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
topic_len = hdr_len - L_LBMR_PSER_T; 13
proto_tree_add_item ( tree , hf_lbmr_pser_topic , tvb , offset + O_LBMR_PSER_T_TOPIC , topic_len , ENC_ASCII | ENC_NA ); 25
------------------------------
592 /home/speedy/test/source2slice/NVD/CVE_2015_3809_PATCHED_dissect_lbmr_pser.c flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ) 12
static int CVE_2015_3809_PATCHED_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
flags_item = proto_tree_add_none_format ( tree , hf_lbmr_pser_flags , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , "Flags (0x%04x)" , flags ); 16
flags_tree = proto_item_add_subtree ( flags_item , ett_lbmr_pser_flags ); 17
proto_tree_add_item ( flags_tree , hf_lbmr_pser_flags_option , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , ENC_BIG_ENDIAN ); 18
if ( ( flags & LBMR_PSER_OPT_FLAG ) != 0 )  28
------------------------------
593 /home/speedy/test/source2slice/NVD/CVE_2015_3809_PATCHED_dissect_lbmr_pser.c hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ) 11
static int CVE_2015_3809_PATCHED_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
topic_len = hdr_len - L_LBMR_PSER_T; 13
proto_tree_add_item ( tree , hf_lbmr_pser_topic , tvb , offset + O_LBMR_PSER_T_TOPIC , topic_len , ENC_ASCII | ENC_NA ); 25
curr_offset += hdr_len; 26
len = hdr_len; 27
opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ); 36
opts_item = proto_tree_add_item ( tree , hf_lbmr_pser_opts , tvb , curr_offset , - 1 , ENC_NA ); 37
opts_tree = proto_item_add_subtree ( opts_item , ett_lbmr_pser_opts ); 38
optlen_item = proto_tree_add_item ( opts_tree , hf_lbmr_pser_optlen , tvb , curr_offset , L_LBMR_PSER_OPTLEN_T , ENC_NA ); 39
optlen_tree = proto_item_add_subtree ( optlen_item , ett_lbmr_pser_opt_len ); 40
proto_tree_add_item ( optlen_tree , hf_lbmr_pser_optlen_type , tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_TYPE , L_LBMR_PSER_OPTLEN_T_TYPE , ENC_BIG_ENDIAN ); 41
proto_tree_add_item ( optlen_tree , hf_lbmr_pser_optlen_optlen , tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN , L_LBMR_PSER_OPTLEN_T_OPTLEN , ENC_BIG_ENDIAN ); 42
proto_item_set_len ( opts_item , opt_len ); 43
len += L_LBMR_PSER_OPTLEN_T; 44
curr_offset += L_LBMR_PSER_OPTLEN_T; 45
opt_len -= L_LBMR_PSER_OPTLEN_T; 46
while ( opt_len > 0 )  47
guint8 opt_type = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_TYPE ) ; 51
guint8 option_len = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_LEN ) ; 52
switch ( opt_type )  54
ctxinst_item = proto_tree_add_item ( opts_tree , hf_lbmr_pser_opt_ctxinst , tvb , curr_offset , L_LBMR_PSER_OPT_CTXINST_T , ENC_NA ); 58
ctxinst_tree = proto_item_add_subtree ( ctxinst_item , ett_lbmr_pser_opt_ctxinst ); 59
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_len , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_LEN , L_LBMR_PSER_OPT_CTXINST_T_LEN , ENC_BIG_ENDIAN ); 60
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_type , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_TYPE , L_LBMR_PSER_OPT_CTXINST_T_TYPE , ENC_BIG_ENDIAN ); 61
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_ctxinst , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_CTXINST , L_LBMR_PSER_OPT_CTXINST_T_CTXINST , ENC_NA ); 62
len += L_LBMR_PSER_OPT_CTXINST_T; 63
curr_offset += L_LBMR_PSER_OPT_CTXINST_T; 64
opt_len -= L_LBMR_PSER_OPT_CTXINST_T; 65
len += option_len; 68
curr_offset += option_len; 69
opt_len -= option_len; 70
expert_add_info_format ( pinfo , NULL , & ei_lbmr_analysis_invalid_value , "Unknown LBMR PSER option 0x%02x" , opt_type ); 71
if ( option_len == 0 )  72
return ( len ) ; 73
return ( len ) ; 79
------------------------------
594 /home/speedy/test/source2slice/NVD/CVE_2015_3809_VULN_dissect_lbmr_pser.c opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ) 36
static int CVE_2015_3809_VULN_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
curr_offset += hdr_len; 26
if ( ( flags & LBMR_PSER_OPT_FLAG ) != 0 )  28
opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ); 36
proto_item_set_len ( opts_item , opt_len ); 43
opt_len -= L_LBMR_PSER_OPTLEN_T; 46
while ( opt_len > 0 )  47
opt_len -= L_LBMR_PSER_OPT_CTXINST_T; 65
opt_len -= option_len; 70
------------------------------
595 /home/speedy/test/source2slice/NVD/CVE_2015_3809_VULN_dissect_lbmr_pser.c flags_item = proto_tree_add_none_format ( tree , hf_lbmr_pser_flags , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , "Flags (0x%04x)" , flags ) 16
static int CVE_2015_3809_VULN_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
flags_item = proto_tree_add_none_format ( tree , hf_lbmr_pser_flags , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , "Flags (0x%04x)" , flags ); 16
flags_tree = proto_item_add_subtree ( flags_item , ett_lbmr_pser_flags ); 17
proto_tree_add_item ( flags_tree , hf_lbmr_pser_flags_option , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , ENC_BIG_ENDIAN ); 18
------------------------------
596 /home/speedy/test/source2slice/NVD/CVE_2015_3809_VULN_dissect_lbmr_pser.c topic_len = hdr_len - L_LBMR_PSER_T 13
static int CVE_2015_3809_VULN_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
topic_len = hdr_len - L_LBMR_PSER_T; 13
proto_tree_add_item ( tree , hf_lbmr_pser_topic , tvb , offset + O_LBMR_PSER_T_TOPIC , topic_len , ENC_ASCII | ENC_NA ); 25
------------------------------
597 /home/speedy/test/source2slice/NVD/CVE_2015_3809_VULN_dissect_lbmr_pser.c flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ) 12
static int CVE_2015_3809_VULN_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
flags_item = proto_tree_add_none_format ( tree , hf_lbmr_pser_flags , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , "Flags (0x%04x)" , flags ); 16
flags_tree = proto_item_add_subtree ( flags_item , ett_lbmr_pser_flags ); 17
proto_tree_add_item ( flags_tree , hf_lbmr_pser_flags_option , tvb , offset + O_LBMR_PSER_T_FLAGS , L_LBMR_PSER_T_FLAGS , ENC_BIG_ENDIAN ); 18
if ( ( flags & LBMR_PSER_OPT_FLAG ) != 0 )  28
------------------------------
598 /home/speedy/test/source2slice/NVD/CVE_2015_3809_VULN_dissect_lbmr_pser.c hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ) 11
static int CVE_2015_3809_VULN_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
topic_len = hdr_len - L_LBMR_PSER_T; 13
proto_tree_add_item ( tree , hf_lbmr_pser_topic , tvb , offset + O_LBMR_PSER_T_TOPIC , topic_len , ENC_ASCII | ENC_NA ); 25
curr_offset += hdr_len; 26
len = hdr_len; 27
opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ); 36
opts_item = proto_tree_add_item ( tree , hf_lbmr_pser_opts , tvb , curr_offset , - 1 , ENC_NA ); 37
opts_tree = proto_item_add_subtree ( opts_item , ett_lbmr_pser_opts ); 38
optlen_item = proto_tree_add_item ( opts_tree , hf_lbmr_pser_optlen , tvb , curr_offset , L_LBMR_PSER_OPTLEN_T , ENC_NA ); 39
optlen_tree = proto_item_add_subtree ( optlen_item , ett_lbmr_pser_opt_len ); 40
proto_tree_add_item ( optlen_tree , hf_lbmr_pser_optlen_type , tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_TYPE , L_LBMR_PSER_OPTLEN_T_TYPE , ENC_BIG_ENDIAN ); 41
proto_tree_add_item ( optlen_tree , hf_lbmr_pser_optlen_optlen , tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN , L_LBMR_PSER_OPTLEN_T_OPTLEN , ENC_BIG_ENDIAN ); 42
proto_item_set_len ( opts_item , opt_len ); 43
len += L_LBMR_PSER_OPTLEN_T; 44
curr_offset += L_LBMR_PSER_OPTLEN_T; 45
opt_len -= L_LBMR_PSER_OPTLEN_T; 46
while ( opt_len > 0 )  47
guint8 opt_type = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_TYPE ) ; 51
switch ( opt_type )  54
ctxinst_item = proto_tree_add_item ( opts_tree , hf_lbmr_pser_opt_ctxinst , tvb , offset , L_LBMR_PSER_OPT_CTXINST_T , ENC_NA ); 58
ctxinst_tree = proto_item_add_subtree ( ctxinst_item , ett_lbmr_pser_opt_ctxinst ); 59
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_len , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_LEN , L_LBMR_PSER_OPT_CTXINST_T_LEN , ENC_BIG_ENDIAN ); 60
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_type , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_TYPE , L_LBMR_PSER_OPT_CTXINST_T_TYPE , ENC_BIG_ENDIAN ); 61
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_ctxinst , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_CTXINST , L_LBMR_PSER_OPT_CTXINST_T_CTXINST , ENC_NA ); 62
len += L_LBMR_PSER_OPT_CTXINST_T; 63
curr_offset += L_LBMR_PSER_OPT_CTXINST_T; 64
opt_len -= L_LBMR_PSER_OPT_CTXINST_T; 65
len += option_len; 68
curr_offset += option_len; 69
opt_len -= option_len; 70
expert_add_info_format ( pinfo , NULL , & ei_lbmr_analysis_invalid_value , "Unknown LBMR PSER option 0x%02x" , opt_type ); 71
return ( len ) ; 76
------------------------------
599 /home/speedy/test/source2slice/NVD/CVE_2015_3811_PATCHED_decompressed_entry.c buf_end = buf_ptr -> buffer + MAX_WIN_BUF_LEN 9
static guint8 *
CVE_2015_3811_PATCHED_decompressed_entry(guint8 *dst, guint16 data_offset,
guint16 data_cnt, int *len, wcp_window_t *buf_ptr) 3
guint8 * buf_start , * buf_end ; 6
buf_end = buf_ptr -> buffer + MAX_WIN_BUF_LEN; 9
* dst = * src; 21
if ( dst ++ == buf_end )  27
if ( src ++ == buf_end )  29
return dst ; 33
------------------------------
600 /home/speedy/test/source2slice/NVD/CVE_2015_3811_PATCHED_wcp_uncompress.c src = ( guint8 * ) tvb_memcpy ( src_tvb , src_buf , offset , cnt - offset ) 40
static tvbuff_t *CVE_2015_3811_PATCHED_wcp_uncompress( tvbuff_t *src_tvb, int offset, packet_info *pinfo, proto_tree *tree) 1
int cnt = tvb_reported_length ( src_tvb ) - 1 ; 9
guint8 src_buf [ MAX_WCP_BUF_LEN ] ; 13
if ( cnt - offset > MAX_WCP_BUF_LEN )  26
src = ( guint8 * ) tvb_memcpy ( src_tvb , src_buf , offset , cnt - offset ); 40
if ( comp_flag_bits & 0x80 )  53
data_offset = pntoh16 ( src ) & WCP_OFFSET_MASK; 62
if ( ( * src & 0xf0 ) == 0x10 )  63
data_cnt = * ( src + 2 ) + 1; 76
proto_tree_add_uint ( sub_tree , hf_wcp_offset , src_tvb , offset , 2 , data_offset ); 81
src += 3; 87
data_cnt = ( * src >> 4 ) + 1; 96
proto_tree_add_uint ( sub_tree , hf_wcp_short_len , src_tvb , offset , 1 , * src ); 101
proto_tree_add_uint ( sub_tree , hf_wcp_offset , src_tvb , offset , 2 , data_offset ); 103
src += 2; 106
if ( data_offset + 1 > buf_ptr -> initialized )  109
expert_add_info_format ( pinfo , cd_item , & ei_wcp_invalid_window_offset , "Data offset exceeds valid window size (%d > %d)" , data_offset + 1 , buf_ptr -> initialized ); 110
if ( data_offset + 1 < data_cnt )  116
expert_add_info_format ( pinfo , cd_item , & ei_wcp_invalid_window_offset , "Data count exceeds offset (%d > %d)" , data_cnt , data_offset + 1 ); 117
dst = decompressed_entry ( dst , data_offset , data_cnt , & len , buf_ptr ); 123
if ( dst == NULL )  126
* dst = * src; 153
if ( dst ++ == buf_end )  154
comp_flag_bits <<= 1; 164
comp_flag_bits = * src ++; 172
proto_tree_add_uint ( cd_tree , hf_wcp_comp_bits , src_tvb , offset , 1 , comp_flag_bits ); 174
buf_ptr -> buf_cur = dst; 200
------------------------------
601 /home/speedy/test/source2slice/NVD/CVE_2015_3811_PATCHED_wcp_uncompress.c cd_item = proto_tree_add_item ( tree , hf_wcp_compressed_data , src_tvb , offset , cnt - offset , ENC_NA ) 23
static tvbuff_t *CVE_2015_3811_PATCHED_wcp_uncompress( tvbuff_t *src_tvb, int offset, packet_info *pinfo, proto_tree *tree) 1
proto_item * cd_item , * ti ; 6
int cnt = tvb_reported_length ( src_tvb ) - 1 ; 9
cd_item = proto_tree_add_item ( tree , hf_wcp_compressed_data , src_tvb , offset , cnt - offset , ENC_NA ); 23
cd_tree = proto_item_add_subtree ( cd_item , ett_wcp_comp_data ); 25
expert_add_info_format ( pinfo , cd_item , & ei_wcp_compressed_data_exceeds , "Compressed data exceeds maximum buffer length (%d > %d)" , cnt - offset , MAX_WCP_BUF_LEN ); 27
ti = proto_tree_add_item ( cd_tree , hf_wcp_long_run , src_tvb , offset , 3 , ENC_NA ); 78
sub_tree = proto_item_add_subtree ( ti , ett_wcp_field ); 80
proto_tree_add_uint ( sub_tree , hf_wcp_offset , src_tvb , offset , 2 , data_offset ); 81
proto_tree_add_item ( sub_tree , hf_wcp_long_len , src_tvb , offset + 2 , 1 , ENC_BIG_ENDIAN ); 84
ti = proto_tree_add_item ( cd_tree , hf_wcp_short_run , src_tvb , offset , 2 , ENC_NA ); 98
sub_tree = proto_item_add_subtree ( ti , ett_wcp_field ); 100
proto_tree_add_uint ( sub_tree , hf_wcp_short_len , src_tvb , offset , 1 , * src ); 101
proto_tree_add_uint ( sub_tree , hf_wcp_offset , src_tvb , offset , 2 , data_offset ); 103
expert_add_info_format ( pinfo , cd_item , & ei_wcp_invalid_window_offset , "Data offset exceeds valid window size (%d > %d)" , data_offset + 1 , buf_ptr -> initialized ); 110
expert_add_info_format ( pinfo , cd_item , & ei_wcp_invalid_window_offset , "Data count exceeds offset (%d > %d)" , data_cnt , data_offset + 1 ); 117
expert_add_info_format ( pinfo , cd_item , & ei_wcp_uncompressed_data_exceeds , "Uncompressed data exceeds maximum buffer length (%d > %d)" , len , MAX_WCP_BUF_LEN ); 127
expert_add_info_format ( pinfo , cd_item , & ei_wcp_uncompressed_data_exceeds , "Uncompressed data exceeds maximum buffer length (%d > %d)" , len , MAX_WCP_BUF_LEN ); 141
if ( cd_tree )  173
proto_tree_add_uint ( cd_tree , hf_wcp_comp_bits , src_tvb , offset , 1 , comp_flag_bits ); 174
------------------------------
602 /home/speedy/test/source2slice/NVD/CVE_2015_3811_PATCHED_wcp_uncompress.c buf_end = buf_start + MAX_WIN_BUF_LEN 21
static tvbuff_t *CVE_2015_3811_PATCHED_wcp_uncompress( tvbuff_t *src_tvb, int offset, packet_info *pinfo, proto_tree *tree) 1
buf_ptr = get_wcp_window_ptr ( pinfo ); 18
buf_start = buf_ptr -> buffer; 20
buf_end = buf_start + MAX_WIN_BUF_LEN; 21
dst = decompressed_entry ( dst , data_offset , data_cnt , & len , buf_ptr ); 123
if ( dst == NULL )  126
* dst = * src; 153
if ( dst ++ == buf_end )  154
buf_ptr -> buf_cur = dst; 200
------------------------------
603 /home/speedy/test/source2slice/NVD/CVE_2015_3811_VULN_wcp_uncompress.c src = ( guint8 * ) tvb_memcpy ( src_tvb , src_buf , offset , cnt - offset ) 40
static tvbuff_t *CVE_2015_3811_VULN_wcp_uncompress( tvbuff_t *src_tvb, int offset, packet_info *pinfo, proto_tree *tree) 1
int cnt = tvb_reported_length ( src_tvb ) - 1 ; 9
guint8 src_buf [ MAX_WCP_BUF_LEN ] ; 13
if ( cnt - offset > MAX_WCP_BUF_LEN )  26
src = ( guint8 * ) tvb_memcpy ( src_tvb , src_buf , offset , cnt - offset ); 40
if ( comp_flag_bits & 0x80 )  53
data_offset = pntoh16 ( src ) & WCP_OFFSET_MASK; 62
if ( ( * src & 0xf0 ) == 0x10 )  63
data_cnt = * ( src + 2 ) + 1; 76
proto_tree_add_uint ( sub_tree , hf_wcp_offset , src_tvb , offset , 2 , data_offset ); 81
src += 3; 87
data_cnt = ( * src >> 4 ) + 1; 96
proto_tree_add_uint ( sub_tree , hf_wcp_short_len , src_tvb , offset , 1 , * src ); 101
proto_tree_add_uint ( sub_tree , hf_wcp_offset , src_tvb , offset , 2 , data_offset ); 103
src += 2; 106
dst = decompressed_entry ( dst , data_offset , data_cnt , & len , buf_start , buf_end ); 110
if ( dst == NULL )  113
* dst = * src; 140
if ( dst ++ == buf_end )  141
comp_flag_bits <<= 1; 149
comp_flag_bits = * src ++; 157
proto_tree_add_uint ( cd_tree , hf_wcp_comp_bits , src_tvb , offset , 1 , comp_flag_bits ); 159
buf_ptr -> buf_cur = dst; 185
------------------------------
604 /home/speedy/test/source2slice/NVD/CVE_2015_3811_VULN_wcp_uncompress.c cd_item = proto_tree_add_item ( tree , hf_wcp_compressed_data , src_tvb , offset , cnt - offset , ENC_NA ) 23
static tvbuff_t *CVE_2015_3811_VULN_wcp_uncompress( tvbuff_t *src_tvb, int offset, packet_info *pinfo, proto_tree *tree) 1
proto_item * cd_item , * ti ; 6
int cnt = tvb_reported_length ( src_tvb ) - 1 ; 9
cd_item = proto_tree_add_item ( tree , hf_wcp_compressed_data , src_tvb , offset , cnt - offset , ENC_NA ); 23
cd_tree = proto_item_add_subtree ( cd_item , ett_wcp_comp_data ); 25
expert_add_info_format ( pinfo , cd_item , & ei_wcp_compressed_data_exceeds , "Compressed data exceeds maximum buffer length (%d > %d)" , cnt - offset , MAX_WCP_BUF_LEN ); 27
ti = proto_tree_add_item ( cd_tree , hf_wcp_long_run , src_tvb , offset , 3 , ENC_NA ); 78
sub_tree = proto_item_add_subtree ( ti , ett_wcp_field ); 80
proto_tree_add_uint ( sub_tree , hf_wcp_offset , src_tvb , offset , 2 , data_offset ); 81
proto_tree_add_item ( sub_tree , hf_wcp_long_len , src_tvb , offset + 2 , 1 , ENC_BIG_ENDIAN ); 84
ti = proto_tree_add_item ( cd_tree , hf_wcp_short_run , src_tvb , offset , 2 , ENC_NA ); 98
sub_tree = proto_item_add_subtree ( ti , ett_wcp_field ); 100
proto_tree_add_uint ( sub_tree , hf_wcp_short_len , src_tvb , offset , 1 , * src ); 101
proto_tree_add_uint ( sub_tree , hf_wcp_offset , src_tvb , offset , 2 , data_offset ); 103
expert_add_info_format ( pinfo , cd_item , & ei_wcp_uncompressed_data_exceeds , "Uncompressed data exceeds maximum buffer length (%d > %d)" , len , MAX_WCP_BUF_LEN ); 114
expert_add_info_format ( pinfo , cd_item , & ei_wcp_uncompressed_data_exceeds , "Uncompressed data exceeds maximum buffer length (%d > %d)" , len , MAX_WCP_BUF_LEN ); 128
if ( cd_tree )  158
proto_tree_add_uint ( cd_tree , hf_wcp_comp_bits , src_tvb , offset , 1 , comp_flag_bits ); 159
------------------------------
605 /home/speedy/test/source2slice/NVD/CVE_2015_3811_VULN_wcp_uncompress.c buf_end = buf_start + MAX_WIN_BUF_LEN 21
static tvbuff_t *CVE_2015_3811_VULN_wcp_uncompress( tvbuff_t *src_tvb, int offset, packet_info *pinfo, proto_tree *tree) 1
buf_ptr = get_wcp_window_ptr ( pinfo ); 18
buf_start = buf_ptr -> buffer; 20
buf_end = buf_start + MAX_WIN_BUF_LEN; 21
dst = decompressed_entry ( dst , data_offset , data_cnt , & len , buf_start , buf_end ); 110
if ( dst == NULL )  113
* dst = * src; 140
if ( dst ++ == buf_end )  141
buf_ptr -> buf_cur = dst; 185
------------------------------
606 /home/speedy/test/source2slice/NVD/CVE_2015_3813_PATCHED_fragment_add_work.c fd_head -> error = "offset + len < offset" 315
static gboolean
CVE_2015_3813_PATCHED_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fragment_item * fd_i ; 7
guint32 max , dfpos , fraglen ; 8
guint8 * data ; 10
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
for(fd_i=fd_head->next; fd_i; fd_i=fd_i->next) 43
if ( ! fd_i -> tvb_data )  44
fd_i -> tvb_data = tvb_new_subset_remaining ( fd_head -> tvb_data , fd_i -> offset ); 45
fd_i -> flags |= FD_SUBSET_TVB; 46
fd_i -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 48
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  166
max = 0; 184
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 185
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  186
max = fd_i -> offset + fd_i -> len; 188
if ( max < ( fd_head -> datalen ) )  192
data = ( guint8 * ) g_malloc ( fd_head -> datalen ); 206
fd_head -> tvb_data = tvb_new_real_data ( data , fd_head -> datalen , fd_head -> datalen ); 207
for (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) 211
if ( fd_i -> len )  212
if ( fd_i -> offset + fd_i -> len > dfpos )  230
if ( fd_i -> offset >= fd_head -> datalen )  231
fd_i -> flags |= FD_TOOLONGFRAGMENT; 248
fd_head -> flags |= FD_TOOLONGFRAGMENT; 249
if ( dfpos < fd_i -> offset )  250
fd_head -> error = "dfpos < offset"; 261
if ( dfpos - fd_i -> offset > fd_i -> len )  262
fd_head -> error = "dfpos - offset > len"; 263
if ( ! fd_head -> tvb_data )  264
fd_head -> error = "no data"; 265
fraglen = fd_i -> len; 267
if ( fd_i -> offset + fraglen > fd_head -> datalen )  268
fd_i -> flags |= FD_TOOLONGFRAGMENT; 283
fd_head -> flags |= FD_TOOLONGFRAGMENT; 284
fraglen = fd_head -> datalen - fd_i -> offset; 285
if ( fd_i -> offset < dfpos )  287
guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 288
fd_i -> flags |= FD_OVERLAP; 290
fd_head -> flags |= FD_OVERLAP; 291
if ( memcmp ( data + fd_i -> offset , tvb_get_ptr ( fd_i -> tvb_data , 0 , cmp_len ) , cmp_len ) )  292
fd_i -> flags |= FD_OVERLAPCONFLICT; 296
fd_head -> flags |= FD_OVERLAPCONFLICT; 297
if ( fraglen < dfpos - fd_i -> offset )  300
fd_head -> error = "fraglen < dfpos - offset"; 304
memcpy ( data + dfpos , tvb_get_ptr ( fd_i -> tvb_data , ( dfpos - fd_i -> offset ) , fraglen - ( dfpos - fd_i -> offset ) ) , fraglen - ( dfpos - fd_i -> offset ) ); 306
dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ); 309
if ( fd_i -> offset + fd_i -> len < fd_i -> offset )  313
fd_head -> error = "offset + len < offset"; 315
if ( fd_i -> flags & FD_SUBSET_TVB )  319
fd_i -> flags &= ~FD_SUBSET_TVB; 320
fd_i -> tvb_data = NULL; 324
fd_head -> flags |= FD_DEFRAGMENTED; 332
fd_head -> reassembled_in = pinfo -> fd -> num; 333
if ( fd_head -> error )  336
THROW_MESSAGE ( ReassemblyError , fd_head -> error ); 337
------------------------------
607 /home/speedy/test/source2slice/NVD/CVE_2015_3813_PATCHED_fragment_add_work.c dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ) 309
static gboolean
CVE_2015_3813_PATCHED_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fragment_item * fd_i ; 7
guint32 max , dfpos , fraglen ; 8
guint8 * data ; 10
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
for(fd_i=fd_head->next; fd_i; fd_i=fd_i->next) 43
if ( ! fd_i -> tvb_data )  44
fd_i -> tvb_data = tvb_new_subset_remaining ( fd_head -> tvb_data , fd_i -> offset ); 45
fd_i -> flags |= FD_SUBSET_TVB; 46
fd_i -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 48
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  166
max = 0; 184
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 185
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  186
max = fd_i -> offset + fd_i -> len; 188
if ( max < ( fd_head -> datalen ) )  192
data = ( guint8 * ) g_malloc ( fd_head -> datalen ); 206
fd_head -> tvb_data = tvb_new_real_data ( data , fd_head -> datalen , fd_head -> datalen ); 207
for (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) 211
if ( fd_i -> len )  212
if ( fd_i -> offset + fd_i -> len > dfpos )  230
if ( fd_i -> offset >= fd_head -> datalen )  231
fd_i -> flags |= FD_TOOLONGFRAGMENT; 248
fd_head -> flags |= FD_TOOLONGFRAGMENT; 249
if ( dfpos < fd_i -> offset )  250
fd_head -> error = "dfpos < offset"; 261
if ( dfpos - fd_i -> offset > fd_i -> len )  262
fd_head -> error = "dfpos - offset > len"; 263
if ( ! fd_head -> tvb_data )  264
fd_head -> error = "no data"; 265
fraglen = fd_i -> len; 267
if ( fd_i -> offset + fraglen > fd_head -> datalen )  268
fd_i -> flags |= FD_TOOLONGFRAGMENT; 283
fd_head -> flags |= FD_TOOLONGFRAGMENT; 284
fraglen = fd_head -> datalen - fd_i -> offset; 285
if ( fd_i -> offset < dfpos )  287
guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 288
fd_i -> flags |= FD_OVERLAP; 290
fd_head -> flags |= FD_OVERLAP; 291
if ( memcmp ( data + fd_i -> offset , tvb_get_ptr ( fd_i -> tvb_data , 0 , cmp_len ) , cmp_len ) )  292
fd_i -> flags |= FD_OVERLAPCONFLICT; 296
fd_head -> flags |= FD_OVERLAPCONFLICT; 297
if ( fraglen < dfpos - fd_i -> offset )  300
fd_head -> error = "fraglen < dfpos - offset"; 304
memcpy ( data + dfpos , tvb_get_ptr ( fd_i -> tvb_data , ( dfpos - fd_i -> offset ) , fraglen - ( dfpos - fd_i -> offset ) ) , fraglen - ( dfpos - fd_i -> offset ) ); 306
dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ); 309
if ( fd_i -> offset + fd_i -> len < fd_i -> offset )  313
fd_head -> error = "offset + len < offset"; 315
if ( fd_i -> flags & FD_SUBSET_TVB )  319
fd_i -> flags &= ~FD_SUBSET_TVB; 320
fd_i -> tvb_data = NULL; 324
------------------------------
608 /home/speedy/test/source2slice/NVD/CVE_2015_3813_PATCHED_fragment_add_work.c fd_head -> error = "fraglen < dfpos - offset" 304
static gboolean
CVE_2015_3813_PATCHED_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fragment_item * fd_i ; 7
guint32 max , dfpos , fraglen ; 8
guint8 * data ; 10
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
for(fd_i=fd_head->next; fd_i; fd_i=fd_i->next) 43
if ( ! fd_i -> tvb_data )  44
fd_i -> tvb_data = tvb_new_subset_remaining ( fd_head -> tvb_data , fd_i -> offset ); 45
fd_i -> flags |= FD_SUBSET_TVB; 46
fd_i -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 48
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  166
max = 0; 184
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 185
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  186
max = fd_i -> offset + fd_i -> len; 188
if ( max < ( fd_head -> datalen ) )  192
data = ( guint8 * ) g_malloc ( fd_head -> datalen ); 206
fd_head -> tvb_data = tvb_new_real_data ( data , fd_head -> datalen , fd_head -> datalen ); 207
for (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) 211
if ( fd_i -> len )  212
if ( fd_i -> offset + fd_i -> len > dfpos )  230
if ( fd_i -> offset >= fd_head -> datalen )  231
fd_i -> flags |= FD_TOOLONGFRAGMENT; 248
fd_head -> flags |= FD_TOOLONGFRAGMENT; 249
if ( dfpos < fd_i -> offset )  250
fd_head -> error = "dfpos < offset"; 261
if ( dfpos - fd_i -> offset > fd_i -> len )  262
fd_head -> error = "dfpos - offset > len"; 263
if ( ! fd_head -> tvb_data )  264
fd_head -> error = "no data"; 265
fraglen = fd_i -> len; 267
if ( fd_i -> offset + fraglen > fd_head -> datalen )  268
fd_i -> flags |= FD_TOOLONGFRAGMENT; 283
fd_head -> flags |= FD_TOOLONGFRAGMENT; 284
fraglen = fd_head -> datalen - fd_i -> offset; 285
if ( fd_i -> offset < dfpos )  287
guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 288
fd_i -> flags |= FD_OVERLAP; 290
fd_head -> flags |= FD_OVERLAP; 291
if ( memcmp ( data + fd_i -> offset , tvb_get_ptr ( fd_i -> tvb_data , 0 , cmp_len ) , cmp_len ) )  292
fd_i -> flags |= FD_OVERLAPCONFLICT; 296
fd_head -> flags |= FD_OVERLAPCONFLICT; 297
if ( fraglen < dfpos - fd_i -> offset )  300
fd_head -> error = "fraglen < dfpos - offset"; 304
memcpy ( data + dfpos , tvb_get_ptr ( fd_i -> tvb_data , ( dfpos - fd_i -> offset ) , fraglen - ( dfpos - fd_i -> offset ) ) , fraglen - ( dfpos - fd_i -> offset ) ); 306
dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ); 309
if ( fd_i -> offset + fd_i -> len < fd_i -> offset )  313
fd_head -> error = "offset + len < offset"; 315
if ( fd_i -> flags & FD_SUBSET_TVB )  319
fd_i -> flags &= ~FD_SUBSET_TVB; 320
fd_i -> tvb_data = NULL; 324
fd_head -> flags |= FD_DEFRAGMENTED; 332
fd_head -> reassembled_in = pinfo -> fd -> num; 333
if ( fd_head -> error )  336
THROW_MESSAGE ( ReassemblyError , fd_head -> error ); 337
------------------------------
609 /home/speedy/test/source2slice/NVD/CVE_2015_3813_PATCHED_fragment_add_work.c fraglen = fd_head -> datalen - fd_i -> offset 285
static gboolean
CVE_2015_3813_PATCHED_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fragment_item * fd_i ; 7
guint32 max , dfpos , fraglen ; 8
guint8 * data ; 10
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
for(fd_i=fd_head->next; fd_i; fd_i=fd_i->next) 43
if ( ! fd_i -> tvb_data )  44
fd_i -> tvb_data = tvb_new_subset_remaining ( fd_head -> tvb_data , fd_i -> offset ); 45
fd_i -> flags |= FD_SUBSET_TVB; 46
fd_i -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 48
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  166
max = 0; 184
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 185
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  186
max = fd_i -> offset + fd_i -> len; 188
if ( max < ( fd_head -> datalen ) )  192
data = ( guint8 * ) g_malloc ( fd_head -> datalen ); 206
fd_head -> tvb_data = tvb_new_real_data ( data , fd_head -> datalen , fd_head -> datalen ); 207
for (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) 211
if ( fd_i -> len )  212
if ( fd_i -> offset + fd_i -> len > dfpos )  230
if ( fd_i -> offset >= fd_head -> datalen )  231
fd_i -> flags |= FD_TOOLONGFRAGMENT; 248
fd_head -> flags |= FD_TOOLONGFRAGMENT; 249
if ( dfpos < fd_i -> offset )  250
fd_head -> error = "dfpos < offset"; 261
if ( dfpos - fd_i -> offset > fd_i -> len )  262
fd_head -> error = "dfpos - offset > len"; 263
if ( ! fd_head -> tvb_data )  264
fd_head -> error = "no data"; 265
fraglen = fd_i -> len; 267
if ( fd_i -> offset + fraglen > fd_head -> datalen )  268
fd_i -> flags |= FD_TOOLONGFRAGMENT; 283
fd_head -> flags |= FD_TOOLONGFRAGMENT; 284
fraglen = fd_head -> datalen - fd_i -> offset; 285
if ( fd_i -> offset < dfpos )  287
guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 288
fd_i -> flags |= FD_OVERLAP; 290
fd_head -> flags |= FD_OVERLAP; 291
if ( memcmp ( data + fd_i -> offset , tvb_get_ptr ( fd_i -> tvb_data , 0 , cmp_len ) , cmp_len ) )  292
fd_i -> flags |= FD_OVERLAPCONFLICT; 296
fd_head -> flags |= FD_OVERLAPCONFLICT; 297
if ( fraglen < dfpos - fd_i -> offset )  300
fd_head -> error = "fraglen < dfpos - offset"; 304
memcpy ( data + dfpos , tvb_get_ptr ( fd_i -> tvb_data , ( dfpos - fd_i -> offset ) , fraglen - ( dfpos - fd_i -> offset ) ) , fraglen - ( dfpos - fd_i -> offset ) ); 306
dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ); 309
if ( fd_i -> offset + fd_i -> len < fd_i -> offset )  313
fd_head -> error = "offset + len < offset"; 315
if ( fd_i -> flags & FD_SUBSET_TVB )  319
fd_i -> flags &= ~FD_SUBSET_TVB; 320
fd_i -> tvb_data = NULL; 324
------------------------------
610 /home/speedy/test/source2slice/NVD/CVE_2015_3813_PATCHED_fragment_add_work.c fd_head -> error = "dfpos - offset > len" 263
static gboolean
CVE_2015_3813_PATCHED_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fragment_item * fd_i ; 7
guint32 max , dfpos , fraglen ; 8
guint8 * data ; 10
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
for(fd_i=fd_head->next; fd_i; fd_i=fd_i->next) 43
if ( ! fd_i -> tvb_data )  44
fd_i -> tvb_data = tvb_new_subset_remaining ( fd_head -> tvb_data , fd_i -> offset ); 45
fd_i -> flags |= FD_SUBSET_TVB; 46
fd_i -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 48
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  166
max = 0; 184
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 185
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  186
max = fd_i -> offset + fd_i -> len; 188
if ( max < ( fd_head -> datalen ) )  192
data = ( guint8 * ) g_malloc ( fd_head -> datalen ); 206
fd_head -> tvb_data = tvb_new_real_data ( data , fd_head -> datalen , fd_head -> datalen ); 207
for (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) 211
if ( fd_i -> len )  212
if ( fd_i -> offset + fd_i -> len > dfpos )  230
if ( fd_i -> offset >= fd_head -> datalen )  231
fd_i -> flags |= FD_TOOLONGFRAGMENT; 248
fd_head -> flags |= FD_TOOLONGFRAGMENT; 249
if ( dfpos < fd_i -> offset )  250
fd_head -> error = "dfpos < offset"; 261
if ( dfpos - fd_i -> offset > fd_i -> len )  262
fd_head -> error = "dfpos - offset > len"; 263
if ( ! fd_head -> tvb_data )  264
fd_head -> error = "no data"; 265
fraglen = fd_i -> len; 267
if ( fd_i -> offset + fraglen > fd_head -> datalen )  268
fd_i -> flags |= FD_TOOLONGFRAGMENT; 283
fd_head -> flags |= FD_TOOLONGFRAGMENT; 284
fraglen = fd_head -> datalen - fd_i -> offset; 285
if ( fd_i -> offset < dfpos )  287
guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 288
fd_i -> flags |= FD_OVERLAP; 290
fd_head -> flags |= FD_OVERLAP; 291
if ( memcmp ( data + fd_i -> offset , tvb_get_ptr ( fd_i -> tvb_data , 0 , cmp_len ) , cmp_len ) )  292
fd_i -> flags |= FD_OVERLAPCONFLICT; 296
fd_head -> flags |= FD_OVERLAPCONFLICT; 297
if ( fraglen < dfpos - fd_i -> offset )  300
fd_head -> error = "fraglen < dfpos - offset"; 304
memcpy ( data + dfpos , tvb_get_ptr ( fd_i -> tvb_data , ( dfpos - fd_i -> offset ) , fraglen - ( dfpos - fd_i -> offset ) ) , fraglen - ( dfpos - fd_i -> offset ) ); 306
dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ); 309
if ( fd_i -> offset + fd_i -> len < fd_i -> offset )  313
fd_head -> error = "offset + len < offset"; 315
if ( fd_i -> flags & FD_SUBSET_TVB )  319
fd_i -> flags &= ~FD_SUBSET_TVB; 320
fd_i -> tvb_data = NULL; 324
fd_head -> flags |= FD_DEFRAGMENTED; 332
fd_head -> reassembled_in = pinfo -> fd -> num; 333
if ( fd_head -> error )  336
THROW_MESSAGE ( ReassemblyError , fd_head -> error ); 337
------------------------------
611 /home/speedy/test/source2slice/NVD/CVE_2015_3813_PATCHED_fragment_add_work.c max = fd_i -> offset + fd_i -> len 188
static gboolean
CVE_2015_3813_PATCHED_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fragment_item * fd_i ; 7
guint32 max , dfpos , fraglen ; 8
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
for(fd_i=fd_head->next; fd_i; fd_i=fd_i->next) 43
if ( ! fd_i -> tvb_data )  44
fd_i -> tvb_data = tvb_new_subset_remaining ( fd_head -> tvb_data , fd_i -> offset ); 45
fd_i -> flags |= FD_SUBSET_TVB; 46
fd_i -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 48
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  166
max = 0; 184
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 185
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  186
max = fd_i -> offset + fd_i -> len; 188
if ( max < ( fd_head -> datalen ) )  192
------------------------------
612 /home/speedy/test/source2slice/NVD/CVE_2015_3813_PATCHED_fragment_add_work.c fd_head -> datalen = fd -> offset + fd -> len 121
static gboolean
CVE_2015_3813_PATCHED_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
fd_head -> flags |= FD_OVERLAP; 136
if ( end_offset > fd_head -> datalen || end_offset < fd -> offset || end_offset < fd -> len )  138
fd_head -> flags |= FD_TOOLONGFRAGMENT; 140
if ( tvb_memeql ( fd_head -> tvb_data , fd -> offset , tvb_get_ptr ( tvb , offset , fd -> len ) , fd -> len ) )  143
fd_head -> flags |= FD_OVERLAPCONFLICT; 146
LINK_FRAG ( fd_head , fd ); 149
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  166
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 185
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  186
max = fd_i -> offset + fd_i -> len; 188
if ( max < ( fd_head -> datalen ) )  192
old_tvb_data = fd_head -> tvb_data; 205
data = ( guint8 * ) g_malloc ( fd_head -> datalen ); 206
fd_head -> tvb_data = tvb_new_real_data ( data , fd_head -> datalen , fd_head -> datalen ); 207
tvb_set_free_cb ( fd_head -> tvb_data , g_free ); 208
for (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) 211
if ( fd_i -> len )  212
if ( fd_i -> offset + fd_i -> len > dfpos )  230
if ( fd_i -> offset >= fd_head -> datalen )  231
fd_i -> flags |= FD_TOOLONGFRAGMENT; 248
fd_head -> flags |= FD_TOOLONGFRAGMENT; 249
if ( dfpos < fd_i -> offset )  250
if ( dfpos - fd_i -> offset > fd_i -> len )  262
if ( ! fd_head -> tvb_data )  264
fraglen = fd_i -> len; 267
if ( fd_i -> offset + fraglen > fd_head -> datalen )  268
fd_i -> flags |= FD_TOOLONGFRAGMENT; 283
fd_head -> flags |= FD_TOOLONGFRAGMENT; 284
fraglen = fd_head -> datalen - fd_i -> offset; 285
if ( fd_i -> offset < dfpos )  287
guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 288
fd_i -> flags |= FD_OVERLAP; 290
fd_head -> flags |= FD_OVERLAP; 291
if ( memcmp ( data + fd_i -> offset , tvb_get_ptr ( fd_i -> tvb_data , 0 , cmp_len ) , cmp_len ) )  292
fd_i -> flags |= FD_OVERLAPCONFLICT; 296
fd_head -> flags |= FD_OVERLAPCONFLICT; 297
if ( fraglen < dfpos - fd_i -> offset )  300
fd_head -> error = "fraglen < dfpos - offset"; 304
memcpy ( data + dfpos , tvb_get_ptr ( fd_i -> tvb_data , ( dfpos - fd_i -> offset ) , fraglen - ( dfpos - fd_i -> offset ) ) , fraglen - ( dfpos - fd_i -> offset ) ); 306
dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ); 309
if ( fd_i -> offset + fd_i -> len < fd_i -> offset )  313
if ( fd_i -> flags & FD_SUBSET_TVB )  319
fd_i -> flags &= ~FD_SUBSET_TVB; 320
if ( fd_i -> tvb_data )  321
tvb_free ( fd_i -> tvb_data ); 322
fd_i -> tvb_data = NULL; 324
if ( old_tvb_data )  328
tvb_add_to_chain ( tvb , old_tvb_data ); 329
fd_head -> flags |= FD_DEFRAGMENTED; 332
fd_head -> reassembled_in = pinfo -> fd -> num; 333
if ( fd_head -> error )  336
THROW_MESSAGE ( ReassemblyError , fd_head -> error ); 337
------------------------------
613 /home/speedy/test/source2slice/NVD/CVE_2015_3813_VULN_fragment_add_work.c fd_head -> error = "offset + len < offset" 313
static gboolean
CVE_2015_3813_VULN_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fragment_item * fd_i ; 7
guint32 max , dfpos , fraglen ; 8
guint8 * data ; 10
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
for(fd_i=fd_head->next; fd_i; fd_i=fd_i->next) 43
if ( ! fd_i -> tvb_data )  44
fd_i -> tvb_data = tvb_new_subset_remaining ( fd_head -> tvb_data , fd_i -> offset ); 45
fd_i -> flags |= FD_SUBSET_TVB; 46
fd_i -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 48
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  164
max = 0; 182
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 183
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  184
max = fd_i -> offset + fd_i -> len; 186
if ( max < ( fd_head -> datalen ) )  190
data = ( guint8 * ) g_malloc ( fd_head -> datalen ); 204
fd_head -> tvb_data = tvb_new_real_data ( data , fd_head -> datalen , fd_head -> datalen ); 205
for (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) 209
if ( fd_i -> len )  210
if ( fd_i -> offset + fd_i -> len > dfpos )  228
if ( fd_i -> offset >= fd_head -> datalen )  229
fd_i -> flags |= FD_TOOLONGFRAGMENT; 246
fd_head -> flags |= FD_TOOLONGFRAGMENT; 247
if ( dfpos < fd_i -> offset )  248
fd_head -> error = "dfpos < offset"; 259
if ( dfpos - fd_i -> offset > fd_i -> len )  260
fd_head -> error = "dfpos - offset > len"; 261
if ( ! fd_head -> tvb_data )  262
fd_head -> error = "no data"; 263
fraglen = fd_i -> len; 265
if ( fd_i -> offset + fraglen > fd_head -> datalen )  266
fd_i -> flags |= FD_TOOLONGFRAGMENT; 281
fd_head -> flags |= FD_TOOLONGFRAGMENT; 282
fraglen = fd_head -> datalen - fd_i -> offset; 283
if ( fd_i -> offset < dfpos )  285
guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 286
fd_i -> flags |= FD_OVERLAP; 288
fd_head -> flags |= FD_OVERLAP; 289
if ( memcmp ( data + fd_i -> offset , tvb_get_ptr ( fd_i -> tvb_data , 0 , cmp_len ) , cmp_len ) )  290
fd_i -> flags |= FD_OVERLAPCONFLICT; 294
fd_head -> flags |= FD_OVERLAPCONFLICT; 295
if ( fraglen < dfpos - fd_i -> offset )  298
fd_head -> error = "fraglen < dfpos - offset"; 302
memcpy ( data + dfpos , tvb_get_ptr ( fd_i -> tvb_data , ( dfpos - fd_i -> offset ) , fraglen - ( dfpos - fd_i -> offset ) ) , fraglen - ( dfpos - fd_i -> offset ) ); 304
dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ); 307
if ( fd_i -> offset + fd_i -> len < fd_i -> offset )  311
fd_head -> error = "offset + len < offset"; 313
if ( fd_i -> flags & FD_SUBSET_TVB )  317
fd_i -> flags &= ~FD_SUBSET_TVB; 318
fd_i -> tvb_data = NULL; 322
fd_head -> flags |= FD_DEFRAGMENTED; 330
fd_head -> reassembled_in = pinfo -> fd -> num; 331
if ( fd_head -> error )  334
THROW_MESSAGE ( ReassemblyError , fd_head -> error ); 335
------------------------------
614 /home/speedy/test/source2slice/NVD/CVE_2015_3813_VULN_fragment_add_work.c dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ) 307
static gboolean
CVE_2015_3813_VULN_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fragment_item * fd_i ; 7
guint32 max , dfpos , fraglen ; 8
guint8 * data ; 10
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
for(fd_i=fd_head->next; fd_i; fd_i=fd_i->next) 43
if ( ! fd_i -> tvb_data )  44
fd_i -> tvb_data = tvb_new_subset_remaining ( fd_head -> tvb_data , fd_i -> offset ); 45
fd_i -> flags |= FD_SUBSET_TVB; 46
fd_i -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 48
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  164
max = 0; 182
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 183
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  184
max = fd_i -> offset + fd_i -> len; 186
if ( max < ( fd_head -> datalen ) )  190
data = ( guint8 * ) g_malloc ( fd_head -> datalen ); 204
fd_head -> tvb_data = tvb_new_real_data ( data , fd_head -> datalen , fd_head -> datalen ); 205
for (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) 209
if ( fd_i -> len )  210
if ( fd_i -> offset + fd_i -> len > dfpos )  228
if ( fd_i -> offset >= fd_head -> datalen )  229
fd_i -> flags |= FD_TOOLONGFRAGMENT; 246
fd_head -> flags |= FD_TOOLONGFRAGMENT; 247
if ( dfpos < fd_i -> offset )  248
fd_head -> error = "dfpos < offset"; 259
if ( dfpos - fd_i -> offset > fd_i -> len )  260
fd_head -> error = "dfpos - offset > len"; 261
if ( ! fd_head -> tvb_data )  262
fd_head -> error = "no data"; 263
fraglen = fd_i -> len; 265
if ( fd_i -> offset + fraglen > fd_head -> datalen )  266
fd_i -> flags |= FD_TOOLONGFRAGMENT; 281
fd_head -> flags |= FD_TOOLONGFRAGMENT; 282
fraglen = fd_head -> datalen - fd_i -> offset; 283
if ( fd_i -> offset < dfpos )  285
guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 286
fd_i -> flags |= FD_OVERLAP; 288
fd_head -> flags |= FD_OVERLAP; 289
if ( memcmp ( data + fd_i -> offset , tvb_get_ptr ( fd_i -> tvb_data , 0 , cmp_len ) , cmp_len ) )  290
fd_i -> flags |= FD_OVERLAPCONFLICT; 294
fd_head -> flags |= FD_OVERLAPCONFLICT; 295
if ( fraglen < dfpos - fd_i -> offset )  298
fd_head -> error = "fraglen < dfpos - offset"; 302
memcpy ( data + dfpos , tvb_get_ptr ( fd_i -> tvb_data , ( dfpos - fd_i -> offset ) , fraglen - ( dfpos - fd_i -> offset ) ) , fraglen - ( dfpos - fd_i -> offset ) ); 304
dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ); 307
if ( fd_i -> offset + fd_i -> len < fd_i -> offset )  311
fd_head -> error = "offset + len < offset"; 313
if ( fd_i -> flags & FD_SUBSET_TVB )  317
fd_i -> flags &= ~FD_SUBSET_TVB; 318
fd_i -> tvb_data = NULL; 322
------------------------------
615 /home/speedy/test/source2slice/NVD/CVE_2015_3813_VULN_fragment_add_work.c fd_head -> error = "fraglen < dfpos - offset" 302
static gboolean
CVE_2015_3813_VULN_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fragment_item * fd_i ; 7
guint32 max , dfpos , fraglen ; 8
guint8 * data ; 10
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
for(fd_i=fd_head->next; fd_i; fd_i=fd_i->next) 43
if ( ! fd_i -> tvb_data )  44
fd_i -> tvb_data = tvb_new_subset_remaining ( fd_head -> tvb_data , fd_i -> offset ); 45
fd_i -> flags |= FD_SUBSET_TVB; 46
fd_i -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 48
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  164
max = 0; 182
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 183
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  184
max = fd_i -> offset + fd_i -> len; 186
if ( max < ( fd_head -> datalen ) )  190
data = ( guint8 * ) g_malloc ( fd_head -> datalen ); 204
fd_head -> tvb_data = tvb_new_real_data ( data , fd_head -> datalen , fd_head -> datalen ); 205
for (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) 209
if ( fd_i -> len )  210
if ( fd_i -> offset + fd_i -> len > dfpos )  228
if ( fd_i -> offset >= fd_head -> datalen )  229
fd_i -> flags |= FD_TOOLONGFRAGMENT; 246
fd_head -> flags |= FD_TOOLONGFRAGMENT; 247
if ( dfpos < fd_i -> offset )  248
fd_head -> error = "dfpos < offset"; 259
if ( dfpos - fd_i -> offset > fd_i -> len )  260
fd_head -> error = "dfpos - offset > len"; 261
if ( ! fd_head -> tvb_data )  262
fd_head -> error = "no data"; 263
fraglen = fd_i -> len; 265
if ( fd_i -> offset + fraglen > fd_head -> datalen )  266
fd_i -> flags |= FD_TOOLONGFRAGMENT; 281
fd_head -> flags |= FD_TOOLONGFRAGMENT; 282
fraglen = fd_head -> datalen - fd_i -> offset; 283
if ( fd_i -> offset < dfpos )  285
guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 286
fd_i -> flags |= FD_OVERLAP; 288
fd_head -> flags |= FD_OVERLAP; 289
if ( memcmp ( data + fd_i -> offset , tvb_get_ptr ( fd_i -> tvb_data , 0 , cmp_len ) , cmp_len ) )  290
fd_i -> flags |= FD_OVERLAPCONFLICT; 294
fd_head -> flags |= FD_OVERLAPCONFLICT; 295
if ( fraglen < dfpos - fd_i -> offset )  298
fd_head -> error = "fraglen < dfpos - offset"; 302
memcpy ( data + dfpos , tvb_get_ptr ( fd_i -> tvb_data , ( dfpos - fd_i -> offset ) , fraglen - ( dfpos - fd_i -> offset ) ) , fraglen - ( dfpos - fd_i -> offset ) ); 304
dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ); 307
if ( fd_i -> offset + fd_i -> len < fd_i -> offset )  311
fd_head -> error = "offset + len < offset"; 313
if ( fd_i -> flags & FD_SUBSET_TVB )  317
fd_i -> flags &= ~FD_SUBSET_TVB; 318
fd_i -> tvb_data = NULL; 322
fd_head -> flags |= FD_DEFRAGMENTED; 330
fd_head -> reassembled_in = pinfo -> fd -> num; 331
if ( fd_head -> error )  334
THROW_MESSAGE ( ReassemblyError , fd_head -> error ); 335
------------------------------
616 /home/speedy/test/source2slice/NVD/CVE_2015_3813_VULN_fragment_add_work.c fraglen = fd_head -> datalen - fd_i -> offset 283
static gboolean
CVE_2015_3813_VULN_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fragment_item * fd_i ; 7
guint32 max , dfpos , fraglen ; 8
guint8 * data ; 10
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
for(fd_i=fd_head->next; fd_i; fd_i=fd_i->next) 43
if ( ! fd_i -> tvb_data )  44
fd_i -> tvb_data = tvb_new_subset_remaining ( fd_head -> tvb_data , fd_i -> offset ); 45
fd_i -> flags |= FD_SUBSET_TVB; 46
fd_i -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 48
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  164
max = 0; 182
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 183
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  184
max = fd_i -> offset + fd_i -> len; 186
if ( max < ( fd_head -> datalen ) )  190
data = ( guint8 * ) g_malloc ( fd_head -> datalen ); 204
fd_head -> tvb_data = tvb_new_real_data ( data , fd_head -> datalen , fd_head -> datalen ); 205
for (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) 209
if ( fd_i -> len )  210
if ( fd_i -> offset + fd_i -> len > dfpos )  228
if ( fd_i -> offset >= fd_head -> datalen )  229
fd_i -> flags |= FD_TOOLONGFRAGMENT; 246
fd_head -> flags |= FD_TOOLONGFRAGMENT; 247
if ( dfpos < fd_i -> offset )  248
fd_head -> error = "dfpos < offset"; 259
if ( dfpos - fd_i -> offset > fd_i -> len )  260
fd_head -> error = "dfpos - offset > len"; 261
if ( ! fd_head -> tvb_data )  262
fd_head -> error = "no data"; 263
fraglen = fd_i -> len; 265
if ( fd_i -> offset + fraglen > fd_head -> datalen )  266
fd_i -> flags |= FD_TOOLONGFRAGMENT; 281
fd_head -> flags |= FD_TOOLONGFRAGMENT; 282
fraglen = fd_head -> datalen - fd_i -> offset; 283
if ( fd_i -> offset < dfpos )  285
guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 286
fd_i -> flags |= FD_OVERLAP; 288
fd_head -> flags |= FD_OVERLAP; 289
if ( memcmp ( data + fd_i -> offset , tvb_get_ptr ( fd_i -> tvb_data , 0 , cmp_len ) , cmp_len ) )  290
fd_i -> flags |= FD_OVERLAPCONFLICT; 294
fd_head -> flags |= FD_OVERLAPCONFLICT; 295
if ( fraglen < dfpos - fd_i -> offset )  298
fd_head -> error = "fraglen < dfpos - offset"; 302
memcpy ( data + dfpos , tvb_get_ptr ( fd_i -> tvb_data , ( dfpos - fd_i -> offset ) , fraglen - ( dfpos - fd_i -> offset ) ) , fraglen - ( dfpos - fd_i -> offset ) ); 304
dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ); 307
if ( fd_i -> offset + fd_i -> len < fd_i -> offset )  311
fd_head -> error = "offset + len < offset"; 313
if ( fd_i -> flags & FD_SUBSET_TVB )  317
fd_i -> flags &= ~FD_SUBSET_TVB; 318
fd_i -> tvb_data = NULL; 322
------------------------------
617 /home/speedy/test/source2slice/NVD/CVE_2015_3813_VULN_fragment_add_work.c fd_head -> error = "dfpos - offset > len" 261
static gboolean
CVE_2015_3813_VULN_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fragment_item * fd_i ; 7
guint32 max , dfpos , fraglen ; 8
guint8 * data ; 10
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
for(fd_i=fd_head->next; fd_i; fd_i=fd_i->next) 43
if ( ! fd_i -> tvb_data )  44
fd_i -> tvb_data = tvb_new_subset_remaining ( fd_head -> tvb_data , fd_i -> offset ); 45
fd_i -> flags |= FD_SUBSET_TVB; 46
fd_i -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 48
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  164
max = 0; 182
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 183
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  184
max = fd_i -> offset + fd_i -> len; 186
if ( max < ( fd_head -> datalen ) )  190
data = ( guint8 * ) g_malloc ( fd_head -> datalen ); 204
fd_head -> tvb_data = tvb_new_real_data ( data , fd_head -> datalen , fd_head -> datalen ); 205
for (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) 209
if ( fd_i -> len )  210
if ( fd_i -> offset + fd_i -> len > dfpos )  228
if ( fd_i -> offset >= fd_head -> datalen )  229
fd_i -> flags |= FD_TOOLONGFRAGMENT; 246
fd_head -> flags |= FD_TOOLONGFRAGMENT; 247
if ( dfpos < fd_i -> offset )  248
fd_head -> error = "dfpos < offset"; 259
if ( dfpos - fd_i -> offset > fd_i -> len )  260
fd_head -> error = "dfpos - offset > len"; 261
if ( ! fd_head -> tvb_data )  262
fd_head -> error = "no data"; 263
fraglen = fd_i -> len; 265
if ( fd_i -> offset + fraglen > fd_head -> datalen )  266
fd_i -> flags |= FD_TOOLONGFRAGMENT; 281
fd_head -> flags |= FD_TOOLONGFRAGMENT; 282
fraglen = fd_head -> datalen - fd_i -> offset; 283
if ( fd_i -> offset < dfpos )  285
guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 286
fd_i -> flags |= FD_OVERLAP; 288
fd_head -> flags |= FD_OVERLAP; 289
if ( memcmp ( data + fd_i -> offset , tvb_get_ptr ( fd_i -> tvb_data , 0 , cmp_len ) , cmp_len ) )  290
fd_i -> flags |= FD_OVERLAPCONFLICT; 294
fd_head -> flags |= FD_OVERLAPCONFLICT; 295
if ( fraglen < dfpos - fd_i -> offset )  298
fd_head -> error = "fraglen < dfpos - offset"; 302
memcpy ( data + dfpos , tvb_get_ptr ( fd_i -> tvb_data , ( dfpos - fd_i -> offset ) , fraglen - ( dfpos - fd_i -> offset ) ) , fraglen - ( dfpos - fd_i -> offset ) ); 304
dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ); 307
if ( fd_i -> offset + fd_i -> len < fd_i -> offset )  311
fd_head -> error = "offset + len < offset"; 313
if ( fd_i -> flags & FD_SUBSET_TVB )  317
fd_i -> flags &= ~FD_SUBSET_TVB; 318
fd_i -> tvb_data = NULL; 322
fd_head -> flags |= FD_DEFRAGMENTED; 330
fd_head -> reassembled_in = pinfo -> fd -> num; 331
if ( fd_head -> error )  334
THROW_MESSAGE ( ReassemblyError , fd_head -> error ); 335
------------------------------
618 /home/speedy/test/source2slice/NVD/CVE_2015_3813_VULN_fragment_add_work.c max = fd_i -> offset + fd_i -> len 186
static gboolean
CVE_2015_3813_VULN_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fragment_item * fd_i ; 7
guint32 max , dfpos , fraglen ; 8
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
for(fd_i=fd_head->next; fd_i; fd_i=fd_i->next) 43
if ( ! fd_i -> tvb_data )  44
fd_i -> tvb_data = tvb_new_subset_remaining ( fd_head -> tvb_data , fd_i -> offset ); 45
fd_i -> flags |= FD_SUBSET_TVB; 46
fd_i -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 48
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  164
max = 0; 182
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 183
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  184
max = fd_i -> offset + fd_i -> len; 186
if ( max < ( fd_head -> datalen ) )  190
------------------------------
619 /home/speedy/test/source2slice/NVD/CVE_2015_3813_VULN_fragment_add_work.c fd_head -> datalen = fd -> offset + fd -> len 121
static gboolean
CVE_2015_3813_VULN_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
fd_head -> flags |= FD_OVERLAP; 136
if ( end_offset > fd_head -> datalen || end_offset < fd -> offset || end_offset < fd -> len )  138
fd_head -> flags |= FD_TOOLONGFRAGMENT; 140
if ( tvb_memeql ( fd_head -> tvb_data , fd -> offset , tvb_get_ptr ( tvb , offset , fd -> len ) , fd -> len ) )  143
fd_head -> flags |= FD_OVERLAPCONFLICT; 146
LINK_FRAG ( fd_head , fd ); 149
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  164
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 183
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  184
max = fd_i -> offset + fd_i -> len; 186
if ( max < ( fd_head -> datalen ) )  190
old_tvb_data = fd_head -> tvb_data; 203
data = ( guint8 * ) g_malloc ( fd_head -> datalen ); 204
fd_head -> tvb_data = tvb_new_real_data ( data , fd_head -> datalen , fd_head -> datalen ); 205
tvb_set_free_cb ( fd_head -> tvb_data , g_free ); 206
for (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) 209
if ( fd_i -> len )  210
if ( fd_i -> offset + fd_i -> len > dfpos )  228
if ( fd_i -> offset >= fd_head -> datalen )  229
fd_i -> flags |= FD_TOOLONGFRAGMENT; 246
fd_head -> flags |= FD_TOOLONGFRAGMENT; 247
if ( dfpos < fd_i -> offset )  248
if ( dfpos - fd_i -> offset > fd_i -> len )  260
if ( ! fd_head -> tvb_data )  262
fraglen = fd_i -> len; 265
if ( fd_i -> offset + fraglen > fd_head -> datalen )  266
fd_i -> flags |= FD_TOOLONGFRAGMENT; 281
fd_head -> flags |= FD_TOOLONGFRAGMENT; 282
fraglen = fd_head -> datalen - fd_i -> offset; 283
if ( fd_i -> offset < dfpos )  285
guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 286
fd_i -> flags |= FD_OVERLAP; 288
fd_head -> flags |= FD_OVERLAP; 289
if ( memcmp ( data + fd_i -> offset , tvb_get_ptr ( fd_i -> tvb_data , 0 , cmp_len ) , cmp_len ) )  290
fd_i -> flags |= FD_OVERLAPCONFLICT; 294
fd_head -> flags |= FD_OVERLAPCONFLICT; 295
if ( fraglen < dfpos - fd_i -> offset )  298
fd_head -> error = "fraglen < dfpos - offset"; 302
memcpy ( data + dfpos , tvb_get_ptr ( fd_i -> tvb_data , ( dfpos - fd_i -> offset ) , fraglen - ( dfpos - fd_i -> offset ) ) , fraglen - ( dfpos - fd_i -> offset ) ); 304
dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ); 307
if ( fd_i -> offset + fd_i -> len < fd_i -> offset )  311
if ( fd_i -> flags & FD_SUBSET_TVB )  317
fd_i -> flags &= ~FD_SUBSET_TVB; 318
if ( fd_i -> tvb_data )  319
tvb_free ( fd_i -> tvb_data ); 320
fd_i -> tvb_data = NULL; 322
if ( old_tvb_data )  326
tvb_add_to_chain ( tvb , old_tvb_data ); 327
fd_head -> flags |= FD_DEFRAGMENTED; 330
fd_head -> reassembled_in = pinfo -> fd -> num; 331
if ( fd_head -> error )  334
THROW_MESSAGE ( ReassemblyError , fd_head -> error ); 335
------------------------------
620 /home/speedy/test/source2slice/NVD/CVE_2015_4001_PATCHED_oz_hcd_get_desc_cnf.c copy_len = required_size - offset 19
void CVE_2015_4001_PATCHED_oz_hcd_get_desc_cnf(void *hport, u8 req_id, u8 status, const u8 *desc,
u8 length, u16 offset, u16 total_size) 2
struct oz_port * port = hport ; 4
struct urb * urb ; 5
urb = oz_find_urb_by_id ( port , 0 , req_id ); 10
if ( ! urb )  11
if ( status == 0 )  13
unsigned int copy_len ; 14
unsigned int required_size = urb -> transfer_buffer_length ; 15
if ( required_size > total_size )  17
required_size = total_size; 18
copy_len = required_size - offset; 19
if ( length <= copy_len )  20
memcpy ( urb -> transfer_buffer + offset , desc , copy_len ); 22
offset += copy_len; 23
if ( offset < required_size )  24
struct usb_ctrlrequest * setup = ( struct usb_ctrlrequest * ) urb -> setup_packet ; 25
unsigned wvalue = le16_to_cpu ( setup -> wValue ) ; 27
if ( oz_enqueue_ep_urb ( port , 0 , 0 , urb , req_id ) )  29
if ( oz_usb_get_desc_req ( port -> hpd , req_id , setup -> bRequestType , ( u8 ) ( wvalue >> 8 ) , ( u8 ) wvalue , setup -> wIndex , offset , required_size - offset ) )  31
oz_dequeue_ep_urb ( port , 0 , 0 , urb ); 35
urb -> actual_length = total_size; 42
oz_complete_urb ( port -> ozhcd -> hcd , urb , 0 ); 43
------------------------------
621 /home/speedy/test/source2slice/NVD/CVE_2015_4001_VULN_oz_hcd_get_desc_cnf.c copy_len = required_size - offset 19
void CVE_2015_4001_VULN_oz_hcd_get_desc_cnf(void *hport, u8 req_id, int status, const u8 *desc,
int length, int offset, int total_size) 2
struct oz_port * port = hport ; 4
struct urb * urb ; 5
urb = oz_find_urb_by_id ( port , 0 , req_id ); 10
if ( ! urb )  11
if ( status == 0 )  13
int copy_len ; 14
int required_size = urb -> transfer_buffer_length ; 15
if ( required_size > total_size )  17
required_size = total_size; 18
copy_len = required_size - offset; 19
if ( length <= copy_len )  20
memcpy ( urb -> transfer_buffer + offset , desc , copy_len ); 22
offset += copy_len; 23
if ( offset < required_size )  24
struct usb_ctrlrequest * setup = ( struct usb_ctrlrequest * ) urb -> setup_packet ; 25
unsigned wvalue = le16_to_cpu ( setup -> wValue ) ; 27
if ( oz_enqueue_ep_urb ( port , 0 , 0 , urb , req_id ) )  29
if ( oz_usb_get_desc_req ( port -> hpd , req_id , setup -> bRequestType , ( u8 ) ( wvalue >> 8 ) , ( u8 ) wvalue , setup -> wIndex , offset , required_size - offset ) )  31
oz_dequeue_ep_urb ( port , 0 , 0 , urb ); 35
------------------------------
622 /home/speedy/test/source2slice/NVD/CVE_2015_4003_PATCHED_oz_usb_handle_ep_data.c count = data_len / unit_size 32
void CVE_2015_4003_PATCHED_oz_usb_handle_ep_data(struct oz_usb_ctx *usb_ctx,
struct oz_usb_hdr *usb_hdr, int len) 2
struct oz_data * data_hdr = ( struct oz_data * ) usb_hdr ; 4
switch ( data_hdr -> format )  5
struct oz_isoc_fixed * body = ( struct oz_isoc_fixed * ) data_hdr ; 23
int data_len = len - sizeof ( struct oz_isoc_fixed ) + 1 ; 25
int unit_size = body -> unit_size ; 26
int count ; 28
if ( ! unit_size )  30
count = data_len / unit_size; 32
for (i = 0; i < count; i++) 33
------------------------------
623 /home/speedy/test/source2slice/NVD/CVE_2015_4003_PATCHED_oz_usb_handle_ep_data.c n = ( len - sizeof ( struct oz_multiple_fixed ) + 1 ) / body -> unit_size 13
void CVE_2015_4003_PATCHED_oz_usb_handle_ep_data(struct oz_usb_ctx *usb_ctx,
struct oz_usb_hdr *usb_hdr, int len) 2
struct oz_data * data_hdr = ( struct oz_data * ) usb_hdr ; 4
switch ( data_hdr -> format )  5
struct oz_multiple_fixed * body = ( struct oz_multiple_fixed * ) data_hdr ; 7
int n ; 10
if ( ! body -> unit_size )  11
n = ( len - sizeof ( struct oz_multiple_fixed ) + 1 ) / body -> unit_size; 13
while ( n -- )  15
------------------------------
624 /home/speedy/test/source2slice/NVD/CVE_2015_4003_VULN_oz_usb_handle_ep_data.c count = data_len / unit_size 29
void CVE_2015_4003_VULN_oz_usb_handle_ep_data(struct oz_usb_ctx *usb_ctx,
struct oz_usb_hdr *usb_hdr, int len) 2
struct oz_data * data_hdr = ( struct oz_data * ) usb_hdr ; 4
switch ( data_hdr -> format )  5
struct oz_isoc_fixed * body = ( struct oz_isoc_fixed * ) data_hdr ; 20
int data_len = len - sizeof ( struct oz_isoc_fixed ) + 1 ; 22
int unit_size = body -> unit_size ; 23
int count ; 25
if ( ! unit_size )  27
count = data_len / unit_size; 29
for (i = 0; i < count; i++) 30
------------------------------
625 /home/speedy/test/source2slice/NVD/CVE_2015_4652_PATCHED_de_bcd_num.c num_string_len = len - ( curr_offset - offset ) 30
static guint16
CVE_2015_4652_PATCHED_de_bcd_num(tvbuff_t *tvb, proto_tree *tree, packet_info *pinfo, guint32 offset, guint len, int header_field, gboolean *address_extracted) 2
guint8 extension ; 5
guint32 curr_offset , num_string_len ; 6
curr_offset = offset; 11
extension = tvb_get_guint8 ( tvb , curr_offset ) & 0x80; 13
curr_offset ++; 17
if ( ! extension )  19
curr_offset ++; 25
num_string_len = len - ( curr_offset - offset ); 30
poctets = ( guint8 * ) tvb_memdup ( wmem_packet_scope ( ) , tvb , curr_offset , num_string_len ); 31
my_dgt_tbcd_unpack ( a_bigbuf , poctets , num_string_len , & Dgt_mbcd ); 34
digit_str = tvb_bcd_dig_to_wmem_packet_str ( tvb , curr_offset , num_string_len , NULL , FALSE ); 37
item = proto_tree_add_string ( tree , header_field , tvb , curr_offset , num_string_len , digit_str ); 38
item = proto_tree_add_string_format ( tree , header_field , tvb , curr_offset , num_string_len , a_bigbuf , "BCD Digits: %s" , a_bigbuf ); 39
if ( strchr ( digit_str , '?' ) )  50
expert_add_info ( pinfo , item , & ei_gsm_a_dtap_end_mark_unexpected ); 51
------------------------------
626 /home/speedy/test/source2slice/NVD/CVE_2015_4652_VULN_de_bcd_num.c num_string_len = len - ( curr_offset - offset ) 30
static guint16
CVE_2015_4652_VULN_de_bcd_num(tvbuff_t *tvb, proto_tree *tree, packet_info *pinfo, guint32 offset, guint len, int header_field, gboolean *address_extracted) 2
guint8 extension , oct ; 5
guint32 curr_offset , i , num_string_len ; 6
curr_offset = offset; 11
extension = tvb_get_guint8 ( tvb , curr_offset ) & 0x80; 13
curr_offset ++; 17
if ( ! extension )  19
curr_offset ++; 25
num_string_len = len - ( curr_offset - offset ); 30
poctets = ( guint8 * ) tvb_memdup ( wmem_packet_scope ( ) , tvb , curr_offset , num_string_len ); 31
my_dgt_tbcd_unpack ( a_bigbuf , poctets , num_string_len , & Dgt_mbcd ); 34
item = proto_tree_add_string_format ( tree , header_field , tvb , curr_offset , num_string_len , a_bigbuf , "BCD Digits: %s" , a_bigbuf ); 37
for(i = 0; i < num_string_len - 1; i++) 44
oct = poctets [ i ]; 46
if ( ( ( oct & 0xf0 ) == 0xf0 ) || ( ( oct & 0x0f ) == 0x0f ) )  47
oct = poctets [ num_string_len - 1 ]; 54
if ( ( oct & 0x0f ) == 0x0f )  55
expert_add_info ( pinfo , item , & ei_gsm_a_dtap_end_mark_unexpected ); 59
------------------------------
627 /home/speedy/test/source2slice/NVD/CVE_2015_6242_PATCHED_wmem_block_split_free_chunk.c available = chunk -> len - aligned_size 29
static void
CVE_2015_6242_PATCHED_wmem_block_split_free_chunk(wmem_block_allocator_t *allocator,
wmem_block_chunk_t *chunk,
const size_t size) 4
size_t aligned_size , available ; 8
aligned_size = WMEM_ALIGN_SIZE ( size ) + WMEM_CHUNK_HEADER_SIZE; 11
if ( WMEM_CHUNK_DATA_LEN ( chunk ) < aligned_size + sizeof ( wmem_block_free_t ) )  13
available = chunk -> len - aligned_size; 29
extra -> len = ( guint32 ) available; 78
extra -> last = last; 79
extra -> prev = chunk -> len; 80
extra -> used = FALSE; 81
extra -> jumbo = FALSE; 82
WMEM_CHUNK_NEXT ( extra ) -> prev = extra -> len; 86
------------------------------
628 /home/speedy/test/source2slice/NVD/CVE_2015_6242_VULN_wmem_block_split_free_chunk.c available = chunk -> len - aligned_size 29
static void
CVE_2015_6242_VULN_wmem_block_split_free_chunk(wmem_block_allocator_t *allocator,
wmem_block_chunk_t *chunk,
const size_t size) 4
size_t aligned_size , available ; 8
aligned_size = WMEM_ALIGN_SIZE ( size ) + WMEM_CHUNK_HEADER_SIZE; 11
if ( WMEM_CHUNK_DATA_LEN ( chunk ) < aligned_size + sizeof ( wmem_block_free_t ) )  13
available = chunk -> len - aligned_size; 29
extra -> len = ( guint32 ) available; 78
extra -> last = last; 79
extra -> prev = chunk -> len; 80
extra -> used = FALSE; 81
extra -> jumbo = FALSE; 82
WMEM_CHUNK_NEXT ( extra ) -> prev = extra -> len; 86
------------------------------
629 /home/speedy/test/source2slice/NVD/CVE_2015_6246_PATCHED_dissect_wa_payload.c current_offset = offset + iLoop * delta 494
static void CVE_2015_6246_PATCHED_dissect_wa_payload(guint32 starting_offset, proto_item *parent_tree, tvbuff_t *tvb, guint32 control_word, guint8 version) 1
switch ( control_word )  3
guint32 offset ; 115
guint32 delta ; 117
guint32 iLoop ; 118
offset = starting_offset + 8; 128
delta = 156; 129
for (iLoop = 0; iLoop < NUM_STATE_CHANGES; iLoop++) 131
guint32 if_status ; 134
int current_offset ; 135
current_offset = offset + iLoop * delta; 137
if_status = tvb_get_ntohl ( tvb , current_offset ); 140
if ( if_status == 0 )  141
guint32 offset ; 201
guint32 num_bss_entries ; 203
guint32 delta ; 205
guint32 iLoop ; 206
num_bss_entries = tvb_get_ntohl ( tvb , starting_offset + 8 ); 219
if ( num_bss_entries > NUM_BSS )  221
num_bss_entries = NUM_BSS; 223
offset = starting_offset + 16; 227
delta = 148; 228
for (iLoop = 0; iLoop < num_bss_entries; iLoop++) 232
int current_offset ; 236
if ( version < 3 )  303
starting_offset += 4; 314
guint32 offset ; 470
guint32 delta ; 471
guint32 iLoop ; 472
guint32 num_bss_entries ; 473
num_bss_entries = tvb_get_ntohl ( tvb , starting_offset + 142 ); 487
offset = starting_offset + 46; 489
delta = 6; 490
for (iLoop = 0; iLoop < num_bss_entries; iLoop++) 491
int current_offset ; 493
current_offset = offset + iLoop * delta; 494
proto_tree_add_item ( parent_tree , hf_waveagent_scanbssid , tvb , current_offset , 6 , ENC_NA ); 496
------------------------------
630 /home/speedy/test/source2slice/NVD/CVE_2015_6246_PATCHED_dissect_wa_payload.c current_offset = offset + iLoop * delta 240
static void CVE_2015_6246_PATCHED_dissect_wa_payload(guint32 starting_offset, proto_item *parent_tree, tvbuff_t *tvb, guint32 control_word, guint8 version) 1
switch ( control_word )  3
guint32 offset ; 115
guint32 delta ; 117
guint32 iLoop ; 118
offset = starting_offset + 8; 128
delta = 156; 129
for (iLoop = 0; iLoop < NUM_STATE_CHANGES; iLoop++) 131
guint32 if_status ; 134
int current_offset ; 135
current_offset = offset + iLoop * delta; 137
if_status = tvb_get_ntohl ( tvb , current_offset ); 140
if ( if_status == 0 )  141
guint32 offset ; 201
guint32 num_bss_entries ; 203
guint32 delta ; 205
guint32 iLoop ; 206
num_bss_entries = tvb_get_ntohl ( tvb , starting_offset + 8 ); 219
if ( num_bss_entries > NUM_BSS )  221
num_bss_entries = NUM_BSS; 223
offset = starting_offset + 16; 227
delta = 148; 228
for (iLoop = 0; iLoop < num_bss_entries; iLoop++) 232
int current_offset ; 236
current_offset = offset + iLoop * delta; 240
bssIndex = proto_tree_add_item ( parent_tree , hf_waveagent_scanssid , tvb , current_offset , 32 , ENC_ASCII | ENC_NA ); 242
bss_tree = proto_item_add_subtree ( bssIndex , ett_bss [ iLoop ] ); 245
tag_len = tvb_get_ntohl ( tvb , current_offset + 52 ); 247
if ( tag_len != 0 )  249
for (isr = 0; isr < tag_len; isr++) 253
proto_tree_add_string ( bss_tree , hf_waveagent_ifwlansupprates , tvb , offset + 36 + isr ,
1 ,
"BSS requires support for mandatory features of HT PHY (IEEE 802.11"
" - Clause 20)" ) 259
proto_tree_add_string ( bss_tree , hf_waveagent_ifwlansupprates , tvb , offset + 36 , tag_len , wmem_strbuf_get_str ( sb ) ); 273
proto_tree_add_item ( bss_tree , hf_waveagent_scanbssid , tvb , current_offset + 56 , 6 , ENC_NA ); 276
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlancapabilities , tvb , current_offset + 62 , 2 , ENC_BIG_ENDIAN ); 279
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanrssi , tvb , current_offset + 64 , 4 , ENC_BIG_ENDIAN ); 282
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlansigquality , tvb , current_offset + 68 , 4 , ENC_BIG_ENDIAN ); 287
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanchannel , tvb , current_offset + 72 , 4 , ENC_BIG_ENDIAN ); 290
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanprivacy , tvb , current_offset + 76 , 4 , ENC_BIG_ENDIAN ); 293
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanbssmode , tvb , current_offset + 80 , 4 , ENC_BIG_ENDIAN ); 296
proto_tree_add_item ( parent_tree , hf_waveagent_scanbssid , tvb , current_offset , 6 , ENC_NA ); 496
------------------------------
631 /home/speedy/test/source2slice/NVD/CVE_2015_6246_PATCHED_dissect_wa_payload.c current_offset = offset + iLoop * delta 137
static void CVE_2015_6246_PATCHED_dissect_wa_payload(guint32 starting_offset, proto_item *parent_tree, tvbuff_t *tvb, guint32 control_word, guint8 version) 1
switch ( control_word )  3
guint32 offset ; 115
guint32 delta ; 117
guint32 iLoop ; 118
offset = starting_offset + 8; 128
delta = 156; 129
for (iLoop = 0; iLoop < NUM_STATE_CHANGES; iLoop++) 131
guint32 if_status ; 134
int current_offset ; 135
current_offset = offset + iLoop * delta; 137
if_status = tvb_get_ntohl ( tvb , current_offset ); 140
if ( if_status == 0 )  141
stIndex = proto_tree_add_uint_format_value ( parent_tree , hf_waveagent_ifwlanl2status , tvb , current_offset , 4 , if_status , "Interface state change %d" , iLoop ); 144
st_change_index_tree = proto_item_add_subtree ( stIndex , ett_scindex [ iLoop ] ); 147
proto_tree_add_item ( st_change_index_tree , hf_waveagent_ifwlanl2status , tvb , current_offset , 4 , ENC_BIG_ENDIAN ); 150
proto_tree_add_item ( st_change_index_tree , hf_waveagent_ifethl2status , tvb , current_offset , 4 , ENC_BIG_ENDIAN ); 153
proto_tree_add_item ( st_change_index_tree , hf_waveagent_ifl3status , tvb , current_offset + 4 , 4 , ENC_BIG_ENDIAN ); 157
proto_tree_add_item ( st_change_index_tree , hf_waveagent_iflinkspeed , tvb , current_offset + 8 , 4 , ENC_BIG_ENDIAN ); 160
dissect_wlan_if_stats ( current_offset + 12 , st_change_index_tree , tvb ); 164
proto_tree_add_item ( st_change_index_tree , hf_waveagent_snap , tvb , current_offset + 108 , 8 , ENC_BIG_ENDIAN ); 167
proto_tree_add_item ( st_change_index_tree , hf_waveagent_ifiptype , tvb , current_offset + 116 , 2 , ENC_BIG_ENDIAN ); 170
if ( tvb_get_ntohs ( tvb , current_offset + 116 ) == IPV4_TYPE )  173
proto_tree_add_item ( st_change_index_tree , hf_waveagent_ifipv4 , tvb , current_offset + 124 , 4 , ENC_BIG_ENDIAN ); 174
proto_tree_add_item ( st_change_index_tree , hf_waveagent_ifipv6 , tvb , current_offset + 124 , 16 , ENC_NA ); 178
bssIndex = proto_tree_add_item ( parent_tree , hf_waveagent_scanssid , tvb , current_offset , 32 , ENC_ASCII | ENC_NA ); 242
bss_tree = proto_item_add_subtree ( bssIndex , ett_bss [ iLoop ] ); 245
tag_len = tvb_get_ntohl ( tvb , current_offset + 52 ); 247
if ( tag_len != 0 )  249
for (isr = 0; isr < tag_len; isr++) 253
proto_tree_add_string ( bss_tree , hf_waveagent_ifwlansupprates , tvb , offset + 36 + isr ,
1 ,
"BSS requires support for mandatory features of HT PHY (IEEE 802.11"
" - Clause 20)" ) 259
proto_tree_add_string ( bss_tree , hf_waveagent_ifwlansupprates , tvb , offset + 36 , tag_len , wmem_strbuf_get_str ( sb ) ); 273
proto_tree_add_item ( bss_tree , hf_waveagent_scanbssid , tvb , current_offset + 56 , 6 , ENC_NA ); 276
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlancapabilities , tvb , current_offset + 62 , 2 , ENC_BIG_ENDIAN ); 279
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanrssi , tvb , current_offset + 64 , 4 , ENC_BIG_ENDIAN ); 282
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlansigquality , tvb , current_offset + 68 , 4 , ENC_BIG_ENDIAN ); 287
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanchannel , tvb , current_offset + 72 , 4 , ENC_BIG_ENDIAN ); 290
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanprivacy , tvb , current_offset + 76 , 4 , ENC_BIG_ENDIAN ); 293
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanbssmode , tvb , current_offset + 80 , 4 , ENC_BIG_ENDIAN ); 296
proto_tree_add_item ( parent_tree , hf_waveagent_scanbssid , tvb , current_offset , 6 , ENC_NA ); 496
------------------------------
632 /home/speedy/test/source2slice/NVD/CVE_2015_6246_VULN_dissect_wa_payload.c current_offset = offset + iLoop * delta 495
static void CVE_2015_6246_VULN_dissect_wa_payload(guint32 starting_offset, proto_item *parent_tree, tvbuff_t *tvb, guint32 control_word, guint8 version) 1
switch ( control_word )  3
guint32 offset ; 115
guint32 delta ; 117
guint32 iLoop ; 118
offset = starting_offset + 8; 128
delta = 156; 129
for (iLoop = 0; iLoop < NUM_STATE_CHANGES; iLoop++) 131
guint32 if_status ; 134
int current_offset ; 135
current_offset = offset + iLoop * delta; 137
if_status = tvb_get_ntohl ( tvb , current_offset ); 140
if ( if_status == 0 )  141
guint32 offset ; 201
guint32 num_bss_entries ; 203
guint32 delta ; 205
guint32 iLoop ; 206
num_bss_entries = tvb_get_ntohl ( tvb , starting_offset + 8 ); 219
if ( num_bss_entries > NUM_BSS )  221
num_bss_entries = NUM_BSS; 223
offset = starting_offset + 16; 227
delta = 148; 228
for (iLoop = 0; iLoop < num_bss_entries; iLoop++) 232
int current_offset ; 236
if ( version < 3 )  304
starting_offset += 4; 315
guint32 offset ; 471
guint32 delta ; 472
guint32 iLoop ; 473
guint32 num_bss_entries ; 474
num_bss_entries = tvb_get_ntohl ( tvb , starting_offset + 142 ); 488
offset = starting_offset + 46; 490
delta = 6; 491
for (iLoop = 0; iLoop < num_bss_entries; iLoop++) 492
int current_offset ; 494
current_offset = offset + iLoop * delta; 495
proto_tree_add_item ( parent_tree , hf_waveagent_scanbssid , tvb , current_offset , 6 , ENC_NA ); 497
------------------------------
633 /home/speedy/test/source2slice/NVD/CVE_2015_6246_VULN_dissect_wa_payload.c current_offset = offset + iLoop * delta 240
static void CVE_2015_6246_VULN_dissect_wa_payload(guint32 starting_offset, proto_item *parent_tree, tvbuff_t *tvb, guint32 control_word, guint8 version) 1
switch ( control_word )  3
guint32 offset ; 115
guint32 delta ; 117
guint32 iLoop ; 118
offset = starting_offset + 8; 128
delta = 156; 129
for (iLoop = 0; iLoop < NUM_STATE_CHANGES; iLoop++) 131
guint32 if_status ; 134
int current_offset ; 135
current_offset = offset + iLoop * delta; 137
if_status = tvb_get_ntohl ( tvb , current_offset ); 140
if ( if_status == 0 )  141
guint32 offset ; 201
guint32 num_bss_entries ; 203
guint32 delta ; 205
guint32 iLoop ; 206
num_bss_entries = tvb_get_ntohl ( tvb , starting_offset + 8 ); 219
if ( num_bss_entries > NUM_BSS )  221
num_bss_entries = NUM_BSS; 223
offset = starting_offset + 16; 227
delta = 148; 228
for (iLoop = 0; iLoop < num_bss_entries; iLoop++) 232
int current_offset ; 236
current_offset = offset + iLoop * delta; 240
bssIndex = proto_tree_add_item ( parent_tree , hf_waveagent_scanssid , tvb , current_offset , 32 , ENC_ASCII | ENC_NA ); 242
bss_tree = proto_item_add_subtree ( bssIndex , ett_bss [ iLoop ] ); 245
tag_len = tvb_get_ntohl ( tvb , current_offset + 52 ); 247
if ( tag_len != 0 )  249
tag_data_ptr = tvb_get_ptr ( tvb , offset + 36 , tag_len ); 253
for (isr = 0; isr < tag_len; isr++) 255
if ( tag_data_ptr [ isr ] == 0xFF )  256
proto_tree_add_string ( bss_tree , hf_waveagent_ifwlansupprates , tvb , offset + 36 + isr ,
1 ,
"BSS requires support for mandatory features of HT PHY (IEEE 802.11"
" - Clause 20)" ) 260
wmem_strbuf_append_printf ( sb , "%2.1f%s " , ( tag_data_ptr [ isr ] & 0x7F ) * 0.5 , ( tag_data_ptr [ isr ] & 0x80 ) ? "(B)" : "" ); 262
proto_tree_add_string ( bss_tree , hf_waveagent_ifwlansupprates , tvb , offset + 36 , tag_len , wmem_strbuf_get_str ( sb ) ); 274
proto_tree_add_item ( bss_tree , hf_waveagent_scanbssid , tvb , current_offset + 56 , 6 , ENC_NA ); 277
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlancapabilities , tvb , current_offset + 62 , 2 , ENC_BIG_ENDIAN ); 280
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanrssi , tvb , current_offset + 64 , 4 , ENC_BIG_ENDIAN ); 283
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlansigquality , tvb , current_offset + 68 , 4 , ENC_BIG_ENDIAN ); 288
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanchannel , tvb , current_offset + 72 , 4 , ENC_BIG_ENDIAN ); 291
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanprivacy , tvb , current_offset + 76 , 4 , ENC_BIG_ENDIAN ); 294
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanbssmode , tvb , current_offset + 80 , 4 , ENC_BIG_ENDIAN ); 297
proto_tree_add_item ( parent_tree , hf_waveagent_scanbssid , tvb , current_offset , 6 , ENC_NA ); 497
------------------------------
634 /home/speedy/test/source2slice/NVD/CVE_2015_6246_VULN_dissect_wa_payload.c current_offset = offset + iLoop * delta 137
static void CVE_2015_6246_VULN_dissect_wa_payload(guint32 starting_offset, proto_item *parent_tree, tvbuff_t *tvb, guint32 control_word, guint8 version) 1
switch ( control_word )  3
guint32 offset ; 115
guint32 delta ; 117
guint32 iLoop ; 118
offset = starting_offset + 8; 128
delta = 156; 129
for (iLoop = 0; iLoop < NUM_STATE_CHANGES; iLoop++) 131
guint32 if_status ; 134
int current_offset ; 135
current_offset = offset + iLoop * delta; 137
if_status = tvb_get_ntohl ( tvb , current_offset ); 140
if ( if_status == 0 )  141
stIndex = proto_tree_add_uint_format_value ( parent_tree , hf_waveagent_ifwlanl2status , tvb , current_offset , 4 , if_status , "Interface state change %d" , iLoop ); 144
st_change_index_tree = proto_item_add_subtree ( stIndex , ett_scindex [ iLoop ] ); 147
proto_tree_add_item ( st_change_index_tree , hf_waveagent_ifwlanl2status , tvb , current_offset , 4 , ENC_BIG_ENDIAN ); 150
proto_tree_add_item ( st_change_index_tree , hf_waveagent_ifethl2status , tvb , current_offset , 4 , ENC_BIG_ENDIAN ); 153
proto_tree_add_item ( st_change_index_tree , hf_waveagent_ifl3status , tvb , current_offset + 4 , 4 , ENC_BIG_ENDIAN ); 157
proto_tree_add_item ( st_change_index_tree , hf_waveagent_iflinkspeed , tvb , current_offset + 8 , 4 , ENC_BIG_ENDIAN ); 160
dissect_wlan_if_stats ( current_offset + 12 , st_change_index_tree , tvb ); 164
proto_tree_add_item ( st_change_index_tree , hf_waveagent_snap , tvb , current_offset + 108 , 8 , ENC_BIG_ENDIAN ); 167
proto_tree_add_item ( st_change_index_tree , hf_waveagent_ifiptype , tvb , current_offset + 116 , 2 , ENC_BIG_ENDIAN ); 170
if ( tvb_get_ntohs ( tvb , current_offset + 116 ) == IPV4_TYPE )  173
proto_tree_add_item ( st_change_index_tree , hf_waveagent_ifipv4 , tvb , current_offset + 124 , 4 , ENC_BIG_ENDIAN ); 174
proto_tree_add_item ( st_change_index_tree , hf_waveagent_ifipv6 , tvb , current_offset + 124 , 16 , ENC_NA ); 178
bssIndex = proto_tree_add_item ( parent_tree , hf_waveagent_scanssid , tvb , current_offset , 32 , ENC_ASCII | ENC_NA ); 242
bss_tree = proto_item_add_subtree ( bssIndex , ett_bss [ iLoop ] ); 245
tag_len = tvb_get_ntohl ( tvb , current_offset + 52 ); 247
if ( tag_len != 0 )  249
tag_data_ptr = tvb_get_ptr ( tvb , offset + 36 , tag_len ); 253
for (isr = 0; isr < tag_len; isr++) 255
if ( tag_data_ptr [ isr ] == 0xFF )  256
proto_tree_add_string ( bss_tree , hf_waveagent_ifwlansupprates , tvb , offset + 36 + isr ,
1 ,
"BSS requires support for mandatory features of HT PHY (IEEE 802.11"
" - Clause 20)" ) 260
wmem_strbuf_append_printf ( sb , "%2.1f%s " , ( tag_data_ptr [ isr ] & 0x7F ) * 0.5 , ( tag_data_ptr [ isr ] & 0x80 ) ? "(B)" : "" ); 262
proto_tree_add_string ( bss_tree , hf_waveagent_ifwlansupprates , tvb , offset + 36 , tag_len , wmem_strbuf_get_str ( sb ) ); 274
proto_tree_add_item ( bss_tree , hf_waveagent_scanbssid , tvb , current_offset + 56 , 6 , ENC_NA ); 277
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlancapabilities , tvb , current_offset + 62 , 2 , ENC_BIG_ENDIAN ); 280
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanrssi , tvb , current_offset + 64 , 4 , ENC_BIG_ENDIAN ); 283
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlansigquality , tvb , current_offset + 68 , 4 , ENC_BIG_ENDIAN ); 288
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanchannel , tvb , current_offset + 72 , 4 , ENC_BIG_ENDIAN ); 291
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanprivacy , tvb , current_offset + 76 , 4 , ENC_BIG_ENDIAN ); 294
proto_tree_add_item ( bss_tree , hf_waveagent_ifwlanbssmode , tvb , current_offset + 80 , 4 , ENC_BIG_ENDIAN ); 297
proto_tree_add_item ( parent_tree , hf_waveagent_scanbssid , tvb , current_offset , 6 , ENC_NA ); 497
------------------------------
635 /home/speedy/test/source2slice/NVD/CVE_2015_6249_PATCHED_dissect_wccp2r1_address_table_info.c wccp_wccp_address_table . table_ipv6 = ( struct e_in6_addr * ) wmem_alloc0 ( pinfo -> pool , wccp_wccp_address_table . table_length * sizeof ( struct e_in6_addr ) ) 50
static gint
CVE_2015_6249_PATCHED_dissect_wccp2r1_address_table_info(tvbuff_t *tvb, int offset, int length,
packet_info *pinfo, proto_tree *info_tree) 3
gint16 family ; 7
guint16 table_length ; 8
if ( length < 2 * 4 )  15
family = tvb_get_ntohs ( tvb , offset ); 18
table_length = tvb_get_ntohl ( tvb , offset ); 26
if ( wccp_wccp_address_table . in_use == FALSE )  31
wccp_wccp_address_table . family = family; 32
wccp_wccp_address_table . table_length = table_length; 33
switch ( wccp_wccp_address_table . family )  36
if ( wccp_wccp_address_table . table_ipv6 == NULL )  49
wccp_wccp_address_table . table_ipv6 = ( struct e_in6_addr * ) wmem_alloc0 ( pinfo -> pool , wccp_wccp_address_table . table_length * sizeof ( struct e_in6_addr ) ); 50
expert_add_info_format ( pinfo , tf , & ei_wccp_address_table_family_unknown , "Unknown address family: %d" , wccp_wccp_address_table . family ); 60
if ( ( wccp_wccp_address_table . in_use == FALSE ) && ( wccp_wccp_address_table . table_ipv4 != NULL ) && ( ( address_length * i ) < wccp_wccp_address_table . table_length ) )  74
wccp_wccp_address_table . table_ipv4 [ i ] = tvb_get_ntohl ( tvb , offset ); 77
if ( ( wccp_wccp_address_table . in_use == FALSE ) && ( wccp_wccp_address_table . table_ipv6 != NULL ) && ( i < wccp_wccp_address_table . table_length ) )  82
tvb_get_ipv6 ( tvb , offset , & ( wccp_wccp_address_table . table_ipv6 [ i ] ) ); 85
addr = wmem_strdup_printf ( wmem_packet_scope ( ) , "unknown family %d" , wccp_wccp_address_table . family ); 88
pi = proto_tree_add_string_format_value ( element_tree , hf_address_table_element , tvb , offset , address_length , addr , "%d: %s" , i + 1 , addr ); 94
if ( i > wccp_wccp_address_table . table_length )  97
expert_add_info_format ( pinfo , pi , & ei_wccp_length_bad , "Ran out of space to store address" ); 98
wccp_wccp_address_table . in_use = TRUE; 103
------------------------------
636 /home/speedy/test/source2slice/NVD/CVE_2015_6249_VULN_dissect_wccp2r1_address_table_info.c wccp_wccp_address_table . table_ipv6 = ( struct e_in6_addr * ) wmem_alloc0 ( pinfo -> pool , wccp_wccp_address_table . table_length * sizeof ( struct e_in6_addr ) ) 51
static gint
CVE_2015_6249_VULN_dissect_wccp2r1_address_table_info(tvbuff_t *tvb, int offset, int length,
packet_info *pinfo, proto_tree *info_tree) 3
gint16 family ; 7
guint16 table_length ; 8
if ( length < 2 * 4 )  15
family = tvb_get_ntohs ( tvb , offset ); 18
table_length = tvb_get_ntohl ( tvb , offset ); 26
if ( wccp_wccp_address_table . in_use == FALSE )  31
wccp_wccp_address_table . in_use = TRUE; 32
wccp_wccp_address_table . family = family; 33
wccp_wccp_address_table . table_length = table_length; 34
switch ( wccp_wccp_address_table . family )  37
if ( wccp_wccp_address_table . table_ipv6 == NULL )  50
wccp_wccp_address_table . table_ipv6 = ( struct e_in6_addr * ) wmem_alloc0 ( pinfo -> pool , wccp_wccp_address_table . table_length * sizeof ( struct e_in6_addr ) ); 51
expert_add_info_format ( pinfo , tf , & ei_wccp_address_table_family_unknown , "Unknown address family: %d" , wccp_wccp_address_table . family ); 61
if ( ( wccp_wccp_address_table . table_ipv4 != NULL ) && ( ( address_length * i ) < wccp_wccp_address_table . table_length ) )  75
wccp_wccp_address_table . table_ipv4 [ i ] = tvb_get_ntohl ( tvb , offset ); 76
if ( ( wccp_wccp_address_table . table_ipv6 != NULL ) && ( ( address_length * i ) < wccp_wccp_address_table . table_length ) )  81
tvb_get_ipv6 ( tvb , offset , & ( wccp_wccp_address_table . table_ipv6 [ i ] ) ); 82
addr = wmem_strdup_printf ( wmem_packet_scope ( ) , "unknown family %d" , wccp_wccp_address_table . family ); 85
pi = proto_tree_add_string_format_value ( element_tree , hf_address_table_element , tvb , offset , address_length , addr , "%d: %s" , i + 1 , addr ); 91
if ( ( address_length * i ) > wccp_wccp_address_table . table_length )  94
expert_add_info_format ( pinfo , pi , & ei_wccp_length_bad , "Ran out of space to store address" ); 95
------------------------------
637 /home/speedy/test/source2slice/NVD/CVE-2015-1872_VULN_ff_mjpeg_decode_sof.c int size = bw * bh * s -> h_count [ i ] * s -> v_count [ i ] ; 364
int ff_mjpeg_decode_sof(MJpegDecodeContext *s) 1
int len , nb_components , i , width , height , bits , ret ; 3
unsigned pix_fmt_id ; 4
int h_count [ MAX_COMPONENTS ] ; 5
int v_count [ MAX_COMPONENTS ] ; 6
s -> cur_scan = 0; 8
s -> upscale_h = s -> upscale_v = 0; 9
s -> avctx -> bits_per_raw_sample = bits = get_bits ( & s -> gb , 8 ); 13
if ( bits > 16 || bits < 1 )  16
if ( s -> pegasus_rct )  21
bits = 9; 22
if ( bits == 9 && ! s -> pegasus_rct )  23
s -> rct = 1; 24
if ( s -> lossless && s -> avctx -> lowres )  26
height = get_bits ( & s -> gb , 16 ); 31
width = get_bits ( & s -> gb , 16 ); 32
if ( s -> interlaced && s -> width == width && s -> height == height + 1 )  38
height = s -> height; 39
if ( av_image_check_size ( width , height , 0 , s -> avctx ) )  42
nb_components = get_bits ( & s -> gb , 8 ); 45
if ( nb_components <= 0 || nb_components > MAX_COMPONENTS )  46
if ( s -> interlaced && ( s -> bottom_field == ! s -> interlace_polarity ) )  49
if ( nb_components != s -> nb_components )  50
if ( s -> ls && ! ( bits <= 8 || nb_components == 1 ) )  56
s -> nb_components = nb_components; 62
s -> h_max = 1; 63
s -> v_max = 1; 64
memset ( h_count , 0 , sizeof ( h_count ) ); 65
memset ( v_count , 0 , sizeof ( v_count ) ); 66
for (i = 0; i < nb_components; i++) 67
s -> component_id [ i ] = get_bits ( & s -> gb , 8 ) - 1; 69
h_count [ i ] = get_bits ( & s -> gb , 4 ); 70
v_count [ i ] = get_bits ( & s -> gb , 4 ); 71
if ( h_count [ i ] > s -> h_max )  73
s -> h_max = h_count [ i ]; 74
if ( v_count [ i ] > s -> v_max )  75
s -> v_max = v_count [ i ]; 76
s -> quant_index [ i ] = get_bits ( & s -> gb , 8 ); 77
if ( s -> quant_index [ i ] >= 4 )  78
if ( ! h_count [ i ] || ! v_count [ i ] )  82
if ( s -> ls && ( s -> h_max > 1 || s -> v_max > 1 ) )  94
if ( width != s -> width || height != s -> height || bits != s -> bits || memcmp ( s -> h_count , h_count , sizeof ( h_count ) ) || memcmp ( s -> v_count , v_count , sizeof ( v_count ) ) )  101
s -> width = width; 106
s -> height = height; 107
s -> bits = bits; 108
memcpy ( s -> h_count , h_count , sizeof ( h_count ) ); 109
memcpy ( s -> v_count , v_count , sizeof ( v_count ) ); 110
s -> interlaced = 0; 111
s -> got_picture = 0; 112
if ( s -> first_picture && s -> org_height != 0 && s -> height < ( ( s -> org_height * 3 ) / 4 ) )  115
s -> interlaced = 1; 118
s -> bottom_field = s -> interlace_polarity; 119
s -> picture_ptr -> interlaced_frame = 1; 120
s -> picture_ptr -> top_field_first = ! s -> interlace_polarity; 121
height *= 2; 122
ret = ff_set_dimensions ( s -> avctx , width , height ); 125
if ( ret < 0 )  126
s -> first_picture = 0; 129
if ( s -> got_picture && s -> interlaced && ( s -> bottom_field == ! s -> interlace_polarity ) )  132
if ( s -> progressive )  133
if ( s -> v_max == 1 && s -> h_max == 1 && s -> lossless == 1 && ( nb_components == 3 || nb_components == 4 ) )  138
s -> rgb = 1; 139
if ( ! s -> lossless )  140
s -> rgb = 0; 141
pix_fmt_id = ( ( unsigned ) s -> h_count [ 0 ] << 28 ) | ( s -> v_count [ 0 ] << 24 ) | ( s -> h_count [ 1 ] << 20 ) | ( s -> v_count [ 1 ] << 16 ) | ( s -> h_count [ 2 ] << 12 ) | ( s -> v_count [ 2 ] << 8 ) | ( s -> h_count [ 3 ] << 4 ) | s -> v_count [ 3 ]; 143
if ( ! ( pix_fmt_id & 0xD0D0D0D0 ) )  150
pix_fmt_id -= ( pix_fmt_id & 0xF0F0F0F0 ) >> 1; 151
if ( ! ( pix_fmt_id & 0x0D0D0D0D ) )  152
pix_fmt_id -= ( pix_fmt_id & 0x0F0F0F0F ) >> 1; 153
for (i = 0; i < 8; i++) 155
int j = 6 + ( i & 1 ) - ( i & 6 ) ; 156
int is = ( pix_fmt_id >> ( 4 * i ) ) & 0xF ; 157
int js = ( pix_fmt_id >> ( 4 * j ) ) & 0xF ; 158
if ( is == 1 && js != 2 && ( i < 2 || i > 5 ) )  160
js = ( pix_fmt_id >> ( 8 + 4 * ( i & 1 ) ) ) & 0xF; 161
if ( is == 1 && js != 2 && ( i < 2 || i > 5 ) )  162
js = ( pix_fmt_id >> ( 16 + 4 * ( i & 1 ) ) ) & 0xF; 163
if ( is == 1 && js == 2 )  165
if ( i & 1 )  166
s -> upscale_h |= 1 << ( j / 2 ); 166
s -> upscale_v |= 1 << ( j / 2 ); 167
switch ( pix_fmt_id )  171
if ( s -> rgb )  173
s -> avctx -> pix_fmt = s -> bits <= 9 ? AV_PIX_FMT_BGR24 : AV_PIX_FMT_BGR48; 174
if ( s -> component_id [ 0 ] == 'Q' && s -> component_id [ 1 ] == 'F' && s -> component_id [ 2 ] == 'A' )  176
s -> avctx -> pix_fmt = s -> bits <= 8 ? AV_PIX_FMT_GBRP : AV_PIX_FMT_GBRP16; 177
if ( s -> bits <= 8 )  179
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P; 179
s -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P16; 180
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 181
if ( s -> rgb )  187
s -> avctx -> pix_fmt = s -> bits <= 9 ? AV_PIX_FMT_ABGR : AV_PIX_FMT_RGBA64; 188
if ( s -> adobe_transform == 0 && s -> bits <= 8 )  190
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRAP; 191
s -> avctx -> pix_fmt = s -> bits <= 8 ? AV_PIX_FMT_YUVA444P : AV_PIX_FMT_YUVA444P16; 193
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 194
if ( s -> adobe_transform == 0 && s -> bits <= 8 )  201
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRAP; 202
s -> upscale_v |= 6; 203
s -> upscale_h |= 6; 204
if ( s -> adobe_transform == 2 && s -> bits <= 8 )  205
s -> avctx -> pix_fmt = AV_PIX_FMT_YUVA444P; 206
s -> upscale_v |= 6; 207
s -> upscale_h |= 6; 208
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 209
if ( s -> bits <= 8 )  211
s -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P; 211
s -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P16; 212
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 213
if ( s -> bits <= 8 )  221
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P; 221
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 224
if ( s -> bits <= 8 )  229
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P; 229
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 232
if ( s -> bits <= 8 )  243
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 244
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 246
if ( s -> component_id [ 0 ] == 'Q' && s -> component_id [ 1 ] == 'F' && s -> component_id [ 2 ] == 'A' )  253
if ( s -> bits <= 8 )  254
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRP; 254
s -> upscale_v |= 3; 257
if ( pix_fmt_id == 0x14111100 )  259
s -> upscale_v |= 6; 260
if ( s -> bits <= 8 )  261
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV440P : AV_PIX_FMT_YUVJ440P; 261
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 264
if ( s -> component_id [ 0 ] == 'Q' && s -> component_id [ 1 ] == 'F' && s -> component_id [ 2 ] == 'A' )  268
if ( s -> bits <= 8 )  269
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRP; 269
s -> upscale_h |= 3; 272
if ( s -> bits <= 8 )  274
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV422P : AV_PIX_FMT_YUVJ422P; 274
s -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P16; 275
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 276
if ( s -> bits <= 8 )  281
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV422P : AV_PIX_FMT_YUVJ422P; 281
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 284
if ( s -> bits <= 8 )  289
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV420P : AV_PIX_FMT_YUVJ420P; 289
s -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P16; 290
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 291
if ( pix_fmt_id == 0x42111100 )  292
if ( s -> bits > 8 )  293
s -> upscale_h = 6; 295
if ( pix_fmt_id == 0x24111100 )  296
if ( s -> bits > 8 )  297
s -> upscale_v = 6; 299
if ( s -> bits <= 8 )  303
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV411P : AV_PIX_FMT_YUVJ411P; 303
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 306
if ( ( s -> upscale_h || s -> upscale_v ) && s -> avctx -> lowres )  314
if ( s -> ls )  318
s -> upscale_h = s -> upscale_v = 0; 319
if ( s -> nb_components > 1 )  320
s -> avctx -> pix_fmt = AV_PIX_FMT_RGB24; 321
if ( s -> palette_index && s -> bits <= 8 )  322
s -> avctx -> pix_fmt = AV_PIX_FMT_PAL8; 323
if ( s -> bits <= 8 )  324
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 325
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 327
s -> pix_desc = av_pix_fmt_desc_get ( s -> avctx -> pix_fmt ); 330
if ( ! s -> pix_desc )  331
if ( ff_get_buffer ( s -> avctx , s -> picture_ptr , AV_GET_BUFFER_FLAG_REF ) < 0 )  337
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
s -> picture_ptr -> pict_type = AV_PICTURE_TYPE_I; 339
s -> picture_ptr -> key_frame = 1; 340
s -> got_picture = 1; 341
for (i = 0; i < 4; i++) 343
s -> linesize [ i ] = s -> picture_ptr -> linesize [ i ] << s -> interlaced; 344
if ( s -> rgb && ! s -> lossless && ! s -> ls )  354
if ( s -> progressive )  360
int bw = ( width + s -> h_max * 8 - 1 ) / ( s -> h_max * 8 ) ; 361
int bh = ( height + s -> v_max * 8 - 1 ) / ( s -> v_max * 8 ) ; 362
for (i = 0; i < s->nb_components; i++) 363
int size = bw * bh * s -> h_count [ i ] * s -> v_count [ i ] ; 364
s -> blocks [ i ] = av_mallocz_array ( size , sizeof ( * * s -> blocks ) ); 367
s -> last_nnz [ i ] = av_mallocz_array ( size , sizeof ( * * s -> last_nnz ) ); 368
if ( ! s -> blocks [ i ] || ! s -> last_nnz [ i ] )  369
s -> block_stride [ i ] = bw * s -> h_count [ i ]; 371
memset ( s -> coefs_finished , 0 , sizeof ( s -> coefs_finished ) ); 373
------------------------------
638 /home/speedy/test/source2slice/NVD/CVE-2015-1872_VULN_ff_mjpeg_decode_sof.c int bh = ( height + s -> v_max * 8 - 1 ) / ( s -> v_max * 8 ) ; 362
int ff_mjpeg_decode_sof(MJpegDecodeContext *s) 1
int len , nb_components , i , width , height , bits , ret ; 3
unsigned pix_fmt_id ; 4
int h_count [ MAX_COMPONENTS ] ; 5
int v_count [ MAX_COMPONENTS ] ; 6
s -> cur_scan = 0; 8
s -> upscale_h = s -> upscale_v = 0; 9
s -> avctx -> bits_per_raw_sample = bits = get_bits ( & s -> gb , 8 ); 13
if ( bits > 16 || bits < 1 )  16
if ( s -> pegasus_rct )  21
bits = 9; 22
if ( bits == 9 && ! s -> pegasus_rct )  23
s -> rct = 1; 24
if ( s -> lossless && s -> avctx -> lowres )  26
height = get_bits ( & s -> gb , 16 ); 31
width = get_bits ( & s -> gb , 16 ); 32
if ( s -> interlaced && s -> width == width && s -> height == height + 1 )  38
height = s -> height; 39
if ( av_image_check_size ( width , height , 0 , s -> avctx ) )  42
nb_components = get_bits ( & s -> gb , 8 ); 45
if ( nb_components <= 0 || nb_components > MAX_COMPONENTS )  46
if ( s -> interlaced && ( s -> bottom_field == ! s -> interlace_polarity ) )  49
if ( nb_components != s -> nb_components )  50
if ( s -> ls && ! ( bits <= 8 || nb_components == 1 ) )  56
s -> nb_components = nb_components; 62
s -> h_max = 1; 63
s -> v_max = 1; 64
memset ( h_count , 0 , sizeof ( h_count ) ); 65
memset ( v_count , 0 , sizeof ( v_count ) ); 66
for (i = 0; i < nb_components; i++) 67
s -> component_id [ i ] = get_bits ( & s -> gb , 8 ) - 1; 69
h_count [ i ] = get_bits ( & s -> gb , 4 ); 70
v_count [ i ] = get_bits ( & s -> gb , 4 ); 71
if ( h_count [ i ] > s -> h_max )  73
s -> h_max = h_count [ i ]; 74
if ( v_count [ i ] > s -> v_max )  75
s -> v_max = v_count [ i ]; 76
s -> quant_index [ i ] = get_bits ( & s -> gb , 8 ); 77
if ( s -> quant_index [ i ] >= 4 )  78
if ( ! h_count [ i ] || ! v_count [ i ] )  82
if ( s -> ls && ( s -> h_max > 1 || s -> v_max > 1 ) )  94
if ( width != s -> width || height != s -> height || bits != s -> bits || memcmp ( s -> h_count , h_count , sizeof ( h_count ) ) || memcmp ( s -> v_count , v_count , sizeof ( v_count ) ) )  101
s -> width = width; 106
s -> height = height; 107
s -> bits = bits; 108
memcpy ( s -> h_count , h_count , sizeof ( h_count ) ); 109
memcpy ( s -> v_count , v_count , sizeof ( v_count ) ); 110
s -> interlaced = 0; 111
s -> got_picture = 0; 112
if ( s -> first_picture && s -> org_height != 0 && s -> height < ( ( s -> org_height * 3 ) / 4 ) )  115
s -> interlaced = 1; 118
s -> bottom_field = s -> interlace_polarity; 119
s -> picture_ptr -> interlaced_frame = 1; 120
s -> picture_ptr -> top_field_first = ! s -> interlace_polarity; 121
height *= 2; 122
ret = ff_set_dimensions ( s -> avctx , width , height ); 125
if ( ret < 0 )  126
s -> first_picture = 0; 129
if ( s -> got_picture && s -> interlaced && ( s -> bottom_field == ! s -> interlace_polarity ) )  132
if ( s -> progressive )  133
if ( s -> v_max == 1 && s -> h_max == 1 && s -> lossless == 1 && ( nb_components == 3 || nb_components == 4 ) )  138
s -> rgb = 1; 139
if ( ! s -> lossless )  140
s -> rgb = 0; 141
pix_fmt_id = ( ( unsigned ) s -> h_count [ 0 ] << 28 ) | ( s -> v_count [ 0 ] << 24 ) | ( s -> h_count [ 1 ] << 20 ) | ( s -> v_count [ 1 ] << 16 ) | ( s -> h_count [ 2 ] << 12 ) | ( s -> v_count [ 2 ] << 8 ) | ( s -> h_count [ 3 ] << 4 ) | s -> v_count [ 3 ]; 143
if ( ! ( pix_fmt_id & 0xD0D0D0D0 ) )  150
pix_fmt_id -= ( pix_fmt_id & 0xF0F0F0F0 ) >> 1; 151
if ( ! ( pix_fmt_id & 0x0D0D0D0D ) )  152
pix_fmt_id -= ( pix_fmt_id & 0x0F0F0F0F ) >> 1; 153
for (i = 0; i < 8; i++) 155
int j = 6 + ( i & 1 ) - ( i & 6 ) ; 156
int is = ( pix_fmt_id >> ( 4 * i ) ) & 0xF ; 157
int js = ( pix_fmt_id >> ( 4 * j ) ) & 0xF ; 158
if ( is == 1 && js != 2 && ( i < 2 || i > 5 ) )  160
js = ( pix_fmt_id >> ( 8 + 4 * ( i & 1 ) ) ) & 0xF; 161
if ( is == 1 && js != 2 && ( i < 2 || i > 5 ) )  162
js = ( pix_fmt_id >> ( 16 + 4 * ( i & 1 ) ) ) & 0xF; 163
if ( is == 1 && js == 2 )  165
if ( i & 1 )  166
s -> upscale_h |= 1 << ( j / 2 ); 166
s -> upscale_v |= 1 << ( j / 2 ); 167
switch ( pix_fmt_id )  171
if ( s -> rgb )  173
s -> avctx -> pix_fmt = s -> bits <= 9 ? AV_PIX_FMT_BGR24 : AV_PIX_FMT_BGR48; 174
if ( s -> component_id [ 0 ] == 'Q' && s -> component_id [ 1 ] == 'F' && s -> component_id [ 2 ] == 'A' )  176
s -> avctx -> pix_fmt = s -> bits <= 8 ? AV_PIX_FMT_GBRP : AV_PIX_FMT_GBRP16; 177
if ( s -> bits <= 8 )  179
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P; 179
s -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P16; 180
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 181
if ( s -> rgb )  187
s -> avctx -> pix_fmt = s -> bits <= 9 ? AV_PIX_FMT_ABGR : AV_PIX_FMT_RGBA64; 188
if ( s -> adobe_transform == 0 && s -> bits <= 8 )  190
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRAP; 191
s -> avctx -> pix_fmt = s -> bits <= 8 ? AV_PIX_FMT_YUVA444P : AV_PIX_FMT_YUVA444P16; 193
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 194
if ( s -> adobe_transform == 0 && s -> bits <= 8 )  201
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRAP; 202
s -> upscale_v |= 6; 203
s -> upscale_h |= 6; 204
if ( s -> adobe_transform == 2 && s -> bits <= 8 )  205
s -> avctx -> pix_fmt = AV_PIX_FMT_YUVA444P; 206
s -> upscale_v |= 6; 207
s -> upscale_h |= 6; 208
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 209
if ( s -> bits <= 8 )  211
s -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P; 211
s -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P16; 212
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 213
if ( s -> bits <= 8 )  221
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P; 221
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 224
if ( s -> bits <= 8 )  229
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P; 229
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 232
if ( s -> bits <= 8 )  243
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 244
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 246
if ( s -> component_id [ 0 ] == 'Q' && s -> component_id [ 1 ] == 'F' && s -> component_id [ 2 ] == 'A' )  253
if ( s -> bits <= 8 )  254
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRP; 254
s -> upscale_v |= 3; 257
if ( pix_fmt_id == 0x14111100 )  259
s -> upscale_v |= 6; 260
if ( s -> bits <= 8 )  261
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV440P : AV_PIX_FMT_YUVJ440P; 261
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 264
if ( s -> component_id [ 0 ] == 'Q' && s -> component_id [ 1 ] == 'F' && s -> component_id [ 2 ] == 'A' )  268
if ( s -> bits <= 8 )  269
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRP; 269
s -> upscale_h |= 3; 272
if ( s -> bits <= 8 )  274
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV422P : AV_PIX_FMT_YUVJ422P; 274
s -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P16; 275
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 276
if ( s -> bits <= 8 )  281
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV422P : AV_PIX_FMT_YUVJ422P; 281
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 284
if ( s -> bits <= 8 )  289
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV420P : AV_PIX_FMT_YUVJ420P; 289
s -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P16; 290
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 291
if ( pix_fmt_id == 0x42111100 )  292
if ( s -> bits > 8 )  293
s -> upscale_h = 6; 295
if ( pix_fmt_id == 0x24111100 )  296
if ( s -> bits > 8 )  297
s -> upscale_v = 6; 299
if ( s -> bits <= 8 )  303
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV411P : AV_PIX_FMT_YUVJ411P; 303
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 306
if ( ( s -> upscale_h || s -> upscale_v ) && s -> avctx -> lowres )  314
if ( s -> ls )  318
s -> upscale_h = s -> upscale_v = 0; 319
if ( s -> nb_components > 1 )  320
s -> avctx -> pix_fmt = AV_PIX_FMT_RGB24; 321
if ( s -> palette_index && s -> bits <= 8 )  322
s -> avctx -> pix_fmt = AV_PIX_FMT_PAL8; 323
if ( s -> bits <= 8 )  324
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 325
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 327
s -> pix_desc = av_pix_fmt_desc_get ( s -> avctx -> pix_fmt ); 330
if ( ! s -> pix_desc )  331
if ( ff_get_buffer ( s -> avctx , s -> picture_ptr , AV_GET_BUFFER_FLAG_REF ) < 0 )  337
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
s -> picture_ptr -> pict_type = AV_PICTURE_TYPE_I; 339
s -> picture_ptr -> key_frame = 1; 340
s -> got_picture = 1; 341
for (i = 0; i < 4; i++) 343
s -> linesize [ i ] = s -> picture_ptr -> linesize [ i ] << s -> interlaced; 344
if ( s -> rgb && ! s -> lossless && ! s -> ls )  354
if ( s -> progressive )  360
int bh = ( height + s -> v_max * 8 - 1 ) / ( s -> v_max * 8 ) ; 362
int size = bw * bh * s -> h_count [ i ] * s -> v_count [ i ] ; 364
s -> blocks [ i ] = av_mallocz_array ( size , sizeof ( * * s -> blocks ) ); 367
s -> last_nnz [ i ] = av_mallocz_array ( size , sizeof ( * * s -> last_nnz ) ); 368
if ( ! s -> blocks [ i ] || ! s -> last_nnz [ i ] )  369
s -> block_stride [ i ] = bw * s -> h_count [ i ]; 371
memset ( s -> coefs_finished , 0 , sizeof ( s -> coefs_finished ) ); 373
------------------------------
639 /home/speedy/test/source2slice/NVD/CVE-2015-1872_VULN_ff_mjpeg_decode_sof.c int bw = ( width + s -> h_max * 8 - 1 ) / ( s -> h_max * 8 ) ; 361
int ff_mjpeg_decode_sof(MJpegDecodeContext *s) 1
int len , nb_components , i , width , height , bits , ret ; 3
unsigned pix_fmt_id ; 4
int h_count [ MAX_COMPONENTS ] ; 5
int v_count [ MAX_COMPONENTS ] ; 6
s -> cur_scan = 0; 8
s -> upscale_h = s -> upscale_v = 0; 9
s -> avctx -> bits_per_raw_sample = bits = get_bits ( & s -> gb , 8 ); 13
if ( bits > 16 || bits < 1 )  16
if ( s -> pegasus_rct )  21
bits = 9; 22
if ( bits == 9 && ! s -> pegasus_rct )  23
s -> rct = 1; 24
if ( s -> lossless && s -> avctx -> lowres )  26
height = get_bits ( & s -> gb , 16 ); 31
width = get_bits ( & s -> gb , 16 ); 32
if ( s -> interlaced && s -> width == width && s -> height == height + 1 )  38
height = s -> height; 39
if ( av_image_check_size ( width , height , 0 , s -> avctx ) )  42
nb_components = get_bits ( & s -> gb , 8 ); 45
if ( nb_components <= 0 || nb_components > MAX_COMPONENTS )  46
if ( s -> interlaced && ( s -> bottom_field == ! s -> interlace_polarity ) )  49
if ( nb_components != s -> nb_components )  50
if ( s -> ls && ! ( bits <= 8 || nb_components == 1 ) )  56
s -> nb_components = nb_components; 62
s -> h_max = 1; 63
s -> v_max = 1; 64
memset ( h_count , 0 , sizeof ( h_count ) ); 65
memset ( v_count , 0 , sizeof ( v_count ) ); 66
for (i = 0; i < nb_components; i++) 67
s -> component_id [ i ] = get_bits ( & s -> gb , 8 ) - 1; 69
h_count [ i ] = get_bits ( & s -> gb , 4 ); 70
v_count [ i ] = get_bits ( & s -> gb , 4 ); 71
if ( h_count [ i ] > s -> h_max )  73
s -> h_max = h_count [ i ]; 74
if ( v_count [ i ] > s -> v_max )  75
s -> v_max = v_count [ i ]; 76
s -> quant_index [ i ] = get_bits ( & s -> gb , 8 ); 77
if ( s -> quant_index [ i ] >= 4 )  78
if ( ! h_count [ i ] || ! v_count [ i ] )  82
if ( s -> ls && ( s -> h_max > 1 || s -> v_max > 1 ) )  94
if ( width != s -> width || height != s -> height || bits != s -> bits || memcmp ( s -> h_count , h_count , sizeof ( h_count ) ) || memcmp ( s -> v_count , v_count , sizeof ( v_count ) ) )  101
s -> width = width; 106
s -> height = height; 107
s -> bits = bits; 108
memcpy ( s -> h_count , h_count , sizeof ( h_count ) ); 109
memcpy ( s -> v_count , v_count , sizeof ( v_count ) ); 110
s -> interlaced = 0; 111
s -> got_picture = 0; 112
if ( s -> first_picture && s -> org_height != 0 && s -> height < ( ( s -> org_height * 3 ) / 4 ) )  115
s -> interlaced = 1; 118
s -> bottom_field = s -> interlace_polarity; 119
s -> picture_ptr -> interlaced_frame = 1; 120
s -> picture_ptr -> top_field_first = ! s -> interlace_polarity; 121
height *= 2; 122
ret = ff_set_dimensions ( s -> avctx , width , height ); 125
if ( ret < 0 )  126
s -> first_picture = 0; 129
if ( s -> got_picture && s -> interlaced && ( s -> bottom_field == ! s -> interlace_polarity ) )  132
if ( s -> progressive )  133
if ( s -> v_max == 1 && s -> h_max == 1 && s -> lossless == 1 && ( nb_components == 3 || nb_components == 4 ) )  138
s -> rgb = 1; 139
if ( ! s -> lossless )  140
s -> rgb = 0; 141
pix_fmt_id = ( ( unsigned ) s -> h_count [ 0 ] << 28 ) | ( s -> v_count [ 0 ] << 24 ) | ( s -> h_count [ 1 ] << 20 ) | ( s -> v_count [ 1 ] << 16 ) | ( s -> h_count [ 2 ] << 12 ) | ( s -> v_count [ 2 ] << 8 ) | ( s -> h_count [ 3 ] << 4 ) | s -> v_count [ 3 ]; 143
if ( ! ( pix_fmt_id & 0xD0D0D0D0 ) )  150
pix_fmt_id -= ( pix_fmt_id & 0xF0F0F0F0 ) >> 1; 151
if ( ! ( pix_fmt_id & 0x0D0D0D0D ) )  152
pix_fmt_id -= ( pix_fmt_id & 0x0F0F0F0F ) >> 1; 153
for (i = 0; i < 8; i++) 155
int j = 6 + ( i & 1 ) - ( i & 6 ) ; 156
int is = ( pix_fmt_id >> ( 4 * i ) ) & 0xF ; 157
int js = ( pix_fmt_id >> ( 4 * j ) ) & 0xF ; 158
if ( is == 1 && js != 2 && ( i < 2 || i > 5 ) )  160
js = ( pix_fmt_id >> ( 8 + 4 * ( i & 1 ) ) ) & 0xF; 161
if ( is == 1 && js != 2 && ( i < 2 || i > 5 ) )  162
js = ( pix_fmt_id >> ( 16 + 4 * ( i & 1 ) ) ) & 0xF; 163
if ( is == 1 && js == 2 )  165
if ( i & 1 )  166
s -> upscale_h |= 1 << ( j / 2 ); 166
s -> upscale_v |= 1 << ( j / 2 ); 167
switch ( pix_fmt_id )  171
if ( s -> rgb )  173
s -> avctx -> pix_fmt = s -> bits <= 9 ? AV_PIX_FMT_BGR24 : AV_PIX_FMT_BGR48; 174
if ( s -> component_id [ 0 ] == 'Q' && s -> component_id [ 1 ] == 'F' && s -> component_id [ 2 ] == 'A' )  176
s -> avctx -> pix_fmt = s -> bits <= 8 ? AV_PIX_FMT_GBRP : AV_PIX_FMT_GBRP16; 177
if ( s -> bits <= 8 )  179
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P; 179
s -> avctx -> pix_fmt = AV_PIX_FMT_YUV444P16; 180
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 181
if ( s -> rgb )  187
s -> avctx -> pix_fmt = s -> bits <= 9 ? AV_PIX_FMT_ABGR : AV_PIX_FMT_RGBA64; 188
if ( s -> adobe_transform == 0 && s -> bits <= 8 )  190
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRAP; 191
s -> avctx -> pix_fmt = s -> bits <= 8 ? AV_PIX_FMT_YUVA444P : AV_PIX_FMT_YUVA444P16; 193
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 194
if ( s -> adobe_transform == 0 && s -> bits <= 8 )  201
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRAP; 202
s -> upscale_v |= 6; 203
s -> upscale_h |= 6; 204
if ( s -> adobe_transform == 2 && s -> bits <= 8 )  205
s -> avctx -> pix_fmt = AV_PIX_FMT_YUVA444P; 206
s -> upscale_v |= 6; 207
s -> upscale_h |= 6; 208
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 209
if ( s -> bits <= 8 )  211
s -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P; 211
s -> avctx -> pix_fmt = AV_PIX_FMT_YUVA420P16; 212
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 213
if ( s -> bits <= 8 )  221
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P; 221
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 224
if ( s -> bits <= 8 )  229
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P; 229
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 232
if ( s -> bits <= 8 )  243
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 244
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 246
if ( s -> component_id [ 0 ] == 'Q' && s -> component_id [ 1 ] == 'F' && s -> component_id [ 2 ] == 'A' )  253
if ( s -> bits <= 8 )  254
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRP; 254
s -> upscale_v |= 3; 257
if ( pix_fmt_id == 0x14111100 )  259
s -> upscale_v |= 6; 260
if ( s -> bits <= 8 )  261
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV440P : AV_PIX_FMT_YUVJ440P; 261
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 264
if ( s -> component_id [ 0 ] == 'Q' && s -> component_id [ 1 ] == 'F' && s -> component_id [ 2 ] == 'A' )  268
if ( s -> bits <= 8 )  269
s -> avctx -> pix_fmt = AV_PIX_FMT_GBRP; 269
s -> upscale_h |= 3; 272
if ( s -> bits <= 8 )  274
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV422P : AV_PIX_FMT_YUVJ422P; 274
s -> avctx -> pix_fmt = AV_PIX_FMT_YUV422P16; 275
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 276
if ( s -> bits <= 8 )  281
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV422P : AV_PIX_FMT_YUVJ422P; 281
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 284
if ( s -> bits <= 8 )  289
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV420P : AV_PIX_FMT_YUVJ420P; 289
s -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P16; 290
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 291
if ( pix_fmt_id == 0x42111100 )  292
if ( s -> bits > 8 )  293
s -> upscale_h = 6; 295
if ( pix_fmt_id == 0x24111100 )  296
if ( s -> bits > 8 )  297
s -> upscale_v = 6; 299
if ( s -> bits <= 8 )  303
s -> avctx -> pix_fmt = s -> cs_itu601 ? AV_PIX_FMT_YUV411P : AV_PIX_FMT_YUVJ411P; 303
s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG; 306
if ( ( s -> upscale_h || s -> upscale_v ) && s -> avctx -> lowres )  314
if ( s -> ls )  318
s -> upscale_h = s -> upscale_v = 0; 319
if ( s -> nb_components > 1 )  320
s -> avctx -> pix_fmt = AV_PIX_FMT_RGB24; 321
if ( s -> palette_index && s -> bits <= 8 )  322
s -> avctx -> pix_fmt = AV_PIX_FMT_PAL8; 323
if ( s -> bits <= 8 )  324
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY8; 325
s -> avctx -> pix_fmt = AV_PIX_FMT_GRAY16; 327
s -> pix_desc = av_pix_fmt_desc_get ( s -> avctx -> pix_fmt ); 330
if ( ! s -> pix_desc )  331
if ( ff_get_buffer ( s -> avctx , s -> picture_ptr , AV_GET_BUFFER_FLAG_REF ) < 0 )  337
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
s -> picture_ptr -> pict_type = AV_PICTURE_TYPE_I; 339
s -> picture_ptr -> key_frame = 1; 340
s -> got_picture = 1; 341
for (i = 0; i < 4; i++) 343
s -> linesize [ i ] = s -> picture_ptr -> linesize [ i ] << s -> interlaced; 344
if ( s -> rgb && ! s -> lossless && ! s -> ls )  354
if ( s -> progressive )  360
int bw = ( width + s -> h_max * 8 - 1 ) / ( s -> h_max * 8 ) ; 361
int size = bw * bh * s -> h_count [ i ] * s -> v_count [ i ] ; 364
s -> blocks [ i ] = av_mallocz_array ( size , sizeof ( * * s -> blocks ) ); 367
s -> last_nnz [ i ] = av_mallocz_array ( size , sizeof ( * * s -> last_nnz ) ); 368
if ( ! s -> blocks [ i ] || ! s -> last_nnz [ i ] )  369
s -> block_stride [ i ] = bw * s -> h_count [ i ]; 371
memset ( s -> coefs_finished , 0 , sizeof ( s -> coefs_finished ) ); 373
------------------------------
640 /home/speedy/test/source2slice/NVD/CVE-2015-4002_VULN_oz_usb_rx.c int data_len = elt -> length - sizeof ( struct oz_get_desc_rsp ) + 1 ; 28
void oz_usb_rx(struct oz_pd *pd, struct oz_elt *elt) 1
struct oz_usb_hdr * usb_hdr = ( struct oz_usb_hdr * ) ( elt + 1 ) ; 3
struct oz_usb_ctx * usb_ctx ; 4
usb_ctx = ( struct oz_usb_ctx * ) pd -> app_ctx [ OZ_APPID_USB ]; 7
if ( usb_ctx == NULL )  11
if ( usb_ctx -> stopped )  13
if ( usb_hdr -> elt_seq_num != 0 )  18
if ( ( ( usb_ctx -> rx_seq_num - usb_hdr -> elt_seq_num ) & 0x80 ) == 0 )  19
switch ( usb_hdr -> type )  24
int data_len = elt -> length - sizeof ( struct oz_get_desc_rsp ) + 1 ; 28
oz_hcd_get_desc_cnf ( usb_ctx -> hport , body -> req_id , body -> rcode , body -> data , data_len , offs , total_size ); 34
------------------------------
641 /home/speedy/test/source2slice/NVD/CVE-2015-8785_VULN_fuse_fill_write_pages.c size_t bytes = min_t ( size_t , PAGE_CACHE_SIZE - offset , iov_iter_count ( ii ) ) ; 17
static ssize_t fuse_fill_write_pages(struct fuse_req *req,
struct address_space *mapping,
struct iov_iter *ii, loff_t pos) 3
struct fuse_conn * fc = get_fuse_conn ( mapping -> host ) ; 5
unsigned offset = pos & ( PAGE_CACHE_SIZE - 1 ) ; 6
size_t count = 0 ; 7
req -> in . argpages = 1; 10
req -> page_descs [ 0 ] . offset = offset; 11
size_t tmp ; 14
struct page * page ; 15
pgoff_t index = pos >> PAGE_CACHE_SHIFT ; 16
size_t bytes = min_t ( size_t , PAGE_CACHE_SIZE - offset , iov_iter_count ( ii ) ) ; 17
bytes = min_t ( size_t , bytes , fc -> max_write - count ); 20
if ( iov_iter_fault_in_readable ( ii , bytes ) )  24
page = grab_cache_page_write_begin ( mapping , index , 0 ); 28
if ( ! page )  29
flush_dcache_page ( page ); 33
tmp = iov_iter_copy_from_user_atomic ( page , ii , offset , bytes ); 35
flush_dcache_page ( page ); 36
if ( ! tmp )  38
unlock_page ( page ); 39
page_cache_release ( page ); 40
bytes = min ( bytes , iov_iter_single_seg_count ( ii ) ); 41
req -> pages [ req -> num_pages ] = page; 46
req -> page_descs [ req -> num_pages ] . length = tmp; 47
req -> num_pages ++; 48
iov_iter_advance ( ii , tmp ); 50
count += tmp; 51
pos += tmp; 52
offset += tmp; 53
if ( offset == PAGE_CACHE_SIZE )  54
offset = 0; 55
if ( ! fc -> big_writes )  57
while ( iov_iter_count ( ii ) && count < fc -> max_write && req -> num_pages < req -> max_pages && offset == 0 )  59
return count > 0 ? count : err ; 62
------------------------------
642 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 130
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 5
int x , y ; 6
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
int x , y ; 42
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
if ( s -> cdef [ 0 ] < 0 )  71
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 128
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 130
if ( codsty -> transform == FF_DWT97 )  148
------------------------------
643 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c Jpeg2000Component * comp = tile -> comp + compno ; 129
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 5
int x , y ; 6
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
int x , y ; 42
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
if ( s -> cdef [ 0 ] < 0 )  71
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 128
Jpeg2000Component * comp = tile -> comp + compno ; 129
float * datap = comp -> f_data ; 131
int32_t * i_datap = comp -> i_data ; 132
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 150
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 152
* dst = val << ( precision - cbps ); 154
datap ++; 155
dst += pixelsize; 156
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 160
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 162
* dst = val << ( precision - cbps ); 164
i_datap ++; 165
dst += pixelsize; 166
------------------------------
644 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 81
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 5
int x , y ; 6
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
int x , y ; 42
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
if ( s -> cdef [ 0 ] < 0 )  71
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 79
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 81
if ( codsty -> transform == FF_DWT97 )  100
------------------------------
645 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c Jpeg2000Component * comp = tile -> comp + compno ; 80
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 5
int x , y ; 6
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
int x , y ; 42
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
if ( s -> cdef [ 0 ] < 0 )  71
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 79
Jpeg2000Component * comp = tile -> comp + compno ; 80
float * datap = comp -> f_data ; 82
int32_t * i_datap = comp -> i_data ; 83
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 102
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 104
* dst = val << ( 8 - cbps ); 105
datap ++; 106
dst += pixelsize; 107
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 111
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 113
* dst = val << ( 8 - cbps ); 114
i_datap ++; 115
dst += pixelsize; 116
------------------------------
646 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 5
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 44
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
y = cblk -> coord [ 1 ] [ 0 ] - band -> coord [ 1 ] [ 0 ]; 50
dequantization_float ( x , y , cblk , comp , & t1 , band ); 53
dequantization_int_97 ( x , y , cblk , comp , & t1 , band ); 55
dequantization_int ( x , y , cblk , comp , & t1 , band ); 57
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 79
int cbps = s -> cbps [ compno ] ; 84
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 85
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 89
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 92
line = picture -> data [ plane ] + y * picture -> linesize [ plane ]; 93
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 94
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 97
dst = line + x * pixelsize + compno * ! planar; 98
for (; x < w; x ++) 101
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 102
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 104
* dst = val << ( 8 - cbps ); 105
dst += pixelsize; 107
for (; x < w; x ++) 110
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 111
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 113
* dst = val << ( 8 - cbps ); 114
dst += pixelsize; 116
line += picture -> linesize [ plane ]; 119
int precision = picture -> format == AV_PIX_FMT_XYZ12 || picture -> format == AV_PIX_FMT_RGB48 || picture -> format == AV_PIX_FMT_RGBA64 || picture -> format == AV_PIX_FMT_GRAY16 ? 16 : s -> precision ; 123
for (compno = 0; compno < s->ncomponents; compno++) 128
int cbps = s -> cbps [ compno ] ; 134
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 135
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 139
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 141
linel = ( uint16_t * ) picture -> data [ plane ] + y * ( picture -> linesize [ plane ] >> 1 ); 142
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 143
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 146
dst = linel + ( x * pixelsize + compno * ! planar ); 147
for (; x < w; x ++) 149
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 150
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 152
* dst = val << ( precision - cbps ); 154
dst += pixelsize; 156
for (; x < w; x ++) 159
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 160
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 162
* dst = val << ( precision - cbps ); 164
dst += pixelsize; 166
linel += picture -> linesize [ plane ] >> 1; 169
------------------------------
647 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c Jpeg2000Prec * prec = band -> prec + precno ; 38
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 5
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
int nb_precincts , precno ; 25
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 44
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
y = cblk -> coord [ 1 ] [ 0 ] - band -> coord [ 1 ] [ 0 ]; 50
dequantization_float ( x , y , cblk , comp , & t1 , band ); 53
dequantization_int_97 ( x , y , cblk , comp , & t1 , band ); 55
dequantization_int ( x , y , cblk , comp , & t1 , band ); 57
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 79
int cbps = s -> cbps [ compno ] ; 84
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 85
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 89
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 92
line = picture -> data [ plane ] + y * picture -> linesize [ plane ]; 93
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 94
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 97
dst = line + x * pixelsize + compno * ! planar; 98
for (; x < w; x ++) 101
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 102
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 104
* dst = val << ( 8 - cbps ); 105
dst += pixelsize; 107
for (; x < w; x ++) 110
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 111
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 113
* dst = val << ( 8 - cbps ); 114
dst += pixelsize; 116
line += picture -> linesize [ plane ]; 119
int precision = picture -> format == AV_PIX_FMT_XYZ12 || picture -> format == AV_PIX_FMT_RGB48 || picture -> format == AV_PIX_FMT_RGBA64 || picture -> format == AV_PIX_FMT_GRAY16 ? 16 : s -> precision ; 123
for (compno = 0; compno < s->ncomponents; compno++) 128
int cbps = s -> cbps [ compno ] ; 134
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 135
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 139
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 141
linel = ( uint16_t * ) picture -> data [ plane ] + y * ( picture -> linesize [ plane ] >> 1 ); 142
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 143
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 146
dst = linel + ( x * pixelsize + compno * ! planar ); 147
for (; x < w; x ++) 149
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 150
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 152
* dst = val << ( precision - cbps ); 154
dst += pixelsize; 156
for (; x < w; x ++) 159
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 160
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 162
* dst = val << ( precision - cbps ); 164
dst += pixelsize; 166
linel += picture -> linesize [ plane ] >> 1; 169
------------------------------
648 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c Jpeg2000Band * band = rlevel -> band + bandno ; 26
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 5
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 44
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
y = cblk -> coord [ 1 ] [ 0 ] - band -> coord [ 1 ] [ 0 ]; 50
dequantization_float ( x , y , cblk , comp , & t1 , band ); 53
dequantization_int_97 ( x , y , cblk , comp , & t1 , band ); 55
dequantization_int ( x , y , cblk , comp , & t1 , band ); 57
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 79
int cbps = s -> cbps [ compno ] ; 84
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 85
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 89
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 92
line = picture -> data [ plane ] + y * picture -> linesize [ plane ]; 93
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 94
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 97
dst = line + x * pixelsize + compno * ! planar; 98
for (; x < w; x ++) 101
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 102
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 104
* dst = val << ( 8 - cbps ); 105
dst += pixelsize; 107
for (; x < w; x ++) 110
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 111
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 113
* dst = val << ( 8 - cbps ); 114
dst += pixelsize; 116
line += picture -> linesize [ plane ]; 119
int precision = picture -> format == AV_PIX_FMT_XYZ12 || picture -> format == AV_PIX_FMT_RGB48 || picture -> format == AV_PIX_FMT_RGBA64 || picture -> format == AV_PIX_FMT_GRAY16 ? 16 : s -> precision ; 123
for (compno = 0; compno < s->ncomponents; compno++) 128
int cbps = s -> cbps [ compno ] ; 134
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 135
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 139
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 141
linel = ( uint16_t * ) picture -> data [ plane ] + y * ( picture -> linesize [ plane ] >> 1 ); 142
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 143
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 146
dst = linel + ( x * pixelsize + compno * ! planar ); 147
for (; x < w; x ++) 149
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 150
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 152
* dst = val << ( precision - cbps ); 154
dst += pixelsize; 156
for (; x < w; x ++) 159
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 160
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 162
* dst = val << ( precision - cbps ); 164
dst += pixelsize; 166
linel += picture -> linesize [ plane ] >> 1; 169
------------------------------
649 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 5
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 44
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
y = cblk -> coord [ 1 ] [ 0 ] - band -> coord [ 1 ] [ 0 ]; 50
dequantization_float ( x , y , cblk , comp , & t1 , band ); 53
dequantization_int_97 ( x , y , cblk , comp , & t1 , band ); 55
dequantization_int ( x , y , cblk , comp , & t1 , band ); 57
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 79
int cbps = s -> cbps [ compno ] ; 84
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 85
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 89
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 92
line = picture -> data [ plane ] + y * picture -> linesize [ plane ]; 93
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 94
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 97
dst = line + x * pixelsize + compno * ! planar; 98
for (; x < w; x ++) 101
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 102
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 104
* dst = val << ( 8 - cbps ); 105
dst += pixelsize; 107
for (; x < w; x ++) 110
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 111
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 113
* dst = val << ( 8 - cbps ); 114
dst += pixelsize; 116
line += picture -> linesize [ plane ]; 119
int precision = picture -> format == AV_PIX_FMT_XYZ12 || picture -> format == AV_PIX_FMT_RGB48 || picture -> format == AV_PIX_FMT_RGBA64 || picture -> format == AV_PIX_FMT_GRAY16 ? 16 : s -> precision ; 123
for (compno = 0; compno < s->ncomponents; compno++) 128
int cbps = s -> cbps [ compno ] ; 134
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 135
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 139
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 141
linel = ( uint16_t * ) picture -> data [ plane ] + y * ( picture -> linesize [ plane ] >> 1 ); 142
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 143
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 146
dst = linel + ( x * pixelsize + compno * ! planar ); 147
for (; x < w; x ++) 149
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 150
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 152
* dst = val << ( precision - cbps ); 154
dst += pixelsize; 156
for (; x < w; x ++) 159
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 160
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 162
* dst = val << ( precision - cbps ); 164
dst += pixelsize; 166
linel += picture -> linesize [ plane ] >> 1; 169
------------------------------
650 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 5
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 16
t1 . stride = ( 1 << codsty -> log2_cblk_width ) + 2; 18
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 21
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 44
if ( codsty -> transform == FF_DWT97 )  52
dequantization_float ( x , y , cblk , comp , & t1 , band ); 53
if ( codsty -> transform == FF_DWT97_INT )  54
dequantization_int_97 ( x , y , cblk , comp , & t1 , band ); 55
dequantization_int ( x , y , cblk , comp , & t1 , band ); 57
ff_dwt_decode ( & comp -> dwt , codsty -> transform == FF_DWT97 ? ( void * ) comp -> f_data : ( void * ) comp -> i_data ); 64
------------------------------
651 /home/speedy/test/source2slice/NVD/CVE-2016-2213_VULN_jpeg2000_decode_tile.c Jpeg2000Component * comp = tile -> comp + compno ; 15
static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 5
for (compno = 0; compno < s->ncomponents; compno++) 14
Jpeg2000Component * comp = tile -> comp + compno ; 15
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 22
for (bandno = 0; bandno < rlevel->nbands; bandno++) 24
Jpeg2000Band * band = rlevel -> band + bandno ; 26
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  31
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 35
for (precno = 0; precno < nb_precincts; precno++) 37
Jpeg2000Prec * prec = band -> prec + precno ; 38
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 41
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 43
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 44
x = cblk -> coord [ 0 ] [ 0 ] - band -> coord [ 0 ] [ 0 ]; 49
y = cblk -> coord [ 1 ] [ 0 ] - band -> coord [ 1 ] [ 0 ]; 50
dequantization_float ( x , y , cblk , comp , & t1 , band ); 53
dequantization_int_97 ( x , y , cblk , comp , & t1 , band ); 55
dequantization_int ( x , y , cblk , comp , & t1 , band ); 57
ff_dwt_decode ( & comp -> dwt , codsty -> transform == FF_DWT97 ? ( void * ) comp -> f_data : ( void * ) comp -> i_data ); 64
for (x = 0; x < s->ncomponents; x++) 72
s -> cdef [ x ] = x + 1; 73
if ( ( s -> ncomponents & 1 ) == 0 )  74
s -> cdef [ s -> ncomponents - 1 ] = 0; 75
if ( s -> precision <= 8 )  78
for (compno = 0; compno < s->ncomponents; compno++) 79
int cbps = s -> cbps [ compno ] ; 84
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 85
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 89
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 92
line = picture -> data [ plane ] + y * picture -> linesize [ plane ]; 93
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 94
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 97
dst = line + x * pixelsize + compno * ! planar; 98
for (; x < w; x ++) 101
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 102
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 104
* dst = val << ( 8 - cbps ); 105
dst += pixelsize; 107
for (; x < w; x ++) 110
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 111
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 113
* dst = val << ( 8 - cbps ); 114
dst += pixelsize; 116
line += picture -> linesize [ plane ]; 119
int precision = picture -> format == AV_PIX_FMT_XYZ12 || picture -> format == AV_PIX_FMT_RGB48 || picture -> format == AV_PIX_FMT_RGBA64 || picture -> format == AV_PIX_FMT_GRAY16 ? 16 : s -> precision ; 123
for (compno = 0; compno < s->ncomponents; compno++) 128
int cbps = s -> cbps [ compno ] ; 134
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 135
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 139
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y / s -> cdy [ compno ]; 141
linel = ( uint16_t * ) picture -> data [ plane ] + y * ( picture -> linesize [ plane ] >> 1 ); 142
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y ++) 143
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x / s -> cdx [ compno ]; 146
dst = linel + ( x * pixelsize + compno * ! planar ); 147
for (; x < w; x ++) 149
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 150
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 152
* dst = val << ( precision - cbps ); 154
dst += pixelsize; 156
for (; x < w; x ++) 159
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 160
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 162
* dst = val << ( precision - cbps ); 164
dst += pixelsize; 166
linel += picture -> linesize [ plane ] >> 1; 169
------------------------------
652 /home/speedy/test/source2slice/NVD/CVE-2016-2327_VULN_apng_encode_frame.c size_t row_start = s -> last_frame -> linesize [ 0 ] * y + bpp * last_fctl_chunk . x_offset ; 66
static int apng_encode_frame(AVCodecContext *avctx, const AVFrame *pict,
APNGFctlChunk *best_fctl_chunk, APNGFctlChunk *best_last_fctl_chunk) 2
PNGEncContext * s = avctx -> priv_data ; 4
int ret ; 5
unsigned int y ; 6
AVFrame * diffFrame ; 7
uint8_t bpp = ( s -> bits_per_pixel + 7 ) >> 3 ; 8
uint8_t * original_bytestream , * original_bytestream_end ; 9
uint8_t * best_bytestream ; 12
size_t best_bytestream_size = SIZE_MAX ; 13
APNGFctlChunk last_fctl_chunk = * best_last_fctl_chunk ; 14
APNGFctlChunk fctl_chunk = * best_fctl_chunk ; 15
if ( avctx -> frame_number == 0 )  17
diffFrame = av_frame_alloc ( ); 26
if ( ! diffFrame )  27
diffFrame -> format = pict -> format; 30
diffFrame -> width = pict -> width; 31
diffFrame -> height = pict -> height; 32
if ( ( ret = av_frame_get_buffer ( diffFrame , 32 ) ) < 0 )  33
original_bytestream = s -> bytestream; 36
original_bytestream_end = s -> bytestream_end; 37
temp_bytestream = av_malloc ( original_bytestream_end - original_bytestream ); 39
temp_bytestream_end = temp_bytestream + ( original_bytestream_end - original_bytestream ); 40
if ( ! temp_bytestream )  41
for (last_fctl_chunk.dispose_op = 0; last_fctl_chunk.dispose_op < 3; ++last_fctl_chunk.dispose_op) 46
for (fctl_chunk.blend_op = 0; fctl_chunk.blend_op < 2; ++fctl_chunk.blend_op) 51
uint32_t original_sequence_number = s -> sequence_number , sequence_number ; 55
uint8_t * bytestream_start = s -> bytestream ; 56
size_t bytestream_size ; 57
if ( last_fctl_chunk . dispose_op != APNG_DISPOSE_OP_PREVIOUS )  60
if ( last_fctl_chunk . dispose_op == APNG_DISPOSE_OP_BACKGROUND )  64
for (y = last_fctl_chunk.y_offset; y < last_fctl_chunk.y_offset + last_fctl_chunk.height; ++y) 65
size_t row_start = s -> last_frame -> linesize [ 0 ] * y + bpp * last_fctl_chunk . x_offset ; 66
memset ( diffFrame -> data [ 0 ] + row_start , 0 , bpp * last_fctl_chunk . width ); 67
if ( ! s -> prev_frame )  71
memcpy ( diffFrame -> data [ 0 ] , s -> prev_frame -> data [ 0 ] , s -> prev_frame -> linesize [ 0 ] * s -> prev_frame -> height ); 74
if ( apng_do_inverse_blend ( diffFrame , pict , & fctl_chunk , bpp ) < 0 )  79
ret = encode_frame ( avctx , diffFrame ); 83
s -> sequence_number = original_sequence_number; 85
bytestream_size = s -> bytestream - bytestream_start; 86
s -> bytestream = bytestream_start; 87
if ( ret < 0 )  88
if ( bytestream_size < best_bytestream_size )  91
best_bytestream = s -> bytestream; 96
best_bytestream_size = bytestream_size; 97
if ( best_bytestream == original_bytestream )  99
s -> bytestream = temp_bytestream; 100
s -> bytestream_end = temp_bytestream_end; 101
s -> bytestream = original_bytestream; 103
s -> bytestream_end = original_bytestream_end; 104
------------------------------
653 /home/speedy/test/source2slice/NVD/CVE-2016-2330_VULN_gif_image_write_image.c const uint8_t * ref = s -> last_frame -> data [ 0 ] + y_start * ref_linesize + x_start ; 108
static int gif_image_write_image(AVCodecContext *avctx,
uint8_t **bytestream, uint8_t *end,
const uint32_t *palette,
const uint8_t *buf, const int linesize,
AVPacket *pkt) 5
GIFContext * s = avctx -> priv_data ; 7
int len = 0 , height = avctx -> height , width = avctx -> width , x , y ; 8
int x_start = 0 , y_start = 0 , trans = s -> transparent_index ; 9
int honor_transparency = ( s -> flags & GF_TRANSDIFF ) && s -> last_frame ; 10
if ( ( s -> flags & GF_OFFSETTING ) && s -> last_frame && ! palette )  14
const uint8_t * ref = s -> last_frame -> data [ 0 ] ; 15
const int ref_linesize = s -> last_frame -> linesize [ 0 ] ; 16
int x_end = avctx -> width - 1 , y_end = avctx -> height - 1 ; 17
while ( y_start < y_end )  21
if ( memcmp ( ref + y_start * ref_linesize , buf + y_start * linesize , width ) )  22
y_start ++; 24
while ( y_end > y_start )  26
if ( memcmp ( ref + y_end * ref_linesize , buf + y_end * linesize , width ) )  27
y_end --; 29
height = y_end + 1 - y_start; 31
while ( x_start < x_end )  34
int same_column = 1 ; 35
for (y = y_start; y <= y_end; y++) 36
if ( ref [ y * ref_linesize + x_start ] != buf [ y * linesize + x_start ] )  37
same_column = 0; 38
if ( ! same_column )  42
x_start ++; 44
while ( x_end > x_start )  46
int same_column = 1 ; 47
for (y = y_start; y <= y_end; y++) 48
if ( ref [ y * ref_linesize + x_end ] != buf [ y * linesize + x_end ] )  49
same_column = 0; 50
if ( ! same_column )  54
x_end --; 56
width = x_end + 1 - x_start; 58
if ( honor_transparency && trans < 0 )  82
trans = pick_palette_entry ( buf + y_start * linesize + x_start , linesize , width , height ); 83
if ( trans < 0 )  85
uint8_t * pal_exdata = s -> pal_exdata ; 88
if ( ! pal_exdata )  89
pal_exdata = av_packet_new_side_data ( pkt , AV_PKT_DATA_PALETTE , AVPALETTE_SIZE ); 90
if ( ! pal_exdata )  91
memcpy ( pal_exdata , s -> palette , AVPALETTE_SIZE ); 93
pal_exdata [ trans * 4 + 3 * ! HAVE_BIGENDIAN ] = 0x00; 94
if ( trans < 0 )  97
honor_transparency = 0; 98
if ( honor_transparency )  106
const int ref_linesize = s -> last_frame -> linesize [ 0 ] ; 107
const uint8_t * ref = s -> last_frame -> data [ 0 ] + y_start * ref_linesize + x_start ; 108
if ( ref [ x ] == ptr [ x ] )  113
ref += ref_linesize; 117
------------------------------
654 /home/speedy/test/source2slice/NVD/CVE-2016-2522_VULN_dissect_ber_constrained_bitstring.c guint8 bits_in_pad = tvb_get_guint8 ( tvb , offset + len - 1 ) & ( 0xFF >> ( 8 - pad ) ) ; 139
dissect_ber_constrained_bitstring(gboolean implicit_tag, asn1_ctx_t *actx, proto_tree *parent_tree, tvbuff_t *tvb, int offset, gint32 min_len, gint32 max_len, const asn_namedbit *named_bits, gint hf_id, gint ett_id, tvbuff_t **out_tvb) 1
gint8 ber_class ; 3
gboolean pc , ind ; 4
gint32 tag ; 5
guint32 len , byteno ; 6
guint8 pad = 0 , b0 , b1 , val , * bitstring ; 7
if ( ! implicit_tag )  17
offset = dissect_ber_identifier ( actx -> pinfo , parent_tree , tvb , offset , & ber_class , & pc , & tag ); 20
offset = dissect_ber_length ( actx -> pinfo , parent_tree , tvb , offset , & len , & ind ); 21
if ( ! implicit_tag && ( ber_class != BER_CLASS_APP ) )  32
if ( ( ber_class != BER_CLASS_UNI ) || ( tag != BER_UNI_TAG_BITSTRING ) )  33
pc = 0; 51
len = tvb_reported_length_remaining ( tvb , offset ); 52
if ( pc )  58
pad = tvb_get_guint8 ( tvb , offset ); 63
offset ++; 76
len --; 77
if ( ( pad > 0 ) && ( pad < 8 ) && ( len > 0 ) )  138
guint8 bits_in_pad = tvb_get_guint8 ( tvb , offset + len - 1 ) & ( 0xFF >> ( 8 - pad ) ) ; 139
if ( bits_in_pad )  140
expert_add_info_format ( actx -> pinfo , item , & ei_ber_bits_set_padded , "Bits set in padded area: 0x%02x" , bits_in_pad ); 141
------------------------------
655 /home/speedy/test/source2slice/NVD/CVE_2005_2617_PATCHED_syscall32_setup_pages.c int npages = ( VSYSCALL32_END - VSYSCALL32_BASE ) >> PAGE_SHIFT ; 3
int CVE_2005_2617_PATCHED_syscall32_setup_pages(struct linux_binprm *bprm, int exstack) 1
int npages = ( VSYSCALL32_END - VSYSCALL32_BASE ) >> PAGE_SHIFT ; 3
if ( security_vm_enough_memory ( npages ) )  11
mm -> total_vm += npages; 33
up_write ( & mm -> mmap_sem ); 34
------------------------------
656 /home/speedy/test/source2slice/NVD/CVE_2005_2617_VULN_syscall32_setup_pages.c int npages = ( VSYSCALL32_END - VSYSCALL32_BASE ) >> PAGE_SHIFT ; 3
int CVE_2005_2617_VULN_syscall32_setup_pages(struct linux_binprm *bprm, int exstack) 1
int npages = ( VSYSCALL32_END - VSYSCALL32_BASE ) >> PAGE_SHIFT ; 3
if ( security_vm_enough_memory ( npages ) )  10
mm -> total_vm += npages; 28
up_write ( & mm -> mmap_sem ); 29
------------------------------
657 /home/speedy/test/source2slice/NVD/CVE_2006_5751_VULN_get_fdb_entries.c size_t size = maxnum * sizeof ( struct __fdb_entry ) ; 6
static int CVE_2006_5751_VULN_get_fdb_entries(struct net_bridge *br, void __user *userbuf,
unsigned long maxnum, unsigned long offset) 2
size_t size = maxnum * sizeof ( struct __fdb_entry ) ; 6
if ( size > PAGE_SIZE )  8
buf = kmalloc ( size , GFP_USER ); 13
if ( ! buf )  14
num = br_fdb_fillbuf ( br , buf , maxnum , offset ); 17
if ( num > 0 )  18
if ( copy_to_user ( userbuf , buf , num * sizeof ( struct __fdb_entry ) ) )  19
kfree ( buf ); 22
return num ; 24
------------------------------
658 /home/speedy/test/source2slice/NVD/CVE_2006_6106_PATCHED_cmtp_recv_interopmsg.c int len = min_t ( uint , skb -> len - CAPI_MSG_BASELEN - 6 , skb -> data [ CAPI_MSG_BASELEN + 5 ] ) ; 126
static void CVE_2006_6106_PATCHED_cmtp_recv_interopmsg(struct cmtp_session *session, struct sk_buff *skb) 1
__u16 appl , msgnum , func , info ; 5
switch ( CAPIMSG_SUBCOMMAND ( skb -> data ) )  10
if ( skb -> len < CAPI_MSG_BASELEN + 6 )  120
func = CAPIMSG_U16 ( skb -> data , CAPI_MSG_BASELEN + 3 ); 123
if ( func == CAPI_FUNCTION_LOOPBACK )  125
int len = min_t ( uint , skb -> len - CAPI_MSG_BASELEN - 6 , skb -> data [ CAPI_MSG_BASELEN + 5 ] ) ; 126
cmtp_send_interopmsg ( session , CAPI_RESP , appl , msgnum , func , skb -> data + CAPI_MSG_BASELEN + 6 , len ); 130
------------------------------
659 /home/speedy/test/source2slice/NVD/CVE_2008_0420_PATCHED_nsBMPDecoder__ProcessData.c PRUint32 rowSize = ( mBIH . bpp * mBIH . width + 7 ) / 8 ; 146
NS_METHOD CVE_2008_0420_PATCHED_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
aCount -= toCopy; 32
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mNumColors = 1 << mBIH . bpp; 45
if ( mBIH . colors && mBIH . colors < mNumColors )  46
mNumColors = mBIH . colors; 47
mColors = new colorTable [ 256 ]; 51
if ( ! mColors )  52
memset ( mColors , 0 , 256 * sizeof ( colorTable ) ); 55
if ( mBIH . width < 0 )  65
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 75
if ( ! mRow )  79
PRUint8 bpc ; 95
bpc = ( mBFH . bihsize == OS2_BIH_LENGTH ) ? 3 : 4; 96
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  97
while ( aCount && ( mPos < ( mLOH + mNumColors * bpc ) ) )  102
mPos ++; 118
aCount --; 118
if ( aCount && mBIH . compression == BI_BITFIELDS && mPos < ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) )  122
PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 125
if ( toCopy > aCount )  126
toCopy = aCount; 127
mPos += toCopy; 129
aCount -= toCopy; 131
while ( aCount && ( mPos < mBFH . dataoffset ) )  139
mPos ++; 140
aCount --; 140
if ( aCount && ++ mPos >= mBFH . dataoffset )  142
if ( ! mBIH . compression || mBIH . compression == BI_BITFIELDS )  145
PRUint32 rowSize = ( mBIH . bpp * mBIH . width + 7 ) / 8 ; 146
if ( rowSize % 4 )  147
rowSize += ( 4 - ( rowSize % 4 ) ); 148
toCopy = rowSize - mRowBytes; 151
if ( toCopy )  152
if ( toCopy > aCount )  153
toCopy = aCount; 154
memcpy ( mRow + mRowBytes , aBuffer , toCopy ); 155
aCount -= toCopy; 156
aBuffer += toCopy; 157
mRowBytes += toCopy; 158
if ( ( rowSize - mRowBytes ) == 0 )  160
PRUint8 * p = mRow ; 167
idx = ( * p >> bit ) & 1; 176
SetPixel ( d , idx , mColors ); 177
Set4BitPixel ( d , * p , lpos , mColors ); 185
SetPixel ( d , * p , mColors ); 191
PRUint16 val = LITTLE_TO_NATIVE16 ( * ( PRUint16 * ) p ) ; 198
SetPixel ( d , ( val & mBitFields . red ) >> mBitFields . redRightShift << mBitFields . redLeftShift , ( val & mBitFields . green ) >> mBitFields . greenRightShift << mBitFields . greenLeftShift , ( val & mBitFields . blue ) >> mBitFields . blueRightShift << mBitFields . blueLeftShift ); 199
p += 2; 204
SetPixel ( d , p [ 2 ] , p [ 1 ] , p [ 0 ] ); 210
p += 2; 211
p ++; 214
while ( aCount > 0 )  231
------------------------------
660 /home/speedy/test/source2slice/NVD/CVE_2008_0420_PATCHED_nsBMPDecoder__ProcessData.c PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 125
NS_METHOD CVE_2008_0420_PATCHED_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
aCount -= toCopy; 32
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mNumColors = 1 << mBIH . bpp; 45
if ( mBIH . colors && mBIH . colors < mNumColors )  46
mNumColors = mBIH . colors; 47
mColors = new colorTable [ 256 ]; 51
if ( ! mColors )  52
memset ( mColors , 0 , 256 * sizeof ( colorTable ) ); 55
if ( mBIH . width < 0 )  65
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 75
if ( ! mRow )  79
PRUint8 bpc ; 95
bpc = ( mBFH . bihsize == OS2_BIH_LENGTH ) ? 3 : 4; 96
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  97
if ( aCount && mBIH . compression == BI_BITFIELDS && mPos < ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) )  122
PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 125
if ( toCopy > aCount )  126
memcpy ( mRawBuf + ( mPos - WIN_HEADER_LENGTH ) , aBuffer , toCopy ); 128
mPos += toCopy; 129
aBuffer += toCopy; 130
aCount -= toCopy; 131
if ( mBIH . compression == BI_BITFIELDS && mPos == WIN_HEADER_LENGTH + BITFIELD_LENGTH )  133
mBitFields . red = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) mRawBuf ); 134
mBitFields . green = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) ( mRawBuf + 4 ) ); 135
mBitFields . blue = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) ( mRawBuf + 8 ) ); 136
while ( aCount && ( mPos < mBFH . dataoffset ) )  139
mPos ++; 140
aBuffer ++; 140
aCount --; 140
if ( aCount && ++ mPos >= mBFH . dataoffset )  142
toCopy = rowSize - mRowBytes; 151
if ( toCopy )  152
if ( toCopy > aCount )  153
toCopy = aCount; 154
memcpy ( mRow + mRowBytes , aBuffer , toCopy ); 155
aCount -= toCopy; 156
aBuffer += toCopy; 157
mRowBytes += toCopy; 158
if ( ( rowSize - mRowBytes ) == 0 )  160
PRUint8 * p = mRow ; 167
idx = ( * p >> bit ) & 1; 176
SetPixel ( d , idx , mColors ); 177
Set4BitPixel ( d , * p , lpos , mColors ); 185
SetPixel ( d , * p , mColors ); 191
PRUint16 val = LITTLE_TO_NATIVE16 ( * ( PRUint16 * ) p ) ; 198
SetPixel ( d , ( val & mBitFields . red ) >> mBitFields . redRightShift << mBitFields . redLeftShift , ( val & mBitFields . green ) >> mBitFields . greenRightShift << mBitFields . greenLeftShift , ( val & mBitFields . blue ) >> mBitFields . blueRightShift << mBitFields . blueLeftShift ); 199
p += 2; 204
SetPixel ( d , p [ 2 ] , p [ 1 ] , p [ 0 ] ); 210
p += 2; 211
p ++; 214
while ( aCount > 0 )  231
while ( aCount > 0 )  258
mStateData = ( PRUint8 ) * aBuffer ++; 263
aCount --; 264
byte = * aBuffer ++; 270
aCount --; 271
if ( mStateData != RLE_ESCAPE )  272
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  279
mStateData = ( PRUint32 ) ( mAlpha + mBIH . width - mAlphaPtr ); 280
memset ( mAlphaPtr , 0xFF , mStateData ); 281
mAlphaPtr += mStateData; 282
while ( mStateData > 0 )  284
SetPixel ( mDecoding , byte , mColors ); 285
mStateData --; 286
while ( mStateData > 0 )  289
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 290
switch ( byte )  298
mStateData = byte; 321
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  322
mStateData -= mBIH . width & 1; 325
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  326
memset ( mAlphaPtr , 0xFF , mStateData ); 329
mAlphaPtr += mStateData; 330
if ( ( ( mStateData - 1 ) & mBIH . compression ) != 0 )  341
byte = * aBuffer ++; 351
aCount --; 352
mAlphaPtr += byte; 353
if ( mAlphaPtr > mAlpha + mBIH . width )  354
mDecoding += byte * GFXBYTESPERPIXEL; 356
byte = * aBuffer ++; 363
aCount --; 364
if ( byte == 0 )  366
rv = WriteRLERows ( PR_MIN ( byte , mCurLine ) ); 369
NS_ENSURE_SUCCESS ( rv , rv ); 370
while ( aCount > 0 && mStateData > 0 )  380
byte = * aBuffer ++; 381
aCount --; 382
SetPixel ( mDecoding , byte , mColors ); 383
mStateData --; 384
while ( aCount > 0 && mStateData > 0 )  387
byte = * aBuffer ++; 388
aCount --; 389
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 390
if ( mStateData == 0 )  394
if ( aCount > 0 )  400
aBuffer ++; 403
aCount --; 404
------------------------------
661 /home/speedy/test/source2slice/NVD/CVE_2008_0420_PATCHED_nsBMPDecoder__ProcessData.c PRUint8 colorNum = colorBytes / bpc ; 100
NS_METHOD CVE_2008_0420_PATCHED_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mNumColors = 1 << mBIH . bpp; 45
if ( mBIH . colors && mBIH . colors < mNumColors )  46
mNumColors = mBIH . colors; 47
mColors = new colorTable [ 256 ]; 51
if ( ! mColors )  52
memset ( mColors , 0 , 256 * sizeof ( colorTable ) ); 55
if ( mBIH . width < 0 )  65
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 75
if ( ! mRow )  79
PRUint8 bpc ; 95
bpc = ( mBFH . bihsize == OS2_BIH_LENGTH ) ? 3 : 4; 96
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  97
PRUint32 colorBytes = mPos - mLOH ; 99
PRUint8 colorNum = colorBytes / bpc ; 100
mColors [ colorNum ] . blue = * aBuffer; 105
mColors [ colorNum ] . green = * aBuffer; 108
mColors [ colorNum ] . red = * aBuffer; 111
colorNum ++; 112
------------------------------
662 /home/speedy/test/source2slice/NVD/CVE_2008_0420_PATCHED_nsBMPDecoder__ProcessData.c PRUint32 colorBytes = mPos - mLOH ; 99
NS_METHOD CVE_2008_0420_PATCHED_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mNumColors = 1 << mBIH . bpp; 45
if ( mBIH . colors && mBIH . colors < mNumColors )  46
mNumColors = mBIH . colors; 47
mColors = new colorTable [ 256 ]; 51
if ( ! mColors )  52
memset ( mColors , 0 , 256 * sizeof ( colorTable ) ); 55
if ( mBIH . width < 0 )  65
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 75
if ( ! mRow )  79
PRUint8 bpc ; 95
bpc = ( mBFH . bihsize == OS2_BIH_LENGTH ) ? 3 : 4; 96
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  97
PRUint32 colorBytes = mPos - mLOH ; 99
PRUint8 colorNum = colorBytes / bpc ; 100
PRUint8 at = colorBytes % bpc ; 101
switch ( at )  103
mColors [ colorNum ] . blue = * aBuffer; 105
mColors [ colorNum ] . green = * aBuffer; 108
mColors [ colorNum ] . red = * aBuffer; 111
colorNum ++; 112
at = ( at + 1 ) % bpc; 119
------------------------------
663 /home/speedy/test/source2slice/NVD/CVE_2008_0420_PATCHED_nsBMPDecoder__ProcessData.c PRUint32 toCopy = mLOH - mPos ; 27
NS_METHOD CVE_2008_0420_PATCHED_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
memcpy ( mRawBuf + ( mPos - BFH_LENGTH ) , aBuffer , toCopy ); 30
mPos += toCopy; 31
aCount -= toCopy; 32
aBuffer += toCopy; 33
if ( mPos == mLOH )  35
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  97
PRUint32 colorBytes = mPos - mLOH ; 99
PRUint8 colorNum = colorBytes / bpc ; 100
PRUint8 at = colorBytes % bpc ; 101
while ( aCount && ( mPos < ( mLOH + mNumColors * bpc ) ) )  102
switch ( at )  103
mColors [ colorNum ] . blue = * aBuffer; 105
mColors [ colorNum ] . green = * aBuffer; 108
mColors [ colorNum ] . red = * aBuffer; 111
colorNum ++; 112
mPos ++; 118
aBuffer ++; 118
aCount --; 118
at = ( at + 1 ) % bpc; 119
if ( aCount && mBIH . compression == BI_BITFIELDS && mPos < ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) )  122
PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 125
if ( toCopy > aCount )  126
toCopy = aCount; 127
memcpy ( mRawBuf + ( mPos - WIN_HEADER_LENGTH ) , aBuffer , toCopy ); 128
mPos += toCopy; 129
aBuffer += toCopy; 130
aCount -= toCopy; 131
if ( mBIH . compression == BI_BITFIELDS && mPos == WIN_HEADER_LENGTH + BITFIELD_LENGTH )  133
mBitFields . red = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) mRawBuf ); 134
mBitFields . green = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) ( mRawBuf + 4 ) ); 135
mBitFields . blue = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) ( mRawBuf + 8 ) ); 136
while ( aCount && ( mPos < mBFH . dataoffset ) )  139
mPos ++; 140
aBuffer ++; 140
aCount --; 140
if ( aCount && ++ mPos >= mBFH . dataoffset )  142
toCopy = rowSize - mRowBytes; 151
if ( toCopy )  152
if ( toCopy > aCount )  153
toCopy = aCount; 154
memcpy ( mRow + mRowBytes , aBuffer , toCopy ); 155
aCount -= toCopy; 156
aBuffer += toCopy; 157
mRowBytes += toCopy; 158
if ( ( rowSize - mRowBytes ) == 0 )  160
PRUint8 * p = mRow ; 167
idx = ( * p >> bit ) & 1; 176
SetPixel ( d , idx , mColors ); 177
Set4BitPixel ( d , * p , lpos , mColors ); 185
SetPixel ( d , * p , mColors ); 191
PRUint16 val = LITTLE_TO_NATIVE16 ( * ( PRUint16 * ) p ) ; 198
SetPixel ( d , ( val & mBitFields . red ) >> mBitFields . redRightShift << mBitFields . redLeftShift , ( val & mBitFields . green ) >> mBitFields . greenRightShift << mBitFields . greenLeftShift , ( val & mBitFields . blue ) >> mBitFields . blueRightShift << mBitFields . blueLeftShift ); 199
p += 2; 204
SetPixel ( d , p [ 2 ] , p [ 1 ] , p [ 0 ] ); 210
p += 2; 211
p ++; 214
while ( aCount > 0 )  231
while ( aCount > 0 )  258
mStateData = ( PRUint8 ) * aBuffer ++; 263
aCount --; 264
byte = * aBuffer ++; 270
aCount --; 271
if ( mStateData != RLE_ESCAPE )  272
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  279
mStateData = ( PRUint32 ) ( mAlpha + mBIH . width - mAlphaPtr ); 280
memset ( mAlphaPtr , 0xFF , mStateData ); 281
mAlphaPtr += mStateData; 282
while ( mStateData > 0 )  284
SetPixel ( mDecoding , byte , mColors ); 285
mStateData --; 286
while ( mStateData > 0 )  289
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 290
switch ( byte )  298
mStateData = byte; 321
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  322
mStateData -= mBIH . width & 1; 325
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  326
memset ( mAlphaPtr , 0xFF , mStateData ); 329
mAlphaPtr += mStateData; 330
if ( ( ( mStateData - 1 ) & mBIH . compression ) != 0 )  341
byte = * aBuffer ++; 351
aCount --; 352
mAlphaPtr += byte; 353
if ( mAlphaPtr > mAlpha + mBIH . width )  354
mDecoding += byte * GFXBYTESPERPIXEL; 356
byte = * aBuffer ++; 363
aCount --; 364
if ( byte == 0 )  366
rv = WriteRLERows ( PR_MIN ( byte , mCurLine ) ); 369
NS_ENSURE_SUCCESS ( rv , rv ); 370
while ( aCount > 0 && mStateData > 0 )  380
byte = * aBuffer ++; 381
aCount --; 382
SetPixel ( mDecoding , byte , mColors ); 383
mStateData --; 384
while ( aCount > 0 && mStateData > 0 )  387
byte = * aBuffer ++; 388
aCount --; 389
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 390
if ( mStateData == 0 )  394
if ( aCount > 0 )  400
aBuffer ++; 403
aCount --; 404
------------------------------
664 /home/speedy/test/source2slice/NVD/CVE_2008_0420_PATCHED_nsBMPDecoder__ProcessData.c PRUint32 toCopy = BFH_LENGTH - mPos ; 9
NS_METHOD CVE_2008_0420_PATCHED_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
memcpy ( mRawBuf + mPos , aBuffer , toCopy ); 12
mPos += toCopy; 13
aCount -= toCopy; 14
aBuffer += toCopy; 15
if ( mPos == BFH_LENGTH )  17
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
memcpy ( mRawBuf + ( mPos - BFH_LENGTH ) , aBuffer , toCopy ); 30
mPos += toCopy; 31
aCount -= toCopy; 32
aBuffer += toCopy; 33
if ( mPos == mLOH )  35
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  97
PRUint32 colorBytes = mPos - mLOH ; 99
PRUint8 colorNum = colorBytes / bpc ; 100
PRUint8 at = colorBytes % bpc ; 101
while ( aCount && ( mPos < ( mLOH + mNumColors * bpc ) ) )  102
switch ( at )  103
mColors [ colorNum ] . blue = * aBuffer; 105
mColors [ colorNum ] . green = * aBuffer; 108
mColors [ colorNum ] . red = * aBuffer; 111
colorNum ++; 112
mPos ++; 118
aBuffer ++; 118
aCount --; 118
at = ( at + 1 ) % bpc; 119
if ( aCount && mBIH . compression == BI_BITFIELDS && mPos < ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) )  122
PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 125
if ( toCopy > aCount )  126
toCopy = aCount; 127
memcpy ( mRawBuf + ( mPos - WIN_HEADER_LENGTH ) , aBuffer , toCopy ); 128
mPos += toCopy; 129
aBuffer += toCopy; 130
aCount -= toCopy; 131
if ( mBIH . compression == BI_BITFIELDS && mPos == WIN_HEADER_LENGTH + BITFIELD_LENGTH )  133
mBitFields . red = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) mRawBuf ); 134
mBitFields . green = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) ( mRawBuf + 4 ) ); 135
mBitFields . blue = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) ( mRawBuf + 8 ) ); 136
while ( aCount && ( mPos < mBFH . dataoffset ) )  139
mPos ++; 140
aBuffer ++; 140
aCount --; 140
if ( aCount && ++ mPos >= mBFH . dataoffset )  142
toCopy = rowSize - mRowBytes; 151
if ( toCopy )  152
if ( toCopy > aCount )  153
toCopy = aCount; 154
memcpy ( mRow + mRowBytes , aBuffer , toCopy ); 155
aCount -= toCopy; 156
aBuffer += toCopy; 157
mRowBytes += toCopy; 158
if ( ( rowSize - mRowBytes ) == 0 )  160
PRUint8 * p = mRow ; 167
idx = ( * p >> bit ) & 1; 176
SetPixel ( d , idx , mColors ); 177
Set4BitPixel ( d , * p , lpos , mColors ); 185
SetPixel ( d , * p , mColors ); 191
PRUint16 val = LITTLE_TO_NATIVE16 ( * ( PRUint16 * ) p ) ; 198
SetPixel ( d , ( val & mBitFields . red ) >> mBitFields . redRightShift << mBitFields . redLeftShift , ( val & mBitFields . green ) >> mBitFields . greenRightShift << mBitFields . greenLeftShift , ( val & mBitFields . blue ) >> mBitFields . blueRightShift << mBitFields . blueLeftShift ); 199
p += 2; 204
SetPixel ( d , p [ 2 ] , p [ 1 ] , p [ 0 ] ); 210
p += 2; 211
p ++; 214
while ( aCount > 0 )  231
while ( aCount > 0 )  258
mStateData = ( PRUint8 ) * aBuffer ++; 263
aCount --; 264
byte = * aBuffer ++; 270
aCount --; 271
if ( mStateData != RLE_ESCAPE )  272
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  279
mStateData = ( PRUint32 ) ( mAlpha + mBIH . width - mAlphaPtr ); 280
memset ( mAlphaPtr , 0xFF , mStateData ); 281
mAlphaPtr += mStateData; 282
while ( mStateData > 0 )  284
SetPixel ( mDecoding , byte , mColors ); 285
mStateData --; 286
while ( mStateData > 0 )  289
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 290
switch ( byte )  298
mStateData = byte; 321
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  322
mStateData -= mBIH . width & 1; 325
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  326
memset ( mAlphaPtr , 0xFF , mStateData ); 329
mAlphaPtr += mStateData; 330
if ( ( ( mStateData - 1 ) & mBIH . compression ) != 0 )  341
byte = * aBuffer ++; 351
aCount --; 352
mAlphaPtr += byte; 353
if ( mAlphaPtr > mAlpha + mBIH . width )  354
mDecoding += byte * GFXBYTESPERPIXEL; 356
byte = * aBuffer ++; 363
aCount --; 364
if ( byte == 0 )  366
rv = WriteRLERows ( PR_MIN ( byte , mCurLine ) ); 369
NS_ENSURE_SUCCESS ( rv , rv ); 370
while ( aCount > 0 && mStateData > 0 )  380
byte = * aBuffer ++; 381
aCount --; 382
SetPixel ( mDecoding , byte , mColors ); 383
mStateData --; 384
while ( aCount > 0 && mStateData > 0 )  387
byte = * aBuffer ++; 388
aCount --; 389
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 390
if ( mStateData == 0 )  394
if ( aCount > 0 )  400
aBuffer ++; 403
aCount --; 404
------------------------------
665 /home/speedy/test/source2slice/NVD/CVE_2008_0420_VULN_nsBMPDecoder__ProcessData.c PRUint32 rowSize = ( mBIH . bpp * mBIH . width + 7 ) / 8 ; 142
NS_METHOD CVE_2008_0420_VULN_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
aCount -= toCopy; 32
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mNumColors = 1 << mBIH . bpp; 45
if ( mBIH . colors && mBIH . colors < mNumColors )  46
mNumColors = mBIH . colors; 47
mColors = new colorTable [ mNumColors ]; 49
if ( ! mColors )  50
if ( mBIH . width < 0 )  61
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 71
if ( ! mRow )  75
PRUint8 bpc ; 91
bpc = ( mBFH . bihsize == OS2_BIH_LENGTH ) ? 3 : 4; 92
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  93
while ( aCount && ( mPos < ( mLOH + mNumColors * bpc ) ) )  98
mPos ++; 114
aCount --; 114
if ( aCount && mBIH . compression == BI_BITFIELDS && mPos < ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) )  118
PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 121
if ( toCopy > aCount )  122
toCopy = aCount; 123
mPos += toCopy; 125
aCount -= toCopy; 127
while ( aCount && ( mPos < mBFH . dataoffset ) )  135
mPos ++; 136
aCount --; 136
if ( aCount && ++ mPos >= mBFH . dataoffset )  138
if ( ! mBIH . compression || mBIH . compression == BI_BITFIELDS )  141
PRUint32 rowSize = ( mBIH . bpp * mBIH . width + 7 ) / 8 ; 142
if ( rowSize % 4 )  143
rowSize += ( 4 - ( rowSize % 4 ) ); 144
toCopy = rowSize - mRowBytes; 147
if ( toCopy )  148
if ( toCopy > aCount )  149
toCopy = aCount; 150
memcpy ( mRow + mRowBytes , aBuffer , toCopy ); 151
aCount -= toCopy; 152
aBuffer += toCopy; 153
mRowBytes += toCopy; 154
if ( ( rowSize - mRowBytes ) == 0 )  156
PRUint8 * p = mRow ; 163
idx = ( * p >> bit ) & 1; 172
SetPixel ( d , idx , mColors ); 173
Set4BitPixel ( d , * p , lpos , mColors ); 181
SetPixel ( d , * p , mColors ); 187
PRUint16 val = LITTLE_TO_NATIVE16 ( * ( PRUint16 * ) p ) ; 194
SetPixel ( d , ( val & mBitFields . red ) >> mBitFields . redRightShift << mBitFields . redLeftShift , ( val & mBitFields . green ) >> mBitFields . greenRightShift << mBitFields . greenLeftShift , ( val & mBitFields . blue ) >> mBitFields . blueRightShift << mBitFields . blueLeftShift ); 195
p += 2; 200
SetPixel ( d , p [ 2 ] , p [ 1 ] , p [ 0 ] ); 206
p += 2; 207
p ++; 210
while ( aCount > 0 )  227
------------------------------
666 /home/speedy/test/source2slice/NVD/CVE_2008_0420_VULN_nsBMPDecoder__ProcessData.c PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 121
NS_METHOD CVE_2008_0420_VULN_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
aCount -= toCopy; 32
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mNumColors = 1 << mBIH . bpp; 45
if ( mBIH . colors && mBIH . colors < mNumColors )  46
mNumColors = mBIH . colors; 47
mColors = new colorTable [ mNumColors ]; 49
if ( ! mColors )  50
if ( mBIH . width < 0 )  61
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 71
if ( ! mRow )  75
PRUint8 bpc ; 91
bpc = ( mBFH . bihsize == OS2_BIH_LENGTH ) ? 3 : 4; 92
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  93
if ( aCount && mBIH . compression == BI_BITFIELDS && mPos < ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) )  118
PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 121
if ( toCopy > aCount )  122
memcpy ( mRawBuf + ( mPos - WIN_HEADER_LENGTH ) , aBuffer , toCopy ); 124
mPos += toCopy; 125
aBuffer += toCopy; 126
aCount -= toCopy; 127
if ( mBIH . compression == BI_BITFIELDS && mPos == WIN_HEADER_LENGTH + BITFIELD_LENGTH )  129
mBitFields . red = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) mRawBuf ); 130
mBitFields . green = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) ( mRawBuf + 4 ) ); 131
mBitFields . blue = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) ( mRawBuf + 8 ) ); 132
while ( aCount && ( mPos < mBFH . dataoffset ) )  135
mPos ++; 136
aBuffer ++; 136
aCount --; 136
if ( aCount && ++ mPos >= mBFH . dataoffset )  138
toCopy = rowSize - mRowBytes; 147
if ( toCopy )  148
if ( toCopy > aCount )  149
toCopy = aCount; 150
memcpy ( mRow + mRowBytes , aBuffer , toCopy ); 151
aCount -= toCopy; 152
aBuffer += toCopy; 153
mRowBytes += toCopy; 154
if ( ( rowSize - mRowBytes ) == 0 )  156
PRUint8 * p = mRow ; 163
idx = ( * p >> bit ) & 1; 172
SetPixel ( d , idx , mColors ); 173
Set4BitPixel ( d , * p , lpos , mColors ); 181
SetPixel ( d , * p , mColors ); 187
PRUint16 val = LITTLE_TO_NATIVE16 ( * ( PRUint16 * ) p ) ; 194
SetPixel ( d , ( val & mBitFields . red ) >> mBitFields . redRightShift << mBitFields . redLeftShift , ( val & mBitFields . green ) >> mBitFields . greenRightShift << mBitFields . greenLeftShift , ( val & mBitFields . blue ) >> mBitFields . blueRightShift << mBitFields . blueLeftShift ); 195
p += 2; 200
SetPixel ( d , p [ 2 ] , p [ 1 ] , p [ 0 ] ); 206
p += 2; 207
p ++; 210
while ( aCount > 0 )  227
while ( aCount > 0 )  254
mStateData = ( PRUint8 ) * aBuffer ++; 259
aCount --; 260
byte = * aBuffer ++; 266
aCount --; 267
if ( mStateData != RLE_ESCAPE )  268
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  275
mStateData = ( PRUint32 ) ( mAlpha + mBIH . width - mAlphaPtr ); 276
memset ( mAlphaPtr , 0xFF , mStateData ); 277
mAlphaPtr += mStateData; 278
while ( mStateData > 0 )  280
SetPixel ( mDecoding , byte , mColors ); 281
mStateData --; 282
while ( mStateData > 0 )  285
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 286
switch ( byte )  294
mStateData = byte; 317
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  318
mStateData -= mBIH . width & 1; 321
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  322
memset ( mAlphaPtr , 0xFF , mStateData ); 325
mAlphaPtr += mStateData; 326
if ( ( ( mStateData - 1 ) & mBIH . compression ) != 0 )  337
byte = * aBuffer ++; 347
aCount --; 348
mAlphaPtr += byte; 349
if ( mAlphaPtr > mAlpha + mBIH . width )  350
mDecoding += byte * GFXBYTESPERPIXEL; 352
byte = * aBuffer ++; 359
aCount --; 360
if ( byte == 0 )  362
rv = WriteRLERows ( PR_MIN ( byte , mCurLine ) ); 365
NS_ENSURE_SUCCESS ( rv , rv ); 366
while ( aCount > 0 && mStateData > 0 )  376
byte = * aBuffer ++; 377
aCount --; 378
SetPixel ( mDecoding , byte , mColors ); 379
mStateData --; 380
while ( aCount > 0 && mStateData > 0 )  383
byte = * aBuffer ++; 384
aCount --; 385
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 386
if ( mStateData == 0 )  390
if ( aCount > 0 )  396
aBuffer ++; 399
aCount --; 400
------------------------------
667 /home/speedy/test/source2slice/NVD/CVE_2008_0420_VULN_nsBMPDecoder__ProcessData.c PRUint8 colorNum = colorBytes / bpc ; 96
NS_METHOD CVE_2008_0420_VULN_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mNumColors = 1 << mBIH . bpp; 45
if ( mBIH . colors && mBIH . colors < mNumColors )  46
mNumColors = mBIH . colors; 47
mColors = new colorTable [ mNumColors ]; 49
if ( ! mColors )  50
if ( mBIH . width < 0 )  61
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 71
if ( ! mRow )  75
PRUint8 bpc ; 91
bpc = ( mBFH . bihsize == OS2_BIH_LENGTH ) ? 3 : 4; 92
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  93
PRUint32 colorBytes = mPos - mLOH ; 95
PRUint8 colorNum = colorBytes / bpc ; 96
mColors [ colorNum ] . blue = * aBuffer; 101
mColors [ colorNum ] . green = * aBuffer; 104
mColors [ colorNum ] . red = * aBuffer; 107
colorNum ++; 108
------------------------------
668 /home/speedy/test/source2slice/NVD/CVE_2008_0420_VULN_nsBMPDecoder__ProcessData.c PRUint32 colorBytes = mPos - mLOH ; 95
NS_METHOD CVE_2008_0420_VULN_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
aCount -= toCopy; 14
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
mPos += toCopy; 31
if ( mPos == mLOH )  35
if ( mBIH . bpp != 1 && mBIH . bpp != 4 && mBIH . bpp != 8 && mBIH . bpp != 16 && mBIH . bpp != 24 && mBIH . bpp != 32 )  40
if ( mBIH . bpp <= 8 )  44
mNumColors = 1 << mBIH . bpp; 45
if ( mBIH . colors && mBIH . colors < mNumColors )  46
mNumColors = mBIH . colors; 47
mColors = new colorTable [ mNumColors ]; 49
if ( ! mColors )  50
if ( mBIH . width < 0 )  61
mRow = new PRUint8 [ ( mBIH . width * mBIH . bpp ) / 8 + 4 ]; 71
if ( ! mRow )  75
PRUint8 bpc ; 91
bpc = ( mBFH . bihsize == OS2_BIH_LENGTH ) ? 3 : 4; 92
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  93
PRUint32 colorBytes = mPos - mLOH ; 95
PRUint8 colorNum = colorBytes / bpc ; 96
PRUint8 at = colorBytes % bpc ; 97
switch ( at )  99
mColors [ colorNum ] . blue = * aBuffer; 101
mColors [ colorNum ] . green = * aBuffer; 104
mColors [ colorNum ] . red = * aBuffer; 107
colorNum ++; 108
at = ( at + 1 ) % bpc; 115
------------------------------
669 /home/speedy/test/source2slice/NVD/CVE_2008_0420_VULN_nsBMPDecoder__ProcessData.c PRUint32 toCopy = mLOH - mPos ; 27
NS_METHOD CVE_2008_0420_VULN_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
toCopy = aCount; 11
mPos += toCopy; 13
if ( mPos == BFH_LENGTH )  17
if ( mBFH . signature [ 0 ] != 'B' || mBFH . signature [ 1 ] != 'M' )  21
if ( mBFH . bihsize == OS2_BIH_LENGTH )  23
mLOH = OS2_HEADER_LENGTH; 24
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
memcpy ( mRawBuf + ( mPos - BFH_LENGTH ) , aBuffer , toCopy ); 30
mPos += toCopy; 31
aCount -= toCopy; 32
aBuffer += toCopy; 33
if ( mPos == mLOH )  35
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  93
PRUint32 colorBytes = mPos - mLOH ; 95
PRUint8 colorNum = colorBytes / bpc ; 96
PRUint8 at = colorBytes % bpc ; 97
while ( aCount && ( mPos < ( mLOH + mNumColors * bpc ) ) )  98
switch ( at )  99
mColors [ colorNum ] . blue = * aBuffer; 101
mColors [ colorNum ] . green = * aBuffer; 104
mColors [ colorNum ] . red = * aBuffer; 107
colorNum ++; 108
mPos ++; 114
aBuffer ++; 114
aCount --; 114
at = ( at + 1 ) % bpc; 115
if ( aCount && mBIH . compression == BI_BITFIELDS && mPos < ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) )  118
PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 121
if ( toCopy > aCount )  122
toCopy = aCount; 123
memcpy ( mRawBuf + ( mPos - WIN_HEADER_LENGTH ) , aBuffer , toCopy ); 124
mPos += toCopy; 125
aBuffer += toCopy; 126
aCount -= toCopy; 127
if ( mBIH . compression == BI_BITFIELDS && mPos == WIN_HEADER_LENGTH + BITFIELD_LENGTH )  129
mBitFields . red = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) mRawBuf ); 130
mBitFields . green = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) ( mRawBuf + 4 ) ); 131
mBitFields . blue = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) ( mRawBuf + 8 ) ); 132
while ( aCount && ( mPos < mBFH . dataoffset ) )  135
mPos ++; 136
aBuffer ++; 136
aCount --; 136
if ( aCount && ++ mPos >= mBFH . dataoffset )  138
toCopy = rowSize - mRowBytes; 147
if ( toCopy )  148
if ( toCopy > aCount )  149
toCopy = aCount; 150
memcpy ( mRow + mRowBytes , aBuffer , toCopy ); 151
aCount -= toCopy; 152
aBuffer += toCopy; 153
mRowBytes += toCopy; 154
if ( ( rowSize - mRowBytes ) == 0 )  156
PRUint8 * p = mRow ; 163
idx = ( * p >> bit ) & 1; 172
SetPixel ( d , idx , mColors ); 173
Set4BitPixel ( d , * p , lpos , mColors ); 181
SetPixel ( d , * p , mColors ); 187
PRUint16 val = LITTLE_TO_NATIVE16 ( * ( PRUint16 * ) p ) ; 194
SetPixel ( d , ( val & mBitFields . red ) >> mBitFields . redRightShift << mBitFields . redLeftShift , ( val & mBitFields . green ) >> mBitFields . greenRightShift << mBitFields . greenLeftShift , ( val & mBitFields . blue ) >> mBitFields . blueRightShift << mBitFields . blueLeftShift ); 195
p += 2; 200
SetPixel ( d , p [ 2 ] , p [ 1 ] , p [ 0 ] ); 206
p += 2; 207
p ++; 210
while ( aCount > 0 )  227
while ( aCount > 0 )  254
mStateData = ( PRUint8 ) * aBuffer ++; 259
aCount --; 260
byte = * aBuffer ++; 266
aCount --; 267
if ( mStateData != RLE_ESCAPE )  268
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  275
mStateData = ( PRUint32 ) ( mAlpha + mBIH . width - mAlphaPtr ); 276
memset ( mAlphaPtr , 0xFF , mStateData ); 277
mAlphaPtr += mStateData; 278
while ( mStateData > 0 )  280
SetPixel ( mDecoding , byte , mColors ); 281
mStateData --; 282
while ( mStateData > 0 )  285
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 286
switch ( byte )  294
mStateData = byte; 317
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  318
mStateData -= mBIH . width & 1; 321
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  322
memset ( mAlphaPtr , 0xFF , mStateData ); 325
mAlphaPtr += mStateData; 326
if ( ( ( mStateData - 1 ) & mBIH . compression ) != 0 )  337
byte = * aBuffer ++; 347
aCount --; 348
mAlphaPtr += byte; 349
if ( mAlphaPtr > mAlpha + mBIH . width )  350
mDecoding += byte * GFXBYTESPERPIXEL; 352
byte = * aBuffer ++; 359
aCount --; 360
if ( byte == 0 )  362
rv = WriteRLERows ( PR_MIN ( byte , mCurLine ) ); 365
NS_ENSURE_SUCCESS ( rv , rv ); 366
while ( aCount > 0 && mStateData > 0 )  376
byte = * aBuffer ++; 377
aCount --; 378
SetPixel ( mDecoding , byte , mColors ); 379
mStateData --; 380
while ( aCount > 0 && mStateData > 0 )  383
byte = * aBuffer ++; 384
aCount --; 385
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 386
if ( mStateData == 0 )  390
if ( aCount > 0 )  396
aBuffer ++; 399
aCount --; 400
------------------------------
670 /home/speedy/test/source2slice/NVD/CVE_2008_0420_VULN_nsBMPDecoder__ProcessData.c PRUint32 toCopy = BFH_LENGTH - mPos ; 9
NS_METHOD CVE_2008_0420_VULN_nsBMPDecoder::ProcessData(const char* aBuffer, PRUint32 aCount) 1
if ( ! aCount || ! mCurLine )  4
if ( mPos < BFH_LENGTH )  8
PRUint32 toCopy = BFH_LENGTH - mPos ; 9
if ( toCopy > aCount )  10
memcpy ( mRawBuf + mPos , aBuffer , toCopy ); 12
mPos += toCopy; 13
aCount -= toCopy; 14
aBuffer += toCopy; 15
if ( mPos == BFH_LENGTH )  17
if ( mPos >= BFH_LENGTH && mPos < mLOH )  26
PRUint32 toCopy = mLOH - mPos ; 27
if ( toCopy > aCount )  28
toCopy = aCount; 29
memcpy ( mRawBuf + ( mPos - BFH_LENGTH ) , aBuffer , toCopy ); 30
mPos += toCopy; 31
aCount -= toCopy; 32
aBuffer += toCopy; 33
if ( mPos == mLOH )  35
if ( mColors && ( mPos >= mLOH && ( mPos < ( mLOH + mNumColors * bpc ) ) ) )  93
PRUint32 colorBytes = mPos - mLOH ; 95
PRUint8 colorNum = colorBytes / bpc ; 96
PRUint8 at = colorBytes % bpc ; 97
while ( aCount && ( mPos < ( mLOH + mNumColors * bpc ) ) )  98
switch ( at )  99
mColors [ colorNum ] . blue = * aBuffer; 101
mColors [ colorNum ] . green = * aBuffer; 104
mColors [ colorNum ] . red = * aBuffer; 107
colorNum ++; 108
mPos ++; 114
aBuffer ++; 114
aCount --; 114
at = ( at + 1 ) % bpc; 115
if ( aCount && mBIH . compression == BI_BITFIELDS && mPos < ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) )  118
PRUint32 toCopy = ( WIN_HEADER_LENGTH + BITFIELD_LENGTH ) - mPos ; 121
if ( toCopy > aCount )  122
toCopy = aCount; 123
memcpy ( mRawBuf + ( mPos - WIN_HEADER_LENGTH ) , aBuffer , toCopy ); 124
mPos += toCopy; 125
aBuffer += toCopy; 126
aCount -= toCopy; 127
if ( mBIH . compression == BI_BITFIELDS && mPos == WIN_HEADER_LENGTH + BITFIELD_LENGTH )  129
mBitFields . red = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) mRawBuf ); 130
mBitFields . green = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) ( mRawBuf + 4 ) ); 131
mBitFields . blue = LITTLE_TO_NATIVE32 ( * ( PRUint32 * ) ( mRawBuf + 8 ) ); 132
while ( aCount && ( mPos < mBFH . dataoffset ) )  135
mPos ++; 136
aBuffer ++; 136
aCount --; 136
if ( aCount && ++ mPos >= mBFH . dataoffset )  138
toCopy = rowSize - mRowBytes; 147
if ( toCopy )  148
if ( toCopy > aCount )  149
toCopy = aCount; 150
memcpy ( mRow + mRowBytes , aBuffer , toCopy ); 151
aCount -= toCopy; 152
aBuffer += toCopy; 153
mRowBytes += toCopy; 154
if ( ( rowSize - mRowBytes ) == 0 )  156
PRUint8 * p = mRow ; 163
idx = ( * p >> bit ) & 1; 172
SetPixel ( d , idx , mColors ); 173
Set4BitPixel ( d , * p , lpos , mColors ); 181
SetPixel ( d , * p , mColors ); 187
PRUint16 val = LITTLE_TO_NATIVE16 ( * ( PRUint16 * ) p ) ; 194
SetPixel ( d , ( val & mBitFields . red ) >> mBitFields . redRightShift << mBitFields . redLeftShift , ( val & mBitFields . green ) >> mBitFields . greenRightShift << mBitFields . greenLeftShift , ( val & mBitFields . blue ) >> mBitFields . blueRightShift << mBitFields . blueLeftShift ); 195
p += 2; 200
SetPixel ( d , p [ 2 ] , p [ 1 ] , p [ 0 ] ); 206
p += 2; 207
p ++; 210
while ( aCount > 0 )  227
while ( aCount > 0 )  254
mStateData = ( PRUint8 ) * aBuffer ++; 259
aCount --; 260
byte = * aBuffer ++; 266
aCount --; 267
if ( mStateData != RLE_ESCAPE )  268
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  275
mStateData = ( PRUint32 ) ( mAlpha + mBIH . width - mAlphaPtr ); 276
memset ( mAlphaPtr , 0xFF , mStateData ); 277
mAlphaPtr += mStateData; 278
while ( mStateData > 0 )  280
SetPixel ( mDecoding , byte , mColors ); 281
mStateData --; 282
while ( mStateData > 0 )  285
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 286
switch ( byte )  294
mStateData = byte; 317
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  318
mStateData -= mBIH . width & 1; 321
if ( mAlphaPtr + mStateData > mAlpha + mBIH . width )  322
memset ( mAlphaPtr , 0xFF , mStateData ); 325
mAlphaPtr += mStateData; 326
if ( ( ( mStateData - 1 ) & mBIH . compression ) != 0 )  337
byte = * aBuffer ++; 347
aCount --; 348
mAlphaPtr += byte; 349
if ( mAlphaPtr > mAlpha + mBIH . width )  350
mDecoding += byte * GFXBYTESPERPIXEL; 352
byte = * aBuffer ++; 359
aCount --; 360
if ( byte == 0 )  362
rv = WriteRLERows ( PR_MIN ( byte , mCurLine ) ); 365
NS_ENSURE_SUCCESS ( rv , rv ); 366
while ( aCount > 0 && mStateData > 0 )  376
byte = * aBuffer ++; 377
aCount --; 378
SetPixel ( mDecoding , byte , mColors ); 379
mStateData --; 380
while ( aCount > 0 && mStateData > 0 )  383
byte = * aBuffer ++; 384
aCount --; 385
Set4BitPixel ( mDecoding , byte , mStateData , mColors ); 386
if ( mStateData == 0 )  390
if ( aCount > 0 )  396
aBuffer ++; 399
aCount --; 400
------------------------------
671 /home/speedy/test/source2slice/NVD/CVE_2009_0946_PATCHED_ft_smooth_render_generic.c FT_Vector * points_end = points + outline -> n_points ; 152
static FT_Error
CVE_2009_0946_PATCHED_ft_smooth_render_generic( FT_Renderer       render,
FT_GlyphSlot      slot,
FT_Render_Mode    mode,
const FT_Vector*  origin,
FT_Render_Mode    required_mode ) 6
FT_BBox cbox ; 10
FT_UInt width , height , height_org , width_org , pitch ; 11
FT_Bitmap * bitmap ; 12
FT_Int hmul = mode == FT_RENDER_MODE_LCD ; 14
FT_Int vmul = mode == FT_RENDER_MODE_LCD_V ; 15
if ( slot -> format != render -> glyph_format )  22
if ( mode != required_mode )  29
outline = & slot -> outline; 32
cbox . xMin = FT_PIX_FLOOR ( cbox . xMin ); 41
cbox . yMin = FT_PIX_FLOOR ( cbox . yMin ); 42
cbox . xMax = FT_PIX_CEIL ( cbox . xMax ); 43
cbox . yMax = FT_PIX_CEIL ( cbox . yMax ); 44
width = ( FT_UInt ) ( ( cbox . xMax - cbox . xMin ) >> 6 ); 46
height = ( FT_UInt ) ( ( cbox . yMax - cbox . yMin ) >> 6 ); 47
bitmap = & slot -> bitmap; 48
if ( slot -> internal -> flags & FT_GLYPH_OWN_BITMAP )  55
slot -> internal -> flags &= ~FT_GLYPH_OWN_BITMAP; 58
pitch = width; 62
if ( hmul )  63
width = width * 3; 65
pitch = FT_PAD_CEIL ( width , 4 ); 66
if ( vmul )  69
height *= 3; 70
if ( slot -> library -> lcd_filter_func )  79
FT_Int extra = slot -> library -> lcd_extra ; 81
if ( hmul )  84
width += 3 * extra; 87
pitch = FT_PAD_CEIL ( width , 4 ); 88
if ( vmul )  92
height += 3 * extra; 95
if ( pitch > 0xFFFF || height > 0xFFFF )  102
bitmap -> pixel_mode = FT_PIXEL_MODE_GRAY; 109
bitmap -> num_grays = 256; 110
bitmap -> width = width; 111
bitmap -> rows = height; 112
bitmap -> pitch = pitch; 113
if ( FT_ALLOC ( bitmap -> buffer , ( FT_ULong ) pitch * height ) )  118
FT_Vector * points = outline -> points ; 151
FT_Vector * points_end = points + outline -> n_points ; 152
for ( vec = points; vec < points_end; vec++ ) 157
for ( vec = points; vec < points_end; vec++ ) 161
------------------------------
672 /home/speedy/test/source2slice/NVD/CVE_2009_0946_PATCHED_ft_smooth_render_generic.c FT_Vector * points_end = points + outline -> n_points ; 133
static FT_Error
CVE_2009_0946_PATCHED_ft_smooth_render_generic( FT_Renderer       render,
FT_GlyphSlot      slot,
FT_Render_Mode    mode,
const FT_Vector*  origin,
FT_Render_Mode    required_mode ) 6
FT_BBox cbox ; 10
FT_UInt width , height , height_org , width_org , pitch ; 11
FT_Bitmap * bitmap ; 12
FT_Int hmul = mode == FT_RENDER_MODE_LCD ; 14
FT_Int vmul = mode == FT_RENDER_MODE_LCD_V ; 15
if ( slot -> format != render -> glyph_format )  22
if ( mode != required_mode )  29
outline = & slot -> outline; 32
cbox . xMin = FT_PIX_FLOOR ( cbox . xMin ); 41
cbox . yMin = FT_PIX_FLOOR ( cbox . yMin ); 42
cbox . xMax = FT_PIX_CEIL ( cbox . xMax ); 43
cbox . yMax = FT_PIX_CEIL ( cbox . yMax ); 44
width = ( FT_UInt ) ( ( cbox . xMax - cbox . xMin ) >> 6 ); 46
height = ( FT_UInt ) ( ( cbox . yMax - cbox . yMin ) >> 6 ); 47
bitmap = & slot -> bitmap; 48
if ( slot -> internal -> flags & FT_GLYPH_OWN_BITMAP )  55
slot -> internal -> flags &= ~FT_GLYPH_OWN_BITMAP; 58
pitch = width; 62
if ( hmul )  63
width = width * 3; 65
pitch = FT_PAD_CEIL ( width , 4 ); 66
if ( vmul )  69
height *= 3; 70
if ( slot -> library -> lcd_filter_func )  79
FT_Int extra = slot -> library -> lcd_extra ; 81
if ( hmul )  84
width += 3 * extra; 87
pitch = FT_PAD_CEIL ( width , 4 ); 88
if ( vmul )  92
height += 3 * extra; 95
if ( pitch > 0xFFFF || height > 0xFFFF )  102
bitmap -> pixel_mode = FT_PIXEL_MODE_GRAY; 109
bitmap -> num_grays = 256; 110
bitmap -> width = width; 111
bitmap -> rows = height; 112
bitmap -> pitch = pitch; 113
if ( FT_ALLOC ( bitmap -> buffer , ( FT_ULong ) pitch * height ) )  118
FT_Vector * points = outline -> points ; 132
FT_Vector * points_end = points + outline -> n_points ; 133
for ( vec = points; vec < points_end; vec++ ) 138
for ( vec = points; vec < points_end; vec++ ) 142
------------------------------
673 /home/speedy/test/source2slice/NVD/CVE_2009_0946_VULN_ft_smooth_render_generic.c FT_Vector * points_end = points + outline -> n_points ; 145
static FT_Error
CVE_2009_0946_VULN_ft_smooth_render_generic( FT_Renderer       render,
FT_GlyphSlot      slot,
FT_Render_Mode    mode,
const FT_Vector*  origin,
FT_Render_Mode    required_mode ) 6
FT_BBox cbox ; 10
FT_UInt width , height , height_org , width_org , pitch ; 11
FT_Bitmap * bitmap ; 12
FT_Int hmul = mode == FT_RENDER_MODE_LCD ; 14
FT_Int vmul = mode == FT_RENDER_MODE_LCD_V ; 15
if ( slot -> format != render -> glyph_format )  22
if ( mode != required_mode )  29
outline = & slot -> outline; 32
cbox . xMin = FT_PIX_FLOOR ( cbox . xMin ); 41
cbox . yMin = FT_PIX_FLOOR ( cbox . yMin ); 42
cbox . xMax = FT_PIX_CEIL ( cbox . xMax ); 43
cbox . yMax = FT_PIX_CEIL ( cbox . yMax ); 44
width = ( FT_UInt ) ( ( cbox . xMax - cbox . xMin ) >> 6 ); 46
height = ( FT_UInt ) ( ( cbox . yMax - cbox . yMin ) >> 6 ); 47
bitmap = & slot -> bitmap; 48
if ( slot -> internal -> flags & FT_GLYPH_OWN_BITMAP )  55
slot -> internal -> flags &= ~FT_GLYPH_OWN_BITMAP; 58
pitch = width; 62
if ( hmul )  63
width = width * 3; 65
pitch = FT_PAD_CEIL ( width , 4 ); 66
if ( vmul )  69
height *= 3; 70
if ( slot -> library -> lcd_filter_func )  79
FT_Int extra = slot -> library -> lcd_extra ; 81
if ( hmul )  84
width += 3 * extra; 87
pitch = FT_PAD_CEIL ( width , 4 ); 88
if ( vmul )  92
height += 3 * extra; 95
bitmap -> pixel_mode = FT_PIXEL_MODE_GRAY; 102
bitmap -> num_grays = 256; 103
bitmap -> width = width; 104
bitmap -> rows = height; 105
bitmap -> pitch = pitch; 106
if ( FT_ALLOC ( bitmap -> buffer , ( FT_ULong ) pitch * height ) )  111
FT_Vector * points = outline -> points ; 144
FT_Vector * points_end = points + outline -> n_points ; 145
for ( vec = points; vec < points_end; vec++ ) 150
for ( vec = points; vec < points_end; vec++ ) 154
------------------------------
674 /home/speedy/test/source2slice/NVD/CVE_2009_0946_VULN_ft_smooth_render_generic.c FT_Vector * points_end = points + outline -> n_points ; 126
static FT_Error
CVE_2009_0946_VULN_ft_smooth_render_generic( FT_Renderer       render,
FT_GlyphSlot      slot,
FT_Render_Mode    mode,
const FT_Vector*  origin,
FT_Render_Mode    required_mode ) 6
FT_BBox cbox ; 10
FT_UInt width , height , height_org , width_org , pitch ; 11
FT_Bitmap * bitmap ; 12
FT_Int hmul = mode == FT_RENDER_MODE_LCD ; 14
FT_Int vmul = mode == FT_RENDER_MODE_LCD_V ; 15
if ( slot -> format != render -> glyph_format )  22
if ( mode != required_mode )  29
outline = & slot -> outline; 32
cbox . xMin = FT_PIX_FLOOR ( cbox . xMin ); 41
cbox . yMin = FT_PIX_FLOOR ( cbox . yMin ); 42
cbox . xMax = FT_PIX_CEIL ( cbox . xMax ); 43
cbox . yMax = FT_PIX_CEIL ( cbox . yMax ); 44
width = ( FT_UInt ) ( ( cbox . xMax - cbox . xMin ) >> 6 ); 46
height = ( FT_UInt ) ( ( cbox . yMax - cbox . yMin ) >> 6 ); 47
bitmap = & slot -> bitmap; 48
if ( slot -> internal -> flags & FT_GLYPH_OWN_BITMAP )  55
slot -> internal -> flags &= ~FT_GLYPH_OWN_BITMAP; 58
pitch = width; 62
if ( hmul )  63
width = width * 3; 65
pitch = FT_PAD_CEIL ( width , 4 ); 66
if ( vmul )  69
height *= 3; 70
if ( slot -> library -> lcd_filter_func )  79
FT_Int extra = slot -> library -> lcd_extra ; 81
if ( hmul )  84
width += 3 * extra; 87
pitch = FT_PAD_CEIL ( width , 4 ); 88
if ( vmul )  92
height += 3 * extra; 95
bitmap -> pixel_mode = FT_PIXEL_MODE_GRAY; 102
bitmap -> num_grays = 256; 103
bitmap -> width = width; 104
bitmap -> rows = height; 105
bitmap -> pitch = pitch; 106
if ( FT_ALLOC ( bitmap -> buffer , ( FT_ULong ) pitch * height ) )  111
FT_Vector * points = outline -> points ; 125
FT_Vector * points_end = points + outline -> n_points ; 126
for ( vec = points; vec < points_end; vec++ ) 131
for ( vec = points; vec < points_end; vec++ ) 135
------------------------------
675 /home/speedy/test/source2slice/NVD/CVE_2009_1046_PATCHED_set_selection.c struct kbd_struct * kbd = kbd_table + fg_console ; 8
int CVE_2009_1046_PATCHED_set_selection(const struct tiocl_selection __user *sel, struct tty_struct *tty) 1
struct kbd_struct * kbd = kbd_table + fg_console ; 8
use_unicode = kbd && kbd -> kbdmode == VC_UNICODE; 52
multiplier = use_unicode ? 3 : 1; 135
bp = kmalloc ( ( ( sel_end - sel_start ) / 2 + 1 ) * multiplier , GFP_KERNEL ); 136
if ( ! bp )  137
sel_buffer = bp; 143
obp = bp; 145
if ( use_unicode )  148
bp += store_utf8 ( c , bp ); 149
* bp ++ = c; 151
obp = bp; 153
if ( obp != bp )  157
bp = obp; 158
* bp ++ = '\r'; 159
obp = bp; 161
sel_buffer_lth = bp - sel_buffer; 164
------------------------------
676 /home/speedy/test/source2slice/NVD/CVE_2009_1046_VULN_set_selection.c struct kbd_struct * kbd = kbd_table + fg_console ; 8
int CVE_2009_1046_VULN_set_selection(const struct tiocl_selection __user *sel, struct tty_struct *tty) 1
struct kbd_struct * kbd = kbd_table + fg_console ; 8
use_unicode = kbd && kbd -> kbdmode == VC_UNICODE; 52
multiplier = use_unicode ? 3 : 1; 135
bp = kmalloc ( ( sel_end - sel_start ) / 2 * multiplier + 1 , GFP_KERNEL ); 136
if ( ! bp )  137
sel_buffer = bp; 143
obp = bp; 145
if ( use_unicode )  148
bp += store_utf8 ( c , bp ); 149
* bp ++ = c; 151
obp = bp; 153
if ( obp != bp )  157
bp = obp; 158
* bp ++ = '\r'; 159
obp = bp; 161
sel_buffer_lth = bp - sel_buffer; 164
------------------------------
677 /home/speedy/test/source2slice/NVD/CVE_2009_1385_PATCHED_e1000_clean_rx_irq.c struct sk_buff * new_skb = netdev_alloc_skb ( netdev , length + NET_IP_ALIGN ) ; 90
static bool CVE_2009_1385_PATCHED_e1000_clean_rx_irq(struct e1000_adapter *adapter,
struct e1000_rx_ring *rx_ring,
int *work_done, int work_to_do) 3
struct e1000_hw * hw = & adapter -> hw ; 5
struct net_device * netdev = adapter -> netdev ; 6
struct e1000_rx_desc * rx_desc , * next_rxd ; 8
struct e1000_buffer * buffer_info , * next_buffer ; 9
u32 length ; 11
u8 last_byte ; 12
unsigned int i ; 13
i = rx_ring -> next_to_clean; 18
rx_desc = E1000_RX_DESC ( * rx_ring , i ); 19
buffer_info = & rx_ring -> buffer_info [ i ]; 20
while ( rx_desc -> status & E1000_RXD_STAT_DD )  22
struct sk_buff * skb ; 23
u8 status ; 24
if ( * work_done >= work_to_do )  26
( * work_done ) ++; 28
status = rx_desc -> status; 30
skb = buffer_info -> skb; 31
buffer_info -> skb = NULL; 32
prefetch ( skb -> data - NET_IP_ALIGN ); 34
if ( ++ i == rx_ring -> count )  36
i = 0; 36
next_rxd = E1000_RX_DESC ( * rx_ring , i ); 37
next_buffer = & rx_ring -> buffer_info [ i ]; 40
length = le16_to_cpu ( rx_desc -> length ); 49
if ( unlikely ( ! ( status & E1000_RXD_STAT_EOP ) || ( length <= 4 ) ) )  52
buffer_info -> skb = skb; 57
if ( unlikely ( rx_desc -> errors & E1000_RXD_ERR_FRAME_ERR_MASK ) )  61
last_byte = * ( skb -> data + length - 1 ); 62
if ( TBI_ACCEPT ( hw , status , rx_desc -> errors , length , last_byte ) )  63
e1000_tbi_adjust_stats ( hw , & adapter -> stats , length , skb -> data ); 66
length --; 70
buffer_info -> skb = skb; 73
length -= 4; 80
if ( length < copybreak )  89
struct sk_buff * new_skb = netdev_alloc_skb ( netdev , length + NET_IP_ALIGN ) ; 90
if ( new_skb )  92
skb_reserve ( new_skb , NET_IP_ALIGN ); 93
skb_copy_to_linear_data_offset ( new_skb , - NET_IP_ALIGN , ( skb -> data - NET_IP_ALIGN ) , ( length + NET_IP_ALIGN ) ); 94
buffer_info -> skb = skb; 101
skb = new_skb; 102
skb_put ( skb , length ); 107
e1000_rx_checksum ( adapter , ( u32 ) ( status ) | ( ( u32 ) ( rx_desc -> errors ) << 24 ) , le16_to_cpu ( rx_desc -> csum ) , skb ); 110
skb -> protocol = eth_type_trans ( skb , netdev ); 115
vlan_hwaccel_receive_skb ( skb , adapter -> vlgrp , le16_to_cpu ( rx_desc -> special ) ); 119
netif_receive_skb ( skb ); 122
rx_desc -> status = 0; 126
rx_desc = next_rxd; 135
buffer_info = next_buffer; 136
------------------------------
678 /home/speedy/test/source2slice/NVD/CVE_2009_1385_VULN_e1000_clean_rx_irq.c struct sk_buff * new_skb = netdev_alloc_skb ( netdev , length + NET_IP_ALIGN ) ; 89
static bool CVE_2009_1385_VULN_e1000_clean_rx_irq(struct e1000_adapter *adapter,
struct e1000_rx_ring *rx_ring,
int *work_done, int work_to_do) 3
struct e1000_hw * hw = & adapter -> hw ; 5
struct net_device * netdev = adapter -> netdev ; 6
struct e1000_rx_desc * rx_desc , * next_rxd ; 8
struct e1000_buffer * buffer_info , * next_buffer ; 9
u32 length ; 11
u8 last_byte ; 12
unsigned int i ; 13
i = rx_ring -> next_to_clean; 18
rx_desc = E1000_RX_DESC ( * rx_ring , i ); 19
buffer_info = & rx_ring -> buffer_info [ i ]; 20
while ( rx_desc -> status & E1000_RXD_STAT_DD )  22
struct sk_buff * skb ; 23
u8 status ; 24
if ( * work_done >= work_to_do )  26
( * work_done ) ++; 28
status = rx_desc -> status; 30
skb = buffer_info -> skb; 31
buffer_info -> skb = NULL; 32
prefetch ( skb -> data - NET_IP_ALIGN ); 34
if ( ++ i == rx_ring -> count )  36
i = 0; 36
next_rxd = E1000_RX_DESC ( * rx_ring , i ); 37
next_buffer = & rx_ring -> buffer_info [ i ]; 40
length = le16_to_cpu ( rx_desc -> length ); 49
if ( unlikely ( ! ( status & E1000_RXD_STAT_EOP ) ) )  51
buffer_info -> skb = skb; 56
if ( unlikely ( rx_desc -> errors & E1000_RXD_ERR_FRAME_ERR_MASK ) )  60
last_byte = * ( skb -> data + length - 1 ); 61
if ( TBI_ACCEPT ( hw , status , rx_desc -> errors , length , last_byte ) )  62
e1000_tbi_adjust_stats ( hw , & adapter -> stats , length , skb -> data ); 65
length --; 69
buffer_info -> skb = skb; 72
length -= 4; 79
if ( length < copybreak )  88
struct sk_buff * new_skb = netdev_alloc_skb ( netdev , length + NET_IP_ALIGN ) ; 89
if ( new_skb )  91
skb_reserve ( new_skb , NET_IP_ALIGN ); 92
skb_copy_to_linear_data_offset ( new_skb , - NET_IP_ALIGN , ( skb -> data - NET_IP_ALIGN ) , ( length + NET_IP_ALIGN ) ); 93
buffer_info -> skb = skb; 100
skb = new_skb; 101
skb_put ( skb , length ); 106
e1000_rx_checksum ( adapter , ( u32 ) ( status ) | ( ( u32 ) ( rx_desc -> errors ) << 24 ) , le16_to_cpu ( rx_desc -> csum ) , skb ); 109
skb -> protocol = eth_type_trans ( skb , netdev ); 114
vlan_hwaccel_receive_skb ( skb , adapter -> vlgrp , le16_to_cpu ( rx_desc -> special ) ); 118
netif_receive_skb ( skb ); 121
rx_desc -> status = 0; 125
rx_desc = next_rxd; 134
buffer_info = next_buffer; 135
------------------------------
679 /home/speedy/test/source2slice/NVD/CVE_2009_4410_PATCHED_fuse_ioctl_copy_user.c size_t iov_len = ii . iov -> iov_len - ii . iov_offset ; 21
static int CVE_2009_4410_PATCHED_fuse_ioctl_copy_user(struct page **pages, struct iovec *iov,
unsigned int nr_segs, size_t bytes, bool to_user) 2
struct iov_iter ii ; 4
int page_idx = 0 ; 5
if ( ! bytes )  7
while ( iov_iter_count ( & ii ) )  12
struct page * page = pages [ page_idx ++ ] ; 13
size_t todo = min_t ( size_t , PAGE_SIZE , iov_iter_count ( & ii ) ) ; 14
void * kaddr , * map ; 15
kaddr = map = kmap ( page ); 17
while ( todo )  19
char __user * uaddr = ii . iov -> iov_base + ii . iov_offset ; 20
size_t iov_len = ii . iov -> iov_len - ii . iov_offset ; 21
size_t copy = min ( todo , iov_len ) ; 22
size_t left ; 23
if ( ! to_user )  25
left = copy_from_user ( kaddr , uaddr , copy ); 26
left = copy_to_user ( uaddr , kaddr , copy ); 28
if ( unlikely ( left ) )  30
iov_iter_advance ( & ii , copy ); 33
todo -= copy; 34
kaddr += copy; 35
------------------------------
680 /home/speedy/test/source2slice/NVD/CVE_2009_4410_PATCHED_fuse_ioctl_copy_user.c char __user * uaddr = ii . iov -> iov_base + ii . iov_offset ; 20
static int CVE_2009_4410_PATCHED_fuse_ioctl_copy_user(struct page **pages, struct iovec *iov,
unsigned int nr_segs, size_t bytes, bool to_user) 2
struct iov_iter ii ; 4
int page_idx = 0 ; 5
if ( ! bytes )  7
while ( iov_iter_count ( & ii ) )  12
struct page * page = pages [ page_idx ++ ] ; 13
size_t todo = min_t ( size_t , PAGE_SIZE , iov_iter_count ( & ii ) ) ; 14
void * kaddr , * map ; 15
kaddr = map = kmap ( page ); 17
while ( todo )  19
char __user * uaddr = ii . iov -> iov_base + ii . iov_offset ; 20
size_t iov_len = ii . iov -> iov_len - ii . iov_offset ; 21
size_t copy = min ( todo , iov_len ) ; 22
size_t left ; 23
if ( ! to_user )  25
left = copy_from_user ( kaddr , uaddr , copy ); 26
left = copy_to_user ( uaddr , kaddr , copy ); 28
if ( unlikely ( left ) )  30
todo -= copy; 34
kaddr += copy; 35
------------------------------
681 /home/speedy/test/source2slice/NVD/CVE_2009_4410_VULN_fuse_ioctl_copy_user.c size_t iov_len = ii . iov -> iov_len - ii . iov_offset ; 21
static int CVE_2009_4410_VULN_fuse_ioctl_copy_user(struct page **pages, struct iovec *iov,
unsigned int nr_segs, size_t bytes, bool to_user) 2
struct iov_iter ii ; 4
int page_idx = 0 ; 5
if ( ! bytes )  7
while ( iov_iter_count ( & ii ) )  12
struct page * page = pages [ page_idx ++ ] ; 13
size_t todo = min_t ( size_t , PAGE_SIZE , iov_iter_count ( & ii ) ) ; 14
void * kaddr , * map ; 15
kaddr = map = kmap ( page ); 17
while ( todo )  19
char __user * uaddr = ii . iov -> iov_base + ii . iov_offset ; 20
size_t iov_len = ii . iov -> iov_len - ii . iov_offset ; 21
size_t copy = min ( todo , iov_len ) ; 22
size_t left ; 23
if ( ! to_user )  25
left = copy_from_user ( kaddr , uaddr , copy ); 26
left = copy_to_user ( uaddr , kaddr , copy ); 28
if ( unlikely ( left ) )  30
iov_iter_advance ( & ii , copy ); 33
todo -= copy; 34
kaddr += copy; 35
------------------------------
682 /home/speedy/test/source2slice/NVD/CVE_2009_4410_VULN_fuse_ioctl_copy_user.c char __user * uaddr = ii . iov -> iov_base + ii . iov_offset ; 20
static int CVE_2009_4410_VULN_fuse_ioctl_copy_user(struct page **pages, struct iovec *iov,
unsigned int nr_segs, size_t bytes, bool to_user) 2
struct iov_iter ii ; 4
int page_idx = 0 ; 5
if ( ! bytes )  7
while ( iov_iter_count ( & ii ) )  12
struct page * page = pages [ page_idx ++ ] ; 13
size_t todo = min_t ( size_t , PAGE_SIZE , iov_iter_count ( & ii ) ) ; 14
void * kaddr , * map ; 15
kaddr = map = kmap ( page ); 17
while ( todo )  19
char __user * uaddr = ii . iov -> iov_base + ii . iov_offset ; 20
size_t iov_len = ii . iov -> iov_len - ii . iov_offset ; 21
size_t copy = min ( todo , iov_len ) ; 22
size_t left ; 23
if ( ! to_user )  25
left = copy_from_user ( kaddr , uaddr , copy ); 26
left = copy_to_user ( uaddr , kaddr , copy ); 28
if ( unlikely ( left ) )  30
todo -= copy; 34
kaddr += copy; 35
------------------------------
683 /home/speedy/test/source2slice/NVD/CVE_2010_2498_PATCHED_psh_glyph_find_strong_points.c PSH_Point point = glyph -> points + first ; 44
static void
CVE_2010_2498_PATCHED_psh_glyph_find_strong_points( PSH_Glyph  glyph,
FT_Int     dimension ) 4
PSH_Hint_Table table = & glyph -> hint_tables [ dimension ] ; 9
PS_Mask mask = table -> hint_masks -> masks ; 10
FT_UInt num_masks = table -> hint_masks -> num_masks ; 11
if ( num_masks > 1 && glyph -> num_points > 0 )  25
first = mask -> end_point > glyph -> num_points ? glyph -> num_points : mask -> end_point; 28
mask ++; 31
for ( ; num_masks > 1; num_masks--, mask++ ) 32
FT_UInt next ; 34
FT_Int count ; 35
next = mask -> end_point > glyph -> num_points ? glyph -> num_points : mask -> end_point; 38
count = next - first; 41
if ( count > 0 )  42
PSH_Point point = glyph -> points + first ; 44
psh_hint_table_find_strong_points ( table , point , count , threshold , major_dir ); 49
first = next; 52
------------------------------
684 /home/speedy/test/source2slice/NVD/CVE_2010_2498_VULN_psh_glyph_find_strong_points.c PSH_Point point = glyph -> points + first ; 39
static void
CVE_2010_2498_VULN_psh_glyph_find_strong_points( PSH_Glyph  glyph,
FT_Int     dimension ) 4
PSH_Hint_Table table = & glyph -> hint_tables [ dimension ] ; 9
PS_Mask mask = table -> hint_masks -> masks ; 10
FT_UInt num_masks = table -> hint_masks -> num_masks ; 11
if ( num_masks > 1 && glyph -> num_points > 0 )  25
first = mask -> end_point; 27
mask ++; 28
for ( ; num_masks > 1; num_masks--, mask++ ) 29
FT_UInt next ; 31
FT_Int count ; 32
next = mask -> end_point; 35
count = next - first; 36
if ( count > 0 )  37
PSH_Point point = glyph -> points + first ; 39
psh_hint_table_find_strong_points ( table , point , count , threshold , major_dir ); 44
first = next; 47
------------------------------
685 /home/speedy/test/source2slice/NVD/CVE_2010_2500_PATCHED_gray_render_span.c unsigned char * q = p + spans -> x ; 31
static void
CVE_2010_2500_PATCHED_gray_render_span( int             y,
int             count,
const FT_Span*  spans,
PWorker         worker ) 5
unsigned char * p ; 7
FT_Bitmap * map = & worker -> target ; 8
p = ( unsigned char * ) map -> buffer - y * map -> pitch; 12
if ( map -> pitch >= 0 )  13
p += ( unsigned ) ( ( map -> rows - 1 ) * map -> pitch ); 14
for ( ; count > 0; count--, spans++ ) 16
unsigned char coverage = spans -> coverage ; 18
if ( coverage )  21
if ( spans -> len >= 8 )  27
unsigned char * q = p + spans -> x ; 31
* q ++ = ( unsigned char ) coverage; 36
* q ++ = ( unsigned char ) coverage; 37
* q ++ = ( unsigned char ) coverage; 38
* q ++ = ( unsigned char ) coverage; 39
* q ++ = ( unsigned char ) coverage; 40
* q ++ = ( unsigned char ) coverage; 41
* q = ( unsigned char ) coverage; 42
------------------------------
686 /home/speedy/test/source2slice/NVD/CVE_2010_2500_VULN_gray_render_span.c unsigned char * q = p + spans -> x ; 31
static void
CVE_2010_2500_VULN_gray_render_span( int             y,
int             count,
const FT_Span*  spans,
PWorker         worker ) 5
unsigned char * p ; 7
FT_Bitmap * map = & worker -> target ; 8
p = ( unsigned char * ) map -> buffer - y * map -> pitch; 12
if ( map -> pitch >= 0 )  13
p += ( map -> rows - 1 ) * map -> pitch; 14
for ( ; count > 0; count--, spans++ ) 16
unsigned char coverage = spans -> coverage ; 18
if ( coverage )  21
if ( spans -> len >= 8 )  27
unsigned char * q = p + spans -> x ; 31
* q ++ = ( unsigned char ) coverage; 36
* q ++ = ( unsigned char ) coverage; 37
* q ++ = ( unsigned char ) coverage; 38
* q ++ = ( unsigned char ) coverage; 39
* q ++ = ( unsigned char ) coverage; 40
* q ++ = ( unsigned char ) coverage; 41
* q = ( unsigned char ) coverage; 42
------------------------------
687 /home/speedy/test/source2slice/NVD/CVE_2013_5593_PATCHED_nsComboboxControlFrame__AbsolutelyPositionDropDown.c const nsPoint newPos = dropdownPosition + translation ; 51
nsComboboxControlFrame::DropDownPositionState
CVE_2013_5593_PATCHED_nsComboboxControlFrame::AbsolutelyPositionDropDown() 2
nsPoint translation ; 4
nscoord above , below ; 5
if ( above <= 0 && below <= 0 )  8
nsSize dropdownSize = mDropdownFrame -> GetSize ( ) ; 18
nscoord height = std :: max ( above , below ) ; 19
nsListControlFrame * lcf = static_cast < nsListControlFrame * > mDropdownFrame 20
if ( height < dropdownSize . height )  21
if ( lcf -> GetNumDisplayRows ( ) > 1 )  22
if ( height > ( dropdownSize . height + lcf -> GetHeightOfARow ( ) * 1.5 ) && lcf -> GetDropdownCanGrow ( ) )  28
bool b = dropdownSize . height <= below || dropdownSize . height > above ; 41
nsPoint dropdownPosition ( 0 , b ? GetRect ( ) . height : - dropdownSize . height ) ; 42
if ( StyleVisibility ( ) -> mDirection == NS_STYLE_DIRECTION_RTL )  43
dropdownPosition . x = GetRect ( ) . width - dropdownSize . width; 45
const nsPoint newPos = dropdownPosition + translation ; 51
if ( currentPos != newPos )  52
mDropdownFrame -> SetPosition ( newPos ); 53
------------------------------
688 /home/speedy/test/source2slice/NVD/CVE_2013_5593_VULN_nsComboboxControlFrame__AbsolutelyPositionDropDown.c const nsPoint newPos = dropdownPosition + translation ; 50
nsComboboxControlFrame::DropDownPositionState
CVE_2013_5593_VULN_nsComboboxControlFrame::AbsolutelyPositionDropDown() 2
nsPoint translation ; 4
nscoord above , below ; 5
if ( above <= 0 && below <= 0 )  8
nsSize dropdownSize = mDropdownFrame -> GetSize ( ) ; 18
nscoord height = std :: max ( above , below ) ; 19
nsListControlFrame * lcf = static_cast < nsListControlFrame * > mDropdownFrame 20
if ( height < dropdownSize . height )  21
if ( lcf -> GetNumDisplayRows ( ) > 1 )  22
if ( height > ( dropdownSize . height + lcf -> GetHeightOfARow ( ) * 1.5 ) && lcf -> GetDropdownCanGrow ( ) )  28
bool b = dropdownSize . height <= below || below >= above ; 40
nsPoint dropdownPosition ( 0 , b ? GetRect ( ) . height : - dropdownSize . height ) ; 41
if ( StyleVisibility ( ) -> mDirection == NS_STYLE_DIRECTION_RTL )  42
dropdownPosition . x = GetRect ( ) . width - dropdownSize . width; 44
const nsPoint newPos = dropdownPosition + translation ; 50
if ( currentPos != newPos )  51
mDropdownFrame -> SetPosition ( newPos ); 52
------------------------------
689 /home/speedy/test/source2slice/NVD/CVE_2013_5596_PATCHED_RasterImage__DecodePool__DecodeJob__Run.c uint32_t bytesDecoded = mImage -> mBytesDecoded - oldByteCount ; 39
NS_IMETHODIMP
CVE_2013_5596_PATCHED_RasterImage::DecodePool::DecodeJob::Run() 2
if ( mRequest -> mRequestStatus == DecodeRequest :: REQUEST_STOPPED )  7
if ( ! mImage -> mDecoder || mImage -> IsDecodeFinished ( ) )  13
if ( mImage -> mDecoder -> NeedsNewFrame ( ) )  21
uint32_t oldByteCount = mImage -> mBytesDecoded ; 27
uint32_t bytesDecoded = mImage -> mBytesDecoded - oldByteCount ; 39
if ( mImage -> mDecoder && ! mImage -> mError && ! mImage -> mPendingError && ! mImage -> IsDecodeFinished ( ) && bytesDecoded < mRequest -> mBytesToDecode && bytesDecoded > 0 )  50
------------------------------
690 /home/speedy/test/source2slice/NVD/CVE_2013_5596_VULN_RasterImage__DecodePool__DecodeJob__Run.c uint32_t bytesDecoded = mImage -> mBytesDecoded - oldByteCount ; 39
NS_IMETHODIMP
CVE_2013_5596_VULN_RasterImage::DecodePool::DecodeJob::Run() 2
if ( mRequest -> mRequestStatus == DecodeRequest :: REQUEST_STOPPED )  7
if ( ! mImage -> mDecoder || mImage -> IsDecodeFinished ( ) )  13
if ( mImage -> mDecoder -> NeedsNewFrame ( ) )  21
uint32_t oldByteCount = mImage -> mBytesDecoded ; 27
uint32_t bytesDecoded = mImage -> mBytesDecoded - oldByteCount ; 39
if ( mImage -> mDecoder && ! mImage -> mError && ! mImage -> IsDecodeFinished ( ) && bytesDecoded < mRequest -> mBytesToDecode && bytesDecoded > 0 )  50
------------------------------
691 /home/speedy/test/source2slice/NVD/CVE_2013_7010_PATCHED_add_bytes_c.c long b = * ( long * ) ( dst + i ) ; 5
static void CVE_2013_7010_PATCHED_add_bytes_c(uint8_t *dst, uint8_t *src, int w) 1
long i ; 2
for(i=0; i<=w-(int)sizeof(long); i+=sizeof(long)) 3
long a = * ( long * ) ( src + i ) ; 4
long b = * ( long * ) ( dst + i ) ; 5
* ( long * ) ( dst + i ) = ( ( a & pb_7f ) + ( b & pb_7f ) ) ^ ( ( a ^ b ) & pb_80 ); 6
for(; i<w; i++) 8
dst [ i + 0 ] += src [ i + 0 ]; 9
------------------------------
692 /home/speedy/test/source2slice/NVD/CVE_2013_7010_PATCHED_add_bytes_c.c long a = * ( long * ) ( src + i ) ; 4
static void CVE_2013_7010_PATCHED_add_bytes_c(uint8_t *dst, uint8_t *src, int w) 1
long i ; 2
for(i=0; i<=w-(int)sizeof(long); i+=sizeof(long)) 3
long a = * ( long * ) ( src + i ) ; 4
long b = * ( long * ) ( dst + i ) ; 5
* ( long * ) ( dst + i ) = ( ( a & pb_7f ) + ( b & pb_7f ) ) ^ ( ( a ^ b ) & pb_80 ); 6
for(; i<w; i++) 8
dst [ i + 0 ] += src [ i + 0 ]; 9
------------------------------
693 /home/speedy/test/source2slice/NVD/CVE_2013_7010_PATCHED_diff_bytes_c.c long b = * ( long * ) ( src2 + i ) ; 19
static void CVE_2013_7010_PATCHED_diff_bytes_c(uint8_t *dst, const uint8_t *src1, const uint8_t *src2, int w) 1
long i ; 2
if ( ( long ) src2 & ( sizeof ( long ) - 1 ) )  4
for(i=0; i<=w-(int)sizeof(long); i+=sizeof(long)) 17
long a = * ( long * ) ( src1 + i ) ; 18
long b = * ( long * ) ( src2 + i ) ; 19
* ( long * ) ( dst + i ) = ( ( a | pb_80 ) - ( b & pb_7f ) ) ^ ( ( a ^ b ^ pb_80 ) & pb_80 ); 20
for(; i<w; i++) 22
dst [ i + 0 ] = src1 [ i + 0 ] - src2 [ i + 0 ]; 23
------------------------------
694 /home/speedy/test/source2slice/NVD/CVE_2013_7010_PATCHED_diff_bytes_c.c long a = * ( long * ) ( src1 + i ) ; 18
static void CVE_2013_7010_PATCHED_diff_bytes_c(uint8_t *dst, const uint8_t *src1, const uint8_t *src2, int w) 1
long i ; 2
if ( ( long ) src2 & ( sizeof ( long ) - 1 ) )  4
for(i=0; i<=w-(int)sizeof(long); i+=sizeof(long)) 17
long a = * ( long * ) ( src1 + i ) ; 18
long b = * ( long * ) ( src2 + i ) ; 19
* ( long * ) ( dst + i ) = ( ( a | pb_80 ) - ( b & pb_7f ) ) ^ ( ( a ^ b ^ pb_80 ) & pb_80 ); 20
for(; i<w; i++) 22
dst [ i + 0 ] = src1 [ i + 0 ] - src2 [ i + 0 ]; 23
------------------------------
695 /home/speedy/test/source2slice/NVD/CVE_2013_7010_VULN_add_bytes_c.c long b = * ( long * ) ( dst + i ) ; 5
static void CVE_2013_7010_VULN_add_bytes_c(uint8_t *dst, uint8_t *src, int w) 1
long i ; 2
for(i=0; i<=w-sizeof(long); i+=sizeof(long)) 3
long a = * ( long * ) ( src + i ) ; 4
long b = * ( long * ) ( dst + i ) ; 5
* ( long * ) ( dst + i ) = ( ( a & pb_7f ) + ( b & pb_7f ) ) ^ ( ( a ^ b ) & pb_80 ); 6
for(; i<w; i++) 8
dst [ i + 0 ] += src [ i + 0 ]; 9
------------------------------
696 /home/speedy/test/source2slice/NVD/CVE_2013_7010_VULN_add_bytes_c.c long a = * ( long * ) ( src + i ) ; 4
static void CVE_2013_7010_VULN_add_bytes_c(uint8_t *dst, uint8_t *src, int w) 1
long i ; 2
for(i=0; i<=w-sizeof(long); i+=sizeof(long)) 3
long a = * ( long * ) ( src + i ) ; 4
long b = * ( long * ) ( dst + i ) ; 5
* ( long * ) ( dst + i ) = ( ( a & pb_7f ) + ( b & pb_7f ) ) ^ ( ( a ^ b ) & pb_80 ); 6
for(; i<w; i++) 8
dst [ i + 0 ] += src [ i + 0 ]; 9
------------------------------
697 /home/speedy/test/source2slice/NVD/CVE_2013_7010_VULN_diff_bytes_c.c long b = * ( long * ) ( src2 + i ) ; 19
static void CVE_2013_7010_VULN_diff_bytes_c(uint8_t *dst, const uint8_t *src1, const uint8_t *src2, int w) 1
long i ; 2
if ( ( long ) src2 & ( sizeof ( long ) - 1 ) )  4
for(i=0; i<=w-sizeof(long); i+=sizeof(long)) 17
long a = * ( long * ) ( src1 + i ) ; 18
long b = * ( long * ) ( src2 + i ) ; 19
* ( long * ) ( dst + i ) = ( ( a | pb_80 ) - ( b & pb_7f ) ) ^ ( ( a ^ b ^ pb_80 ) & pb_80 ); 20
for(; i<w; i++) 22
dst [ i + 0 ] = src1 [ i + 0 ] - src2 [ i + 0 ]; 23
------------------------------
698 /home/speedy/test/source2slice/NVD/CVE_2013_7010_VULN_diff_bytes_c.c long a = * ( long * ) ( src1 + i ) ; 18
static void CVE_2013_7010_VULN_diff_bytes_c(uint8_t *dst, const uint8_t *src1, const uint8_t *src2, int w) 1
long i ; 2
if ( ( long ) src2 & ( sizeof ( long ) - 1 ) )  4
for(i=0; i<=w-sizeof(long); i+=sizeof(long)) 17
long a = * ( long * ) ( src1 + i ) ; 18
long b = * ( long * ) ( src2 + i ) ; 19
* ( long * ) ( dst + i ) = ( ( a | pb_80 ) - ( b & pb_7f ) ) ^ ( ( a ^ b ^ pb_80 ) & pb_80 ); 20
for(; i<w; i++) 22
dst [ i + 0 ] = src1 [ i + 0 ] - src2 [ i + 0 ]; 23
------------------------------
699 /home/speedy/test/source2slice/NVD/CVE_2013_7011_PATCHED_read_header.c int size = AV_RB24 ( p - trailer ) ; 146
static int CVE_2013_7011_PATCHED_read_header(FFV1Context *f) 1
uint8_t state [ CONTEXT_SIZE ] ; 3
RangeCoder * const c = & f -> slice_context [ 0 ] -> c 5
memset ( state , 128 , sizeof ( state ) ); 7
if ( f -> version < 2 )  9
int chroma_planes , chroma_h_shift , chroma_v_shift , transparency ; 10
unsigned v = get_symbol ( c , state , 0 ) ; 11
if ( v >= 2 )  12
f -> version = v; 16
f -> ac = f -> avctx -> coder_type = get_symbol ( c , state , 0 ); 17
if ( f -> ac > 1 )  18
for (i = 1; i < 256; i++) 19
f -> state_transition [ i ] = get_symbol ( c , state , 1 ) + c -> one_state [ i ]; 20
f -> colorspace = get_symbol ( c , state , 0 ); 23
if ( f -> version > 0 )  25
f -> avctx -> bits_per_raw_sample = get_symbol ( c , state , 0 ); 26
chroma_planes = get_rac ( c , state ); 28
chroma_h_shift = get_symbol ( c , state , 0 ); 29
chroma_v_shift = get_symbol ( c , state , 0 ); 30
transparency = get_rac ( c , state ); 31
if ( f -> plane_count )  33
if ( chroma_planes != f -> chroma_planes || chroma_h_shift != f -> chroma_h_shift || chroma_v_shift != f -> chroma_v_shift || transparency != f -> transparency )  34
f -> chroma_planes = chroma_planes; 43
f -> chroma_h_shift = chroma_h_shift; 44
f -> chroma_v_shift = chroma_v_shift; 45
f -> transparency = transparency; 46
f -> plane_count = 2 + f -> transparency; 48
if ( f -> colorspace == 0 )  51
if ( ! f -> transparency && ! f -> chroma_planes )  52
if ( f -> avctx -> bits_per_raw_sample <= 8 && ! f -> transparency )  57
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  58
if ( f -> avctx -> bits_per_raw_sample <= 8 && f -> transparency )  69
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  70
if ( f -> avctx -> bits_per_raw_sample == 9 )  78
f -> packed_at_lsb = 1; 79
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  80
if ( f -> avctx -> bits_per_raw_sample == 10 )  88
f -> packed_at_lsb = 1; 89
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  90
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  99
if ( f -> colorspace == 1 )  108
if ( f -> chroma_h_shift || f -> chroma_v_shift )  109
if ( f -> version < 2 )  132
if ( f -> version < 3 )  138
const uint8_t * p = c -> bytestream_end ; 141
for (f->slice_count = 0;
f->slice_count < MAX_SLICES && 3 < p - c->bytestream_start;
f->slice_count++) 144
int trailer = 3 + 5 * ! ! f -> ec ; 145
int size = AV_RB24 ( p - trailer ) ; 146
if ( size + trailer > p - c -> bytestream_start )  147
p -= size + trailer; 149
p -> quant_table_index = idx; 192
memcpy ( p -> quant_table , f -> quant_tables [ idx ] , sizeof ( p -> quant_table ) ); 193
memcpy ( p -> quant_table , f -> quant_table , sizeof ( p -> quant_table ) ); 197
if ( p -> context_count < context_count )  202
av_freep ( & p -> state ); 203
av_freep ( & p -> vlc_state ); 204
p -> context_count = context_count; 206
------------------------------
700 /home/speedy/test/source2slice/NVD/CVE_2013_7011_VULN_read_header.c int size = AV_RB24 ( p - trailer ) ; 129
static int CVE_2013_7011_VULN_read_header(FFV1Context *f) 1
uint8_t state [ CONTEXT_SIZE ] ; 3
RangeCoder * const c = & f -> slice_context [ 0 ] -> c 5
memset ( state , 128 , sizeof ( state ) ); 7
if ( f -> version < 2 )  9
unsigned v = get_symbol ( c , state , 0 ) ; 10
if ( v >= 2 )  11
f -> version = v; 15
f -> ac = f -> avctx -> coder_type = get_symbol ( c , state , 0 ); 16
if ( f -> ac > 1 )  17
for (i = 1; i < 256; i++) 18
f -> state_transition [ i ] = get_symbol ( c , state , 1 ) + c -> one_state [ i ]; 19
f -> colorspace = get_symbol ( c , state , 0 ); 22
if ( f -> version > 0 )  24
f -> avctx -> bits_per_raw_sample = get_symbol ( c , state , 0 ); 25
f -> chroma_planes = get_rac ( c , state ); 27
f -> chroma_h_shift = get_symbol ( c , state , 0 ); 28
f -> chroma_v_shift = get_symbol ( c , state , 0 ); 29
f -> transparency = get_rac ( c , state ); 30
f -> plane_count = 2 + f -> transparency; 31
if ( f -> colorspace == 0 )  34
if ( ! f -> transparency && ! f -> chroma_planes )  35
if ( f -> avctx -> bits_per_raw_sample <= 8 && ! f -> transparency )  40
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  41
if ( f -> avctx -> bits_per_raw_sample <= 8 && f -> transparency )  52
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  53
if ( f -> avctx -> bits_per_raw_sample == 9 )  61
f -> packed_at_lsb = 1; 62
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  63
if ( f -> avctx -> bits_per_raw_sample == 10 )  71
f -> packed_at_lsb = 1; 72
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  73
switch ( 16 * f -> chroma_h_shift + f -> chroma_v_shift )  82
if ( f -> colorspace == 1 )  91
if ( f -> chroma_h_shift || f -> chroma_v_shift )  92
if ( f -> version < 2 )  115
if ( f -> version < 3 )  121
const uint8_t * p = c -> bytestream_end ; 124
for (f->slice_count = 0;
f->slice_count < MAX_SLICES && 3 < p - c->bytestream_start;
f->slice_count++) 127
int trailer = 3 + 5 * ! ! f -> ec ; 128
int size = AV_RB24 ( p - trailer ) ; 129
if ( size + trailer > p - c -> bytestream_start )  130
p -= size + trailer; 132
p -> quant_table_index = idx; 175
memcpy ( p -> quant_table , f -> quant_tables [ idx ] , sizeof ( p -> quant_table ) ); 176
memcpy ( p -> quant_table , f -> quant_table , sizeof ( p -> quant_table ) ); 180
if ( p -> context_count < context_count )  185
av_freep ( & p -> state ); 186
av_freep ( & p -> vlc_state ); 187
p -> context_count = context_count; 189
------------------------------
701 /home/speedy/test/source2slice/NVD/CVE_2013_7014_PATCHED_add_bytes_l2_c.c long b = * ( long * ) ( src2 + i ) ; 6
static void CVE_2013_7014_PATCHED_add_bytes_l2_c(uint8_t *dst, uint8_t *src1, uint8_t *src2, int w) 1
long i ; 3
for (i = 0; i <= w - (int)sizeof(long); i += sizeof(long)) 4
long a = * ( long * ) ( src1 + i ) ; 5
long b = * ( long * ) ( src2 + i ) ; 6
* ( long * ) ( dst + i ) = ( ( a & pb_7f ) + ( b & pb_7f ) ) ^ ( ( a ^ b ) & pb_80 ); 7
for (; i < w; i++) 9
dst [ i ] = src1 [ i ] + src2 [ i ]; 10
------------------------------
702 /home/speedy/test/source2slice/NVD/CVE_2013_7014_PATCHED_add_bytes_l2_c.c long a = * ( long * ) ( src1 + i ) ; 5
static void CVE_2013_7014_PATCHED_add_bytes_l2_c(uint8_t *dst, uint8_t *src1, uint8_t *src2, int w) 1
long i ; 3
for (i = 0; i <= w - (int)sizeof(long); i += sizeof(long)) 4
long a = * ( long * ) ( src1 + i ) ; 5
long b = * ( long * ) ( src2 + i ) ; 6
* ( long * ) ( dst + i ) = ( ( a & pb_7f ) + ( b & pb_7f ) ) ^ ( ( a ^ b ) & pb_80 ); 7
for (; i < w; i++) 9
dst [ i ] = src1 [ i ] + src2 [ i ]; 10
------------------------------
703 /home/speedy/test/source2slice/NVD/CVE_2013_7014_VULN_add_bytes_l2_c.c long b = * ( long * ) ( src2 + i ) ; 6
static void CVE_2013_7014_VULN_add_bytes_l2_c(uint8_t *dst, uint8_t *src1, uint8_t *src2, int w) 1
long i ; 3
for (i = 0; i <= w - sizeof(long); i += sizeof(long)) 4
long a = * ( long * ) ( src1 + i ) ; 5
long b = * ( long * ) ( src2 + i ) ; 6
* ( long * ) ( dst + i ) = ( ( a & pb_7f ) + ( b & pb_7f ) ) ^ ( ( a ^ b ) & pb_80 ); 7
for (; i < w; i++) 9
dst [ i ] = src1 [ i ] + src2 [ i ]; 10
------------------------------
704 /home/speedy/test/source2slice/NVD/CVE_2013_7014_VULN_add_bytes_l2_c.c long a = * ( long * ) ( src1 + i ) ; 5
static void CVE_2013_7014_VULN_add_bytes_l2_c(uint8_t *dst, uint8_t *src1, uint8_t *src2, int w) 1
long i ; 3
for (i = 0; i <= w - sizeof(long); i += sizeof(long)) 4
long a = * ( long * ) ( src1 + i ) ; 5
long b = * ( long * ) ( src2 + i ) ; 6
* ( long * ) ( dst + i ) = ( ( a & pb_7f ) + ( b & pb_7f ) ) ^ ( ( a ^ b ) & pb_80 ); 7
for (; i < w; i++) 9
dst [ i ] = src1 [ i ] + src2 [ i ]; 10
------------------------------
705 /home/speedy/test/source2slice/NVD/CVE_2013_7017_PATCHED_ff_jpeg2000_cleanup.c Jpeg2000Prec * prec = band -> prec + precno ; 13
void CVE_2013_7017_PATCHED_ff_jpeg2000_cleanup(Jpeg2000Component *comp, Jpeg2000CodingStyle *codsty) 1
int reslevelno , bandno , precno ; 3
for (reslevelno = 0;
comp->reslevel && reslevelno < codsty->nreslevels;
reslevelno++) 6
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 7
for (bandno = 0; bandno < reslevel->nbands; bandno++) 9
Jpeg2000Band * band = reslevel -> band + bandno ; 10
for (precno = 0; precno < reslevel->num_precincts_x * reslevel->num_precincts_y; precno++) 11
if ( band -> prec )  12
Jpeg2000Prec * prec = band -> prec + precno ; 13
av_freep ( & prec -> zerobits ); 14
av_freep ( & prec -> cblkincl ); 15
av_freep ( & prec -> cblk ); 16
------------------------------
706 /home/speedy/test/source2slice/NVD/CVE_2013_7017_PATCHED_ff_jpeg2000_cleanup.c Jpeg2000Band * band = reslevel -> band + bandno ; 10
void CVE_2013_7017_PATCHED_ff_jpeg2000_cleanup(Jpeg2000Component *comp, Jpeg2000CodingStyle *codsty) 1
int reslevelno , bandno , precno ; 3
for (reslevelno = 0;
comp->reslevel && reslevelno < codsty->nreslevels;
reslevelno++) 6
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 7
for (bandno = 0; bandno < reslevel->nbands; bandno++) 9
Jpeg2000Band * band = reslevel -> band + bandno ; 10
if ( band -> prec )  12
Jpeg2000Prec * prec = band -> prec + precno ; 13
av_freep ( & prec -> zerobits ); 14
av_freep ( & prec -> cblkincl ); 15
av_freep ( & prec -> cblk ); 16
av_freep ( & band -> prec ); 20
------------------------------
707 /home/speedy/test/source2slice/NVD/CVE_2013_7017_PATCHED_ff_jpeg2000_cleanup.c Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 7
void CVE_2013_7017_PATCHED_ff_jpeg2000_cleanup(Jpeg2000Component *comp, Jpeg2000CodingStyle *codsty) 1
int reslevelno , bandno , precno ; 3
for (reslevelno = 0;
comp->reslevel && reslevelno < codsty->nreslevels;
reslevelno++) 6
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 7
for (bandno = 0; bandno < reslevel->nbands; bandno++) 9
Jpeg2000Band * band = reslevel -> band + bandno ; 10
for (precno = 0; precno < reslevel->num_precincts_x * reslevel->num_precincts_y; precno++) 11
if ( band -> prec )  12
Jpeg2000Prec * prec = band -> prec + precno ; 13
av_freep ( & prec -> zerobits ); 14
av_freep ( & prec -> cblkincl ); 15
av_freep ( & prec -> cblk ); 16
av_freep ( & band -> prec ); 20
av_freep ( & reslevel -> band ); 22
------------------------------
708 /home/speedy/test/source2slice/NVD/CVE_2013_7017_PATCHED_ff_jpeg2000_init_component.c Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
int CVE_2013_7017_PATCHED_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_calloc ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_calloc ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
709 /home/speedy/test/source2slice/NVD/CVE_2013_7017_PATCHED_ff_jpeg2000_init_component.c Jpeg2000Prec * prec = band -> prec + precno ; 188
int CVE_2013_7017_PATCHED_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_calloc ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_calloc ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
710 /home/speedy/test/source2slice/NVD/CVE_2013_7017_PATCHED_ff_jpeg2000_init_component.c Jpeg2000Band * band = reslevel -> band + bandno ; 88
int CVE_2013_7017_PATCHED_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_calloc ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_calloc ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
711 /home/speedy/test/source2slice/NVD/CVE_2013_7017_PATCHED_ff_jpeg2000_init_component.c Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
int CVE_2013_7017_PATCHED_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_calloc ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_calloc ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
712 /home/speedy/test/source2slice/NVD/CVE_2013_7017_PATCHED_ff_jpeg2000_init_component.c int declvl = codsty -> nreslevels - reslevelno ; 40
int CVE_2013_7017_PATCHED_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_calloc ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_calloc ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
713 /home/speedy/test/source2slice/NVD/CVE_2013_7017_VULN_ff_jpeg2000_cleanup.c Jpeg2000Prec * prec = band -> prec + precno ; 12
void CVE_2013_7017_VULN_ff_jpeg2000_cleanup(Jpeg2000Component *comp, Jpeg2000CodingStyle *codsty) 1
int reslevelno , bandno , precno ; 3
for (reslevelno = 0;
comp->reslevel && reslevelno < codsty->nreslevels;
reslevelno++) 6
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 7
for (bandno = 0; bandno < reslevel->nbands; bandno++) 9
Jpeg2000Band * band = reslevel -> band + bandno ; 10
for (precno = 0; precno < reslevel->num_precincts_x * reslevel->num_precincts_y; precno++) 11
Jpeg2000Prec * prec = band -> prec + precno ; 12
av_freep ( & prec -> zerobits ); 13
av_freep ( & prec -> cblkincl ); 14
av_freep ( & prec -> cblk ); 15
------------------------------
714 /home/speedy/test/source2slice/NVD/CVE_2013_7017_VULN_ff_jpeg2000_cleanup.c Jpeg2000Band * band = reslevel -> band + bandno ; 10
void CVE_2013_7017_VULN_ff_jpeg2000_cleanup(Jpeg2000Component *comp, Jpeg2000CodingStyle *codsty) 1
int reslevelno , bandno , precno ; 3
for (reslevelno = 0;
comp->reslevel && reslevelno < codsty->nreslevels;
reslevelno++) 6
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 7
for (bandno = 0; bandno < reslevel->nbands; bandno++) 9
Jpeg2000Band * band = reslevel -> band + bandno ; 10
Jpeg2000Prec * prec = band -> prec + precno ; 12
av_freep ( & prec -> zerobits ); 13
av_freep ( & prec -> cblkincl ); 14
av_freep ( & prec -> cblk ); 15
av_freep ( & band -> prec ); 18
------------------------------
715 /home/speedy/test/source2slice/NVD/CVE_2013_7017_VULN_ff_jpeg2000_cleanup.c Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 7
void CVE_2013_7017_VULN_ff_jpeg2000_cleanup(Jpeg2000Component *comp, Jpeg2000CodingStyle *codsty) 1
int reslevelno , bandno , precno ; 3
for (reslevelno = 0;
comp->reslevel && reslevelno < codsty->nreslevels;
reslevelno++) 6
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 7
for (bandno = 0; bandno < reslevel->nbands; bandno++) 9
Jpeg2000Band * band = reslevel -> band + bandno ; 10
for (precno = 0; precno < reslevel->num_precincts_x * reslevel->num_precincts_y; precno++) 11
Jpeg2000Prec * prec = band -> prec + precno ; 12
av_freep ( & prec -> zerobits ); 13
av_freep ( & prec -> cblkincl ); 14
av_freep ( & prec -> cblk ); 15
av_freep ( & band -> prec ); 18
av_freep ( & reslevel -> band ); 20
------------------------------
716 /home/speedy/test/source2slice/NVD/CVE_2013_7017_VULN_ff_jpeg2000_init_component.c Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
int CVE_2013_7017_VULN_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_malloc_array ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_malloc_array ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
717 /home/speedy/test/source2slice/NVD/CVE_2013_7017_VULN_ff_jpeg2000_init_component.c Jpeg2000Prec * prec = band -> prec + precno ; 188
int CVE_2013_7017_VULN_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_malloc_array ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_malloc_array ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
718 /home/speedy/test/source2slice/NVD/CVE_2013_7017_VULN_ff_jpeg2000_init_component.c Jpeg2000Band * band = reslevel -> band + bandno ; 88
int CVE_2013_7017_VULN_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_malloc_array ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_malloc_array ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
719 /home/speedy/test/source2slice/NVD/CVE_2013_7017_VULN_ff_jpeg2000_init_component.c Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
int CVE_2013_7017_VULN_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_malloc_array ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_malloc_array ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
720 /home/speedy/test/source2slice/NVD/CVE_2013_7017_VULN_ff_jpeg2000_init_component.c int declvl = codsty -> nreslevels - reslevelno ; 40
int CVE_2013_7017_VULN_ff_jpeg2000_init_component(Jpeg2000Component *comp,
Jpeg2000CodingStyle *codsty,
Jpeg2000QuantStyle *qntsty,
int cbps, int dx, int dy,
AVCodecContext *avctx) 5
uint8_t log2_band_prec_width , log2_band_prec_height ; 7
int reslevelno , bandno , gbandno = 0 , ret , i , j ; 8
uint32_t csize ; 9
if ( codsty -> nreslevels2decode <= 0 )  11
if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) )  16
csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ); 21
if ( codsty -> transform == FF_DWT97 )  24
comp -> i_data = NULL; 25
comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ); 26
if ( ! comp -> f_data )  27
comp -> f_data = NULL; 30
comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ); 31
if ( ! comp -> i_data )  32
comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ); 35
if ( ! comp -> reslevel )  36
for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) 39
int declvl = codsty -> nreslevels - reslevelno ; 40
Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; 41
for (i = 0; i < 2; i++) 46
for (j = 0; j < 2; j++) 47
reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ); 48
reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; 51
reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; 52
if ( reslevelno == 0 )  55
reslevel -> nbands = 1; 56
reslevel -> nbands = 3; 58
if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] )  67
reslevel -> num_precincts_x = 0; 68
reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ); 70
if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] )  75
reslevel -> num_precincts_y = 0; 76
reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ); 78
reslevel -> band = av_malloc_array ( reslevel -> nbands , sizeof ( * reslevel -> band ) ); 83
if ( ! reslevel -> band )  84
for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) 87
Jpeg2000Band * band = reslevel -> band + bandno ; 88
int cblkno , precno ; 89
int nb_precincts ; 90
switch ( qntsty -> quantsty )  94
band -> f_stepsize = 1; 99
numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ]; 103
band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ); 105
gain = cbps; 117
band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ); 118
band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0; 119
band -> f_stepsize = 0; 122
if ( ! av_codec_is_encoder ( avctx -> codec ) )  128
band -> f_stepsize *= 0.5; 129
band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ); 131
if ( reslevelno == 0 )  137
for (i = 0; i < 2; i++) 139
for (j = 0; j < 2; j++) 140
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ); 141
log2_band_prec_width = reslevel -> log2_prec_width; 144
log2_band_prec_height = reslevel -> log2_prec_height; 145
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ); 147
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ); 149
for (i = 0; i < 2; i++) 154
for (j = 0; j < 2; j++) 155
band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ); 157
band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ); 165
band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ); 167
log2_band_prec_width = reslevel -> log2_prec_width - 1; 170
log2_band_prec_height = reslevel -> log2_prec_height - 1; 171
for (j = 0; j < 2; j++) 174
band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ); 175
for (j = 0; j < 2; j++) 176
band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ); 177
band -> prec = av_malloc_array ( reslevel -> num_precincts_x * ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ); 179
if ( ! band -> prec )  182
nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y; 185
for (precno = 0; precno < nb_precincts; precno++) 187
Jpeg2000Prec * prec = band -> prec + precno ; 188
prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ); 194
prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ); 196
prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ); 199
prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ); 201
prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ); 204
prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ); 206
prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ); 209
prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ); 211
prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ); 213
prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ); 217
prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 223
if ( ! prec -> cblkincl )  226
prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ); 229
if ( ! prec -> zerobits )  232
prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ); 235
if ( ! prec -> cblk )  238
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 240
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 241
Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width; 246
Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ); 247
cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ); 248
Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height; 251
Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ); 252
cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ); 253
cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ); 256
cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ); 260
cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 264
cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ]; 266
cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 270
cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ]; 272
cblk -> zero = 0; 276
cblk -> lblock = 3; 277
cblk -> length = 0; 278
cblk -> lengthinc = 0; 279
cblk -> npasses = 0; 280
------------------------------
721 /home/speedy/test/source2slice/NVD/CVE_2013_7023_PATCHED_ff_combine_frame.c void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , next + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ) ; 40
int CVE_2013_7023_PATCHED_ff_combine_frame(ParseContext *pc, int next, const uint8_t **buf, int *buf_size) 1
for(; pc->overread>0; pc->overread--) 10
pc -> buffer [ pc -> index ++ ] = pc -> buffer [ pc -> overread_index ++ ]; 11
if ( ! * buf_size && next == END_NOT_FOUND )  15
next = 0; 16
pc -> last_index = pc -> index; 19
if ( next == END_NOT_FOUND )  22
* buf_size = pc -> overread_index = pc -> index + next; 35
if ( pc -> index )  39
void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , next + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ) ; 40
if ( ! new_buffer )  41
pc -> buffer = new_buffer; 46
memcpy ( & pc -> buffer [ pc -> index ] , * buf , next + FF_INPUT_BUFFER_PADDING_SIZE ); 48
pc -> index = 0; 50
* buf = pc -> buffer; 51
pc -> state = ( pc -> state << 8 ) | pc -> buffer [ pc -> last_index + next ]; 56
pc -> state64 = ( pc -> state64 << 8 ) | pc -> buffer [ pc -> last_index + next ]; 57
pc -> overread ++; 58
if ( pc -> overread )  61
av_dlog ( NULL , "overread %d, state:%X next:%d index:%d o_index:%d\n" , pc -> overread , pc -> state , next , pc -> index , pc -> overread_index ); 62
av_dlog ( NULL , "%X %X %X %X\n" , ( * buf ) [ 0 ] , ( * buf ) [ 1 ] , ( * buf ) [ 2 ] , ( * buf ) [ 3 ] ); 64
------------------------------
722 /home/speedy/test/source2slice/NVD/CVE_2013_7023_PATCHED_ff_combine_frame.c void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , ( * buf_size ) + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ) ; 23
int CVE_2013_7023_PATCHED_ff_combine_frame(ParseContext *pc, int next, const uint8_t **buf, int *buf_size) 1
for(; pc->overread>0; pc->overread--) 10
pc -> buffer [ pc -> index ++ ] = pc -> buffer [ pc -> overread_index ++ ]; 11
if ( ! * buf_size && next == END_NOT_FOUND )  15
next = 0; 16
pc -> last_index = pc -> index; 19
if ( next == END_NOT_FOUND )  22
void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , ( * buf_size ) + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ) ; 23
if ( ! new_buffer )  25
pc -> buffer = new_buffer; 29
memcpy ( & pc -> buffer [ pc -> index ] , * buf , * buf_size ); 30
pc -> index += * buf_size; 31
------------------------------
723 /home/speedy/test/source2slice/NVD/CVE_2013_7023_VULN_ff_combine_frame.c void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , next + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ) ; 38
int CVE_2013_7023_VULN_ff_combine_frame(ParseContext *pc, int next, const uint8_t **buf, int *buf_size) 1
for(; pc->overread>0; pc->overread--) 10
pc -> buffer [ pc -> index ++ ] = pc -> buffer [ pc -> overread_index ++ ]; 11
if ( ! * buf_size && next == END_NOT_FOUND )  15
next = 0; 16
pc -> last_index = pc -> index; 19
if ( next == END_NOT_FOUND )  22
* buf_size = pc -> overread_index = pc -> index + next; 33
if ( pc -> index )  37
void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , next + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ) ; 38
if ( ! new_buffer )  40
pc -> buffer = new_buffer; 42
memcpy ( & pc -> buffer [ pc -> index ] , * buf , next + FF_INPUT_BUFFER_PADDING_SIZE ); 44
pc -> index = 0; 46
* buf = pc -> buffer; 47
pc -> state = ( pc -> state << 8 ) | pc -> buffer [ pc -> last_index + next ]; 52
pc -> state64 = ( pc -> state64 << 8 ) | pc -> buffer [ pc -> last_index + next ]; 53
pc -> overread ++; 54
if ( pc -> overread )  57
av_dlog ( NULL , "overread %d, state:%X next:%d index:%d o_index:%d\n" , pc -> overread , pc -> state , next , pc -> index , pc -> overread_index ); 58
av_dlog ( NULL , "%X %X %X %X\n" , ( * buf ) [ 0 ] , ( * buf ) [ 1 ] , ( * buf ) [ 2 ] , ( * buf ) [ 3 ] ); 60
------------------------------
724 /home/speedy/test/source2slice/NVD/CVE_2013_7023_VULN_ff_combine_frame.c void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , ( * buf_size ) + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ) ; 23
int CVE_2013_7023_VULN_ff_combine_frame(ParseContext *pc, int next, const uint8_t **buf, int *buf_size) 1
for(; pc->overread>0; pc->overread--) 10
pc -> buffer [ pc -> index ++ ] = pc -> buffer [ pc -> overread_index ++ ]; 11
if ( ! * buf_size && next == END_NOT_FOUND )  15
next = 0; 16
pc -> last_index = pc -> index; 19
if ( next == END_NOT_FOUND )  22
void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , ( * buf_size ) + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ) ; 23
if ( ! new_buffer )  25
pc -> buffer = new_buffer; 27
memcpy ( & pc -> buffer [ pc -> index ] , * buf , * buf_size ); 28
pc -> index += * buf_size; 29
------------------------------
725 /home/speedy/test/source2slice/NVD/CVE_2013_7024_PATCHED_jpeg2000_decode_tile.c Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 120
static int CVE_2013_7024_PATCHED_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
int x , y ; 5
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
int x , y ; 37
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
x = cblk -> coord [ 0 ] [ 0 ]; 44
if ( s -> cdef [ 0 ] < 0 )  64
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 118
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 120
if ( codsty -> transform == FF_DWT97 )  140
------------------------------
726 /home/speedy/test/source2slice/NVD/CVE_2013_7024_PATCHED_jpeg2000_decode_tile.c Jpeg2000Component * comp = tile -> comp + compno ; 119
static int CVE_2013_7024_PATCHED_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
int x , y ; 5
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
int x , y ; 37
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
x = cblk -> coord [ 0 ] [ 0 ]; 44
if ( s -> cdef [ 0 ] < 0 )  64
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 118
Jpeg2000Component * comp = tile -> comp + compno ; 119
float * datap = comp -> f_data ; 121
int32_t * i_datap = comp -> i_data ; 122
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 142
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 144
* dst = val << ( 16 - cbps ); 146
datap ++; 147
dst += pixelsize; 148
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 152
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 154
* dst = val << ( 16 - cbps ); 156
i_datap ++; 157
dst += pixelsize; 158
------------------------------
727 /home/speedy/test/source2slice/NVD/CVE_2013_7024_PATCHED_jpeg2000_decode_tile.c Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 74
static int CVE_2013_7024_PATCHED_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
int x , y ; 5
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
int x , y ; 37
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
x = cblk -> coord [ 0 ] [ 0 ]; 44
if ( s -> cdef [ 0 ] < 0 )  64
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 74
if ( codsty -> transform == FF_DWT97 )  95
------------------------------
728 /home/speedy/test/source2slice/NVD/CVE_2013_7024_PATCHED_jpeg2000_decode_tile.c Jpeg2000Component * comp = tile -> comp + compno ; 73
static int CVE_2013_7024_PATCHED_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
int x , y ; 5
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
int x , y ; 37
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
x = cblk -> coord [ 0 ] [ 0 ]; 44
if ( s -> cdef [ 0 ] < 0 )  64
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
Jpeg2000Component * comp = tile -> comp + compno ; 73
float * datap = comp -> f_data ; 75
int32_t * i_datap = comp -> i_data ; 76
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 97
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 99
* dst = val << ( 8 - cbps ); 100
datap ++; 101
dst += pixelsize; 102
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 106
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 108
* dst = val << ( 8 - cbps ); 109
i_datap ++; 110
dst += pixelsize; 111
------------------------------
729 /home/speedy/test/source2slice/NVD/CVE_2013_7024_PATCHED_jpeg2000_decode_tile.c Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
static int CVE_2013_7024_PATCHED_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 39
x = cblk -> coord [ 0 ] [ 0 ]; 44
y = cblk -> coord [ 1 ] [ 0 ]; 45
dequantization_float ( x , y , cblk , comp , & t1 , band ); 48
dequantization_int ( x , y , cblk , comp , & t1 , band ); 50
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
int cbps = s -> cbps [ compno ] ; 77
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 78
int pixelsize = planar ? 1 : s -> ncomponents ; 80
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 84
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 87
line = picture -> data [ plane ] + y / s -> cdy [ compno ] * picture -> linesize [ plane ]; 88
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 89
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 92
dst = line + x / s -> cdx [ compno ] * pixelsize + compno * ! planar; 93
for (; x < w; x += s->cdx[compno]) 96
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 97
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 99
* dst = val << ( 8 - cbps ); 100
dst += pixelsize; 102
for (; x < w; x += s->cdx[compno]) 105
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 106
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 108
* dst = val << ( 8 - cbps ); 109
dst += pixelsize; 111
line += picture -> linesize [ plane ]; 114
for (compno = 0; compno < s->ncomponents; compno++) 118
int cbps = s -> cbps [ compno ] ; 124
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 125
int pixelsize = planar ? 1 : s -> ncomponents ; 127
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 131
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 133
linel = ( uint16_t * ) picture -> data [ plane ] + y / s -> cdy [ compno ] * ( picture -> linesize [ plane ] >> 1 ); 134
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 135
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 138
dst = linel + ( x / s -> cdx [ compno ] * pixelsize + compno * ! planar ); 139
for (; x < w; x += s-> cdx[compno]) 141
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 142
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 144
* dst = val << ( 16 - cbps ); 146
dst += pixelsize; 148
for (; x < w; x += s-> cdx[compno]) 151
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 152
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 154
* dst = val << ( 16 - cbps ); 156
dst += pixelsize; 158
linel += picture -> linesize [ plane ] >> 1; 161
------------------------------
730 /home/speedy/test/source2slice/NVD/CVE_2013_7024_PATCHED_jpeg2000_decode_tile.c Jpeg2000Prec * prec = band -> prec + precno ; 33
static int CVE_2013_7024_PATCHED_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 39
x = cblk -> coord [ 0 ] [ 0 ]; 44
y = cblk -> coord [ 1 ] [ 0 ]; 45
dequantization_float ( x , y , cblk , comp , & t1 , band ); 48
dequantization_int ( x , y , cblk , comp , & t1 , band ); 50
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
int cbps = s -> cbps [ compno ] ; 77
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 78
int pixelsize = planar ? 1 : s -> ncomponents ; 80
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 84
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 87
line = picture -> data [ plane ] + y / s -> cdy [ compno ] * picture -> linesize [ plane ]; 88
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 89
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 92
dst = line + x / s -> cdx [ compno ] * pixelsize + compno * ! planar; 93
for (; x < w; x += s->cdx[compno]) 96
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 97
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 99
* dst = val << ( 8 - cbps ); 100
dst += pixelsize; 102
for (; x < w; x += s->cdx[compno]) 105
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 106
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 108
* dst = val << ( 8 - cbps ); 109
dst += pixelsize; 111
line += picture -> linesize [ plane ]; 114
for (compno = 0; compno < s->ncomponents; compno++) 118
int cbps = s -> cbps [ compno ] ; 124
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 125
int pixelsize = planar ? 1 : s -> ncomponents ; 127
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 131
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 133
linel = ( uint16_t * ) picture -> data [ plane ] + y / s -> cdy [ compno ] * ( picture -> linesize [ plane ] >> 1 ); 134
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 135
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 138
dst = linel + ( x / s -> cdx [ compno ] * pixelsize + compno * ! planar ); 139
for (; x < w; x += s-> cdx[compno]) 141
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 142
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 144
* dst = val << ( 16 - cbps ); 146
dst += pixelsize; 148
for (; x < w; x += s-> cdx[compno]) 151
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 152
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 154
* dst = val << ( 16 - cbps ); 156
dst += pixelsize; 158
linel += picture -> linesize [ plane ] >> 1; 161
------------------------------
731 /home/speedy/test/source2slice/NVD/CVE_2013_7024_PATCHED_jpeg2000_decode_tile.c Jpeg2000Band * band = rlevel -> band + bandno ; 21
static int CVE_2013_7024_PATCHED_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 39
x = cblk -> coord [ 0 ] [ 0 ]; 44
y = cblk -> coord [ 1 ] [ 0 ]; 45
dequantization_float ( x , y , cblk , comp , & t1 , band ); 48
dequantization_int ( x , y , cblk , comp , & t1 , band ); 50
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
int cbps = s -> cbps [ compno ] ; 77
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 78
int pixelsize = planar ? 1 : s -> ncomponents ; 80
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 84
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 87
line = picture -> data [ plane ] + y / s -> cdy [ compno ] * picture -> linesize [ plane ]; 88
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 89
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 92
dst = line + x / s -> cdx [ compno ] * pixelsize + compno * ! planar; 93
for (; x < w; x += s->cdx[compno]) 96
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 97
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 99
* dst = val << ( 8 - cbps ); 100
dst += pixelsize; 102
for (; x < w; x += s->cdx[compno]) 105
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 106
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 108
* dst = val << ( 8 - cbps ); 109
dst += pixelsize; 111
line += picture -> linesize [ plane ]; 114
for (compno = 0; compno < s->ncomponents; compno++) 118
int cbps = s -> cbps [ compno ] ; 124
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 125
int pixelsize = planar ? 1 : s -> ncomponents ; 127
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 131
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 133
linel = ( uint16_t * ) picture -> data [ plane ] + y / s -> cdy [ compno ] * ( picture -> linesize [ plane ] >> 1 ); 134
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 135
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 138
dst = linel + ( x / s -> cdx [ compno ] * pixelsize + compno * ! planar ); 139
for (; x < w; x += s-> cdx[compno]) 141
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 142
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 144
* dst = val << ( 16 - cbps ); 146
dst += pixelsize; 148
for (; x < w; x += s-> cdx[compno]) 151
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 152
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 154
* dst = val << ( 16 - cbps ); 156
dst += pixelsize; 158
linel += picture -> linesize [ plane ] >> 1; 161
------------------------------
732 /home/speedy/test/source2slice/NVD/CVE_2013_7024_PATCHED_jpeg2000_decode_tile.c Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
static int CVE_2013_7024_PATCHED_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 39
x = cblk -> coord [ 0 ] [ 0 ]; 44
y = cblk -> coord [ 1 ] [ 0 ]; 45
dequantization_float ( x , y , cblk , comp , & t1 , band ); 48
dequantization_int ( x , y , cblk , comp , & t1 , band ); 50
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
int cbps = s -> cbps [ compno ] ; 77
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 78
int pixelsize = planar ? 1 : s -> ncomponents ; 80
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 84
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 87
line = picture -> data [ plane ] + y / s -> cdy [ compno ] * picture -> linesize [ plane ]; 88
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 89
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 92
dst = line + x / s -> cdx [ compno ] * pixelsize + compno * ! planar; 93
for (; x < w; x += s->cdx[compno]) 96
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 97
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 99
* dst = val << ( 8 - cbps ); 100
dst += pixelsize; 102
for (; x < w; x += s->cdx[compno]) 105
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 106
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 108
* dst = val << ( 8 - cbps ); 109
dst += pixelsize; 111
line += picture -> linesize [ plane ]; 114
for (compno = 0; compno < s->ncomponents; compno++) 118
int cbps = s -> cbps [ compno ] ; 124
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 125
int pixelsize = planar ? 1 : s -> ncomponents ; 127
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 131
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 133
linel = ( uint16_t * ) picture -> data [ plane ] + y / s -> cdy [ compno ] * ( picture -> linesize [ plane ] >> 1 ); 134
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 135
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 138
dst = linel + ( x / s -> cdx [ compno ] * pixelsize + compno * ! planar ); 139
for (; x < w; x += s-> cdx[compno]) 141
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 142
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 144
* dst = val << ( 16 - cbps ); 146
dst += pixelsize; 148
for (; x < w; x += s-> cdx[compno]) 151
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 152
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 154
* dst = val << ( 16 - cbps ); 156
dst += pixelsize; 158
linel += picture -> linesize [ plane ] >> 1; 161
------------------------------
733 /home/speedy/test/source2slice/NVD/CVE_2013_7024_PATCHED_jpeg2000_decode_tile.c Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
static int CVE_2013_7024_PATCHED_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 39
if ( codsty -> transform == FF_DWT97 )  47
ff_dwt_decode ( & comp -> dwt , codsty -> transform == FF_DWT97 ? ( void * ) comp -> f_data : ( void * ) comp -> i_data ); 57
------------------------------
734 /home/speedy/test/source2slice/NVD/CVE_2013_7024_PATCHED_jpeg2000_decode_tile.c Jpeg2000Component * comp = tile -> comp + compno ; 12
static int CVE_2013_7024_PATCHED_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 39
x = cblk -> coord [ 0 ] [ 0 ]; 44
y = cblk -> coord [ 1 ] [ 0 ]; 45
dequantization_float ( x , y , cblk , comp , & t1 , band ); 48
dequantization_int ( x , y , cblk , comp , & t1 , band ); 50
ff_dwt_decode ( & comp -> dwt , codsty -> transform == FF_DWT97 ? ( void * ) comp -> f_data : ( void * ) comp -> i_data ); 57
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
int cbps = s -> cbps [ compno ] ; 77
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 78
int pixelsize = planar ? 1 : s -> ncomponents ; 80
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 84
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 87
line = picture -> data [ plane ] + y / s -> cdy [ compno ] * picture -> linesize [ plane ]; 88
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 89
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 92
dst = line + x / s -> cdx [ compno ] * pixelsize + compno * ! planar; 93
for (; x < w; x += s->cdx[compno]) 96
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 97
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 99
* dst = val << ( 8 - cbps ); 100
dst += pixelsize; 102
for (; x < w; x += s->cdx[compno]) 105
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 106
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 108
* dst = val << ( 8 - cbps ); 109
dst += pixelsize; 111
line += picture -> linesize [ plane ]; 114
for (compno = 0; compno < s->ncomponents; compno++) 118
int cbps = s -> cbps [ compno ] ; 124
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 125
int pixelsize = planar ? 1 : s -> ncomponents ; 127
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 131
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 133
linel = ( uint16_t * ) picture -> data [ plane ] + y / s -> cdy [ compno ] * ( picture -> linesize [ plane ] >> 1 ); 134
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 135
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 138
dst = linel + ( x / s -> cdx [ compno ] * pixelsize + compno * ! planar ); 139
for (; x < w; x += s-> cdx[compno]) 141
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 142
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 144
* dst = val << ( 16 - cbps ); 146
dst += pixelsize; 148
for (; x < w; x += s-> cdx[compno]) 151
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 152
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 154
* dst = val << ( 16 - cbps ); 156
dst += pixelsize; 158
linel += picture -> linesize [ plane ] >> 1; 161
------------------------------
735 /home/speedy/test/source2slice/NVD/CVE_2013_7024_VULN_jpeg2000_decode_tile.c Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 120
static int CVE_2013_7024_VULN_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
int x , y ; 5
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
int x , y ; 37
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
x = cblk -> coord [ 0 ] [ 0 ]; 44
if ( s -> cdef [ 0 ] < 0 )  64
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 118
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 120
if ( codsty -> transform == FF_DWT97 )  140
------------------------------
736 /home/speedy/test/source2slice/NVD/CVE_2013_7024_VULN_jpeg2000_decode_tile.c Jpeg2000Component * comp = tile -> comp + compno ; 119
static int CVE_2013_7024_VULN_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
int x , y ; 5
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
int x , y ; 37
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
x = cblk -> coord [ 0 ] [ 0 ]; 44
if ( s -> cdef [ 0 ] < 0 )  64
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 118
Jpeg2000Component * comp = tile -> comp + compno ; 119
float * datap = comp -> f_data ; 121
int32_t * i_datap = comp -> i_data ; 122
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 142
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 144
* dst = val << ( 16 - cbps ); 146
datap ++; 147
dst += pixelsize; 148
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 152
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 154
* dst = val << ( 16 - cbps ); 156
i_datap ++; 157
dst += pixelsize; 158
------------------------------
737 /home/speedy/test/source2slice/NVD/CVE_2013_7024_VULN_jpeg2000_decode_tile.c Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 74
static int CVE_2013_7024_VULN_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
int x , y ; 5
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
int x , y ; 37
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
x = cblk -> coord [ 0 ] [ 0 ]; 44
if ( s -> cdef [ 0 ] < 0 )  64
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 74
if ( codsty -> transform == FF_DWT97 )  95
------------------------------
738 /home/speedy/test/source2slice/NVD/CVE_2013_7024_VULN_jpeg2000_decode_tile.c Jpeg2000Component * comp = tile -> comp + compno ; 73
static int CVE_2013_7024_VULN_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
int x , y ; 5
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
int x , y ; 37
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
x = cblk -> coord [ 0 ] [ 0 ]; 44
if ( s -> cdef [ 0 ] < 0 )  64
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
Jpeg2000Component * comp = tile -> comp + compno ; 73
float * datap = comp -> f_data ; 75
int32_t * i_datap = comp -> i_data ; 76
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 97
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 99
* dst = val << ( 8 - cbps ); 100
datap ++; 101
dst += pixelsize; 102
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 106
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 108
* dst = val << ( 8 - cbps ); 109
i_datap ++; 110
dst += pixelsize; 111
------------------------------
739 /home/speedy/test/source2slice/NVD/CVE_2013_7024_VULN_jpeg2000_decode_tile.c Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
static int CVE_2013_7024_VULN_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 39
x = cblk -> coord [ 0 ] [ 0 ]; 44
y = cblk -> coord [ 1 ] [ 0 ]; 45
dequantization_float ( x , y , cblk , comp , & t1 , band ); 48
dequantization_int ( x , y , cblk , comp , & t1 , band ); 50
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
int cbps = s -> cbps [ compno ] ; 77
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 78
int pixelsize = planar ? 1 : s -> ncomponents ; 80
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 84
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 87
line = picture -> data [ plane ] + y * picture -> linesize [ plane ]; 88
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 89
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 92
dst = line + x * pixelsize + compno * ! planar; 93
for (; x < w; x += s->cdx[compno]) 96
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 97
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 99
* dst = val << ( 8 - cbps ); 100
dst += pixelsize; 102
for (; x < w; x += s->cdx[compno]) 105
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 106
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 108
* dst = val << ( 8 - cbps ); 109
dst += pixelsize; 111
line += picture -> linesize [ plane ]; 114
for (compno = 0; compno < s->ncomponents; compno++) 118
int cbps = s -> cbps [ compno ] ; 124
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 125
int pixelsize = planar ? 1 : s -> ncomponents ; 127
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 131
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 133
linel = ( uint16_t * ) picture -> data [ plane ] + y * ( picture -> linesize [ plane ] >> 1 ); 134
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 135
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 138
dst = linel + ( x * pixelsize + compno * ! planar ); 139
for (; x < w; x += s-> cdx[compno]) 141
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 142
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 144
* dst = val << ( 16 - cbps ); 146
dst += pixelsize; 148
for (; x < w; x += s-> cdx[compno]) 151
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 152
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 154
* dst = val << ( 16 - cbps ); 156
dst += pixelsize; 158
linel += picture -> linesize [ plane ] >> 1; 161
------------------------------
740 /home/speedy/test/source2slice/NVD/CVE_2013_7024_VULN_jpeg2000_decode_tile.c Jpeg2000Prec * prec = band -> prec + precno ; 33
static int CVE_2013_7024_VULN_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
int nb_precincts , precno ; 20
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 39
x = cblk -> coord [ 0 ] [ 0 ]; 44
y = cblk -> coord [ 1 ] [ 0 ]; 45
dequantization_float ( x , y , cblk , comp , & t1 , band ); 48
dequantization_int ( x , y , cblk , comp , & t1 , band ); 50
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
int cbps = s -> cbps [ compno ] ; 77
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 78
int pixelsize = planar ? 1 : s -> ncomponents ; 80
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 84
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 87
line = picture -> data [ plane ] + y * picture -> linesize [ plane ]; 88
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 89
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 92
dst = line + x * pixelsize + compno * ! planar; 93
for (; x < w; x += s->cdx[compno]) 96
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 97
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 99
* dst = val << ( 8 - cbps ); 100
dst += pixelsize; 102
for (; x < w; x += s->cdx[compno]) 105
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 106
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 108
* dst = val << ( 8 - cbps ); 109
dst += pixelsize; 111
line += picture -> linesize [ plane ]; 114
for (compno = 0; compno < s->ncomponents; compno++) 118
int cbps = s -> cbps [ compno ] ; 124
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 125
int pixelsize = planar ? 1 : s -> ncomponents ; 127
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 131
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 133
linel = ( uint16_t * ) picture -> data [ plane ] + y * ( picture -> linesize [ plane ] >> 1 ); 134
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 135
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 138
dst = linel + ( x * pixelsize + compno * ! planar ); 139
for (; x < w; x += s-> cdx[compno]) 141
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 142
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 144
* dst = val << ( 16 - cbps ); 146
dst += pixelsize; 148
for (; x < w; x += s-> cdx[compno]) 151
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 152
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 154
* dst = val << ( 16 - cbps ); 156
dst += pixelsize; 158
linel += picture -> linesize [ plane ] >> 1; 161
------------------------------
741 /home/speedy/test/source2slice/NVD/CVE_2013_7024_VULN_jpeg2000_decode_tile.c Jpeg2000Band * band = rlevel -> band + bandno ; 21
static int CVE_2013_7024_VULN_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 39
x = cblk -> coord [ 0 ] [ 0 ]; 44
y = cblk -> coord [ 1 ] [ 0 ]; 45
dequantization_float ( x , y , cblk , comp , & t1 , band ); 48
dequantization_int ( x , y , cblk , comp , & t1 , band ); 50
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
int cbps = s -> cbps [ compno ] ; 77
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 78
int pixelsize = planar ? 1 : s -> ncomponents ; 80
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 84
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 87
line = picture -> data [ plane ] + y * picture -> linesize [ plane ]; 88
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 89
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 92
dst = line + x * pixelsize + compno * ! planar; 93
for (; x < w; x += s->cdx[compno]) 96
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 97
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 99
* dst = val << ( 8 - cbps ); 100
dst += pixelsize; 102
for (; x < w; x += s->cdx[compno]) 105
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 106
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 108
* dst = val << ( 8 - cbps ); 109
dst += pixelsize; 111
line += picture -> linesize [ plane ]; 114
for (compno = 0; compno < s->ncomponents; compno++) 118
int cbps = s -> cbps [ compno ] ; 124
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 125
int pixelsize = planar ? 1 : s -> ncomponents ; 127
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 131
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 133
linel = ( uint16_t * ) picture -> data [ plane ] + y * ( picture -> linesize [ plane ] >> 1 ); 134
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 135
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 138
dst = linel + ( x * pixelsize + compno * ! planar ); 139
for (; x < w; x += s-> cdx[compno]) 141
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 142
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 144
* dst = val << ( 16 - cbps ); 146
dst += pixelsize; 148
for (; x < w; x += s-> cdx[compno]) 151
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 152
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 154
* dst = val << ( 16 - cbps ); 156
dst += pixelsize; 158
linel += picture -> linesize [ plane ] >> 1; 161
------------------------------
742 /home/speedy/test/source2slice/NVD/CVE_2013_7024_VULN_jpeg2000_decode_tile.c Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
static int CVE_2013_7024_VULN_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 39
x = cblk -> coord [ 0 ] [ 0 ]; 44
y = cblk -> coord [ 1 ] [ 0 ]; 45
dequantization_float ( x , y , cblk , comp , & t1 , band ); 48
dequantization_int ( x , y , cblk , comp , & t1 , band ); 50
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
int cbps = s -> cbps [ compno ] ; 77
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 78
int pixelsize = planar ? 1 : s -> ncomponents ; 80
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 84
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 87
line = picture -> data [ plane ] + y * picture -> linesize [ plane ]; 88
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 89
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 92
dst = line + x * pixelsize + compno * ! planar; 93
for (; x < w; x += s->cdx[compno]) 96
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 97
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 99
* dst = val << ( 8 - cbps ); 100
dst += pixelsize; 102
for (; x < w; x += s->cdx[compno]) 105
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 106
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 108
* dst = val << ( 8 - cbps ); 109
dst += pixelsize; 111
line += picture -> linesize [ plane ]; 114
for (compno = 0; compno < s->ncomponents; compno++) 118
int cbps = s -> cbps [ compno ] ; 124
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 125
int pixelsize = planar ? 1 : s -> ncomponents ; 127
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 131
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 133
linel = ( uint16_t * ) picture -> data [ plane ] + y * ( picture -> linesize [ plane ] >> 1 ); 134
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 135
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 138
dst = linel + ( x * pixelsize + compno * ! planar ); 139
for (; x < w; x += s-> cdx[compno]) 141
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 142
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 144
* dst = val << ( 16 - cbps ); 146
dst += pixelsize; 148
for (; x < w; x += s-> cdx[compno]) 151
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 152
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 154
* dst = val << ( 16 - cbps ); 156
dst += pixelsize; 158
linel += picture -> linesize [ plane ] >> 1; 161
------------------------------
743 /home/speedy/test/source2slice/NVD/CVE_2013_7024_VULN_jpeg2000_decode_tile.c Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
static int CVE_2013_7024_VULN_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; 13
for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) 16
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 39
if ( codsty -> transform == FF_DWT97 )  47
ff_dwt_decode ( & comp -> dwt , codsty -> transform == FF_DWT97 ? ( void * ) comp -> f_data : ( void * ) comp -> i_data ); 57
------------------------------
744 /home/speedy/test/source2slice/NVD/CVE_2013_7024_VULN_jpeg2000_decode_tile.c Jpeg2000Component * comp = tile -> comp + compno ; 12
static int CVE_2013_7024_VULN_jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,
AVFrame *picture) 2
int compno , reslevelno , bandno ; 4
for (compno = 0; compno < s->ncomponents; compno++) 11
Jpeg2000Component * comp = tile -> comp + compno ; 12
Jpeg2000ResLevel * rlevel = comp -> reslevel + reslevelno ; 17
for (bandno = 0; bandno < rlevel->nbands; bandno++) 19
Jpeg2000Band * band = rlevel -> band + bandno ; 21
if ( band -> coord [ 0 ] [ 0 ] == band -> coord [ 0 ] [ 1 ] || band -> coord [ 1 ] [ 0 ] == band -> coord [ 1 ] [ 1 ] )  26
nb_precincts = rlevel -> num_precincts_x * rlevel -> num_precincts_y; 30
for (precno = 0; precno < nb_precincts; precno++) 32
Jpeg2000Prec * prec = band -> prec + precno ; 33
for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) 36
Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; 38
decode_cblk ( s , codsty , & t1 , cblk , cblk -> coord [ 0 ] [ 1 ] - cblk -> coord [ 0 ] [ 0 ] , cblk -> coord [ 1 ] [ 1 ] - cblk -> coord [ 1 ] [ 0 ] , bandpos ); 39
x = cblk -> coord [ 0 ] [ 0 ]; 44
y = cblk -> coord [ 1 ] [ 0 ]; 45
dequantization_float ( x , y , cblk , comp , & t1 , band ); 48
dequantization_int ( x , y , cblk , comp , & t1 , band ); 50
ff_dwt_decode ( & comp -> dwt , codsty -> transform == FF_DWT97 ? ( void * ) comp -> f_data : ( void * ) comp -> i_data ); 57
for (x = 0; x < s->ncomponents; x++) 65
s -> cdef [ x ] = x + 1; 66
if ( ( s -> ncomponents & 1 ) == 0 )  67
s -> cdef [ s -> ncomponents - 1 ] = 0; 68
if ( s -> precision <= 8 )  71
for (compno = 0; compno < s->ncomponents; compno++) 72
int cbps = s -> cbps [ compno ] ; 77
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 78
int pixelsize = planar ? 1 : s -> ncomponents ; 80
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 84
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 87
line = picture -> data [ plane ] + y * picture -> linesize [ plane ]; 88
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 89
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 92
dst = line + x * pixelsize + compno * ! planar; 93
for (; x < w; x += s->cdx[compno]) 96
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 97
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 99
* dst = val << ( 8 - cbps ); 100
dst += pixelsize; 102
for (; x < w; x += s->cdx[compno]) 105
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 106
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 108
* dst = val << ( 8 - cbps ); 109
dst += pixelsize; 111
line += picture -> linesize [ plane ]; 114
for (compno = 0; compno < s->ncomponents; compno++) 118
int cbps = s -> cbps [ compno ] ; 124
int w = tile -> comp [ compno ] . coord [ 0 ] [ 1 ] - s -> image_offset_x ; 125
int pixelsize = planar ? 1 : s -> ncomponents ; 127
plane = s -> cdef [ compno ] ? s -> cdef [ compno ] - 1 : ( s -> ncomponents - 1 ); 131
y = tile -> comp [ compno ] . coord [ 1 ] [ 0 ] - s -> image_offset_y; 133
linel = ( uint16_t * ) picture -> data [ plane ] + y * ( picture -> linesize [ plane ] >> 1 ); 134
for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) 135
x = tile -> comp [ compno ] . coord [ 0 ] [ 0 ] - s -> image_offset_x; 138
dst = linel + ( x * pixelsize + compno * ! planar ); 139
for (; x < w; x += s-> cdx[compno]) 141
int val = lrintf ( * datap ) + ( 1 << ( cbps - 1 ) ) ; 142
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 144
* dst = val << ( 16 - cbps ); 146
dst += pixelsize; 148
for (; x < w; x += s-> cdx[compno]) 151
int val = * i_datap + ( 1 << ( cbps - 1 ) ) ; 152
val = av_clip ( val , 0 , ( 1 << cbps ) - 1 ); 154
* dst = val << ( 16 - cbps ); 156
dst += pixelsize; 158
linel += picture -> linesize [ plane ] >> 1; 161
------------------------------
745 /home/speedy/test/source2slice/NVD/CVE_2014_0160_PATCHED_dtls1_process_heartbeat.c unsigned int write_length = 1 + 2 + payload + padding ; 26
int
CVE_2014_0160_PATCHED_dtls1_process_heartbeat(SSL *s) 2
unsigned char * p = & s -> s3 -> rrec . data [ 0 ] , * pl ; 4
unsigned short hbtype ; 5
unsigned int payload ; 6
unsigned int padding = 16 ; 7
if ( 1 + 2 + 16 > s -> s3 -> rrec . length )  15
hbtype = * p ++; 17
if ( 1 + 2 + payload + 16 > s -> s3 -> rrec . length )  19
if ( hbtype == TLS1_HB_REQUEST )  23
unsigned int write_length = 1 + 2 + payload + padding ; 26
if ( write_length > SSL3_RT_MAX_PLAIN_LENGTH )  31
buffer = OPENSSL_malloc ( write_length ); 38
bp = buffer; 39
* bp ++ = TLS1_HB_RESPONSE; 42
s2n ( payload , bp ); 43
memcpy ( bp , pl , payload ); 44
bp += payload; 45
RAND_pseudo_bytes ( bp , padding ); 47
r = dtls1_write_bytes ( s , TLS1_RT_HEARTBEAT , buffer , write_length ); 49
if ( r >= 0 && s -> msg_callback )  51
s -> msg_callback ( 1 , s -> version , TLS1_RT_HEARTBEAT , buffer , write_length , s , s -> msg_callback_arg ); 52
OPENSSL_free ( buffer ); 56
if ( r < 0 )  58
return r ; 59
------------------------------
746 /home/speedy/test/source2slice/NVD/CVE_2014_0221_PATCHED_dtls1_get_message_fragment.c unsigned char * p = ( unsigned char * ) s -> init_buf -> data + DTLS1_HM_HEADER_LENGTH ; 86
static long
CVE_2014_0221_PATCHED_dtls1_get_message_fragment(SSL *s, int st1, int stn, long max, int *ok) 2
unsigned char wire [ DTLS1_HM_HEADER_LENGTH ] ; 4
unsigned long len , frag_off , frag_len ; 5
int i , al ; 6
struct hm_header_st msg_hdr ; 7
if ( ( frag_len = dtls1_retrieve_buffered_fragment ( s , max , ok ) ) || * ok )  11
i = s -> method -> ssl_read_bytes ( s , SSL3_RT_HANDSHAKE , wire , DTLS1_HM_HEADER_LENGTH , 0 ); 18
if ( i <= 0 )  20
s -> rwstate = SSL_READING; 22
if ( i != DTLS1_HM_HEADER_LENGTH )  27
if ( msg_hdr . seq != s -> d1 -> handshake_read_seq && ! ( s -> d1 -> listen && msg_hdr . seq == 1 ) )  43
len = msg_hdr . msg_len; 46
frag_len = msg_hdr . frag_len; 48
if ( frag_len && frag_len < len )  50
if ( ! s -> server && s -> d1 -> r_msg_hdr . frag_off == 0 && wire [ 0 ] == SSL3_MT_HELLO_REQUEST )  53
if ( wire [ 1 ] == 0 && wire [ 2 ] == 0 && wire [ 3 ] == 0 )  60
s -> init_num = 0; 67
if ( al = dtls1_preprocess_fragment ( s , & msg_hdr , max ) )  78
s -> state = stn; 82
if ( frag_len > 0 )  84
unsigned char * p = ( unsigned char * ) s -> init_buf -> data + DTLS1_HM_HEADER_LENGTH ; 86
i = s -> method -> ssl_read_bytes ( s , SSL3_RT_HANDSHAKE , & p [ frag_off ] , frag_len , 0 ); 88
if ( i <= 0 )  91
return i ; 95
if ( i != ( int ) frag_len )  103
------------------------------
747 /home/speedy/test/source2slice/NVD/CVE_2014_0221_VULN_dtls1_get_message_fragment.c unsigned char * p = ( unsigned char * ) s -> init_buf -> data + DTLS1_HM_HEADER_LENGTH ; 86
static long
CVE_2014_0221_VULN_dtls1_get_message_fragment(SSL *s, int st1, int stn, long max, int *ok) 2
unsigned char wire [ DTLS1_HM_HEADER_LENGTH ] ; 4
unsigned long len , frag_off , frag_len ; 5
int i , al ; 6
struct hm_header_st msg_hdr ; 7
if ( ( frag_len = dtls1_retrieve_buffered_fragment ( s , max , ok ) ) || * ok )  10
i = s -> method -> ssl_read_bytes ( s , SSL3_RT_HANDSHAKE , wire , DTLS1_HM_HEADER_LENGTH , 0 ); 17
if ( i <= 0 )  19
if ( i != DTLS1_HM_HEADER_LENGTH )  26
if ( msg_hdr . seq != s -> d1 -> handshake_read_seq && ! ( s -> d1 -> listen && msg_hdr . seq == 1 ) )  42
len = msg_hdr . msg_len; 45
frag_len = msg_hdr . frag_len; 47
if ( frag_len && frag_len < len )  49
if ( ! s -> server && s -> d1 -> r_msg_hdr . frag_off == 0 && wire [ 0 ] == SSL3_MT_HELLO_REQUEST )  52
if ( wire [ 1 ] == 0 && wire [ 2 ] == 0 && wire [ 3 ] == 0 )  59
s -> init_num = 0; 66
return CVE_2014_0221_VULN_dtls1_get_message_fragment ( s , st1 , stn , max , ok ) ; 67
static long
CVE_2014_0221_VULN_dtls1_get_message_fragment(SSL *s, int st1, int stn, long max, int *ok) 2
unsigned char wire [ DTLS1_HM_HEADER_LENGTH ] ; 4
unsigned long len , frag_off , frag_len ; 5
int i , al ; 6
struct hm_header_st msg_hdr ; 7
if ( ( frag_len = dtls1_retrieve_buffered_fragment ( s , max , ok ) ) || * ok )  10
i = s -> method -> ssl_read_bytes ( s , SSL3_RT_HANDSHAKE , wire , DTLS1_HM_HEADER_LENGTH , 0 ); 17
if ( i <= 0 )  19
if ( i != DTLS1_HM_HEADER_LENGTH )  26
if ( msg_hdr . seq != s -> d1 -> handshake_read_seq && ! ( s -> d1 -> listen && msg_hdr . seq == 1 ) )  42
len = msg_hdr . msg_len; 45
frag_len = msg_hdr . frag_len; 47
if ( frag_len && frag_len < len )  49
if ( ! s -> server && s -> d1 -> r_msg_hdr . frag_off == 0 && wire [ 0 ] == SSL3_MT_HELLO_REQUEST )  52
if ( wire [ 1 ] == 0 && wire [ 2 ] == 0 && wire [ 3 ] == 0 )  59
s -> init_num = 0; 66
return CVE_2014_0221_VULN_dtls1_get_message_fragment ( s , st1 , stn , max , ok ) ; 67
static long
CVE_2014_0221_VULN_dtls1_get_message_fragment(SSL *s, int st1, int stn, long max, int *ok) 2
unsigned char wire [ DTLS1_HM_HEADER_LENGTH ] ; 4
unsigned long len , frag_off , frag_len ; 5
int i , al ; 6
struct hm_header_st msg_hdr ; 7
if ( ( frag_len = dtls1_retrieve_buffered_fragment ( s , max , ok ) ) || * ok )  10
i = s -> method -> ssl_read_bytes ( s , SSL3_RT_HANDSHAKE , wire , DTLS1_HM_HEADER_LENGTH , 0 ); 17
if ( i <= 0 )  19
if ( i != DTLS1_HM_HEADER_LENGTH )  26
if ( msg_hdr . seq != s -> d1 -> handshake_read_seq && ! ( s -> d1 -> listen && msg_hdr . seq == 1 ) )  42
len = msg_hdr . msg_len; 45
frag_len = msg_hdr . frag_len; 47
if ( frag_len && frag_len < len )  49
if ( ! s -> server && s -> d1 -> r_msg_hdr . frag_off == 0 && wire [ 0 ] == SSL3_MT_HELLO_REQUEST )  52
if ( wire [ 1 ] == 0 && wire [ 2 ] == 0 && wire [ 3 ] == 0 )  59
s -> init_num = 0; 66
return CVE_2014_0221_VULN_dtls1_get_message_fragment ( s , st1 , stn , max , ok ) ; 67
static long
CVE_2014_0221_VULN_dtls1_get_message_fragment(SSL *s, int st1, int stn, long max, int *ok) 2
unsigned char wire [ DTLS1_HM_HEADER_LENGTH ] ; 4
unsigned long len , frag_off , frag_len ; 5
int i , al ; 6
struct hm_header_st msg_hdr ; 7
if ( ( frag_len = dtls1_retrieve_buffered_fragment ( s , max , ok ) ) || * ok )  10
i = s -> method -> ssl_read_bytes ( s , SSL3_RT_HANDSHAKE , wire , DTLS1_HM_HEADER_LENGTH , 0 ); 17
if ( i <= 0 )  19
if ( i != DTLS1_HM_HEADER_LENGTH )  26
if ( msg_hdr . seq != s -> d1 -> handshake_read_seq && ! ( s -> d1 -> listen && msg_hdr . seq == 1 ) )  42
len = msg_hdr . msg_len; 45
frag_len = msg_hdr . frag_len; 47
if ( frag_len && frag_len < len )  49
if ( ! s -> server && s -> d1 -> r_msg_hdr . frag_off == 0 && wire [ 0 ] == SSL3_MT_HELLO_REQUEST )  52
if ( al = dtls1_preprocess_fragment ( s , & msg_hdr , max ) )  78
s -> state = stn; 82
if ( frag_len > 0 )  84
unsigned char * p = ( unsigned char * ) s -> init_buf -> data + DTLS1_HM_HEADER_LENGTH ; 86
i = s -> method -> ssl_read_bytes ( s , SSL3_RT_HANDSHAKE , & p [ frag_off ] , frag_len , 0 ); 88
if ( i <= 0 )  91
return i ; 95
if ( i != ( int ) frag_len )  103
------------------------------
748 /home/speedy/test/source2slice/NVD/CVE_2014_1508_PATCHED_nsDisplayNotation__Paint.c gfxFloat h = H * f ; 51
void CVE_2014_1508_PATCHED_nsDisplayNotation::Paint(nsDisplayListBuilder* aBuilder,
nsRenderingContext* aCtx) 2
nsPresContext * presContext = mFrame -> PresContext ( ) ; 5
gfxRect rect = presContext -> AppUnitsToGfxUnits ( mRect + ToReferenceFrame ( ) ) ; 6
gfxFloat e = presContext -> AppUnitsToGfxUnits ( mThickness ) ; 13
switch ( mType )  19
gfxFloat W = rect . Width ( ) ; 48
gfxFloat H = rect . Height ( ) ; 48
gfxFloat l = sqrt ( W * W + H * H ) ; 49
gfxFloat f = gfxFloat ( kArrowHeadSize ) * e / l ; 50
gfxFloat h = H * f ; 51
gfxCtx -> Line ( rect . BottomLeft ( ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) ); 55
gfxPoint p [ ] = { rect . TopRight ( ) , rect . TopRight ( ) + gfxPoint ( - w - .4 * h , std :: max ( - e / 2.0 , h - .4 * w ) ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) , rect . TopRight ( ) + gfxPoint ( std :: min ( e / 2.0 , - w + .4 * h ) , h + .4 * w ) , rect . TopRight ( ) } ; 60
gfxCtx -> Polygon ( p , MOZ_ARRAY_LENGTH ( p ) ); 67
------------------------------
749 /home/speedy/test/source2slice/NVD/CVE_2014_1508_PATCHED_nsDisplayNotation__Paint.c gfxFloat w = W * f ; 51
void CVE_2014_1508_PATCHED_nsDisplayNotation::Paint(nsDisplayListBuilder* aBuilder,
nsRenderingContext* aCtx) 2
nsPresContext * presContext = mFrame -> PresContext ( ) ; 5
gfxRect rect = presContext -> AppUnitsToGfxUnits ( mRect + ToReferenceFrame ( ) ) ; 6
gfxFloat e = presContext -> AppUnitsToGfxUnits ( mThickness ) ; 13
switch ( mType )  19
gfxFloat W = rect . Width ( ) ; 48
gfxFloat H = rect . Height ( ) ; 48
gfxFloat l = sqrt ( W * W + H * H ) ; 49
gfxFloat f = gfxFloat ( kArrowHeadSize ) * e / l ; 50
gfxFloat w = W * f ; 51
gfxCtx -> Line ( rect . BottomLeft ( ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) ); 55
gfxPoint p [ ] = { rect . TopRight ( ) , rect . TopRight ( ) + gfxPoint ( - w - .4 * h , std :: max ( - e / 2.0 , h - .4 * w ) ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) , rect . TopRight ( ) + gfxPoint ( std :: min ( e / 2.0 , - w + .4 * h ) , h + .4 * w ) , rect . TopRight ( ) } ; 60
gfxCtx -> Polygon ( p , MOZ_ARRAY_LENGTH ( p ) ); 67
------------------------------
750 /home/speedy/test/source2slice/NVD/CVE_2014_1508_PATCHED_nsDisplayNotation__Paint.c gfxFloat f = gfxFloat ( kArrowHeadSize ) * e / l ; 50
void CVE_2014_1508_PATCHED_nsDisplayNotation::Paint(nsDisplayListBuilder* aBuilder,
nsRenderingContext* aCtx) 2
nsPresContext * presContext = mFrame -> PresContext ( ) ; 5
gfxRect rect = presContext -> AppUnitsToGfxUnits ( mRect + ToReferenceFrame ( ) ) ; 6
gfxFloat e = presContext -> AppUnitsToGfxUnits ( mThickness ) ; 13
switch ( mType )  19
gfxFloat W = rect . Width ( ) ; 48
gfxFloat H = rect . Height ( ) ; 48
gfxFloat l = sqrt ( W * W + H * H ) ; 49
gfxFloat f = gfxFloat ( kArrowHeadSize ) * e / l ; 50
gfxFloat w = W * f ; 51
gfxFloat h = H * f ; 51
gfxCtx -> Line ( rect . BottomLeft ( ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) ); 55
gfxPoint p [ ] = { rect . TopRight ( ) , rect . TopRight ( ) + gfxPoint ( - w - .4 * h , std :: max ( - e / 2.0 , h - .4 * w ) ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) , rect . TopRight ( ) + gfxPoint ( std :: min ( e / 2.0 , - w + .4 * h ) , h + .4 * w ) , rect . TopRight ( ) } ; 60
gfxCtx -> Polygon ( p , MOZ_ARRAY_LENGTH ( p ) ); 67
------------------------------
751 /home/speedy/test/source2slice/NVD/CVE_2014_1508_PATCHED_nsDisplayNotation__Paint.c gfxFloat l = sqrt ( W * W + H * H ) ; 49
void CVE_2014_1508_PATCHED_nsDisplayNotation::Paint(nsDisplayListBuilder* aBuilder,
nsRenderingContext* aCtx) 2
nsPresContext * presContext = mFrame -> PresContext ( ) ; 5
gfxRect rect = presContext -> AppUnitsToGfxUnits ( mRect + ToReferenceFrame ( ) ) ; 6
switch ( mType )  19
gfxFloat W = rect . Width ( ) ; 48
gfxFloat H = rect . Height ( ) ; 48
gfxFloat l = sqrt ( W * W + H * H ) ; 49
gfxFloat f = gfxFloat ( kArrowHeadSize ) * e / l ; 50
gfxFloat w = W * f ; 51
gfxFloat h = H * f ; 51
gfxCtx -> Line ( rect . BottomLeft ( ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) ); 55
gfxPoint p [ ] = { rect . TopRight ( ) , rect . TopRight ( ) + gfxPoint ( - w - .4 * h , std :: max ( - e / 2.0 , h - .4 * w ) ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) , rect . TopRight ( ) + gfxPoint ( std :: min ( e / 2.0 , - w + .4 * h ) , h + .4 * w ) , rect . TopRight ( ) } ; 60
gfxCtx -> Polygon ( p , MOZ_ARRAY_LENGTH ( p ) ); 67
------------------------------
752 /home/speedy/test/source2slice/NVD/CVE_2014_1508_PATCHED_nsDisplayNotation__Paint.c gfxRect rect = presContext -> AppUnitsToGfxUnits ( mRect + ToReferenceFrame ( ) ) ; 6
void CVE_2014_1508_PATCHED_nsDisplayNotation::Paint(nsDisplayListBuilder* aBuilder,
nsRenderingContext* aCtx) 2
nsPresContext * presContext = mFrame -> PresContext ( ) ; 5
gfxRect rect = presContext -> AppUnitsToGfxUnits ( mRect + ToReferenceFrame ( ) ) ; 6
rect . Deflate ( e / 2.0 ); 17
gfxCtx -> Ellipse ( rect . Center ( ) , rect . Size ( ) ); 23
gfxCtx -> RoundedRectangle ( rect , gfxCornerSizes ( 3 * e ) , true ); 29
gfxCtx -> Line ( rect . BottomLeft ( ) , rect . TopRight ( ) ); 35
gfxCtx -> Line ( rect . TopLeft ( ) , rect . BottomRight ( ) ); 41
gfxFloat W = rect . Width ( ) ; 48
gfxFloat H = rect . Height ( ) ; 48
gfxFloat l = sqrt ( W * W + H * H ) ; 49
gfxFloat f = gfxFloat ( kArrowHeadSize ) * e / l ; 50
gfxFloat w = W * f ; 51
gfxFloat h = H * f ; 51
gfxCtx -> Line ( rect . BottomLeft ( ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) ); 55
gfxPoint p [ ] = { rect . TopRight ( ) , rect . TopRight ( ) + gfxPoint ( - w - .4 * h , std :: max ( - e / 2.0 , h - .4 * w ) ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) , rect . TopRight ( ) + gfxPoint ( std :: min ( e / 2.0 , - w + .4 * h ) , h + .4 * w ) , rect . TopRight ( ) } ; 60
gfxCtx -> Polygon ( p , MOZ_ARRAY_LENGTH ( p ) ); 67
------------------------------
753 /home/speedy/test/source2slice/NVD/CVE_2014_1508_VULN_nsDisplayNotation__Paint.c gfxFloat h = H * f ; 51
void CVE_2014_1508_VULN_nsDisplayNotation::Paint(nsDisplayListBuilder* aBuilder,
nsRenderingContext* aCtx) 2
nsPresContext * presContext = mFrame -> PresContext ( ) ; 5
gfxRect rect = presContext -> AppUnitsToGfxUnits ( mRect + ToReferenceFrame ( ) ) ; 6
gfxFloat e = presContext -> AppUnitsToGfxUnits ( mThickness ) ; 13
switch ( mType )  19
gfxFloat W = rect . Width ( ) ; 48
gfxFloat H = rect . Height ( ) ; 48
gfxFloat l = sqrt ( W * W + H * H ) ; 49
gfxFloat f = gfxFloat ( kArrowHeadSize ) * e / l ; 50
gfxFloat h = H * f ; 51
gfxCtx -> Line ( rect . BottomLeft ( ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) ); 55
gfxPoint p [ ] = { rect . TopRight ( ) , rect . TopRight ( ) + gfxPoint ( - w - .4 * h , std :: max ( - e / 2.0 , h - .4 * w ) ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) , rect . TopRight ( ) + gfxPoint ( std :: min ( e / 2.0 , - w + .4 * h ) , h + .4 * w ) , rect . TopRight ( ) } ; 60
gfxCtx -> Polygon ( p , sizeof ( p ) ); 67
------------------------------
754 /home/speedy/test/source2slice/NVD/CVE_2014_1508_VULN_nsDisplayNotation__Paint.c gfxFloat w = W * f ; 51
void CVE_2014_1508_VULN_nsDisplayNotation::Paint(nsDisplayListBuilder* aBuilder,
nsRenderingContext* aCtx) 2
nsPresContext * presContext = mFrame -> PresContext ( ) ; 5
gfxRect rect = presContext -> AppUnitsToGfxUnits ( mRect + ToReferenceFrame ( ) ) ; 6
gfxFloat e = presContext -> AppUnitsToGfxUnits ( mThickness ) ; 13
switch ( mType )  19
gfxFloat W = rect . Width ( ) ; 48
gfxFloat H = rect . Height ( ) ; 48
gfxFloat l = sqrt ( W * W + H * H ) ; 49
gfxFloat f = gfxFloat ( kArrowHeadSize ) * e / l ; 50
gfxFloat w = W * f ; 51
gfxCtx -> Line ( rect . BottomLeft ( ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) ); 55
gfxPoint p [ ] = { rect . TopRight ( ) , rect . TopRight ( ) + gfxPoint ( - w - .4 * h , std :: max ( - e / 2.0 , h - .4 * w ) ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) , rect . TopRight ( ) + gfxPoint ( std :: min ( e / 2.0 , - w + .4 * h ) , h + .4 * w ) , rect . TopRight ( ) } ; 60
gfxCtx -> Polygon ( p , sizeof ( p ) ); 67
------------------------------
755 /home/speedy/test/source2slice/NVD/CVE_2014_1508_VULN_nsDisplayNotation__Paint.c gfxFloat f = gfxFloat ( kArrowHeadSize ) * e / l ; 50
void CVE_2014_1508_VULN_nsDisplayNotation::Paint(nsDisplayListBuilder* aBuilder,
nsRenderingContext* aCtx) 2
nsPresContext * presContext = mFrame -> PresContext ( ) ; 5
gfxRect rect = presContext -> AppUnitsToGfxUnits ( mRect + ToReferenceFrame ( ) ) ; 6
gfxFloat e = presContext -> AppUnitsToGfxUnits ( mThickness ) ; 13
switch ( mType )  19
gfxFloat W = rect . Width ( ) ; 48
gfxFloat H = rect . Height ( ) ; 48
gfxFloat l = sqrt ( W * W + H * H ) ; 49
gfxFloat f = gfxFloat ( kArrowHeadSize ) * e / l ; 50
gfxFloat w = W * f ; 51
gfxFloat h = H * f ; 51
gfxCtx -> Line ( rect . BottomLeft ( ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) ); 55
gfxPoint p [ ] = { rect . TopRight ( ) , rect . TopRight ( ) + gfxPoint ( - w - .4 * h , std :: max ( - e / 2.0 , h - .4 * w ) ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) , rect . TopRight ( ) + gfxPoint ( std :: min ( e / 2.0 , - w + .4 * h ) , h + .4 * w ) , rect . TopRight ( ) } ; 60
gfxCtx -> Polygon ( p , sizeof ( p ) ); 67
------------------------------
756 /home/speedy/test/source2slice/NVD/CVE_2014_1508_VULN_nsDisplayNotation__Paint.c gfxFloat l = sqrt ( W * W + H * H ) ; 49
void CVE_2014_1508_VULN_nsDisplayNotation::Paint(nsDisplayListBuilder* aBuilder,
nsRenderingContext* aCtx) 2
nsPresContext * presContext = mFrame -> PresContext ( ) ; 5
gfxRect rect = presContext -> AppUnitsToGfxUnits ( mRect + ToReferenceFrame ( ) ) ; 6
switch ( mType )  19
gfxFloat W = rect . Width ( ) ; 48
gfxFloat H = rect . Height ( ) ; 48
gfxFloat l = sqrt ( W * W + H * H ) ; 49
gfxFloat f = gfxFloat ( kArrowHeadSize ) * e / l ; 50
gfxFloat w = W * f ; 51
gfxFloat h = H * f ; 51
gfxCtx -> Line ( rect . BottomLeft ( ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) ); 55
gfxPoint p [ ] = { rect . TopRight ( ) , rect . TopRight ( ) + gfxPoint ( - w - .4 * h , std :: max ( - e / 2.0 , h - .4 * w ) ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) , rect . TopRight ( ) + gfxPoint ( std :: min ( e / 2.0 , - w + .4 * h ) , h + .4 * w ) , rect . TopRight ( ) } ; 60
gfxCtx -> Polygon ( p , sizeof ( p ) ); 67
------------------------------
757 /home/speedy/test/source2slice/NVD/CVE_2014_1508_VULN_nsDisplayNotation__Paint.c gfxRect rect = presContext -> AppUnitsToGfxUnits ( mRect + ToReferenceFrame ( ) ) ; 6
void CVE_2014_1508_VULN_nsDisplayNotation::Paint(nsDisplayListBuilder* aBuilder,
nsRenderingContext* aCtx) 2
nsPresContext * presContext = mFrame -> PresContext ( ) ; 5
gfxRect rect = presContext -> AppUnitsToGfxUnits ( mRect + ToReferenceFrame ( ) ) ; 6
rect . Deflate ( e / 2.0 ); 17
gfxCtx -> Ellipse ( rect . Center ( ) , rect . Size ( ) ); 23
gfxCtx -> RoundedRectangle ( rect , gfxCornerSizes ( 3 * e ) , true ); 29
gfxCtx -> Line ( rect . BottomLeft ( ) , rect . TopRight ( ) ); 35
gfxCtx -> Line ( rect . TopLeft ( ) , rect . BottomRight ( ) ); 41
gfxFloat W = rect . Width ( ) ; 48
gfxFloat H = rect . Height ( ) ; 48
gfxFloat l = sqrt ( W * W + H * H ) ; 49
gfxFloat f = gfxFloat ( kArrowHeadSize ) * e / l ; 50
gfxFloat w = W * f ; 51
gfxFloat h = H * f ; 51
gfxCtx -> Line ( rect . BottomLeft ( ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) ); 55
gfxPoint p [ ] = { rect . TopRight ( ) , rect . TopRight ( ) + gfxPoint ( - w - .4 * h , std :: max ( - e / 2.0 , h - .4 * w ) ) , rect . TopRight ( ) + gfxPoint ( - .7 * w , .7 * h ) , rect . TopRight ( ) + gfxPoint ( std :: min ( e / 2.0 , - w + .4 * h ) , h + .4 * w ) , rect . TopRight ( ) } ; 60
gfxCtx -> Polygon ( p , sizeof ( p ) ); 67
------------------------------
758 /home/speedy/test/source2slice/NVD/CVE_2014_1522_PATCHED_ComputeCustom.c float higher = sampleInterpolationFactor * higherWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * higherWaveData [ j2 ] ; 32
void CVE_2014_1522_PATCHED_ComputeCustom(float* aOutput,
TrackTicks ticks,
uint32_t aStart,
uint32_t aEnd) 4
uint32_t periodicWaveSize = mPeriodicWave -> periodicWaveSize ( ) ; 8
float * higherWaveData = nullptr ; 9
float rate = 1.0 / mSource -> SampleRate ( ) ; 12
for (uint32_t i = aStart; i < aEnd; ++i) 14
mPhase += periodicWaveSize * mFinalFrequency * rate; 21
mPhase = fmod ( mPhase , periodicWaveSize ); 22
uint32_t j1 = floor ( mPhase ) ; 24
uint32_t j2 = j1 + 1 ; 25
if ( j2 >= periodicWaveSize )  26
j2 -= periodicWaveSize; 27
float sampleInterpolationFactor = mPhase - j1 ; 29
float higher = sampleInterpolationFactor * higherWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * higherWaveData [ j2 ] ; 32
aOutput [ i ] = tableInterpolationFactor * lower + ( 1 - tableInterpolationFactor ) * higher; 34
------------------------------
759 /home/speedy/test/source2slice/NVD/CVE_2014_1522_PATCHED_ComputeCustom.c float lower = sampleInterpolationFactor * lowerWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * lowerWaveData [ j2 ] ; 30
void CVE_2014_1522_PATCHED_ComputeCustom(float* aOutput,
TrackTicks ticks,
uint32_t aStart,
uint32_t aEnd) 4
uint32_t periodicWaveSize = mPeriodicWave -> periodicWaveSize ( ) ; 8
float * lowerWaveData = nullptr ; 10
float rate = 1.0 / mSource -> SampleRate ( ) ; 12
for (uint32_t i = aStart; i < aEnd; ++i) 14
mPhase += periodicWaveSize * mFinalFrequency * rate; 21
mPhase = fmod ( mPhase , periodicWaveSize ); 22
uint32_t j1 = floor ( mPhase ) ; 24
uint32_t j2 = j1 + 1 ; 25
if ( j2 >= periodicWaveSize )  26
j2 -= periodicWaveSize; 27
float sampleInterpolationFactor = mPhase - j1 ; 29
float lower = sampleInterpolationFactor * lowerWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * lowerWaveData [ j2 ] ; 30
aOutput [ i ] = tableInterpolationFactor * lower + ( 1 - tableInterpolationFactor ) * higher; 34
------------------------------
760 /home/speedy/test/source2slice/NVD/CVE_2014_1522_PATCHED_ComputeCustom.c float sampleInterpolationFactor = mPhase - j1 ; 29
void CVE_2014_1522_PATCHED_ComputeCustom(float* aOutput,
TrackTicks ticks,
uint32_t aStart,
uint32_t aEnd) 4
uint32_t periodicWaveSize = mPeriodicWave -> periodicWaveSize ( ) ; 8
float rate = 1.0 / mSource -> SampleRate ( ) ; 12
for (uint32_t i = aStart; i < aEnd; ++i) 14
mPhase += periodicWaveSize * mFinalFrequency * rate; 21
mPhase = fmod ( mPhase , periodicWaveSize ); 22
uint32_t j1 = floor ( mPhase ) ; 24
float sampleInterpolationFactor = mPhase - j1 ; 29
float lower = sampleInterpolationFactor * lowerWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * lowerWaveData [ j2 ] ; 30
float higher = sampleInterpolationFactor * higherWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * higherWaveData [ j2 ] ; 32
aOutput [ i ] = tableInterpolationFactor * lower + ( 1 - tableInterpolationFactor ) * higher; 34
------------------------------
761 /home/speedy/test/source2slice/NVD/CVE_2014_1522_VULN_ComputeCustom.c float higher = sampleInterpolationFactor * higherWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * higherWaveData [ j2 ] ; 34
void CVE_2014_1522_VULN_ComputeCustom(float* aOutput,
TrackTicks ticks,
uint32_t aStart,
uint32_t aEnd) 4
uint32_t periodicWaveSize = mPeriodicWave -> periodicWaveSize ( ) ; 8
float * higherWaveData = nullptr ; 9
float rate = 1.0 / mSource -> SampleRate ( ) ; 12
for (uint32_t i = aStart; i < aEnd; ++i) 14
mPhase += periodicWaveSize * mFinalFrequency * rate; 21
if ( mPhase >= periodicWaveSize )  22
mPhase -= periodicWaveSize; 23
uint32_t j1 = floor ( mPhase ) ; 26
uint32_t j2 = j1 + 1 ; 27
if ( j2 >= periodicWaveSize )  28
j2 -= periodicWaveSize; 29
float sampleInterpolationFactor = mPhase - j1 ; 31
float higher = sampleInterpolationFactor * higherWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * higherWaveData [ j2 ] ; 34
aOutput [ i ] = tableInterpolationFactor * lower + ( 1 - tableInterpolationFactor ) * higher; 36
------------------------------
762 /home/speedy/test/source2slice/NVD/CVE_2014_1522_VULN_ComputeCustom.c float lower = sampleInterpolationFactor * lowerWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * lowerWaveData [ j2 ] ; 32
void CVE_2014_1522_VULN_ComputeCustom(float* aOutput,
TrackTicks ticks,
uint32_t aStart,
uint32_t aEnd) 4
uint32_t periodicWaveSize = mPeriodicWave -> periodicWaveSize ( ) ; 8
float * lowerWaveData = nullptr ; 10
float rate = 1.0 / mSource -> SampleRate ( ) ; 12
for (uint32_t i = aStart; i < aEnd; ++i) 14
mPhase += periodicWaveSize * mFinalFrequency * rate; 21
if ( mPhase >= periodicWaveSize )  22
mPhase -= periodicWaveSize; 23
uint32_t j1 = floor ( mPhase ) ; 26
uint32_t j2 = j1 + 1 ; 27
if ( j2 >= periodicWaveSize )  28
j2 -= periodicWaveSize; 29
float sampleInterpolationFactor = mPhase - j1 ; 31
float lower = sampleInterpolationFactor * lowerWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * lowerWaveData [ j2 ] ; 32
aOutput [ i ] = tableInterpolationFactor * lower + ( 1 - tableInterpolationFactor ) * higher; 36
------------------------------
763 /home/speedy/test/source2slice/NVD/CVE_2014_1522_VULN_ComputeCustom.c float sampleInterpolationFactor = mPhase - j1 ; 31
void CVE_2014_1522_VULN_ComputeCustom(float* aOutput,
TrackTicks ticks,
uint32_t aStart,
uint32_t aEnd) 4
uint32_t periodicWaveSize = mPeriodicWave -> periodicWaveSize ( ) ; 8
float rate = 1.0 / mSource -> SampleRate ( ) ; 12
for (uint32_t i = aStart; i < aEnd; ++i) 14
mPhase += periodicWaveSize * mFinalFrequency * rate; 21
if ( mPhase >= periodicWaveSize )  22
mPhase -= periodicWaveSize; 23
uint32_t j1 = floor ( mPhase ) ; 26
float sampleInterpolationFactor = mPhase - j1 ; 31
float lower = sampleInterpolationFactor * lowerWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * lowerWaveData [ j2 ] ; 32
float higher = sampleInterpolationFactor * higherWaveData [ j1 ] + ( 1 - sampleInterpolationFactor ) * higherWaveData [ j2 ] ; 34
aOutput [ i ] = tableInterpolationFactor * lower + ( 1 - tableInterpolationFactor ) * higher; 36
------------------------------
764 /home/speedy/test/source2slice/NVD/CVE_2014_1738_PATCHED_raw_cmd_copyout.c long length = ptr -> buffer_length - ptr -> length ; 17
static int CVE_2014_1738_PATCHED_raw_cmd_copyout(int cmd, void __user *param,
struct floppy_raw_cmd *ptr) 2
int ret ; 4
while ( ptr )  6
struct floppy_raw_cmd cmd = * ptr ; 7
cmd . next = NULL; 8
cmd . kernel_data = NULL; 9
ret = copy_to_user ( param , & cmd , sizeof ( cmd ) ); 10
if ( ret )  11
param += sizeof ( struct floppy_raw_cmd ); 13
if ( ( ptr -> flags & FD_RAW_READ ) && ptr -> buffer_length )  14
if ( ptr -> length >= 0 && ptr -> length <= ptr -> buffer_length )  15
long length = ptr -> buffer_length - ptr -> length ; 17
ret = fd_copyout ( ptr -> data , ptr -> kernel_data , length ); 18
if ( ret )  20
return ret ; 21
ptr = ptr -> next; 24
------------------------------
765 /home/speedy/test/source2slice/NVD/CVE_2014_1738_VULN_raw_cmd_copyout.c long length = ptr -> buffer_length - ptr -> length ; 14
static int CVE_2014_1738_VULN_raw_cmd_copyout(int cmd, void __user *param,
struct floppy_raw_cmd *ptr) 2
int ret ; 4
while ( ptr )  6
ret = copy_to_user ( param , ptr , sizeof ( * ptr ) ); 7
if ( ret )  8
param += sizeof ( struct floppy_raw_cmd ); 10
if ( ( ptr -> flags & FD_RAW_READ ) && ptr -> buffer_length )  11
if ( ptr -> length >= 0 && ptr -> length <= ptr -> buffer_length )  12
long length = ptr -> buffer_length - ptr -> length ; 14
ret = fd_copyout ( ptr -> data , ptr -> kernel_data , length ); 15
if ( ret )  17
return ret ; 18
ptr = ptr -> next; 21
------------------------------
766 /home/speedy/test/source2slice/NVD/CVE_2014_2099_PATCHED_msrle_decode_frame.c int istride = FFALIGN ( avctx -> width * avctx -> bits_per_coded_sample , 32 ) / 8 ; 8
static int CVE_2014_2099_PATCHED_msrle_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
int istride = FFALIGN ( avctx -> width * avctx -> bits_per_coded_sample , 32 ) / 8 ; 8
if ( avctx -> height * istride == avpkt -> size )  29
uint8_t * buf = avpkt -> data + ( avctx -> height - 1 ) * istride ; 32
ptr [ j + 0 ] = buf [ j >> 1 ] >> 4; 38
ptr [ j + 1 ] = buf [ j >> 1 ] & 0xF; 39
ptr [ j + 0 ] = buf [ j >> 1 ] >> 4; 42
memcpy ( ptr , buf , linesize ); 44
buf -= istride; 46
ptr += s -> frame -> linesize [ 0 ]; 47
------------------------------
767 /home/speedy/test/source2slice/NVD/CVE_2014_2099_VULN_msrle_decode_frame.c int linesize = ( avctx -> width * avctx -> bits_per_coded_sample + 7 ) / 8 ; 30
static int CVE_2014_2099_VULN_msrle_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
const uint8_t * buf = avpkt -> data ; 5
int buf_size = avpkt -> size ; 6
MsrleContext * s = avctx -> priv_data ; 7
int istride = FFALIGN ( avctx -> width * avctx -> bits_per_coded_sample , 32 ) / 8 ; 8
int ret ; 9
s -> buf = buf; 11
s -> size = buf_size; 12
if ( ( ret = ff_reget_buffer ( avctx , s -> frame ) ) < 0 )  14
if ( avctx -> height * istride == avpkt -> size )  29
int linesize = ( avctx -> width * avctx -> bits_per_coded_sample + 7 ) / 8 ; 30
ptr [ j + 0 ] = buf [ j >> 1 ] >> 4; 38
ptr [ j + 1 ] = buf [ j >> 1 ] & 0xF; 39
ptr [ j + 0 ] = buf [ j >> 1 ] >> 4; 42
memcpy ( ptr , buf , linesize ); 44
ptr += s -> frame -> linesize [ 0 ]; 47
------------------------------
768 /home/speedy/test/source2slice/NVD/CVE_2014_2099_VULN_msrle_decode_frame.c int istride = FFALIGN ( avctx -> width * avctx -> bits_per_coded_sample , 32 ) / 8 ; 8
static int CVE_2014_2099_VULN_msrle_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
int istride = FFALIGN ( avctx -> width * avctx -> bits_per_coded_sample , 32 ) / 8 ; 8
if ( avctx -> height * istride == avpkt -> size )  29
uint8_t * buf = avpkt -> data + ( avctx -> height - 1 ) * istride ; 32
ptr [ j + 0 ] = buf [ j >> 1 ] >> 4; 38
ptr [ j + 1 ] = buf [ j >> 1 ] & 0xF; 39
ptr [ j + 0 ] = buf [ j >> 1 ] >> 4; 42
memcpy ( ptr , buf , linesize ); 44
buf -= istride; 46
ptr += s -> frame -> linesize [ 0 ]; 47
------------------------------
769 /home/speedy/test/source2slice/NVD/CVE_2014_2523_PATCHED_dccp_error.c unsigned int dccp_len = skb -> len - dataoff ; 7
static int CVE_2014_2523_PATCHED_dccp_error(struct net *net, struct nf_conn *tmpl,
struct sk_buff *skb, unsigned int dataoff,
enum ip_conntrack_info *ctinfo,
u_int8_t pf, unsigned int hooknum) 4
unsigned int dccp_len = skb -> len - dataoff ; 7
if ( dh -> dccph_doff * 4 < sizeof ( struct dccp_hdr ) || dh -> dccph_doff * 4 > dccp_len )  17
cscov = dccp_len; 23
if ( cscov > dccp_len )  26
if ( net -> ct . sysctl_checksum && hooknum == NF_INET_PRE_ROUTING && nf_checksum_partial ( skb , hooknum , dataoff , cscov , IPPROTO_DCCP , pf ) )  32
------------------------------
770 /home/speedy/test/source2slice/NVD/CVE_2014_2523_VULN_dccp_error.c unsigned int dccp_len = skb -> len - dataoff ; 7
static int CVE_2014_2523_VULN_dccp_error(struct net *net, struct nf_conn *tmpl,
struct sk_buff *skb, unsigned int dataoff,
enum ip_conntrack_info *ctinfo,
u_int8_t pf, unsigned int hooknum) 4
unsigned int dccp_len = skb -> len - dataoff ; 7
if ( dh -> dccph_doff * 4 < sizeof ( struct dccp_hdr ) || dh -> dccph_doff * 4 > dccp_len )  17
cscov = dccp_len; 23
if ( cscov > dccp_len )  26
if ( net -> ct . sysctl_checksum && hooknum == NF_INET_PRE_ROUTING && nf_checksum_partial ( skb , hooknum , dataoff , cscov , IPPROTO_DCCP , pf ) )  32
------------------------------
771 /home/speedy/test/source2slice/NVD/CVE_2014_4027_PATCHED_rd_build_device_space.c u32 max_sg_per_table = ( RD_MAX_ALLOCATION_SIZE / sizeof ( struct scatterlist ) ) ; 5
static int CVE_2014_4027_PATCHED_rd_build_device_space(struct rd_dev *rd_dev) 1
u32 max_sg_per_table = ( RD_MAX_ALLOCATION_SIZE / sizeof ( struct scatterlist ) ) ; 5
sg_tables = ( total_sg_needed / max_sg_per_table ) + 1; 21
sg_table = kzalloc ( sg_tables * sizeof ( struct rd_dev_sg_table ) , GFP_KERNEL ); 23
if ( ! sg_table )  24
rd_dev -> sg_table_array = sg_table; 30
rd_dev -> sg_table_count = sg_tables; 31
rc = rd_allocate_sgl_table ( rd_dev , sg_table , total_sg_needed , 0x00 ); 33
if ( rc )  34
return rc ; 35
pr_debug ( "CORE_RD[%u] - Built Ramdisk Device ID: %u space of"
" %u pages in %u tables\n" , rd_dev -> rd_host -> rd_host_id ,
rd_dev -> rd_dev_id , rd_dev -> rd_page_count ,
rd_dev -> sg_table_count ) 40
------------------------------
772 /home/speedy/test/source2slice/NVD/CVE_2014_4027_VULN_rd_build_device_space.c u32 max_sg_per_table = ( RD_MAX_ALLOCATION_SIZE / sizeof ( struct scatterlist ) ) ; 4
static int CVE_2014_4027_VULN_rd_build_device_space(struct rd_dev *rd_dev) 1
u32 max_sg_per_table = ( RD_MAX_ALLOCATION_SIZE / sizeof ( struct scatterlist ) ) ; 4
sg_tables = ( total_sg_needed / max_sg_per_table ) + 1; 22
sg_table = kzalloc ( sg_tables * sizeof ( struct rd_dev_sg_table ) , GFP_KERNEL ); 24
if ( ! sg_table )  25
rd_dev -> sg_table_array = sg_table; 31
rd_dev -> sg_table_count = sg_tables; 32
while ( total_sg_needed )  34
sg_per_table = ( total_sg_needed > max_sg_per_table ) ? max_sg_per_table : total_sg_needed; 35
sg = kzalloc ( sg_per_table * sizeof ( struct scatterlist ) , GFP_KERNEL ); 38
if ( ! sg )  40
sg_init_table ( sg , sg_per_table ); 46
sg_table [ i ] . sg_table = sg; 48
sg_table [ i ] . rd_sg_count = sg_per_table; 49
sg_table [ i ] . page_start_offset = page_offset; 50
sg_table [ i ++ ] . page_end_offset = ( page_offset + sg_per_table ) - 1; 51
for (j = 0; j < sg_per_table; j++) 54
sg_assign_page ( & sg [ j ] , pg ); 61
sg [ j ] . length = PAGE_SIZE; 62
page_offset += sg_per_table; 65
total_sg_needed -= sg_per_table; 66
pr_debug ( "CORE_RD[%u] - Built Ramdisk Device ID: %u space of"
" %u pages in %u tables\n" , rd_dev -> rd_host -> rd_host_id ,
rd_dev -> rd_dev_id , rd_dev -> rd_page_count ,
rd_dev -> sg_table_count ) 72
------------------------------
773 /home/speedy/test/source2slice/NVD/CVE_2014_4608_PATCHED_lzo1x_decompress_safe.c unsigned char * oe = op + t ; 156
int CVE_2014_4608_PATCHED_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t , 15 ) && HAVE_OP ( t , 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
ip = ie; 52
op = oe; 53
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t , 15 ) ) )  130
op += 8; 133
op += 8; 136
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 , 0 ) )  140
state = next; 141
op += next; 143
ip += next; 144
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 , 0 ) && HAVE_OP ( 4 , 0 ) ) )  170
op += t; 172
ip += t; 173
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
------------------------------
774 /home/speedy/test/source2slice/NVD/CVE_2014_4608_PATCHED_lzo1x_decompress_safe.c unsigned char * oe = op + t ; 129
int CVE_2014_4608_PATCHED_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t , 15 ) && HAVE_OP ( t , 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
COPY8 ( op , ip ); 45
op += 8; 46
ip += 8; 47
COPY8 ( op , ip ); 48
op += 8; 49
ip += 8; 50
while ( ip < ie )  51
ip = ie; 52
op = oe; 53
NEED_OP ( t , 0 ); 57
NEED_IP ( t , 3 ); 58
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
TEST_LB ( m_pos ); 70
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
TEST_LB ( m_pos ); 126
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t , 15 ) ) )  130
COPY8 ( op , m_pos ); 132
op += 8; 133
m_pos += 8; 134
COPY8 ( op , m_pos ); 135
op += 8; 136
m_pos += 8; 137
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 , 0 ) )  140
state = next; 141
COPY4 ( op , ip ); 142
op += next; 143
ip += next; 144
NEED_OP ( t , 0 ); 148
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
NEED_OP ( t , 0 ); 157
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 , 0 ) && HAVE_OP ( 4 , 0 ) ) )  170
COPY4 ( op , ip ); 171
op += t; 172
ip += t; 173
NEED_IP ( t , 3 ); 177
NEED_OP ( t , 0 ); 178
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
* out_len = op - out; 187
return ( t != 3 ? LZO_E_ERROR : ip == ip_end ? LZO_E_OK : ip < ip_end ? LZO_E_INPUT_NOT_CONSUMED : LZO_E_INPUT_OVERRUN ) ; 188
* out_len = op - out; 193
* out_len = op - out; 197
* out_len = op - out; 201
------------------------------
775 /home/speedy/test/source2slice/NVD/CVE_2014_4608_PATCHED_lzo1x_decompress_safe.c unsigned char * oe = op + t ; 43
int CVE_2014_4608_PATCHED_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t , 15 ) && HAVE_OP ( t , 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
COPY8 ( op , ip ); 45
op += 8; 46
ip += 8; 47
COPY8 ( op , ip ); 48
op += 8; 49
ip += 8; 50
while ( ip < ie )  51
ip = ie; 52
op = oe; 53
NEED_OP ( t , 0 ); 57
NEED_IP ( t , 3 ); 58
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
TEST_LB ( m_pos ); 70
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
TEST_LB ( m_pos ); 126
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t , 15 ) ) )  130
COPY8 ( op , m_pos ); 132
op += 8; 133
m_pos += 8; 134
COPY8 ( op , m_pos ); 135
op += 8; 136
m_pos += 8; 137
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 , 0 ) )  140
state = next; 141
COPY4 ( op , ip ); 142
op += next; 143
ip += next; 144
NEED_OP ( t , 0 ); 148
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
NEED_OP ( t , 0 ); 157
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 , 0 ) && HAVE_OP ( 4 , 0 ) ) )  170
COPY4 ( op , ip ); 171
op += t; 172
ip += t; 173
NEED_IP ( t , 3 ); 177
NEED_OP ( t , 0 ); 178
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
* out_len = op - out; 187
return ( t != 3 ? LZO_E_ERROR : ip == ip_end ? LZO_E_OK : ip < ip_end ? LZO_E_INPUT_NOT_CONSUMED : LZO_E_INPUT_OVERRUN ) ; 188
* out_len = op - out; 193
* out_len = op - out; 197
* out_len = op - out; 201
------------------------------
776 /home/speedy/test/source2slice/NVD/CVE_2014_4608_PATCHED_lzo1x_decompress_safe.c const unsigned char * ie = ip + t ; 42
int CVE_2014_4608_PATCHED_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t , 15 ) && HAVE_OP ( t , 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
COPY8 ( op , ip ); 45
op += 8; 46
ip += 8; 47
COPY8 ( op , ip ); 48
op += 8; 49
ip += 8; 50
while ( ip < ie )  51
ip = ie; 52
op = oe; 53
NEED_OP ( t , 0 ); 57
NEED_IP ( t , 3 ); 58
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
TEST_LB ( m_pos ); 70
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
TEST_LB ( m_pos ); 126
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t , 15 ) ) )  130
COPY8 ( op , m_pos ); 132
op += 8; 133
m_pos += 8; 134
COPY8 ( op , m_pos ); 135
op += 8; 136
m_pos += 8; 137
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 , 0 ) )  140
state = next; 141
COPY4 ( op , ip ); 142
op += next; 143
ip += next; 144
NEED_OP ( t , 0 ); 148
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
NEED_OP ( t , 0 ); 157
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 , 0 ) && HAVE_OP ( 4 , 0 ) ) )  170
COPY4 ( op , ip ); 171
op += t; 172
ip += t; 173
NEED_IP ( t , 3 ); 177
NEED_OP ( t , 0 ); 178
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
* out_len = op - out; 187
return ( t != 3 ? LZO_E_ERROR : ip == ip_end ? LZO_E_OK : ip < ip_end ? LZO_E_INPUT_NOT_CONSUMED : LZO_E_INPUT_OVERRUN ) ; 188
* out_len = op - out; 193
* out_len = op - out; 197
* out_len = op - out; 201
------------------------------
777 /home/speedy/test/source2slice/NVD/CVE_2014_4608_VULN_lzo1x_decompress_safe.c unsigned char * oe = op + t ; 156
int CVE_2014_4608_VULN_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t + 15 ) && HAVE_OP ( t + 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
ip = ie; 52
op = oe; 53
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t + 15 ) ) )  130
op += 8; 133
op += 8; 136
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 ) )  140
state = next; 141
op += next; 143
ip += next; 144
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 ) && HAVE_OP ( 4 ) ) )  170
op += t; 172
ip += t; 173
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
------------------------------
778 /home/speedy/test/source2slice/NVD/CVE_2014_4608_VULN_lzo1x_decompress_safe.c unsigned char * oe = op + t ; 129
int CVE_2014_4608_VULN_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t + 15 ) && HAVE_OP ( t + 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
COPY8 ( op , ip ); 45
op += 8; 46
ip += 8; 47
COPY8 ( op , ip ); 48
op += 8; 49
ip += 8; 50
while ( ip < ie )  51
ip = ie; 52
op = oe; 53
NEED_OP ( t ); 57
NEED_IP ( t + 3 ); 58
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
TEST_LB ( m_pos ); 70
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
TEST_LB ( m_pos ); 126
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t + 15 ) ) )  130
COPY8 ( op , m_pos ); 132
op += 8; 133
m_pos += 8; 134
COPY8 ( op , m_pos ); 135
op += 8; 136
m_pos += 8; 137
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 ) )  140
state = next; 141
COPY4 ( op , ip ); 142
op += next; 143
ip += next; 144
NEED_OP ( t ); 148
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
NEED_OP ( t ); 157
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 ) && HAVE_OP ( 4 ) ) )  170
COPY4 ( op , ip ); 171
op += t; 172
ip += t; 173
NEED_IP ( t + 3 ); 177
NEED_OP ( t ); 178
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
* out_len = op - out; 187
return ( t != 3 ? LZO_E_ERROR : ip == ip_end ? LZO_E_OK : ip < ip_end ? LZO_E_INPUT_NOT_CONSUMED : LZO_E_INPUT_OVERRUN ) ; 188
* out_len = op - out; 193
* out_len = op - out; 197
* out_len = op - out; 201
------------------------------
779 /home/speedy/test/source2slice/NVD/CVE_2014_4608_VULN_lzo1x_decompress_safe.c unsigned char * oe = op + t ; 43
int CVE_2014_4608_VULN_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t + 15 ) && HAVE_OP ( t + 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
COPY8 ( op , ip ); 45
op += 8; 46
ip += 8; 47
COPY8 ( op , ip ); 48
op += 8; 49
ip += 8; 50
while ( ip < ie )  51
ip = ie; 52
op = oe; 53
NEED_OP ( t ); 57
NEED_IP ( t + 3 ); 58
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
TEST_LB ( m_pos ); 70
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
TEST_LB ( m_pos ); 126
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t + 15 ) ) )  130
COPY8 ( op , m_pos ); 132
op += 8; 133
m_pos += 8; 134
COPY8 ( op , m_pos ); 135
op += 8; 136
m_pos += 8; 137
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 ) )  140
state = next; 141
COPY4 ( op , ip ); 142
op += next; 143
ip += next; 144
NEED_OP ( t ); 148
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
NEED_OP ( t ); 157
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 ) && HAVE_OP ( 4 ) ) )  170
COPY4 ( op , ip ); 171
op += t; 172
ip += t; 173
NEED_IP ( t + 3 ); 177
NEED_OP ( t ); 178
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
* out_len = op - out; 187
return ( t != 3 ? LZO_E_ERROR : ip == ip_end ? LZO_E_OK : ip < ip_end ? LZO_E_INPUT_NOT_CONSUMED : LZO_E_INPUT_OVERRUN ) ; 188
* out_len = op - out; 193
* out_len = op - out; 197
* out_len = op - out; 201
------------------------------
780 /home/speedy/test/source2slice/NVD/CVE_2014_4608_VULN_lzo1x_decompress_safe.c const unsigned char * ie = ip + t ; 42
int CVE_2014_4608_VULN_lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
unsigned char *out, size_t *out_len) 2
unsigned char * op ; 4
const unsigned char * ip ; 5
size_t t , next ; 6
size_t state = 0 ; 7
const unsigned char * m_pos ; 8
op = out; 12
ip = in; 13
if ( unlikely ( in_len < 3 ) )  15
if ( * ip > 17 )  17
t = * ip ++ - 17; 18
if ( t < 4 )  19
next = t; 20
t = * ip ++; 27
if ( t < 16 )  28
if ( likely ( state == 0 ) )  29
if ( unlikely ( t == 0 ) )  30
while ( unlikely ( * ip == 0 ) )  31
t += 255; 32
ip ++; 33
t += 15 + * ip ++; 36
t += 3; 38
if ( likely ( HAVE_IP ( t + 15 ) && HAVE_OP ( t + 15 ) ) )  41
const unsigned char * ie = ip + t ; 42
unsigned char * oe = op + t ; 43
COPY8 ( op , ip ); 45
op += 8; 46
ip += 8; 47
COPY8 ( op , ip ); 48
op += 8; 49
ip += 8; 50
while ( ip < ie )  51
ip = ie; 52
op = oe; 53
NEED_OP ( t ); 57
NEED_IP ( t + 3 ); 58
* op ++ = * ip ++; 60
while ( -- t > 0 )  61
state = 4; 63
if ( state != 4 )  65
next = t & 3; 66
m_pos = op - 1; 67
m_pos -= t >> 2; 68
m_pos -= * ip ++ << 2; 69
TEST_LB ( m_pos ); 70
op [ 0 ] = m_pos [ 0 ]; 72
op [ 1 ] = m_pos [ 1 ]; 73
op += 2; 74
next = t & 3; 77
m_pos = op - ( 1 + M2_MAX_OFFSET ); 78
m_pos -= t >> 2; 79
m_pos -= * ip ++ << 2; 80
t = 3; 81
if ( t >= 64 )  83
next = t & 3; 84
m_pos = op - 1; 85
m_pos -= ( t >> 2 ) & 7; 86
m_pos -= * ip ++ << 3; 87
t = ( t >> 5 ) - 1 + ( 3 - 1 ); 88
if ( t >= 32 )  89
t = ( t & 31 ) + ( 3 - 1 ); 90
if ( unlikely ( t == 2 ) )  91
while ( unlikely ( * ip == 0 ) )  92
t += 255; 93
ip ++; 94
t += 31 + * ip ++; 97
m_pos = op - 1; 100
next = get_unaligned_le16 ( ip ); 101
ip += 2; 102
m_pos -= next >> 2; 103
next &= 3; 104
m_pos = op; 106
m_pos -= ( t & 8 ) << 11; 107
t = ( t & 7 ) + ( 3 - 1 ); 108
if ( unlikely ( t == 2 ) )  109
while ( unlikely ( * ip == 0 ) )  110
t += 255; 111
ip ++; 112
t += 7 + * ip ++; 115
next = get_unaligned_le16 ( ip ); 118
ip += 2; 119
m_pos -= next >> 2; 120
next &= 3; 121
if ( m_pos == op )  122
m_pos -= 0x4000; 124
TEST_LB ( m_pos ); 126
if ( op - m_pos >= 8 )  128
unsigned char * oe = op + t ; 129
if ( likely ( HAVE_OP ( t + 15 ) ) )  130
COPY8 ( op , m_pos ); 132
op += 8; 133
m_pos += 8; 134
COPY8 ( op , m_pos ); 135
op += 8; 136
m_pos += 8; 137
while ( op < oe )  138
op = oe; 139
if ( HAVE_IP ( 6 ) )  140
state = next; 141
COPY4 ( op , ip ); 142
op += next; 143
ip += next; 144
NEED_OP ( t ); 148
* op ++ = * m_pos ++; 150
while ( op < oe )  151
unsigned char * oe = op + t ; 156
NEED_OP ( t ); 157
op [ 0 ] = m_pos [ 0 ]; 158
op [ 1 ] = m_pos [ 1 ]; 159
op += 2; 160
m_pos += 2; 161
* op ++ = * m_pos ++; 163
while ( op < oe )  164
state = next; 167
t = next; 168
if ( likely ( HAVE_IP ( 6 ) && HAVE_OP ( 4 ) ) )  170
COPY4 ( op , ip ); 171
op += t; 172
ip += t; 173
NEED_IP ( t + 3 ); 177
NEED_OP ( t ); 178
while ( t > 0 )  179
* op ++ = * ip ++; 180
t --; 181
* out_len = op - out; 187
return ( t != 3 ? LZO_E_ERROR : ip == ip_end ? LZO_E_OK : ip < ip_end ? LZO_E_INPUT_NOT_CONSUMED : LZO_E_INPUT_OVERRUN ) ; 188
* out_len = op - out; 193
* out_len = op - out; 197
* out_len = op - out; 201
------------------------------
781 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 168
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  34
if ( s -> ham )  43
memset ( s -> frame . data [ 0 ] , 0 , avctx -> height * s -> frame . linesize [ 0 ] ); 44
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  120
if ( avctx -> codec_tag == MKTAG ( 'P' , 'B' , 'M' , ' ' ) )  160
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  161
if ( s -> ham )  166
for (y = 0; y < avctx->height ; y++) 167
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 168
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 170
------------------------------
782 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 163
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  34
if ( s -> ham )  43
memset ( s -> frame . data [ 0 ] , 0 , avctx -> height * s -> frame . linesize [ 0 ] ); 44
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  120
if ( avctx -> codec_tag == MKTAG ( 'P' , 'B' , 'M' , ' ' ) )  160
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  161
for(y = 0; y < avctx->height ; y++ ) 162
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 163
buf += decode_byterun ( row , avctx -> width , buf , buf_end ); 164
------------------------------
783 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 152
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  34
if ( s -> ham )  43
memset ( s -> frame . data [ 0 ] , 0 , avctx -> height * s -> frame . linesize [ 0 ] ); 44
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  120
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  121
if ( avctx -> bits_per_coded_sample <= 8 )  130
if ( s -> ham )  140
for(y = 0; y < avctx->height ; y++ ) 151
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 152
memset ( row , 0 , avctx -> width << 2 ); 153
decodeplane32 ( ( uint32_t * ) row , s -> planebuf , s -> planesize , plane ); 156
------------------------------
784 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 142
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  34
if ( s -> ham )  43
memset ( s -> frame . data [ 0 ] , 0 , avctx -> height * s -> frame . linesize [ 0 ] ); 44
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  120
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  121
if ( avctx -> bits_per_coded_sample <= 8 )  130
if ( s -> ham )  140
for (y = 0; y < avctx->height ; y++) 141
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 142
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 148
------------------------------
785 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 132
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  34
if ( s -> ham )  43
memset ( s -> frame . data [ 0 ] , 0 , avctx -> height * s -> frame . linesize [ 0 ] ); 44
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  120
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  121
if ( avctx -> bits_per_coded_sample <= 8 )  130
for (y = 0; y < avctx->height ; y++ ) 131
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 132
lookup_pal_indicies ( ( uint32_t * ) row , s -> mask_buf , s -> mask_palbuf , avctx -> width ); 138
------------------------------
786 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 123
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  34
if ( s -> ham )  43
memset ( s -> frame . data [ 0 ] , 0 , avctx -> height * s -> frame . linesize [ 0 ] ); 44
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  120
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  121
for(y = 0; y < avctx->height ; y++ ) 122
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 123
memset ( row , 0 , avctx -> width ); 124
decodeplane8 ( row , s -> planebuf , s -> planesize , plane ); 127
------------------------------
787 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 110
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
const uint8_t * buf_end = buf + buf_size ; 8
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> codec_tag == MKTAG ( 'D' , 'E' , 'E' , 'P' ) )  58
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  71
if ( avctx -> codec_tag == MKTAG ( 'P' , 'B' , 'M' , ' ' ) )  101
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  102
if ( s -> ham )  108
for (y = 0; y < avctx->height && buf_end > buf; y++) 109
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 110
buf += avctx -> width + ( avctx -> width & 1 ); 112
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 113
------------------------------
788 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 104
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
const uint8_t * buf_end = buf + buf_size ; 8
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> codec_tag == MKTAG ( 'D' , 'E' , 'E' , 'P' ) )  58
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  71
if ( avctx -> codec_tag == MKTAG ( 'P' , 'B' , 'M' , ' ' ) )  101
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  102
for(y = 0; y < avctx->height && buf_end > buf; y++ ) 103
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 104
memcpy ( row , buf , FFMIN ( avctx -> width , buf_end - buf ) ); 105
buf += avctx -> width + ( avctx -> width % 2 ); 106
------------------------------
789 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 93
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> codec_tag == MKTAG ( 'D' , 'E' , 'E' , 'P' ) )  58
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  71
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  72
if ( s -> ham )  81
for(y = 0; y < avctx->height; y++ ) 92
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 93
memset ( row , 0 , avctx -> width << 2 ); 94
decodeplane32 ( ( uint32_t * ) row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 96
------------------------------
790 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 83
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> codec_tag == MKTAG ( 'D' , 'E' , 'E' , 'P' ) )  58
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  71
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  72
if ( s -> ham )  81
for (y = 0; y < avctx->height; y++) 82
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 83
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 89
------------------------------
791 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 74
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> codec_tag == MKTAG ( 'D' , 'E' , 'E' , 'P' ) )  58
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  71
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  72
for(y = 0; y < avctx->height; y++ ) 73
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 74
memset ( row , 0 , avctx -> width ); 75
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 77
------------------------------
792 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 63
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
const uint8_t * buf_end = buf + buf_size ; 8
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> codec_tag == MKTAG ( 'D' , 'E' , 'E' , 'P' ) )  58
const AVPixFmtDescriptor * desc = av_pix_fmt_desc_get ( avctx -> pix_fmt ) ; 59
int raw_width = avctx -> width * ( av_get_bits_per_pixel ( desc ) >> 3 ) ; 60
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 62
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 63
memcpy ( row , buf , FFMIN ( raw_width , buf_end - buf ) ); 64
buf += raw_width; 65
row [ 4 * x + 3 ] = row [ 4 * x + 3 ] & 0xF0 | ( row [ 4 * x + 3 ] >> 4 ); 68
------------------------------
793 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c const uint8_t * start = buf + ( plane * avctx -> height + y ) * s -> planesize ; 49
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
const uint8_t * buf_end = buf + buf_size ; 8
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  34
if ( s -> ham )  43
for(y = 0; y < avctx->height; y++) 45
memset ( s -> ham_buf , 0 , s -> planesize * 8 ); 47
for (plane = 0; plane < s->bpp; plane++) 48
const uint8_t * start = buf + ( plane * avctx -> height + y ) * s -> planesize ; 49
if ( start >= buf_end )  50
decodeplane8 ( s -> ham_buf , start , FFMIN ( s -> planesize , buf_end - start ) , plane ); 52
------------------------------
794 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 46
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  34
if ( s -> ham )  43
memset ( s -> frame . data [ 0 ] , 0 , avctx -> height * s -> frame . linesize [ 0 ] ); 44
for(y = 0; y < avctx->height; y++) 45
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 46
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 54
------------------------------
795 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 38
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
const uint8_t * buf_end = buf + buf_size ; 8
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  34
memset ( s -> frame . data [ 0 ] , 0 , avctx -> height * s -> frame . linesize [ 0 ] ); 35
for (plane = 0; plane < s->bpp; plane++) 36
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 37
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 38
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 39
buf += s -> planesize; 40
------------------------------
796 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c const uint8_t * buf_end = buf + buf_size ; 8
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
const uint8_t * buf_end = buf + buf_size ; 8
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 37
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 39
if ( start >= buf_end )  50
decodeplane8 ( s -> ham_buf , start , FFMIN ( s -> planesize , buf_end - start ) , plane ); 52
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 62
memcpy ( row , buf , FFMIN ( raw_width , buf_end - buf ) ); 64
row [ 4 * x + 3 ] = row [ 4 * x + 3 ] & 0xF0 | ( row [ 4 * x + 3 ] >> 4 ); 68
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 76
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 77
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 85
decodeplane8 ( s -> ham_buf , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 86
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 95
decodeplane32 ( ( uint32_t * ) row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 96
for(y = 0; y < avctx->height && buf_end > buf; y++ ) 103
memcpy ( row , buf , FFMIN ( avctx -> width , buf_end - buf ) ); 105
for (y = 0; y < avctx->height && buf_end > buf; y++) 109
memcpy ( s -> ham_buf , buf , FFMIN ( avctx -> width , buf_end - buf ) ); 111
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 113
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 126
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 135
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 145
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 155
buf += decode_byterun ( row , avctx -> width , buf , buf_end ); 164
buf += decode_byterun ( s -> ham_buf , avctx -> width , buf , buf_end ); 169
------------------------------
797 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
const uint8_t * buf_end = buf + buf_size ; 8
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 37
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 39
if ( start >= buf_end )  50
decodeplane8 ( s -> ham_buf , start , FFMIN ( s -> planesize , buf_end - start ) , plane ); 52
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 62
memcpy ( row , buf , FFMIN ( raw_width , buf_end - buf ) ); 64
row [ 4 * x + 3 ] = row [ 4 * x + 3 ] & 0xF0 | ( row [ 4 * x + 3 ] >> 4 ); 68
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 76
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 77
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 85
decodeplane8 ( s -> ham_buf , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 86
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 95
decodeplane32 ( ( uint32_t * ) row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 96
for(y = 0; y < avctx->height && buf_end > buf; y++ ) 103
memcpy ( row , buf , FFMIN ( avctx -> width , buf_end - buf ) ); 105
for (y = 0; y < avctx->height && buf_end > buf; y++) 109
memcpy ( s -> ham_buf , buf , FFMIN ( avctx -> width , buf_end - buf ) ); 111
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 113
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 126
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 135
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 145
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 155
buf += decode_byterun ( row , avctx -> width , buf , buf_end ); 164
buf += decode_byterun ( s -> ham_buf , avctx -> width , buf , buf_end ); 169
decode_deep_rle32 ( s -> frame . data [ 0 ] , buf , buf_size , avctx -> width , avctx -> height , s -> frame . linesize [ 0 ] ); 177
bytestream2_init ( & gb , buf , buf_size ); 183
decode_deep_tvdc32 ( s -> frame . data [ 0 ] , buf , buf_size , avctx -> width , avctx -> height , s -> frame . linesize [ 0 ] , s -> tvdc ); 195
return buf_size ; 207
------------------------------
798 /home/speedy/test/source2slice/NVD/CVE_2014_5272_PATCHED_decode_frame.c const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
static int CVE_2014_5272_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
const uint8_t * buf_end = buf + buf_size ; 8
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 37
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 39
buf += s -> planesize; 40
const uint8_t * start = buf + ( plane * avctx -> height + y ) * s -> planesize ; 49
if ( start >= buf_end )  50
decodeplane8 ( s -> ham_buf , start , FFMIN ( s -> planesize , buf_end - start ) , plane ); 52
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 62
memcpy ( row , buf , FFMIN ( raw_width , buf_end - buf ) ); 64
buf += raw_width; 65
row [ 4 * x + 3 ] = row [ 4 * x + 3 ] & 0xF0 | ( row [ 4 * x + 3 ] >> 4 ); 68
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 76
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 77
buf += s -> planesize; 78
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 85
decodeplane8 ( s -> ham_buf , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 86
buf += s -> planesize; 87
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 95
decodeplane32 ( ( uint32_t * ) row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 96
buf += s -> planesize; 97
for(y = 0; y < avctx->height && buf_end > buf; y++ ) 103
memcpy ( row , buf , FFMIN ( avctx -> width , buf_end - buf ) ); 105
buf += avctx -> width + ( avctx -> width % 2 ); 106
for (y = 0; y < avctx->height && buf_end > buf; y++) 109
memcpy ( s -> ham_buf , buf , FFMIN ( avctx -> width , buf_end - buf ) ); 111
buf += avctx -> width + ( avctx -> width & 1 ); 112
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 113
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 126
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 135
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 145
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 155
buf += decode_byterun ( row , avctx -> width , buf , buf_end ); 164
buf += decode_byterun ( s -> ham_buf , avctx -> width , buf , buf_end ); 169
decode_deep_rle32 ( s -> frame . data [ 0 ] , buf , buf_size , avctx -> width , avctx -> height , s -> frame . linesize [ 0 ] ); 177
bytestream2_init ( & gb , buf , buf_size ); 183
decode_deep_tvdc32 ( s -> frame . data [ 0 ] , buf , buf_size , avctx -> width , avctx -> height , s -> frame . linesize [ 0 ] , s -> tvdc ); 195
------------------------------
799 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 168
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  120
if ( avctx -> codec_tag == MKTAG ( 'P' , 'B' , 'M' , ' ' ) )  160
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  161
if ( s -> ham )  166
for (y = 0; y < avctx->height ; y++) 167
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 168
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 170
------------------------------
800 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 163
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  120
if ( avctx -> codec_tag == MKTAG ( 'P' , 'B' , 'M' , ' ' ) )  160
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  161
for(y = 0; y < avctx->height ; y++ ) 162
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 163
buf += decode_byterun ( row , avctx -> width , buf , buf_end ); 164
------------------------------
801 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 152
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  120
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  121
if ( avctx -> bits_per_coded_sample <= 8 )  130
if ( s -> ham )  140
for(y = 0; y < avctx->height ; y++ ) 151
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 152
memset ( row , 0 , avctx -> width << 2 ); 153
decodeplane32 ( ( uint32_t * ) row , s -> planebuf , s -> planesize , plane ); 156
------------------------------
802 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 142
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  120
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  121
if ( avctx -> bits_per_coded_sample <= 8 )  130
if ( s -> ham )  140
for (y = 0; y < avctx->height ; y++) 141
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 142
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 148
------------------------------
803 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 132
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  120
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  121
if ( avctx -> bits_per_coded_sample <= 8 )  130
for (y = 0; y < avctx->height ; y++ ) 131
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 132
lookup_pal_indicies ( ( uint32_t * ) row , s -> mask_buf , s -> mask_palbuf , avctx -> width ); 138
------------------------------
804 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 123
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  120
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  121
for(y = 0; y < avctx->height ; y++ ) 122
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 123
memset ( row , 0 , avctx -> width ); 124
decodeplane8 ( row , s -> planebuf , s -> planesize , plane ); 127
------------------------------
805 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 110
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
const uint8_t * buf_end = buf + buf_size ; 8
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> codec_tag == MKTAG ( 'D' , 'E' , 'E' , 'P' ) )  58
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  71
if ( avctx -> codec_tag == MKTAG ( 'P' , 'B' , 'M' , ' ' ) )  101
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  102
if ( s -> ham )  108
for (y = 0; y < avctx->height && buf_end > buf; y++) 109
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 110
buf += avctx -> width + ( avctx -> width & 1 ); 112
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 113
------------------------------
806 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 104
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
const uint8_t * buf_end = buf + buf_size ; 8
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> codec_tag == MKTAG ( 'D' , 'E' , 'E' , 'P' ) )  58
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  71
if ( avctx -> codec_tag == MKTAG ( 'P' , 'B' , 'M' , ' ' ) )  101
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  102
for(y = 0; y < avctx->height && buf_end > buf; y++ ) 103
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 104
memcpy ( row , buf , FFMIN ( avctx -> width , buf_end - buf ) ); 105
buf += avctx -> width + ( avctx -> width % 2 ); 106
------------------------------
807 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 93
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> codec_tag == MKTAG ( 'D' , 'E' , 'E' , 'P' ) )  58
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  71
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  72
if ( s -> ham )  81
for(y = 0; y < avctx->height; y++ ) 92
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 93
memset ( row , 0 , avctx -> width << 2 ); 94
decodeplane32 ( ( uint32_t * ) row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 96
------------------------------
808 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 83
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> codec_tag == MKTAG ( 'D' , 'E' , 'E' , 'P' ) )  58
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  71
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  72
if ( s -> ham )  81
for (y = 0; y < avctx->height; y++) 82
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 83
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 89
------------------------------
809 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 74
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> codec_tag == MKTAG ( 'D' , 'E' , 'E' , 'P' ) )  58
if ( avctx -> codec_tag == MKTAG ( 'I' , 'L' , 'B' , 'M' ) )  71
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  72
for(y = 0; y < avctx->height; y++ ) 73
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 74
memset ( row , 0 , avctx -> width ); 75
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 77
------------------------------
810 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 63
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
const uint8_t * buf_end = buf + buf_size ; 8
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> codec_tag == MKTAG ( 'D' , 'E' , 'E' , 'P' ) )  58
const AVPixFmtDescriptor * desc = av_pix_fmt_desc_get ( avctx -> pix_fmt ) ; 59
int raw_width = avctx -> width * ( av_get_bits_per_pixel ( desc ) >> 3 ) ; 60
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 62
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 63
memcpy ( row , buf , FFMIN ( raw_width , buf_end - buf ) ); 64
buf += raw_width; 65
row [ 4 * x + 3 ] = row [ 4 * x + 3 ] & 0xF0 | ( row [ 4 * x + 3 ] >> 4 ); 68
------------------------------
811 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c const uint8_t * start = buf + ( plane * avctx -> height + y ) * s -> planesize ; 49
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
const uint8_t * buf_end = buf + buf_size ; 8
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  34
if ( s -> ham )  43
for(y = 0; y < avctx->height; y++) 45
memset ( s -> ham_buf , 0 , s -> planesize * 8 ); 47
for (plane = 0; plane < s->bpp; plane++) 48
const uint8_t * start = buf + ( plane * avctx -> height + y ) * s -> planesize ; 49
if ( start >= buf_end )  50
decodeplane8 ( s -> ham_buf , start , FFMIN ( s -> planesize , buf_end - start ) , plane ); 52
------------------------------
812 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 46
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  34
if ( s -> ham )  43
memset ( s -> frame . data [ 0 ] , 0 , avctx -> height * s -> frame . linesize [ 0 ] ); 44
for(y = 0; y < avctx->height; y++) 45
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 46
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 54
------------------------------
813 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 38
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
IffContext * s = avctx -> priv_data ; 5
const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
const uint8_t * buf_end = buf + buf_size ; 8
int y , plane , res ; 9
if ( ( res = extract_header ( avctx , avpkt ) ) < 0 )  12
if ( s -> init )  14
if ( ( res = avctx -> reget_buffer ( avctx , & s -> frame ) ) < 0 )  15
if ( ( res = ff_get_buffer ( avctx , & s -> frame ) ) < 0 )  19
int ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags) 1
int ret = get_buffer_internal ( avctx , frame , flags ) ; 3
return ret ; 6
if ( avctx -> bits_per_coded_sample <= 8 && avctx -> pix_fmt == AV_PIX_FMT_PAL8 )  22
if ( ( res = cmap_read_palette ( avctx , ( uint32_t * ) s -> frame . data [ 1 ] ) ) < 0 )  23
if ( avctx -> pix_fmt == AV_PIX_FMT_RGB32 && avctx -> bits_per_coded_sample <= 8 )  25
if ( ( res = cmap_read_palette ( avctx , s -> mask_palbuf ) ) < 0 )  26
s -> init = 1; 29
switch ( s -> compression )  31
if ( avctx -> codec_tag == MKTAG ( 'A' , 'C' , 'B' , 'M' ) )  33
if ( avctx -> pix_fmt == AV_PIX_FMT_PAL8 || avctx -> pix_fmt == AV_PIX_FMT_GRAY8 )  34
memset ( s -> frame . data [ 0 ] , 0 , avctx -> height * s -> frame . linesize [ 0 ] ); 35
for (plane = 0; plane < s->bpp; plane++) 36
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 37
uint8_t * row = & s -> frame . data [ 0 ] [ y * s -> frame . linesize [ 0 ] ] ; 38
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 39
buf += s -> planesize; 40
------------------------------
814 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c const uint8_t * buf_end = buf + buf_size ; 8
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
const uint8_t * buf_end = buf + buf_size ; 8
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 37
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 39
if ( start >= buf_end )  50
decodeplane8 ( s -> ham_buf , start , FFMIN ( s -> planesize , buf_end - start ) , plane ); 52
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 62
memcpy ( row , buf , FFMIN ( raw_width , buf_end - buf ) ); 64
row [ 4 * x + 3 ] = row [ 4 * x + 3 ] & 0xF0 | ( row [ 4 * x + 3 ] >> 4 ); 68
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 76
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 77
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 85
decodeplane8 ( s -> ham_buf , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 86
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 95
decodeplane32 ( ( uint32_t * ) row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 96
for(y = 0; y < avctx->height && buf_end > buf; y++ ) 103
memcpy ( row , buf , FFMIN ( avctx -> width , buf_end - buf ) ); 105
for (y = 0; y < avctx->height && buf_end > buf; y++) 109
memcpy ( s -> ham_buf , buf , FFMIN ( avctx -> width , buf_end - buf ) ); 111
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 113
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 126
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 135
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 145
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 155
buf += decode_byterun ( row , avctx -> width , buf , buf_end ); 164
buf += decode_byterun ( s -> ham_buf , avctx -> width , buf , buf_end ); 169
------------------------------
815 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
const int buf_size = avpkt -> size >= 2 ? avpkt -> size - AV_RB16 ( avpkt -> data ) : 0 ; 7
const uint8_t * buf_end = buf + buf_size ; 8
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 37
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 39
if ( start >= buf_end )  50
decodeplane8 ( s -> ham_buf , start , FFMIN ( s -> planesize , buf_end - start ) , plane ); 52
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 62
memcpy ( row , buf , FFMIN ( raw_width , buf_end - buf ) ); 64
row [ 4 * x + 3 ] = row [ 4 * x + 3 ] & 0xF0 | ( row [ 4 * x + 3 ] >> 4 ); 68
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 76
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 77
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 85
decodeplane8 ( s -> ham_buf , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 86
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 95
decodeplane32 ( ( uint32_t * ) row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 96
for(y = 0; y < avctx->height && buf_end > buf; y++ ) 103
memcpy ( row , buf , FFMIN ( avctx -> width , buf_end - buf ) ); 105
for (y = 0; y < avctx->height && buf_end > buf; y++) 109
memcpy ( s -> ham_buf , buf , FFMIN ( avctx -> width , buf_end - buf ) ); 111
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 113
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 126
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 135
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 145
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 155
buf += decode_byterun ( row , avctx -> width , buf , buf_end ); 164
buf += decode_byterun ( s -> ham_buf , avctx -> width , buf , buf_end ); 169
decode_deep_rle32 ( s -> frame . data [ 0 ] , buf , buf_size , avctx -> width , avctx -> height , s -> frame . linesize [ 0 ] ); 177
bytestream2_init ( & gb , buf , buf_size ); 183
decode_deep_tvdc32 ( s -> frame . data [ 0 ] , buf , buf_size , avctx -> width , avctx -> height , s -> frame . linesize [ 0 ] , s -> tvdc ); 195
return buf_size ; 207
------------------------------
816 /home/speedy/test/source2slice/NVD/CVE_2014_5272_VULN_decode_frame.c const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
static int CVE_2014_5272_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *got_frame,
AVPacket *avpkt) 3
const uint8_t * buf = avpkt -> size >= 2 ? avpkt -> data + AV_RB16 ( avpkt -> data ) : NULL ; 6
const uint8_t * buf_end = buf + buf_size ; 8
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 37
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 39
buf += s -> planesize; 40
const uint8_t * start = buf + ( plane * avctx -> height + y ) * s -> planesize ; 49
if ( start >= buf_end )  50
decodeplane8 ( s -> ham_buf , start , FFMIN ( s -> planesize , buf_end - start ) , plane ); 52
for(y = 0; y < avctx->height && buf < buf_end; y++ ) 62
memcpy ( row , buf , FFMIN ( raw_width , buf_end - buf ) ); 64
buf += raw_width; 65
row [ 4 * x + 3 ] = row [ 4 * x + 3 ] & 0xF0 | ( row [ 4 * x + 3 ] >> 4 ); 68
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 76
decodeplane8 ( row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 77
buf += s -> planesize; 78
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 85
decodeplane8 ( s -> ham_buf , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 86
buf += s -> planesize; 87
for (plane = 0; plane < s->bpp && buf < buf_end; plane++) 95
decodeplane32 ( ( uint32_t * ) row , buf , FFMIN ( s -> planesize , buf_end - buf ) , plane ); 96
buf += s -> planesize; 97
for(y = 0; y < avctx->height && buf_end > buf; y++ ) 103
memcpy ( row , buf , FFMIN ( avctx -> width , buf_end - buf ) ); 105
buf += avctx -> width + ( avctx -> width % 2 ); 106
for (y = 0; y < avctx->height && buf_end > buf; y++) 109
memcpy ( s -> ham_buf , buf , FFMIN ( avctx -> width , buf_end - buf ) ); 111
buf += avctx -> width + ( avctx -> width & 1 ); 112
decode_ham_plane32 ( ( uint32_t * ) row , s -> ham_buf , s -> ham_palbuf , s -> planesize ); 113
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 126
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 135
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 145
buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); 155
buf += decode_byterun ( row , avctx -> width , buf , buf_end ); 164
buf += decode_byterun ( s -> ham_buf , avctx -> width , buf , buf_end ); 169
decode_deep_rle32 ( s -> frame . data [ 0 ] , buf , buf_size , avctx -> width , avctx -> height , s -> frame . linesize [ 0 ] ); 177
bytestream2_init ( & gb , buf , buf_size ); 183
decode_deep_tvdc32 ( s -> frame . data [ 0 ] , buf , buf_size , avctx -> width , avctx -> height , s -> frame . linesize [ 0 ] , s -> tvdc ); 195
------------------------------
817 /home/speedy/test/source2slice/NVD/CVE_2014_5471_PATCHED_isofs_read_inode.c int frag1 = bufsize - offset ; 27
static int CVE_2014_5471_PATCHED_isofs_read_inode(struct inode *inode, int relocated) 1
unsigned long bufsize = ISOFS_BUFFER_SIZE ( inode ) ; 5
unsigned long block ; 6
struct iso_directory_record * de ; 9
unsigned int de_len ; 11
unsigned long offset ; 12
struct iso_inode_info * ei = ISOFS_I ( inode ) ; 13
block = ei -> i_iget5_block; 16
bh = sb_bread ( inode -> i_sb , block ); 17
if ( ! bh )  18
offset = ei -> i_iget5_offset; 21
de = ( struct iso_directory_record * ) ( bh -> b_data + offset ); 23
de_len = * ( unsigned char * ) de; 24
if ( offset + de_len > bufsize )  26
int frag1 = bufsize - offset ; 27
memcpy ( tmpde , bh -> b_data + offset , frag1 ); 35
memcpy ( ( char * ) tmpde + frag1 , bh -> b_data , de_len - frag1 ); 40
de = tmpde; 41
if ( de -> flags [ - high_sierra ] & 2 )  51
ei -> i_section_size = isonum_733 ( de -> size ); 84
if ( de -> flags [ - high_sierra ] & 0x80 )  85
ei -> i_next_section_block = 0; 91
ei -> i_next_section_offset = 0; 92
inode -> i_size = isonum_733 ( de -> size ); 93
inode -> i_size &= 0x00ffffff; 103
if ( de -> interleave [ 0 ] )  105
inode -> i_size = 0; 107
if ( de -> file_unit_size [ 0 ] != 0 )  112
printk ( KERN_DEBUG "ISOFS: File unit size != 0 for ISO file (%ld).\n" ,
inode -> i_ino ) 114
if ( ( de -> flags [ - high_sierra ] & ~2 ) != 0 )  120
printk ( KERN_DEBUG "ISOFS: Unusual flag settings for ISO file "
"(%ld %x).\n" ,
inode -> i_ino , de -> flags [ - high_sierra ] ) 123
inode -> i_mtime . tv_sec = inode -> i_atime . tv_sec = inode -> i_ctime . tv_sec = iso_date ( de -> date , high_sierra ); 127
inode -> i_mtime . tv_nsec = inode -> i_atime . tv_nsec = inode -> i_ctime . tv_nsec = 0; 130
ei -> i_first_extent = ( isonum_733 ( de -> extent ) + isonum_711 ( de -> ext_attr_length ) ); 134
inode -> i_blocks = ( inode -> i_size + 511 ) >> 9; 138
parse_rock_ridge_inode ( de , inode , relocated ); 146
inode -> i_uid = sbi -> s_uid; 149
inode -> i_gid = sbi -> s_gid; 151
if ( S_ISDIR ( inode -> i_mode ) && sbi -> s_overriderockperm && sbi -> s_dmode != ISOFS_INVALID_MODE )  154
inode -> i_mode = S_IFDIR | sbi -> s_dmode; 156
if ( S_ISREG ( inode -> i_mode ) && sbi -> s_overriderockperm && sbi -> s_fmode != ISOFS_INVALID_MODE )  157
inode -> i_mode = S_IFREG | sbi -> s_fmode; 159
if ( S_ISREG ( inode -> i_mode ) )  162
inode -> i_fop = & generic_ro_fops; 163
switch ( ei -> i_file_format )  164
inode -> i_data . a_ops = & zisofs_aops; 167
inode -> i_data . a_ops = & isofs_aops; 171
if ( S_ISDIR ( inode -> i_mode ) )  174
if ( S_ISLNK ( inode -> i_mode ) )  177
init_special_inode ( inode , inode -> i_mode , inode -> i_rdev ); 182
kfree ( tmpde ); 186
------------------------------
818 /home/speedy/test/source2slice/NVD/CVE_2014_5471_VULN_isofs_read_inode.c int frag1 = bufsize - offset ; 27
static int CVE_2014_5471_VULN_isofs_read_inode(struct inode *inode) 1
unsigned long bufsize = ISOFS_BUFFER_SIZE ( inode ) ; 5
unsigned long block ; 6
struct iso_directory_record * de ; 9
unsigned int de_len ; 11
unsigned long offset ; 12
struct iso_inode_info * ei = ISOFS_I ( inode ) ; 13
block = ei -> i_iget5_block; 16
bh = sb_bread ( inode -> i_sb , block ); 17
if ( ! bh )  18
offset = ei -> i_iget5_offset; 21
de = ( struct iso_directory_record * ) ( bh -> b_data + offset ); 23
de_len = * ( unsigned char * ) de; 24
if ( offset + de_len > bufsize )  26
int frag1 = bufsize - offset ; 27
memcpy ( tmpde , bh -> b_data + offset , frag1 ); 35
memcpy ( ( char * ) tmpde + frag1 , bh -> b_data , de_len - frag1 ); 40
------------------------------
819 /home/speedy/test/source2slice/NVD/CVE_2014_5472_PATCHED_isofs_read_inode.c int frag1 = bufsize - offset ; 27
static int CVE_2014_5472_PATCHED_isofs_read_inode(struct inode *inode, int relocated) 1
unsigned long bufsize = ISOFS_BUFFER_SIZE ( inode ) ; 5
unsigned long block ; 6
struct iso_directory_record * de ; 9
unsigned int de_len ; 11
unsigned long offset ; 12
struct iso_inode_info * ei = ISOFS_I ( inode ) ; 13
block = ei -> i_iget5_block; 16
bh = sb_bread ( inode -> i_sb , block ); 17
if ( ! bh )  18
offset = ei -> i_iget5_offset; 21
de = ( struct iso_directory_record * ) ( bh -> b_data + offset ); 23
de_len = * ( unsigned char * ) de; 24
if ( offset + de_len > bufsize )  26
int frag1 = bufsize - offset ; 27
memcpy ( tmpde , bh -> b_data + offset , frag1 ); 35
memcpy ( ( char * ) tmpde + frag1 , bh -> b_data , de_len - frag1 ); 40
------------------------------
820 /home/speedy/test/source2slice/NVD/CVE_2014_5472_VULN_isofs_read_inode.c int frag1 = bufsize - offset ; 27
static int CVE_2014_5472_VULN_isofs_read_inode(struct inode *inode) 1
unsigned long bufsize = ISOFS_BUFFER_SIZE ( inode ) ; 5
unsigned long block ; 6
struct iso_directory_record * de ; 9
unsigned int de_len ; 11
unsigned long offset ; 12
struct iso_inode_info * ei = ISOFS_I ( inode ) ; 13
block = ei -> i_iget5_block; 16
bh = sb_bread ( inode -> i_sb , block ); 17
if ( ! bh )  18
offset = ei -> i_iget5_offset; 21
de = ( struct iso_directory_record * ) ( bh -> b_data + offset ); 23
de_len = * ( unsigned char * ) de; 24
if ( offset + de_len > bufsize )  26
int frag1 = bufsize - offset ; 27
memcpy ( tmpde , bh -> b_data + offset , frag1 ); 35
memcpy ( ( char * ) tmpde + frag1 , bh -> b_data , de_len - frag1 ); 40
de = tmpde; 41
if ( de -> flags [ - high_sierra ] & 2 )  51
ei -> i_section_size = isonum_733 ( de -> size ); 84
if ( de -> flags [ - high_sierra ] & 0x80 )  85
ei -> i_next_section_block = 0; 91
ei -> i_next_section_offset = 0; 92
inode -> i_size = isonum_733 ( de -> size ); 93
inode -> i_size &= 0x00ffffff; 103
if ( de -> interleave [ 0 ] )  105
inode -> i_size = 0; 107
if ( de -> file_unit_size [ 0 ] != 0 )  112
printk ( KERN_DEBUG "ISOFS: File unit size != 0 for ISO file (%ld).\n" ,
inode -> i_ino ) 114
if ( ( de -> flags [ - high_sierra ] & ~2 ) != 0 )  120
printk ( KERN_DEBUG "ISOFS: Unusual flag settings for ISO file "
"(%ld %x).\n" ,
inode -> i_ino , de -> flags [ - high_sierra ] ) 123
inode -> i_mtime . tv_sec = inode -> i_atime . tv_sec = inode -> i_ctime . tv_sec = iso_date ( de -> date , high_sierra ); 127
inode -> i_mtime . tv_nsec = inode -> i_atime . tv_nsec = inode -> i_ctime . tv_nsec = 0; 130
ei -> i_first_extent = ( isonum_733 ( de -> extent ) + isonum_711 ( de -> ext_attr_length ) ); 134
inode -> i_blocks = ( inode -> i_size + 511 ) >> 9; 138
parse_rock_ridge_inode ( de , inode ); 146
inode -> i_uid = sbi -> s_uid; 149
inode -> i_gid = sbi -> s_gid; 151
if ( S_ISDIR ( inode -> i_mode ) && sbi -> s_overriderockperm && sbi -> s_dmode != ISOFS_INVALID_MODE )  154
inode -> i_mode = S_IFDIR | sbi -> s_dmode; 156
if ( S_ISREG ( inode -> i_mode ) && sbi -> s_overriderockperm && sbi -> s_fmode != ISOFS_INVALID_MODE )  157
inode -> i_mode = S_IFREG | sbi -> s_fmode; 159
if ( S_ISREG ( inode -> i_mode ) )  162
inode -> i_fop = & generic_ro_fops; 163
switch ( ei -> i_file_format )  164
inode -> i_data . a_ops = & zisofs_aops; 167
inode -> i_data . a_ops = & isofs_aops; 171
if ( S_ISDIR ( inode -> i_mode ) )  174
if ( S_ISLNK ( inode -> i_mode ) )  177
init_special_inode ( inode , inode -> i_mode , inode -> i_rdev ); 182
kfree ( tmpde ); 186
------------------------------
821 /home/speedy/test/source2slice/NVD/CVE_2015_0833_PATCHED_NS_main.c size_t len = NS_tstrlen ( gInstallDirPath + commonPrefixLength ) ; 636
int CVE_2015_0833_PATCHED_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
gInstallDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 48
bool noServiceFallback = getenv ( "MOZ_NO_SERVICE_FALLBACK" ) != nullptr ; 57
useService = IsUpdateStatusPendingService ( ); 63
testOnlyFallbackKeyExists = DoesFallbackKeyExist ( ); 67
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
gWorkingDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 117
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( ! _waccess ( updateLockFilePath , F_OK ) && NS_tremove ( updateLockFilePath ) != 0 )  277
updateLockFileHandle = CreateFileW ( updateLockFilePath , GENERIC_READ | GENERIC_WRITE , 0 , nullptr , OPEN_ALWAYS , FILE_FLAG_DELETE_ON_CLOSE , nullptr ); 290
if ( updateLockFileHandle == INVALID_HANDLE_VALUE || ( useService && testOnlyFallbackKeyExists && noServiceFallback ) )  318
GonkAutoMounter mounter ; 544
if ( mounter . GetAccess ( ) != MountAccess :: ReadWrite )  545
if ( ! sReplaceRequest )  556
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  558
int rv = NS_tmkdir ( gWorkingDirPath , 0755 ) ; 560
if ( rv == OK && errno != EEXIST )  561
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  563
if ( ! sReplaceRequest )  577
NS_tchar * destpath = ( NS_tchar * ) malloc ( ( NS_tstrlen ( gWorkingDirPath ) + 2 ) * sizeof ( NS_tchar ) ) ; 580
if ( ! destpath )  581
NS_tchar applyDirLongPath [ MAXPATHLEN ] ; 598
if ( ! GetLongPathNameW ( gWorkingDirPath , applyDirLongPath , sizeof ( applyDirLongPath ) / sizeof ( applyDirLongPath [ 0 ] ) ) )  599
if ( argc > callbackIndex )  613
if ( sReplaceRequest )  624
size_t commonPrefixLength = PathCommonPrefixW ( argv [ callbackIndex ] , gInstallDirPath , nullptr ) ; 627
size_t len = NS_tstrlen ( gInstallDirPath + commonPrefixLength ) ; 636
p += len; 637
bufferLeft -= len; 638
* p = NS_T ( '\\' ); 639
bufferLeft --; 641
* p = NS_T ( '\0' ); 642
NS_tstrncpy ( p , argv [ callbackIndex ] + std :: max ( callbackPrefixLength , commonPrefixLength ) , bufferLeft ); 648
------------------------------
822 /home/speedy/test/source2slice/NVD/CVE_2015_0833_VULN_NS_main.c size_t len = NS_tstrlen ( gInstallDirPath + commonPrefixLength ) ; 636
int CVE_2015_0833_VULN_NS_main(int argc, NS_tchar **argv) 1
if ( argc < 4 )  36
gInstallDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 48
bool noServiceFallback = getenv ( "MOZ_NO_SERVICE_FALLBACK" ) != nullptr ; 57
useService = IsUpdateStatusPendingService ( ); 63
testOnlyFallbackKeyExists = DoesFallbackKeyExist ( ); 67
__int64 pid = 0 ; 91
if ( argc > 4 )  95
pid = _wtoi64 ( argv [ 4 ] ); 97
if ( pid == - 1 )  101
sStagedUpdate = true; 104
if ( NS_tstrstr ( argv [ 4 ] , NS_T ( "/replace" ) ) )  105
sReplaceRequest = true; 108
gWorkingDirPath [ MAXPATHLEN - 1 ] = NS_T ( '\0' ); 117
if ( ! WriteStatusFile ( "applying" ) )  149
if ( pid > 0 )  194
HANDLE parent = OpenProcess ( SYNCHRONIZE , false , ( DWORD ) pid ) ; 195
if ( parent )  199
updateFromMetro = IsUpdateFromMetro ( argc , argv ); 202
DWORD waitTime = updateFromMetro ? IMMERSIVE_PARENT_WAIT : PARENT_WAIT ; 204
DWORD result = WaitForSingleObject ( parent , waitTime ) ; 206
if ( result != WAIT_OBJECT_0 && ! updateFromMetro )  208
const int callbackIndex = 6 ; 231
sUsingService = getenv ( "MOZ_USING_SERVICE" ) != nullptr; 234
if ( ! sUsingService && ( argc > callbackIndex || sStagedUpdate || sReplaceRequest ) )  247
NS_tchar updateLockFilePath [ MAXPATHLEN ] ; 249
if ( ! _waccess ( updateLockFilePath , F_OK ) && NS_tremove ( updateLockFilePath ) != 0 )  277
updateLockFileHandle = CreateFileW ( updateLockFilePath , GENERIC_READ | GENERIC_WRITE , 0 , nullptr , OPEN_ALWAYS , FILE_FLAG_DELETE_ON_CLOSE , nullptr ); 290
if ( updateLockFileHandle == INVALID_HANDLE_VALUE || ( useService && testOnlyFallbackKeyExists && noServiceFallback ) )  318
GonkAutoMounter mounter ; 544
if ( mounter . GetAccess ( ) != MountAccess :: ReadWrite )  545
if ( ! sReplaceRequest )  556
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  558
int rv = NS_tmkdir ( gWorkingDirPath , 0755 ) ; 560
if ( rv == OK && errno != EEXIST )  561
if ( NS_tchdir ( gWorkingDirPath ) != 0 )  563
if ( ! sReplaceRequest )  577
NS_tchar * destpath = ( NS_tchar * ) malloc ( ( NS_tstrlen ( gWorkingDirPath ) + 2 ) * sizeof ( NS_tchar ) ) ; 580
if ( ! destpath )  581
NS_tchar applyDirLongPath [ MAXPATHLEN ] ; 598
if ( ! GetLongPathNameW ( gWorkingDirPath , applyDirLongPath , sizeof ( applyDirLongPath ) / sizeof ( applyDirLongPath [ 0 ] ) ) )  599
if ( argc > callbackIndex )  613
if ( sReplaceRequest )  624
size_t commonPrefixLength = PathCommonPrefixW ( argv [ callbackIndex ] , gInstallDirPath , nullptr ) ; 627
size_t len = NS_tstrlen ( gInstallDirPath + commonPrefixLength ) ; 636
p += len; 637
bufferLeft -= len; 638
* p = NS_T ( '\\' ); 639
bufferLeft --; 641
* p = NS_T ( '\0' ); 642
NS_tstrncpy ( p , argv [ callbackIndex ] + std :: max ( callbackPrefixLength , commonPrefixLength ) , bufferLeft ); 648
------------------------------
823 /home/speedy/test/source2slice/NVD/CVE_2015_3395_VULN_msrle_decode_pal4.c int frame_size = row_dec * avctx -> height ; 10
static int CVE_2015_3395_VULN_msrle_decode_pal4(AVCodecContext *avctx, AVPicture *pic,
GetByteContext *gb) 2
int row_dec = pic -> linesize [ 0 ] ; 8
int frame_size = row_dec * avctx -> height ; 10
if ( row_ptr + pixel_ptr + stream_byte > frame_size || bytestream2_get_bytes_left ( gb ) < rle_code )  42
if ( row_ptr + pixel_ptr + stream_byte > frame_size )  69
------------------------------
824 /home/speedy/test/source2slice/NVD/CVE_2015_3808_PATCHED_dissect_lbmr_pser.c guint8 option_len = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_LEN ) ; 52
static int CVE_2015_3808_PATCHED_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
curr_offset += hdr_len; 26
if ( ( flags & LBMR_PSER_OPT_FLAG ) != 0 )  28
opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ); 36
curr_offset += L_LBMR_PSER_OPTLEN_T; 45
opt_len -= L_LBMR_PSER_OPTLEN_T; 46
while ( opt_len > 0 )  47
guint8 opt_type = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_TYPE ) ; 51
guint8 option_len = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_LEN ) ; 52
switch ( opt_type )  54
ctxinst_item = proto_tree_add_item ( opts_tree , hf_lbmr_pser_opt_ctxinst , tvb , curr_offset , L_LBMR_PSER_OPT_CTXINST_T , ENC_NA ); 58
ctxinst_tree = proto_item_add_subtree ( ctxinst_item , ett_lbmr_pser_opt_ctxinst ); 59
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_len , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_LEN , L_LBMR_PSER_OPT_CTXINST_T_LEN , ENC_BIG_ENDIAN ); 60
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_type , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_TYPE , L_LBMR_PSER_OPT_CTXINST_T_TYPE , ENC_BIG_ENDIAN ); 61
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_ctxinst , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_CTXINST , L_LBMR_PSER_OPT_CTXINST_T_CTXINST , ENC_NA ); 62
len += L_LBMR_PSER_OPT_CTXINST_T; 63
curr_offset += L_LBMR_PSER_OPT_CTXINST_T; 64
opt_len -= L_LBMR_PSER_OPT_CTXINST_T; 65
len += option_len; 68
curr_offset += option_len; 69
opt_len -= option_len; 70
expert_add_info_format ( pinfo , NULL , & ei_lbmr_analysis_invalid_value , "Unknown LBMR PSER option 0x%02x" , opt_type ); 71
if ( option_len == 0 )  72
return ( len ) ; 73
return ( len ) ; 79
------------------------------
825 /home/speedy/test/source2slice/NVD/CVE_2015_3808_PATCHED_dissect_lbmr_pser.c guint8 opt_type = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_TYPE ) ; 51
static int CVE_2015_3808_PATCHED_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
curr_offset += hdr_len; 26
if ( ( flags & LBMR_PSER_OPT_FLAG ) != 0 )  28
opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ); 36
curr_offset += L_LBMR_PSER_OPTLEN_T; 45
opt_len -= L_LBMR_PSER_OPTLEN_T; 46
while ( opt_len > 0 )  47
guint8 opt_type = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_TYPE ) ; 51
guint8 option_len = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_LEN ) ; 52
switch ( opt_type )  54
curr_offset += L_LBMR_PSER_OPT_CTXINST_T; 64
opt_len -= L_LBMR_PSER_OPT_CTXINST_T; 65
curr_offset += option_len; 69
opt_len -= option_len; 70
expert_add_info_format ( pinfo , NULL , & ei_lbmr_analysis_invalid_value , "Unknown LBMR PSER option 0x%02x" , opt_type ); 71
if ( option_len == 0 )  72
------------------------------
826 /home/speedy/test/source2slice/NVD/CVE_2015_3808_VULN_dissect_lbmr_pser.c guint8 opt_type = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_TYPE ) ; 51
static int CVE_2015_3808_VULN_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
curr_offset += hdr_len; 26
if ( ( flags & LBMR_PSER_OPT_FLAG ) != 0 )  28
opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ); 36
curr_offset += L_LBMR_PSER_OPTLEN_T; 45
opt_len -= L_LBMR_PSER_OPTLEN_T; 46
while ( opt_len > 0 )  47
guint8 opt_type = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_TYPE ) ; 51
guint8 option_len = tvb_get_guint8 ( tvb , O_LBMR_PSER_OPT_HDR_T_LEN ) ; 52
switch ( opt_type )  54
curr_offset += L_LBMR_PSER_OPT_CTXINST_T; 64
opt_len -= L_LBMR_PSER_OPT_CTXINST_T; 65
curr_offset += option_len; 69
opt_len -= option_len; 70
expert_add_info_format ( pinfo , NULL , & ei_lbmr_analysis_invalid_value , "Unknown LBMR PSER option 0x%02x" , opt_type ); 71
------------------------------
827 /home/speedy/test/source2slice/NVD/CVE_2015_3809_PATCHED_dissect_lbmr_pser.c guint8 option_len = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_LEN ) ; 52
static int CVE_2015_3809_PATCHED_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
curr_offset += hdr_len; 26
if ( ( flags & LBMR_PSER_OPT_FLAG ) != 0 )  28
opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ); 36
curr_offset += L_LBMR_PSER_OPTLEN_T; 45
opt_len -= L_LBMR_PSER_OPTLEN_T; 46
while ( opt_len > 0 )  47
guint8 opt_type = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_TYPE ) ; 51
guint8 option_len = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_LEN ) ; 52
switch ( opt_type )  54
ctxinst_item = proto_tree_add_item ( opts_tree , hf_lbmr_pser_opt_ctxinst , tvb , curr_offset , L_LBMR_PSER_OPT_CTXINST_T , ENC_NA ); 58
ctxinst_tree = proto_item_add_subtree ( ctxinst_item , ett_lbmr_pser_opt_ctxinst ); 59
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_len , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_LEN , L_LBMR_PSER_OPT_CTXINST_T_LEN , ENC_BIG_ENDIAN ); 60
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_type , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_TYPE , L_LBMR_PSER_OPT_CTXINST_T_TYPE , ENC_BIG_ENDIAN ); 61
proto_tree_add_item ( ctxinst_tree , hf_lbmr_pser_opt_ctxinst_ctxinst , tvb , curr_offset + O_LBMR_PSER_OPT_CTXINST_T_CTXINST , L_LBMR_PSER_OPT_CTXINST_T_CTXINST , ENC_NA ); 62
len += L_LBMR_PSER_OPT_CTXINST_T; 63
curr_offset += L_LBMR_PSER_OPT_CTXINST_T; 64
opt_len -= L_LBMR_PSER_OPT_CTXINST_T; 65
len += option_len; 68
curr_offset += option_len; 69
opt_len -= option_len; 70
expert_add_info_format ( pinfo , NULL , & ei_lbmr_analysis_invalid_value , "Unknown LBMR PSER option 0x%02x" , opt_type ); 71
if ( option_len == 0 )  72
return ( len ) ; 73
return ( len ) ; 79
------------------------------
828 /home/speedy/test/source2slice/NVD/CVE_2015_3809_PATCHED_dissect_lbmr_pser.c guint8 opt_type = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_TYPE ) ; 51
static int CVE_2015_3809_PATCHED_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
curr_offset += hdr_len; 26
if ( ( flags & LBMR_PSER_OPT_FLAG ) != 0 )  28
opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ); 36
curr_offset += L_LBMR_PSER_OPTLEN_T; 45
opt_len -= L_LBMR_PSER_OPTLEN_T; 46
while ( opt_len > 0 )  47
guint8 opt_type = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_TYPE ) ; 51
guint8 option_len = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_LEN ) ; 52
switch ( opt_type )  54
curr_offset += L_LBMR_PSER_OPT_CTXINST_T; 64
opt_len -= L_LBMR_PSER_OPT_CTXINST_T; 65
curr_offset += option_len; 69
opt_len -= option_len; 70
expert_add_info_format ( pinfo , NULL , & ei_lbmr_analysis_invalid_value , "Unknown LBMR PSER option 0x%02x" , opt_type ); 71
if ( option_len == 0 )  72
------------------------------
829 /home/speedy/test/source2slice/NVD/CVE_2015_3809_VULN_dissect_lbmr_pser.c guint8 opt_type = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_TYPE ) ; 51
static int CVE_2015_3809_VULN_dissect_lbmr_pser(tvbuff_t * tvb, int offset, packet_info * pinfo, proto_tree * tree) 1
int curr_offset = offset ; 8
hdr_len = ( int ) tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_LEN ); 11
flags = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_T_FLAGS ); 12
curr_offset += hdr_len; 26
if ( ( flags & LBMR_PSER_OPT_FLAG ) != 0 )  28
opt_len = tvb_get_ntohs ( tvb , curr_offset + O_LBMR_PSER_OPTLEN_T_OPTLEN ); 36
curr_offset += L_LBMR_PSER_OPTLEN_T; 45
opt_len -= L_LBMR_PSER_OPTLEN_T; 46
while ( opt_len > 0 )  47
guint8 opt_type = tvb_get_guint8 ( tvb , curr_offset + O_LBMR_PSER_OPT_HDR_T_TYPE ) ; 51
guint8 option_len = tvb_get_guint8 ( tvb , O_LBMR_PSER_OPT_HDR_T_LEN ) ; 52
switch ( opt_type )  54
curr_offset += L_LBMR_PSER_OPT_CTXINST_T; 64
opt_len -= L_LBMR_PSER_OPT_CTXINST_T; 65
curr_offset += option_len; 69
opt_len -= option_len; 70
expert_add_info_format ( pinfo , NULL , & ei_lbmr_analysis_invalid_value , "Unknown LBMR PSER option 0x%02x" , opt_type ); 71
------------------------------
830 /home/speedy/test/source2slice/NVD/CVE_2015_3813_PATCHED_fragment_add_work.c guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 288
static gboolean
CVE_2015_3813_PATCHED_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fragment_item * fd_i ; 7
guint32 max , dfpos , fraglen ; 8
guint8 * data ; 10
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
for(fd_i=fd_head->next; fd_i; fd_i=fd_i->next) 43
if ( ! fd_i -> tvb_data )  44
fd_i -> tvb_data = tvb_new_subset_remaining ( fd_head -> tvb_data , fd_i -> offset ); 45
fd_i -> flags |= FD_SUBSET_TVB; 46
fd_i -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 48
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  166
max = 0; 184
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 185
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  186
max = fd_i -> offset + fd_i -> len; 188
if ( max < ( fd_head -> datalen ) )  192
data = ( guint8 * ) g_malloc ( fd_head -> datalen ); 206
fd_head -> tvb_data = tvb_new_real_data ( data , fd_head -> datalen , fd_head -> datalen ); 207
for (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) 211
if ( fd_i -> len )  212
if ( fd_i -> offset + fd_i -> len > dfpos )  230
if ( fd_i -> offset >= fd_head -> datalen )  231
fd_i -> flags |= FD_TOOLONGFRAGMENT; 248
fd_head -> flags |= FD_TOOLONGFRAGMENT; 249
if ( dfpos < fd_i -> offset )  250
fd_head -> error = "dfpos < offset"; 261
if ( dfpos - fd_i -> offset > fd_i -> len )  262
fd_head -> error = "dfpos - offset > len"; 263
if ( ! fd_head -> tvb_data )  264
fd_head -> error = "no data"; 265
fraglen = fd_i -> len; 267
if ( fd_i -> offset + fraglen > fd_head -> datalen )  268
fd_i -> flags |= FD_TOOLONGFRAGMENT; 283
fd_head -> flags |= FD_TOOLONGFRAGMENT; 284
fraglen = fd_head -> datalen - fd_i -> offset; 285
if ( fd_i -> offset < dfpos )  287
guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 288
fd_i -> flags |= FD_OVERLAP; 290
fd_head -> flags |= FD_OVERLAP; 291
if ( memcmp ( data + fd_i -> offset , tvb_get_ptr ( fd_i -> tvb_data , 0 , cmp_len ) , cmp_len ) )  292
fd_i -> flags |= FD_OVERLAPCONFLICT; 296
fd_head -> flags |= FD_OVERLAPCONFLICT; 297
if ( fraglen < dfpos - fd_i -> offset )  300
fd_head -> error = "fraglen < dfpos - offset"; 304
dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ); 309
if ( fd_i -> offset + fd_i -> len < fd_i -> offset )  313
fd_head -> error = "offset + len < offset"; 315
if ( fd_i -> flags & FD_SUBSET_TVB )  319
fd_i -> flags &= ~FD_SUBSET_TVB; 320
fd_i -> tvb_data = NULL; 324
------------------------------
831 /home/speedy/test/source2slice/NVD/CVE_2015_3813_PATCHED_fragment_add_work.c guint32 end_offset = fd -> offset + fd -> len ; 134
static gboolean
CVE_2015_3813_PATCHED_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd -> flags |= FD_MULTIPLETAILS; 114
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
guint32 end_offset = fd -> offset + fd -> len ; 134
if ( end_offset > fd_head -> datalen || end_offset < fd -> offset || end_offset < fd -> len )  138
------------------------------
832 /home/speedy/test/source2slice/NVD/CVE_2015_3813_VULN_fragment_add_work.c guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 286
static gboolean
CVE_2015_3813_VULN_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fragment_item * fd_i ; 7
guint32 max , dfpos , fraglen ; 8
guint8 * data ; 10
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
for(fd_i=fd_head->next; fd_i; fd_i=fd_i->next) 43
if ( ! fd_i -> tvb_data )  44
fd_i -> tvb_data = tvb_new_subset_remaining ( fd_head -> tvb_data , fd_i -> offset ); 45
fd_i -> flags |= FD_SUBSET_TVB; 46
fd_i -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 48
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
if ( ! ( fd_head -> flags & FD_DATALEN_SET ) )  164
max = 0; 182
for (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) 183
if ( ( ( fd_i -> offset ) <= max ) && ( ( fd_i -> offset + fd_i -> len ) > max ) )  184
max = fd_i -> offset + fd_i -> len; 186
if ( max < ( fd_head -> datalen ) )  190
data = ( guint8 * ) g_malloc ( fd_head -> datalen ); 204
fd_head -> tvb_data = tvb_new_real_data ( data , fd_head -> datalen , fd_head -> datalen ); 205
for (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) 209
if ( fd_i -> len )  210
if ( fd_i -> offset + fd_i -> len > dfpos )  228
if ( fd_i -> offset >= fd_head -> datalen )  229
fd_i -> flags |= FD_TOOLONGFRAGMENT; 246
fd_head -> flags |= FD_TOOLONGFRAGMENT; 247
if ( dfpos < fd_i -> offset )  248
fd_head -> error = "dfpos < offset"; 259
if ( dfpos - fd_i -> offset > fd_i -> len )  260
fd_head -> error = "dfpos - offset > len"; 261
if ( ! fd_head -> tvb_data )  262
fd_head -> error = "no data"; 263
fraglen = fd_i -> len; 265
if ( fd_i -> offset + fraglen > fd_head -> datalen )  266
fd_i -> flags |= FD_TOOLONGFRAGMENT; 281
fd_head -> flags |= FD_TOOLONGFRAGMENT; 282
fraglen = fd_head -> datalen - fd_i -> offset; 283
if ( fd_i -> offset < dfpos )  285
guint32 cmp_len = MIN ( fd_i -> len , ( dfpos - fd_i -> offset ) ) ; 286
fd_i -> flags |= FD_OVERLAP; 288
fd_head -> flags |= FD_OVERLAP; 289
if ( memcmp ( data + fd_i -> offset , tvb_get_ptr ( fd_i -> tvb_data , 0 , cmp_len ) , cmp_len ) )  290
fd_i -> flags |= FD_OVERLAPCONFLICT; 294
fd_head -> flags |= FD_OVERLAPCONFLICT; 295
if ( fraglen < dfpos - fd_i -> offset )  298
fd_head -> error = "fraglen < dfpos - offset"; 302
dfpos = MAX ( dfpos , ( fd_i -> offset + fraglen ) ); 307
if ( fd_i -> offset + fd_i -> len < fd_i -> offset )  311
fd_head -> error = "offset + len < offset"; 313
if ( fd_i -> flags & FD_SUBSET_TVB )  317
fd_i -> flags &= ~FD_SUBSET_TVB; 318
fd_i -> tvb_data = NULL; 322
------------------------------
833 /home/speedy/test/source2slice/NVD/CVE_2015_3813_VULN_fragment_add_work.c guint32 end_offset = fd -> offset + fd -> len ; 134
static gboolean
CVE_2015_3813_VULN_fragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,
const packet_info *pinfo, const guint32 frag_offset,
const guint32 frag_data_len, const gboolean more_frags) 4
fragment_item * fd ; 6
fd = g_slice_new ( fragment_item ); 13
fd -> next = NULL; 14
fd -> flags = 0; 15
fd -> frame = pinfo -> fd -> num; 16
fd -> offset = frag_offset; 17
fd -> fragment_nr_offset = 0; 18
fd -> len = frag_data_len; 19
fd -> tvb_data = NULL; 20
fd -> error = NULL; 21
if ( fd_head -> flags & FD_DEFRAGMENTED )  26
if ( frag_offset + frag_data_len >= fd_head -> datalen )  34
if ( fd_head -> flags & FD_PARTIAL_REASSEMBLY )  38
fd_head -> flags &= ~ ( FD_DEFRAGMENTED | FD_PARTIAL_REASSEMBLY | FD_DATALEN_SET ); 50
fd_head -> flags &= ( ~FD_TOOLONGFRAGMENT ) & ( ~FD_MULTIPLETAILS ); 51
fd_head -> datalen = 0; 52
fd_head -> reassembled_in = 0; 53
if ( fd -> frame > fd_head -> frame )  99
fd_head -> frame = fd -> frame; 100
if ( ! more_frags )  102
if ( fd_head -> flags & FD_DATALEN_SET )  106
if ( fd_head -> datalen != ( fd -> offset + fd -> len ) )  110
fd -> flags |= FD_MULTIPLETAILS; 114
fd_head -> flags |= FD_MULTIPLETAILS; 115
fd_head -> datalen = fd -> offset + fd -> len; 121
fd_head -> flags |= FD_DATALEN_SET; 122
if ( fd_head -> flags & FD_DEFRAGMENTED )  133
guint32 end_offset = fd -> offset + fd -> len ; 134
if ( end_offset > fd_head -> datalen || end_offset < fd -> offset || end_offset < fd -> len )  138
------------------------------
834 /home/speedy/test/source2slice/NVD/CVE_2015_4003_PATCHED_oz_usb_handle_ep_data.c int data_len = len - sizeof ( struct oz_isoc_fixed ) + 1 ; 25
void CVE_2015_4003_PATCHED_oz_usb_handle_ep_data(struct oz_usb_ctx *usb_ctx,
struct oz_usb_hdr *usb_hdr, int len) 2
struct oz_data * data_hdr = ( struct oz_data * ) usb_hdr ; 4
switch ( data_hdr -> format )  5
int data_len = len - sizeof ( struct oz_isoc_fixed ) + 1 ; 25
count = data_len / unit_size; 32
for (i = 0; i < count; i++) 33
------------------------------
835 /home/speedy/test/source2slice/NVD/CVE_2015_4003_VULN_oz_usb_handle_ep_data.c int data_len = len - sizeof ( struct oz_isoc_fixed ) + 1 ; 22
void CVE_2015_4003_VULN_oz_usb_handle_ep_data(struct oz_usb_ctx *usb_ctx,
struct oz_usb_hdr *usb_hdr, int len) 2
struct oz_data * data_hdr = ( struct oz_data * ) usb_hdr ; 4
switch ( data_hdr -> format )  5
int data_len = len - sizeof ( struct oz_isoc_fixed ) + 1 ; 22
count = data_len / unit_size; 29
for (i = 0; i < count; i++) 30
------------------------------
836 /home/speedy/test/source2slice/NVD/CVE_2015_4003_VULN_oz_usb_handle_ep_data.c int n = ( len - sizeof ( struct oz_multiple_fixed ) + 1 ) / body -> unit_size ; 10
void CVE_2015_4003_VULN_oz_usb_handle_ep_data(struct oz_usb_ctx *usb_ctx,
struct oz_usb_hdr *usb_hdr, int len) 2
struct oz_data * data_hdr = ( struct oz_data * ) usb_hdr ; 4
switch ( data_hdr -> format )  5
struct oz_multiple_fixed * body = ( struct oz_multiple_fixed * ) data_hdr ; 7
int n = ( len - sizeof ( struct oz_multiple_fixed ) + 1 ) / body -> unit_size ; 10
while ( n -- )  12
------------------------------
